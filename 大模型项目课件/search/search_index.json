{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html","text":"LLM\u80cc\u666f\u77e5\u8bc6\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3LLM\u80cc\u666f\u7684\u77e5\u8bc6. \u638c\u63e1\u4ec0\u4e48\u662f\u8bed\u8a00\u6a21\u578b \u5927\u8bed\u8a00\u6a21\u578b (LLM) \u80cc\u666f \u00b6 \u5927\u8bed\u8a00\u6a21\u578b (\u82f1\u6587\uff1aLarge Language Model\uff0c\u7f29\u5199LLM) \u662f\u4e00\u79cd\u4eba\u5de5\u667a\u80fd\u6a21\u578b, \u65e8\u5728\u7406\u89e3\u548c\u751f\u6210\u4eba\u7c7b\u8bed\u8a00. \u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5904\u7406\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\uff0c\u5982\u6587\u672c\u5206\u7c7b\u3001\u95ee\u7b54\u3001\u7ffb\u8bd1\u3001\u5bf9\u8bdd\u7b49\u7b49. \u901a\u5e38, \u5927\u8bed\u8a00\u6a21\u578b (LLM) \u662f\u6307\u5305\u542b\u6570\u5343\u4ebf (\u6216\u66f4\u591a) \u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b(\u76ee\u524d\u5b9a\u4e49\u53c2\u6570\u91cf\u8d85\u8fc710B\u7684\u6a21\u578b\u4e3a\u5927\u8bed\u8a00\u6a21\u578b)\uff0c\u8fd9\u4e9b\u53c2\u6570\u662f\u5728\u5927\u91cf\u6587\u672c\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\uff0c\u4f8b\u5982\u6a21\u578b GPT-3\u3001ChatGPT\u3001PaLM\u3001BLOOM\u548c LLaMA\u7b49. \u622a\u6b6223\u5e743\u6708\u5e95\uff0c\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u8d70\u8fc7\u4e86\u4e09\u4e2a\u9636\u6bb5\uff1a \u7b2c\u4e00\u9636\u6bb5 \uff1a\u8bbe\u8ba1\u4e00\u7cfb\u5217\u7684\u81ea\u76d1\u7763\u8bad\u7ec3\u76ee\u6807\uff08MLM\u3001NSP\u7b49\uff09\uff0c\u8bbe\u8ba1\u65b0\u9896\u7684\u6a21\u578b\u67b6\u6784\uff08Transformer\uff09\uff0c\u9075\u5faaPre-training\u548cFine-tuning\u8303\u5f0f\u3002\u5178\u578b\u4ee3\u8868\u662fBERT\u3001GPT\u3001XLNet\u7b49\uff1b \u7b2c\u4e8c\u9636\u6bb5 \uff1a\u9010\u6b65\u6269\u5927\u6a21\u578b\u53c2\u6570\u548c\u8bad\u7ec3\u8bed\u6599\u89c4\u6a21\uff0c\u63a2\u7d22\u4e0d\u540c\u7c7b\u578b\u7684\u67b6\u6784\u3002\u5178\u578b\u4ee3\u8868\u662fBART\u3001T5\u3001GPT-3\u7b49\uff1b \u7b2c\u4e09\u9636\u6bb5 \uff1a\u8d70\u5411AIGC\uff08Artificial Intelligent Generated Content\uff09\u65f6\u4ee3\uff0c\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u6b65\u5165\u5343\u4e07\u4ebf\uff0c\u6a21\u578b\u67b6\u6784\u4e3a\u81ea\u56de\u5f52\u67b6\u6784\uff0c\u5927\u6a21\u578b\u8d70\u5411\u5bf9\u8bdd\u5f0f\u3001\u751f\u6210\u5f0f\u3001\u591a\u6a21\u6001\u65f6\u4ee3\uff0c\u66f4\u52a0\u6ce8\u91cd\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u8fdb\u884c\u5bf9\u9f50\uff0c\u5b9e\u73b0\u53ef\u9760\u3001\u5b89\u5168\u3001\u65e0\u6bd2\u7684\u6a21\u578b\u3002\u5178\u578b\u4ee3\u8868\u662fInstructionGPT\u3001ChatGPT\u3001Bard\u3001GPT-4\u7b49\u3002 \u8bed\u8a00\u6a21\u578b (Language Model, LM) \u00b6 \u8bed\u8a00\u6a21\u578b\uff08Language Model\uff09\u65e8\u5728\u5efa\u6a21\u8bcd\u6c47\u5e8f\u5217\u7684\u751f\u6210\u6982\u7387\uff0c\u63d0\u5347\u673a\u5668\u7684\u8bed\u8a00\u667a\u80fd\u6c34\u5e73\uff0c\u4f7f\u673a\u5668\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u8bf4\u8bdd\u3001\u5199\u4f5c\u7684\u6a21\u5f0f\u8fdb\u884c\u81ea\u52a8\u6587\u672c\u8f93\u51fa\u3002 \u901a\u4fd7\u7406\u89e3: \u7528\u6765\u8ba1\u7b97\u4e00\u4e2a\u53e5\u5b50\u7684\u6982\u7387\u7684\u6a21\u578b\uff0c\u4e5f\u5c31\u662f\u5224\u65ad\u4e00\u53e5\u8bdd\u662f\u5426\u662f\u4eba\u8bdd\u7684\u6982\u7387. \u6807\u51c6\u5b9a\u4e49\uff1a\u5bf9\u4e8e\u67d0\u4e2a\u53e5\u5b50\u5e8f\u5217, \u5982S = {W1, W2, W3, \u2026, Wn}, \u8bed\u8a00\u6a21\u578b\u5c31\u662f\u8ba1\u7b97\u8be5\u5e8f\u5217\u53d1\u751f\u7684\u6982\u7387, \u5373P(S). \u5982\u679c\u7ed9\u5b9a\u7684\u8bcd\u5e8f\u5217\u7b26\u5408\u8bed\u7528\u4e60\u60ef, \u5219\u7ed9\u51fa\u9ad8\u6982\u7387, \u5426\u5219\u7ed9\u51fa\u4f4e\u6982\u7387. \u4e3e\u4f8b\u8bf4\u660e\uff1a \u5047\u8bbe\u6211\u4eec\u8981\u4e3a\u4e2d\u6587\u521b\u5efa\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c V V <span class=\"arithmatex\"><span class=\"MathJax_Preview\">V</span><script type=\"math/tex\">V \u8868\u793a\u8bcd\u5178\uff0c V V ={\u9ed1\u9a6c\u3001\u7a0b\u5e8f\u3001\u5458\u3001\u6765\u3001\u5b66\u4e60}\u200b\uff0c W_i W_i \u5c5e\u4e8e V V \u3002\u8bed\u8a00\u6a21\u578b\u63cf\u8ff0\uff1a\u7ed9\u5b9a\u8bcd\u5178 V V , \u80fd\u591f\u8ba1\u7b97\u51fa\u4efb\u610f\u5355\u8bcd\u5e8f\u5217 S={W_1,W_2,W_3,\u2026,W_n} S={W_1,W_2,W_3,\u2026,W_n} \u662f\u4e00\u53e5\u8bdd\u7684\u6982\u7387 P(S) P(S) , \u5176\u4e2d P >= 0\u200b P >= 0\u200b \u90a3\u4e48\u5982\u4f55\u8ba1\u7b97\u4e00\u4e2a\u53e5\u5b50\u7684 P(S) P(S) \u5462\uff1f\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u8ba1\u6570\uff0c\u5047\u8bbe\u6570\u636e\u96c6\u4e2d\u5171\u6709 N N \u4e2a\u53e5\u5b50\uff0c\u6211\u4eec\u53ef\u4ee5\u7edf\u8ba1\u4e00\u4e0b\u6570\u636e\u96c6\u4e2d S={W_1,W_2,W_3,\u2026,W_n} S={W_1,W_2,W_3,\u2026,W_n} \u6bcf\u4e2a\u53e5\u5b50\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u5982\u679c\u5047\u8bbe\u4e3a n n \uff0c\u5219 P(S)=\\frac{n}{N} P(S)=\\frac{n}{N} . \u90a3\u4e48\u53ef\u4ee5\u60f3\u8c61\u4e00\u4e0b\uff0c\u8fd9\u4e2a\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u51e0\u4e4e\u4e3a0\uff0c\u4e00\u65e6\u5355\u8bcd\u5e8f\u5217\u6ca1\u5728\u4e4b\u524d\u6570\u636e\u96c6\u4e2d\u51fa\u73b0\u8fc7\uff0c\u6a21\u578b\u7684\u8f93\u51fa\u6982\u7387\u5c31\u662f0\uff0c\u663e\u7136\u76f8\u5f53\u4e0d\u5408\u7406\u3002 \u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6982\u7387\u8bba\u4e2d\u7684\u94fe\u5f0f\u6cd5\u5219\uff0c\u5c06 P P \u53ef\u4ee5\u8868\u793a\u4e3a\uff1a P(S) = P(W_1, W_2, ....,W_n) = P(W_1)*P(W_2|W_1)*....*P(W_n|W_1, W_2, ....,W_{n-1}) P(S) = P(W_1, W_2, ....,W_n) = P(W_1)*P(W_2|W_1)*....*P(W_n|W_1, W_2, ....,W_{n-1}) \u5982\u679c\u80fd\u8ba1\u7b97 P(W_n|W_1,W_2,\u2026W_{n-1}) P(W_n|W_1,W_2,\u2026W_{n-1}) \uff0c\u90a3\u4e48\u5c31\u80fd\u8f7b\u677e\u5f97\u5230 P(W_1,W_2,\u2026,W_n) P(W_1,W_2,\u2026,W_n) , \u6240\u4ee5\u5728\u67d0\u4e9b\u6587\u732e\u4e2d\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u770b\u5230\u8bed\u8a00\u6a21\u578b\u7684\u53e6\u5916\u4e00\u4e2a\u5b9a\u4e49\uff1a\u80fd\u591f\u8ba1\u7b97\u51fa P(W_1,W_2,\u2026,W_n) P(W_1,W_2,\u2026,W_n) \u7684\u6a21\u578b\u5c31\u662f\u8bed\u8a00\u6a21\u578b\u3002 \u4ece\u6587\u672c\u751f\u6210\u89d2\u5ea6\uff0c\u4e5f\u53ef\u4ee5\u8fd9\u6837\u5b9a\u4e49\u8bed\u8a00\u6a21\u578b\uff1a\u7ed9\u5b9a\u4e00\u4e2a\u77ed\u8bed\uff08\u4e00\u4e2a\u8bcd\u7ec4\u6216\u8005\u4e00\u53e5\u8bdd\uff09\uff0c\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u751f\u6210\uff08\u9884\u6d4b\uff09\u63a5\u4e0b\u6765\u7684\u4e00\u4e2a\u8bcd\u3002 \u8bed\u8a00\u6a21\u578b\u6280\u672f\u7684\u53d1\u5c55\u53ef\u4ee5\u603b\u7ed3\u4e3a\u56db\u4e2a\u9636\u6bb5\uff1a \u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u8bed\u8a00\u6a21\u578b \u795e\u7ecf\u8bed\u8a00\u6a21\u578b \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b \u5927\u8bed\u8a00\u6a21\u578b \u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u8bed\u8a00\u6a21\u578b\uff08N-gram\uff09 \u00b6 \u7531\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\u5e76\u4f7f\u7528\u7edf\u8ba1\u65b9\u6cd5\u5bf9\u56fa\u5b9a\u957f\u5ea6\u7684\u6587\u672c\u7a97\u53e3\u5e8f\u5217\u8fdb\u884c\u5efa\u6a21\u5206\u6790\uff0c\u8fd9\u79cd\u5efa\u6a21\u65b9\u5f0f\u4e5f\u88ab\u79f0\u4e3aN-gram\u8bed\u8a00\u6a21\u578b\u3002\u5728\u4e0a\u8ff0\u4f8b\u5b50\u4e2d\u8ba1\u7b97\u53e5\u5b50\u5e8f\u5217\u6982\u7387\u6211\u4eec\u4f7f\u7528\u94fe\u5f0f\u6cd5\u5219\u8ba1\u7b97\uff0c \u8be5\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u7f3a\u9677\uff1a \u53c2\u6570\u7a7a\u95f4\u8fc7\u5927\uff1a\u6761\u4ef6\u6982\u7387 P(W_n|W_1, W_2,\u2026.W_n) P(W_n|W_1, W_2,\u2026.W_n) \u7684\u53ef\u80fd\u6027\u592a\u591a\uff0c\u65e0\u6cd5\u4f30\u7b97\uff0c\u4e5f\u4e0d\u4e00\u5b9a\u6709\u7528 \u6570\u636e\u7a00\u758f\u4e25\u91cd\uff1a\u8bb8\u591a\u8bcd\u5bf9\u7684\u7ec4\u5408\uff0c\u5728\u8bed\u6599\u5e93\u4e2d\u90fd\u6ca1\u6709\u51fa\u73b0\uff0c\u4f9d\u636e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5f97\u5230\u7684\u6982\u7387\u4e3a0 \u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u5f15\u5165\u9a6c\u5c14\u79d1\u592b\u5047\u8bbe\uff1a\u968f\u610f\u4e00\u4e2a\u8bcd\u51fa\u73b0\u7684\u6982\u7387\u53ea\u4e0e\u5b83\u524d\u9762\u51fa\u73b0\u7684\u6709\u9650\u7684\u4e00\u4e2a\u6216\u8005\u51e0\u4e2a\u8bcd\u6709\u5173\u3002 \u5982\u679c\u4e00\u4e2a\u8bcd\u7684\u51fa\u73b0\u4e0e\u5b83\u5468\u56f4\u7684\u8bcd\u662f\u72ec\u7acb\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u79f0\u4e4b\u4e3aunigram\u4e5f\u5c31\u662f\u4e00\u5143\u8bed\u8a00\u6a21\u578b. P(S) = P(W_1)*P(W_2)*....*P(W_n) P(S) = P(W_1)*P(W_2)*....*P(W_n) \u5982\u679c\u4e00\u4e2a\u8bcd\u7684\u51fa\u73b0\u4ec5\u4f9d\u8d56\u4e8e\u5b83\u524d\u9762\u51fa\u73b0\u7684\u4e00\u4e2a\u8bcd\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u79f0\u4e4b\u4e3abigram. P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2)*...*P(W_n|W_{n-1}) P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2)*...*P(W_n|W_{n-1}) \u5982\u679c\u4e00\u4e2a\u8bcd\u7684\u51fa\u73b0\u4ec5\u4f9d\u8d56\u4e8e\u5b83\u524d\u9762\u51fa\u73b0\u7684\u4e24\u4e2a\u8bcd\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u79f0\u4e4b\u4e3atrigram. P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2,W_1)*...*P(W_n|W_{n-1},W_{n-2}) P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2,W_1)*...*P(W_n|W_{n-1},W_{n-2}) \u4e00\u822c\u6765\u8bf4\uff0cN\u5143\u6a21\u578b\u5c31\u662f\u5047\u8bbe\u5f53\u524d\u8bcd\u7684\u51fa\u73b0\u6982\u7387\u53ea\u4e0e\u5b83\u524d\u9762\u7684N-1\u4e2a\u8bcd\u6709\u5173\uff0c\u800c\u8fd9\u4e9b\u6982\u7387\u53c2\u6570\u90fd\u662f\u53ef\u4ee5\u901a\u8fc7\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u6765\u8ba1\u7b97\uff0c\u6bd4\u5982\u4e09\u5143\u6982\u7387\uff1a $$ P(W_i|W_{i-1},W_{i-2}) = Count(W_{i-2}W_{i-1}W_i)/Count(W_{i-2}W_{i-1}) $$ \u5728\u5b9e\u8df5\u4e2d\u7528\u7684\u6700\u591a\u7684\u5c31\u662fbigram\u548ctrigram\uff0c\u63a5\u4e0b\u6765\u4ee5bigram\u8bed\u8a00\u6a21\u578b\u4e3a\u4f8b\uff0c\u7406\u89e3\u5176\u5de5\u4f5c\u539f\u7406\uff1a \u9996\u5148\u6211\u4eec\u51c6\u5907\u4e00\u4e2a\u8bed\u6599\u5e93\uff08\u7b80\u5355\u7406\u89e3\u8ba9\u6a21\u578b\u5b66\u4e60\u7684\u6570\u636e\u96c6\uff09\uff0c\u4e3a\u4e86\u8ba1\u7b97\u5bf9\u5e94\u7684\u4e8c\u5143\u6a21\u578b\u7684\u53c2\u6570\uff0c\u5373 P(W_i|W_{i-1}) P(W_i|W_{i-1}) \uff0c\u6211\u4eec\u8981\u5148\u8ba1\u6570\u5373 C(W_{i-1},W_i) C(W_{i-1},W_i) \uff0c\u7136\u540e\u8ba1\u6570 C(W_{i-1}) C(W_{i-1}) , \u518d\u7528\u9664\u6cd5\u53ef\u5f97\u5230\u6982\u7387\u3002 C(W_{i-1}, W_i)\u200b C(W_{i-1}, W_i)\u200b \u8ba1\u6570\u7ed3\u679c\u5982\u4e0b\uff1a C(W_{i-1})\u200b C(W_{i-1})\u200b \u7684\u8ba1\u6570\u7ed3\u679c\u5982\u4e0b\uff1a \u90a3\u4e48bigram\u8bed\u8a00\u6a21\u578b\u9488\u5bf9\u4e0a\u8ff0\u8bed\u6599\u7684\u53c2\u6570\u8ba1\u7b97\u7ed3\u679c\u5982\u4f55\u5b9e\u73b0\uff1f\u5047\u5982\uff0c\u6211\u60f3\u8ba1\u7b97 P(\u60f3\uff5c\u6211)\\approx0.38\u200b P(\u60f3\uff5c\u6211)\\approx0.38\u200b ,\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\u663e\u793a\uff1a\uff08\u5176\u4ed6\u53c2\u6570\u8ba1\u7b97\u8fc7\u7a0b\u7c7b\u4f3c\uff09 $$ P(\u60f3\uff5c\u6211) = \\frac{C(\u6211,\u60f3)}{C(\u6211)} = \\frac{800}{2100}\\approx0.38 $$ \u5982\u679c\u9488\u5bf9\u8fd9\u4e2a\u8bed\u6599\u5e93\u7684\u4e8c\u5143\u6a21\u578b\uff08bigram\uff09\u5efa\u7acb\u597d\u4e4b\u540e\uff0c\u5c31\u53ef\u4ee5\u5b9e\u73b0\u6211\u4eec\u7684\u76ee\u6807\u8ba1\u7b97\u3002 \u8ba1\u7b97\u4e00\u4e2a\u53e5\u5b50\u7684\u6982\u7387\uff0c\u4e3e\u4f8b\u5982\u4e0b\uff1a P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = P(\u60f3\uff5c\u6211)*P(\u53bb\uff5c\u60f3)*P(\u6253\uff5c\u53bb)*P(\u7bee\u7403\uff5c\u6253)=\\frac{800}{2100}*\\frac{600}{900}*\\frac{690}{2000}*\\frac{20}{800} \\approx0.0022 P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = P(\u60f3\uff5c\u6211)*P(\u53bb\uff5c\u60f3)*P(\u6253\uff5c\u53bb)*P(\u7bee\u7403\uff5c\u6253)=\\frac{800}{2100}*\\frac{600}{900}*\\frac{690}{2000}*\\frac{20}{800} \\approx0.0022 \u9884\u6d4b\u4e00\u53e5\u8bdd\u6700\u53ef\u80fd\u51fa\u73b0\u7684\u4e0b\u4e00\u4e2a\u8bcd\u6c47\uff0c\u6bd4\u5982\uff1a\u6211\u60f3\u53bb\u6253\u3010mask\u3011? \u601d\u8003\uff1amask = \u7bee\u7403 \u6216\u8005 mask = \u665a\u996d P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = \\approx0.0022 P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = \\approx0.0022 P(\u6211\u60f3\u53bb\u6253\u665a\u996d) =\\approx0.00022 P(\u6211\u60f3\u53bb\u6253\u665a\u996d) =\\approx0.00022 \u53ef\u4ee5\u770b\u51fa P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) > P(\u6211\u60f3\u53bb\u6253\u665a\u996d) P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) > P(\u6211\u60f3\u53bb\u6253\u665a\u996d) \uff0c\u56e0\u6b64mask = \u7bee\u7403\uff0c\u5bf9\u6bd4\u771f\u5b9e\u8bed\u5883\u4e0b\uff0c\u4e5f\u7b26\u5408\u4eba\u7c7b\u4e60\u60ef\u3002 N-gram\u8bed\u8a00\u6a21\u578b\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u91c7\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1, \u53c2\u6570\u6613\u8bad\u7ec3; \u5b8c\u5168\u5305\u542b\u4e86\u524dn-1\u4e2a\u8bcd\u7684\u5168\u90e8\u4fe1\u606f; \u53ef\u89e3\u91ca\u6027\u5f3a, \u76f4\u89c2\u6613\u7406\u89e3\u3002 \u7f3a\u70b9\uff1a\u7f3a\u4e4f\u957f\u671f\u4ee5\u6765\uff0c\u53ea\u80fd\u5efa\u6a21\u5230\u524dn-1\u4e2a\u8bcd; \u968f\u7740n\u7684\u589e\u5927\uff0c\u53c2\u6570\u7a7a\u95f4\u5448\u6307\u6570\u589e\u957f3.\u6570\u636e\u7a00\u758f\uff0c\u96be\u514d\u4f1a\u51fa\u73b0OOV\u95ee\u9898; \u5355\u7eaf\u7684\u57fa\u4e8e\u7edf\u8ba1\u9891\u6b21\uff0c\u6cdb\u5316\u80fd\u529b\u5dee. \u795e\u7ecf\u7f51\u7edc\u8bed\u8a00\u6a21\u578b \u00b6 \u57fa\u4e8eN-gram\u8bed\u8a00\u6a21\u578b\u4ee5\u4e0a\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u968f\u7740\u795e\u7ecf\u7f51\u7edc\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4eba\u4eec\u5f00\u59cb\u5c1d\u8bd5\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u6765\u5efa\u7acb\u8bed\u8a00\u6a21\u578b\u3002 \u6a21\u578b\u7684\u8f93\u5165\uff1a w_{t-n+1}, \u2026, w_{t-2}, w_{t-1} w_{t-n+1}, \u2026, w_{t-2}, w_{t-1} \u5c31\u662f\u524dn-1\u4e2a\u8bcd\u3002\u73b0\u5728\u9700\u8981\u6839\u636e\u8fd9\u5df2\u77e5\u7684n-1\u4e2a\u8bcd\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd w_t w_t \u3002 C(w) C(w) \u8868\u793a w w \u6240\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf. \u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\uff08\u8f93\u5165\u5c42\uff09\u662f\u5c06 C(w_{t-n+1}),\u2026,C(w_{t-2}), C(w_{t-1})\u200b C(w_{t-n+1}),\u2026,C(w_{t-2}), C(w_{t-1})\u200b \u8fd9n-1\u4e2a\u5411\u91cf\u9996\u5c3e\u62fc\u63a5\u8d77\u6765\u5f62\u6210\u4e00\u4e2a (n-1)*m\u200b (n-1)*m\u200b \u5927\u5c0f\u7684\u5411\u91cf\uff0c\u8bb0\u4f5c x\u200b x\u200b . \u7f51\u7edc\u7684\u7b2c\u4e8c\u5c42\uff08\u9690\u85cf\u5c42\uff09\u5c31\u5982\u540c\u666e\u901a\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u76f4\u63a5\u4f7f\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42, \u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u540e\u518d\u4f7f\u7528 tanh\u200b tanh\u200b \u8fd9\u4e2a\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884c\u5904\u7406\u3002 \u7f51\u7edc\u7684\u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\u4e00\u5171\u6709 V V \u4e2a\u8282\u70b9 ( V V \u4ee3\u8868\u8bed\u6599\u7684\u8bcd\u6c47)\uff0c\u672c\u8d28\u4e0a\u8fd9\u4e2a\u8f93\u51fa\u5c42\u4e5f\u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u3002\u6bcf\u4e2a\u8f93\u51fa\u8282\u70b9 y_i y_i \u8868\u793a\u4e0b\u4e00\u4e2a\u8bcd\u8bed\u4e3a i i \u7684\u672a\u5f52\u4e00\u5316log \u6982\u7387\u3002\u6700\u540e\u4f7f\u7528 softmax \u6fc0\u6d3b\u51fd\u6570\u5c06\u8f93\u51fa\u503c y y \u8fdb\u884c\u5f52\u4e00\u5316\u3002\u5f97\u5230\u6700\u5927\u6982\u7387\u503c\uff0c\u5c31\u662f\u6211\u4eec\u9700\u8981\u9884\u6d4b\u7684\u7ed3\u679c\u3002 \u795e\u7ecf\u7f51\u7edc\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u53bb\u5efa\u6a21\u5f53\u524d\u8bcd\u51fa\u73b0\u7684\u6982\u7387\u4e0e\u5176\u524d n-1 \u4e2a\u8bcd\u4e4b\u95f4\u7684\u7ea6\u675f\u5173\u7cfb\uff0c\u5f88\u663e\u7136\u8fd9\u79cd\u65b9\u5f0f\u76f8\u6bd4 n-gram \u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53ea\u8981\u8bcd\u8868\u5f81\u8db3\u591f\u597d\u3002\u4ece\u800c\u5f88\u5927\u7a0b\u5ea6\u5730\u964d\u4f4e\u4e86\u6570\u636e\u7a00\u758f\u5e26\u6765\u7684\u95ee\u9898\u3002 \u7f3a\u70b9\uff1a\u5bf9\u957f\u5e8f\u5217\u7684\u5efa\u6a21\u80fd\u529b\u6709\u9650\uff0c\u53ef\u80fd\u4f1a\u51fa\u73b0\u957f\u8ddd\u79bb\u9057\u5fd8\u4ee5\u53ca\u8bad\u7ec3\u65f6\u7684\u68af\u5ea6\u6d88\u5931\u7b49\u95ee\u9898\uff0c\u6784\u5efa\u7684\u6a21\u578b\u96be\u4ee5\u8fdb\u884c\u7a33\u5b9a\u7684\u957f\u6587\u672c\u8f93\u51fa\u3002 \u57fa\u4e8eTransformer\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b \u00b6 Transformer\u6a21\u578b\u7531\u4e00\u4e9b\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5c42\u7ec4\u6210\uff08\u89c1\u56fe\uff09\uff0c\u5b66\u4e60\u590d\u6742\u8bed\u4e49\u4fe1\u606f\u7684\u80fd\u529b\u5f3a\uff0c\u5f88\u591a\u4e3b\u6d41\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u63d0\u53d6\u7279\u5f81\u65f6\u90fd\u4f1a\u9009\u62e9Transformer\u7ed3\u6784\uff0c\u5e76\u4ea7\u751f\u4e86\u4e00\u7cfb\u5217\u7684\u57fa\u4e8eTransformer\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5305\u62ecGPT\u3001BERT\u3001T5\u7b49.\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u4ece\u5927\u91cf\u7684\u901a\u7528\u6587\u672c\u6570\u636e\u4e2d\u5b66\u4e60\u5927\u91cf\u7684\u8bed\u8a00\u8868\u793a\uff0c\u5e76\u5c06\u8fd9\u4e9b\u77e5\u8bc6\u8fd0\u7528\u5230\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u83b7\u5f97\u4e86\u8f83\u597d\u7684\u6548\u679c. \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u4f7f\u7528\u65b9\u5f0f\uff1a 1.\u9884\u8bad\u7ec3\uff1a\u9884\u8bad\u7ec3\u6307\u5efa\u7acb\u57fa\u672c\u7684\u6a21\u578b\uff0c\u5148\u5728\u4e00\u4e9b\u6bd4\u8f83\u57fa\u7840\u7684\u6570\u636e\u96c6\u3001\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u7136\u540e\u6309\u7167\u5177\u4f53\u4efb\u52a1\u8bad\u7ec3\uff0c\u5b66\u4e60\u6570\u636e\u7684\u666e\u904d\u7279\u5f81\u3002 2.\u5fae\u8c03\uff1a\u5fae\u8c03\u6307\u5728\u5177\u4f53\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff0c\u4ee5\u83b7\u53d6\u66f4\u597d\u7684\u6cdb\u5316\u6548\u679c\u3002 \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u66f4\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e30\u5bcc\u7684\u8bed\u4e49\u8868\u793a\uff0c\u53ef\u4ee5\u6709\u6548\u9632\u6b62\u8fc7\u62df\u5408\u3002 \u7f3a\u70b9\uff1a\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7b49 \u5927\u8bed\u8a00\u6a21\u578b \u00b6 \u968f\u7740\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u7684\u5f00\u5c55\uff0c\u4eba\u4eec\u9010\u6e10\u53d1\u73b0\u53ef\u80fd\u5b58\u5728\u4e00\u79cd\u6807\u5ea6\u5b9a\u5f8b\uff08Scaling Law\uff09\uff0c\u5373\u968f\u7740\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u7684\u6307\u6570\u7ea7\u63d0\u5347\uff0c\u5176\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u4e5f\u4f1a\u7ebf\u6027\u4e0a\u5347\u30022020\u5e74\uff0cOpenAI\u53d1\u5e03\u4e86\u53c2\u6570\u91cf\u9ad8\u8fbe1750\u4ebf\u7684GPT-3\uff0c\u9996\u6b21\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002 \u76f8\u8f83\u4e8e\u6b64\u524d\u7684\u53c2\u6570\u91cf\u8f83\u5c0f\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u4f8b\u5982\uff0c3.3\u4ebf\u53c2\u6570\u7684Bert-large\u548c17\u4ebf\u53c2\u6570\u7684GPT-2\uff0cGPT-3\u5c55\u73b0\u4e86\u5728Few-shot\u8bed\u8a00\u4efb\u52a1\u80fd\u529b\u4e0a\u7684\u98de\u8dc3\uff0c\u5e76\u5177\u5907\u4e86\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0d\u5177\u5907\u7684\u4e00\u4e9b\u80fd\u529b\u3002\u540e\u7eed\u5c06\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a\u80fd\u529b\u6d8c\u73b0\u3002\u4f8b\u5982\uff0cGPT-3\u80fd\u8fdb\u884c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5728\u4e0d\u8c03\u6574\u6743\u91cd\u7684\u60c5\u51b5\u4e0b\u4ec5\u4f9d\u636e\u7528\u6237\u7ed9\u51fa\u7684\u4efb\u52a1\u793a\u4f8b\u5b8c\u6210\u540e\u7eed\u4efb\u52a1\u3002\u8fd9\u79cd\u80fd\u529b\u65b9\u9762\u7684\u98de\u8dc3\u5f15\u53d1\u7814\u7a76\u754c\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u7814\u7a76\u70ed\u6f6e\uff0c\u5404\u5927\u79d1\u6280\u5de8\u5934\u7eb7\u7eb7\u63a8\u51fa\u53c2\u6570\u91cf\u5de8\u5927\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u4f8b\u5982\uff0cMeta\u516c\u53f81300\u4ebf\u53c2\u6570\u91cf\u7684LLaMA\u6a21\u578b\u4ee5\u53ca\u8c37\u6b4c\u516c\u53f85400\u4ebf\u53c2\u6570\u91cf\u7684PaLM\u3002\u56fd\u5185\u5982\u767e\u5ea6\u63a8\u51fa\u7684\u6587\u5fc3\u4e00\u8a00ERNIE\u7cfb\u5217\u3001\u6e05\u534e\u5927\u5b66\u56e2\u961f\u63a8\u51fa\u7684GLM\u7cfb\u5217\uff0c\u7b49\u7b49\u3002 \u5927\u8bed\u8a00\u6a21\u578b\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u50cf\u201c\u4eba\u7c7b\u201d\u4e00\u6837\u667a\u80fd\uff0c\u5177\u5907\u4e86\u80fd\u4e0e\u4eba\u7c7b\u6c9f\u901a\u804a\u5929\u7684\u80fd\u529b\uff0c\u751a\u81f3\u5177\u5907\u4e86\u4f7f\u7528\u63d2\u4ef6\u8fdb\u884c\u81ea\u52a8\u4fe1\u606f\u68c0\u7d22\u7684\u80fd\u529b \u7f3a\u70b9\uff1a\u53c2\u6570\u91cf\u5927\uff0c\u7b97\u529b\u8981\u6c42\u9ad8\u3001\u751f\u6210\u90e8\u5206\u6709\u5bb3\u7684\u3001\u6709\u504f\u89c1\u7684\u5185\u5bb9\u7b49\u7b49 \u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u6307\u6807 \u00b6 BLEU \u00b6 BLEU\uff1aBLEU \uff08\u53cc\u8bed\u8bc4\u4f30\u66ff\u8865\uff09\u5206\u6570\u662f\u8bc4\u4f30\u4e00\u79cd\u8bed\u8a00\u7ffb\u8bd1\u6210\u53e6\u4e00\u79cd\u8bed\u8a00\u7684\u6587\u672c\u8d28\u91cf\u7684\u6307\u6807\u3002\u5b83\u5c06\u201c\u8d28\u91cf\u201d\u7684\u597d\u574f\u5b9a\u4e49\u4e3a\u4e0e\u4eba\u7c7b\u7ffb\u8bd1\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u7a0b\u5ea6\u3002 BLEU\u7b97\u6cd5\u5b9e\u9645\u4e0a\u5c31\u662f\u5728\u5224\u65ad\u4e24\u4e2a\u53e5\u5b50\u7684\u76f8\u4f3c\u7a0b\u5ea6. BLEU \u7684\u5206\u6570\u53d6\u503c\u8303\u56f4\u662f 0\uff5e1\uff0c\u5206\u6570\u8d8a\u63a5\u8fd11\uff0c\u8bf4\u660e\u7ffb\u8bd1\u7684\u8d28\u91cf\u8d8a\u9ad8\u3002 BLEU\u6709\u8bb8\u591a\u53d8\u79cd\uff0c\u6839\u636e n-gram \u53ef\u4ee5\u5212\u5206\u6210\u591a\u79cd\u8bc4\u4ef7\u6307\u6807\uff0c\u5e38\u89c1\u7684\u8bc4\u4ef7\u6307\u6807\u6709BLEU-1\u3001BLEU-2\u3001BLEU-3\u3001BLEU-4\u56db\u79cd\uff0c\u5176\u4e2d n-gram \u6307\u7684\u662f\u8fde\u7eed\u7684\u5355\u8bcd\u4e2a\u6570\u4e3an\uff0cBLEU-1\u8861\u91cf\u7684\u662f\u5355\u8bcd\u7ea7\u522b\u7684\u51c6\u786e\u6027\uff0c\u66f4\u9ad8\u9636\u7684BLEU\u53ef\u4ee5\u8861\u91cf\u53e5\u5b50\u7684\u6d41\u7545\u6027.\u5b9e\u8df5\u4e2d\uff0c\u901a\u5e38\u662f\u53d6N=1~4\uff0c\u7136\u540e\u5bf9\u8fdb\u884c\u52a0\u6743\u5e73\u5747 \u4e0b\u9762\u4e3e\u4f8b\u8bf4\u8ba1\u7b97\u8fc7\u7a0b\uff1a \u57fa\u672c\u6b65\u9aa4\uff1a \u5206\u522b\u8ba1\u7b97candidate\u53e5\u548creference\u53e5\u7684N-grams\u6a21\u578b\uff0c\u7136\u540e\u7edf\u8ba1\u5176\u5339\u914d\u7684\u4e2a\u6570\uff0c\u8ba1\u7b97\u5339\u914d\u5ea6: \u516c\u5f0f\uff1acandidate\u548creference\u4e2d\u5339\u914d\u7684 n\u2212gram \u7684\u4e2a\u6570 /candidate\u4e2dn\u2212gram \u7684\u4e2a\u6570 \u5047\u8bbe\u673a\u5668\u7ffb\u8bd1\u7684\u8bd1\u6587candidate\u548c\u4e00\u4e2a\u53c2\u8003\u7ffb\u8bd1reference\u5982\u4e0b\uff1a candidate : It is a nice day today reference : Today is a nice day \u4f7f\u75281-gram\u8fdb\u884c\u5339\u914d candidate : {it, is, a, nice, day, today} reference : {today, is, a, nice, day} \u7ed3\u679c : \u5176\u4e2d{today, is, a, nice, day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a5/6 - \u4f7f\u75282-gram\u8fdb\u884c\u5339\u914d candidate : {it is, is a, a nice, nice day, day today} reference : {today is, is a, a nice, nice day} \u7ed3\u679c : \u5176\u4e2d{is a, a nice, nice day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a3/5 \u4f7f\u75283-gram\u8fdb\u884c\u5339\u914d candidate : {it is a, is a nice, a nice day, nice day today} reference : {today is a, is a nice, a nice day} \u7ed3\u679c : \u5176\u4e2d{is a nice, a nice day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a2/4 \u4f7f\u75284-gram\u8fdb\u884c\u5339\u914d candidate : {it is a nice, is a nice day, a nice day today} reference : {today is a nice, is a nice day} \u7ed3\u679c : \u5176\u4e2d{is a nice day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a1/3 \u901a\u8fc7\u4e0a\u9762\u7684\u4f8b\u5b50\u5206\u6790\u53ef\u4ee5\u53d1\u73b0\uff0c\u5339\u914d\u7684\u4e2a\u6570\u8d8a\u591a\uff0cBLEU\u503c\u8d8a\u5927\uff0c\u5219\u8bf4\u660e\u5019\u9009\u53e5\u5b50\u66f4\u597d. \u4f46\u662f\u4e5f\u4f1a\u51fa\u73b0\u4e0b\u9762\u7684\u6781\u7aef\u60c5\u51b5\uff1a \u4e3e\u4f8b\u8bf4\u660e\uff1a candidate : the the the the reference : The cat is standing on the ground \u5982\u679c\u6309\u71671-gram\u7684\u65b9\u6cd5\u8fdb\u884c\u5339\u914d\uff0c\u5219\u5339\u914d\u5ea6\u4e3a1\uff0c\u663e\u7136\u662f\u4e0d\u5408\u7406\u7684\uff0c\u6240\u4ee5\u8ba1\u7b97\u67d0\u4e2a\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\u8fdb\u884c\u6539\u8fdb \u5c06\u8ba1\u7b97\u67d0\u4e2a\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\u7684\u65b9\u6cd5\u6539\u4e3a\u8ba1\u7b97**\u67d0\u4e2a\u8bcd\u5728\u8bd1\u6587\u4e2d\u51fa\u73b0\u7684\u6700\u5c0f\u6b21\u6570**,\u5982\u4e0b\u6240\u793a\u7684\u516c\u5f0f\uff1a count_k=min(c_k,s_k) count_k=min(c_k,s_k) \u5176\u4e2d k k \u8868\u793a\u5728\u673a\u5668\u8bd1\u6587\uff08candidate\uff09\u4e2d\u51fa\u73b0\u7684\u7b2c k k \u4e2a\u8bcd\u8bed, c_k c_k \u5219\u4ee3\u8868\u5728\u673a\u5668\u8bd1\u6587\u4e2d\u8fd9\u4e2a\u8bcd\u8bed\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u800c s_k s_k \u5219\u4ee3\u8868\u5728\u4eba\u5de5\u8bd1\u6587\uff08reference\uff09\u4e2d\u8fd9\u4e2a\u8bcd\u8bed\u51fa\u73b0\u7684\u6b21\u6570\u3002 python\u4ee3\u7801\u5b9e\u73b0\uff1a # \u7b2c\u4e00\u6b65\u5b89\u88c5nltk\u7684\u5305-->pip install nltk from nltk.translate.bleu_score import sentence_bleu def cumulative_bleu ( reference , candidate ): bleu_1_gram = sentence_bleu ( reference , candidate , weights = ( 1 , 0 , 0 , 0 )) bleu_2_gram = sentence_bleu ( reference , candidate , weights = ( 0.5 , 0.5 , 0 , 0 )) bleu_3_gram = sentence_bleu ( reference , candidate , weights = ( 0.33 , 0.33 , 0.33 , 0 )) bleu_4_gram = sentence_bleu ( reference , candidate , weights = ( 0.25 , 0.25 , 0.25 , 0.25 )) # print('bleu 1-gram: %f' % bleu_1_gram) # print('bleu 2-gram: %f' % bleu_2_gram) # print('bleu 3-gram: %f' % bleu_3_gram) # print('bleu 4-gram: %f' % bleu_4_gram) return bleu_1_gram , bleu_2_gram , bleu_3_gram , bleu_4_gram # \u751f\u6210\u6587\u672c generated_text = \"This is some generated text.\" # \u53c2\u8003\u6587\u672c\u5217\u8868 reference_texts = [ \"This is a reference text.\" , \"This is another reference text.\" ] # \u8ba1\u7b97 Bleu \u6307\u6807 c_bleu = cumulative_bleu ( reference_texts , generated_text ) # \u6253\u5370\u7ed3\u679c print ( \"The Bleu score is:\" , c_bleu ) # The Bleu score is: (0.8571, 0.6900, 0.5711, 0.4920) ROUGE \u00b6 ROUGE\u6307\u6807\u662f\u5728\u673a\u5668\u7ffb\u8bd1\u3001\u81ea\u52a8\u6458\u8981\u3001\u95ee\u7b54\u751f\u6210\u7b49\u9886\u57df\u5e38\u89c1\u7684\u8bc4\u4f30\u6307\u6807\u3002ROUGE\u901a\u8fc7\u5c06\u6a21\u578b\u751f\u6210\u7684\u6458\u8981\u6216\u8005\u56de\u7b54\u4e0e\u53c2\u8003\u7b54\u6848\uff08\u4e00\u822c\u662f\u4eba\u5de5\u751f\u6210\u7684\uff09\u8fdb\u884c\u6bd4\u8f83\u8ba1\u7b97\uff0c\u5f97\u5230\u5bf9\u5e94\u7684\u5f97\u5206\u3002 ROUGE\u6307\u6807\u4e0eBLEU\u6307\u6807\u975e\u5e38\u7c7b\u4f3c\uff0c\u5747\u53ef\u7528\u6765\u8861\u91cf\u751f\u6210\u7ed3\u679c\u548c\u6807\u51c6\u7ed3\u679c\u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u4e0d\u540c\u7684\u662fROUGE\u57fa\u4e8e\u53ec\u56de\u7387\uff0cBLEU\u66f4\u770b\u91cd\u51c6\u786e\u7387\u3002 ROUGE\u5206\u4e3a\u56db\u79cd\u65b9\u6cd5\uff1aROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S. \u4e0b\u9762\u4e3e\u4f8b\u8bf4\u8ba1\u7b97\u8fc7\u7a0b\uff08\u8fd9\u91cc\u53ea\u4ecb\u7ecdROUGE_N\uff09\uff1a \u57fa\u672c\u6b65\u9aa4\uff1a Rouge-N\u5b9e\u9645\u4e0a\u662f\u5c06\u6a21\u578b\u751f\u6210\u7684\u7ed3\u679c\u548c\u6807\u51c6\u7ed3\u679c\u6309N-gram\u62c6\u5206\u540e\uff0c\u8ba1\u7b97\u53ec\u56de\u7387 \u5047\u8bbe\u6a21\u578b\u751f\u6210\u7684\u6587\u672ccandidate\u548c\u4e00\u4e2a\u53c2\u8003\u6587\u672creference\u5982\u4e0b\uff1a candidate : It is a nice day today reference : Today is a nice day \u4f7f\u7528ROUGE-1\u8fdb\u884c\u5339\u914d candidate : {it, is, a, nice, day, today} reference : {today, is, a, nice, day} \u7ed3\u679c : : \u5176\u4e2d{today, is, a, nice, day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a5/5=1,\u8fd9\u8bf4\u660e\u751f\u6210\u7684\u5185\u5bb9\u5b8c\u5168\u8986\u76d6\u4e86\u53c2\u8003\u6587\u672c\u4e2d\u7684\u6240\u6709\u5355\u8bcd\uff0c\u8d28\u91cf\u8f83\u9ad8\u3002 \u901a\u8fc7\u7c7b\u4f3c\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5176\u4ed6ROUGE\u6307\u6807\uff08\u5982ROUGE-2\u3001ROUGE-L\u3001ROUGE-S\uff09\u7684\u8bc4\u5206\uff0c\u4ece\u800c\u7efc\u5408\u8bc4\u4f30\u7cfb\u7edf\u751f\u6210\u7684\u6587\u672c\u8d28\u91cf\u3002 python\u4ee3\u7801\u5b9e\u73b0\uff1a # \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5rouge-->pip install rouge import Rouge # \u751f\u6210\u6587\u672c generated_text = \"This is some generated text.\" # \u53c2\u8003\u6587\u672c\u5217\u8868 reference_texts = [ \"This is a reference text.\" , \"This is another generated reference text.\" ] # \u8ba1\u7b97 ROUGE \u6307\u6807 rouge = Rouge () scores = rouge . get_scores ( generated_text , reference_texts [ 1 ]) # \u6253\u5370\u7ed3\u679c print ( \"ROUGE-1 precision:\" , scores [ 0 ][ \"rouge-1\" ][ \"p\" ]) print ( \"ROUGE-1 recall:\" , scores [ 0 ][ \"rouge-1\" ][ \"r\" ]) print ( \"ROUGE-1 F1 score:\" , scores [ 0 ][ \"rouge-1\" ][ \"f\" ]) # ROUGE-1 precision: 0.8 # ROUGE-1 recall: 0.6666666666666666 # ROUGE-1 F1 score: 0.7272727223140496 \u56f0\u60d1\u5ea6PPL(perplexity) \u00b6 PPL\u7528\u6765\u5ea6\u91cf\u4e00\u4e2a\u6982\u7387\u5206\u5e03\u6216\u6982\u7387\u6a21\u578b\u9884\u6d4b\u6837\u672c\u7684\u597d\u574f\u7a0b\u5ea6\u3002 PPL\u57fa\u672c\u601d\u60f3: \u7ed9\u6d4b\u8bd5\u96c6\u7684\u53e5\u5b50\u8d4b\u4e88\u8f83\u9ad8\u6982\u7387\u503c\u7684\u8bed\u8a00\u6a21\u578b\u8f83\u597d,\u5f53\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u5b8c\u4e4b\u540e\uff0c\u6d4b\u8bd5\u96c6\u4e2d\u7684\u53e5\u5b50\u90fd\u662f\u6b63\u5e38\u7684\u53e5\u5b50\uff0c\u90a3\u4e48\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5c31\u662f\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6982\u7387\u8d8a\u9ad8\u8d8a\u597d. \u57fa\u672c\u516c\u5f0f\uff08\u4e24\u79cd\u65b9\u5f0f\uff09\uff1a \u7531\u516c\u5f0f\u53ef\u77e5\uff0c \u53e5\u5b50\u6982\u7387\u8d8a\u5927\uff0c\u8bed\u8a00\u6a21\u578b\u8d8a\u597d\uff0c\u8ff7\u60d1\u5ea6\u8d8a\u5c0f\u3002 python\u4ee3\u7801\u5b9e\u73b0\uff1a import math # \u5b9a\u4e49\u8bed\u6599\u5e93 sentences = [ [ 'I' , 'have' , 'a' , 'pen' ], [ 'He' , 'has' , 'a' , 'book' ], [ 'She' , 'has' , 'a' , 'cat' ] ] # \u5b9a\u4e49\u8bed\u8a00\u6a21\u578b unigram = { 'I' : 1 / 11 , 'have' : 1 / 11 , 'a' : 3 / 11 , 'pen' : 1 / 11 , 'He' : 1 / 11 , 'has' : 2 / 11 , 'book' : 1 / 11 , 'She' : 1 / 11 , 'cat' : 1 / 11 } # \u8ba1\u7b97\u56f0\u60d1\u5ea6 perplexity = 0 for sentence in sentences : sentence_prob = 1 for word in sentence : sentence_prob *= unigram [ word ] temp = - math . log ( sentence_prob , 2 ) / len ( sentence ) perplexity += 2 ** temp perplexity = perplexity / len ( sentences ) print ( '\u56f0\u60d1\u5ea6\u4e3a\uff1a' , perplexity ) # \u56f0\u60d1\u5ea6\u4e3a\uff1a 7.47 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecdLLM\u7684\u80cc\u666f\u77e5\u8bc6\uff0c\u4e86\u89e3\u76ee\u524dLLM\u53d1\u5c55\u57fa\u672c\u5386\u7a0b \u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u7c7b\u522b\u5206\u522b\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u5982\u57fa\u4e8e\u7edf\u8ba1\u7684N-gram\u6a21\u578b\uff0c\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b","title":"1.1 LLM\u57fa\u7840\u77e5\u8bc6"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#llm","text":"","title":"LLM\u80cc\u666f\u77e5\u8bc6\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#_1","text":"\u4e86\u89e3LLM\u80cc\u666f\u7684\u77e5\u8bc6. \u638c\u63e1\u4ec0\u4e48\u662f\u8bed\u8a00\u6a21\u578b","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#llm_1","text":"\u5927\u8bed\u8a00\u6a21\u578b (\u82f1\u6587\uff1aLarge Language Model\uff0c\u7f29\u5199LLM) \u662f\u4e00\u79cd\u4eba\u5de5\u667a\u80fd\u6a21\u578b, \u65e8\u5728\u7406\u89e3\u548c\u751f\u6210\u4eba\u7c7b\u8bed\u8a00. \u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5904\u7406\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\uff0c\u5982\u6587\u672c\u5206\u7c7b\u3001\u95ee\u7b54\u3001\u7ffb\u8bd1\u3001\u5bf9\u8bdd\u7b49\u7b49. \u901a\u5e38, \u5927\u8bed\u8a00\u6a21\u578b (LLM) \u662f\u6307\u5305\u542b\u6570\u5343\u4ebf (\u6216\u66f4\u591a) \u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b(\u76ee\u524d\u5b9a\u4e49\u53c2\u6570\u91cf\u8d85\u8fc710B\u7684\u6a21\u578b\u4e3a\u5927\u8bed\u8a00\u6a21\u578b)\uff0c\u8fd9\u4e9b\u53c2\u6570\u662f\u5728\u5927\u91cf\u6587\u672c\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\uff0c\u4f8b\u5982\u6a21\u578b GPT-3\u3001ChatGPT\u3001PaLM\u3001BLOOM\u548c LLaMA\u7b49. \u622a\u6b6223\u5e743\u6708\u5e95\uff0c\u8bed\u8a00\u6a21\u578b\u53d1\u5c55\u8d70\u8fc7\u4e86\u4e09\u4e2a\u9636\u6bb5\uff1a \u7b2c\u4e00\u9636\u6bb5 \uff1a\u8bbe\u8ba1\u4e00\u7cfb\u5217\u7684\u81ea\u76d1\u7763\u8bad\u7ec3\u76ee\u6807\uff08MLM\u3001NSP\u7b49\uff09\uff0c\u8bbe\u8ba1\u65b0\u9896\u7684\u6a21\u578b\u67b6\u6784\uff08Transformer\uff09\uff0c\u9075\u5faaPre-training\u548cFine-tuning\u8303\u5f0f\u3002\u5178\u578b\u4ee3\u8868\u662fBERT\u3001GPT\u3001XLNet\u7b49\uff1b \u7b2c\u4e8c\u9636\u6bb5 \uff1a\u9010\u6b65\u6269\u5927\u6a21\u578b\u53c2\u6570\u548c\u8bad\u7ec3\u8bed\u6599\u89c4\u6a21\uff0c\u63a2\u7d22\u4e0d\u540c\u7c7b\u578b\u7684\u67b6\u6784\u3002\u5178\u578b\u4ee3\u8868\u662fBART\u3001T5\u3001GPT-3\u7b49\uff1b \u7b2c\u4e09\u9636\u6bb5 \uff1a\u8d70\u5411AIGC\uff08Artificial Intelligent Generated Content\uff09\u65f6\u4ee3\uff0c\u6a21\u578b\u53c2\u6570\u89c4\u6a21\u6b65\u5165\u5343\u4e07\u4ebf\uff0c\u6a21\u578b\u67b6\u6784\u4e3a\u81ea\u56de\u5f52\u67b6\u6784\uff0c\u5927\u6a21\u578b\u8d70\u5411\u5bf9\u8bdd\u5f0f\u3001\u751f\u6210\u5f0f\u3001\u591a\u6a21\u6001\u65f6\u4ee3\uff0c\u66f4\u52a0\u6ce8\u91cd\u4e0e\u4eba\u7c7b\u4ea4\u4e92\u8fdb\u884c\u5bf9\u9f50\uff0c\u5b9e\u73b0\u53ef\u9760\u3001\u5b89\u5168\u3001\u65e0\u6bd2\u7684\u6a21\u578b\u3002\u5178\u578b\u4ee3\u8868\u662fInstructionGPT\u3001ChatGPT\u3001Bard\u3001GPT-4\u7b49\u3002","title":"\u5927\u8bed\u8a00\u6a21\u578b (LLM) \u80cc\u666f"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#language-model-lm","text":"\u8bed\u8a00\u6a21\u578b\uff08Language Model\uff09\u65e8\u5728\u5efa\u6a21\u8bcd\u6c47\u5e8f\u5217\u7684\u751f\u6210\u6982\u7387\uff0c\u63d0\u5347\u673a\u5668\u7684\u8bed\u8a00\u667a\u80fd\u6c34\u5e73\uff0c\u4f7f\u673a\u5668\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u8bf4\u8bdd\u3001\u5199\u4f5c\u7684\u6a21\u5f0f\u8fdb\u884c\u81ea\u52a8\u6587\u672c\u8f93\u51fa\u3002 \u901a\u4fd7\u7406\u89e3: \u7528\u6765\u8ba1\u7b97\u4e00\u4e2a\u53e5\u5b50\u7684\u6982\u7387\u7684\u6a21\u578b\uff0c\u4e5f\u5c31\u662f\u5224\u65ad\u4e00\u53e5\u8bdd\u662f\u5426\u662f\u4eba\u8bdd\u7684\u6982\u7387. \u6807\u51c6\u5b9a\u4e49\uff1a\u5bf9\u4e8e\u67d0\u4e2a\u53e5\u5b50\u5e8f\u5217, \u5982S = {W1, W2, W3, \u2026, Wn}, \u8bed\u8a00\u6a21\u578b\u5c31\u662f\u8ba1\u7b97\u8be5\u5e8f\u5217\u53d1\u751f\u7684\u6982\u7387, \u5373P(S). \u5982\u679c\u7ed9\u5b9a\u7684\u8bcd\u5e8f\u5217\u7b26\u5408\u8bed\u7528\u4e60\u60ef, \u5219\u7ed9\u51fa\u9ad8\u6982\u7387, \u5426\u5219\u7ed9\u51fa\u4f4e\u6982\u7387. \u4e3e\u4f8b\u8bf4\u660e\uff1a \u5047\u8bbe\u6211\u4eec\u8981\u4e3a\u4e2d\u6587\u521b\u5efa\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c V V <span class=\"arithmatex\"><span class=\"MathJax_Preview\">V</span><script type=\"math/tex\">V \u8868\u793a\u8bcd\u5178\uff0c V V ={\u9ed1\u9a6c\u3001\u7a0b\u5e8f\u3001\u5458\u3001\u6765\u3001\u5b66\u4e60}\u200b\uff0c W_i W_i \u5c5e\u4e8e V V \u3002\u8bed\u8a00\u6a21\u578b\u63cf\u8ff0\uff1a\u7ed9\u5b9a\u8bcd\u5178 V V , \u80fd\u591f\u8ba1\u7b97\u51fa\u4efb\u610f\u5355\u8bcd\u5e8f\u5217 S={W_1,W_2,W_3,\u2026,W_n} S={W_1,W_2,W_3,\u2026,W_n} \u662f\u4e00\u53e5\u8bdd\u7684\u6982\u7387 P(S) P(S) , \u5176\u4e2d P >= 0\u200b P >= 0\u200b \u90a3\u4e48\u5982\u4f55\u8ba1\u7b97\u4e00\u4e2a\u53e5\u5b50\u7684 P(S) P(S) \u5462\uff1f\u6700\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u8ba1\u6570\uff0c\u5047\u8bbe\u6570\u636e\u96c6\u4e2d\u5171\u6709 N N \u4e2a\u53e5\u5b50\uff0c\u6211\u4eec\u53ef\u4ee5\u7edf\u8ba1\u4e00\u4e0b\u6570\u636e\u96c6\u4e2d S={W_1,W_2,W_3,\u2026,W_n} S={W_1,W_2,W_3,\u2026,W_n} \u6bcf\u4e2a\u53e5\u5b50\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u5982\u679c\u5047\u8bbe\u4e3a n n \uff0c\u5219 P(S)=\\frac{n}{N} P(S)=\\frac{n}{N} . \u90a3\u4e48\u53ef\u4ee5\u60f3\u8c61\u4e00\u4e0b\uff0c\u8fd9\u4e2a\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u51e0\u4e4e\u4e3a0\uff0c\u4e00\u65e6\u5355\u8bcd\u5e8f\u5217\u6ca1\u5728\u4e4b\u524d\u6570\u636e\u96c6\u4e2d\u51fa\u73b0\u8fc7\uff0c\u6a21\u578b\u7684\u8f93\u51fa\u6982\u7387\u5c31\u662f0\uff0c\u663e\u7136\u76f8\u5f53\u4e0d\u5408\u7406\u3002 \u6211\u4eec\u53ef\u4ee5\u6839\u636e\u6982\u7387\u8bba\u4e2d\u7684\u94fe\u5f0f\u6cd5\u5219\uff0c\u5c06 P P \u53ef\u4ee5\u8868\u793a\u4e3a\uff1a P(S) = P(W_1, W_2, ....,W_n) = P(W_1)*P(W_2|W_1)*....*P(W_n|W_1, W_2, ....,W_{n-1}) P(S) = P(W_1, W_2, ....,W_n) = P(W_1)*P(W_2|W_1)*....*P(W_n|W_1, W_2, ....,W_{n-1}) \u5982\u679c\u80fd\u8ba1\u7b97 P(W_n|W_1,W_2,\u2026W_{n-1}) P(W_n|W_1,W_2,\u2026W_{n-1}) \uff0c\u90a3\u4e48\u5c31\u80fd\u8f7b\u677e\u5f97\u5230 P(W_1,W_2,\u2026,W_n) P(W_1,W_2,\u2026,W_n) , \u6240\u4ee5\u5728\u67d0\u4e9b\u6587\u732e\u4e2d\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u770b\u5230\u8bed\u8a00\u6a21\u578b\u7684\u53e6\u5916\u4e00\u4e2a\u5b9a\u4e49\uff1a\u80fd\u591f\u8ba1\u7b97\u51fa P(W_1,W_2,\u2026,W_n) P(W_1,W_2,\u2026,W_n) \u7684\u6a21\u578b\u5c31\u662f\u8bed\u8a00\u6a21\u578b\u3002 \u4ece\u6587\u672c\u751f\u6210\u89d2\u5ea6\uff0c\u4e5f\u53ef\u4ee5\u8fd9\u6837\u5b9a\u4e49\u8bed\u8a00\u6a21\u578b\uff1a\u7ed9\u5b9a\u4e00\u4e2a\u77ed\u8bed\uff08\u4e00\u4e2a\u8bcd\u7ec4\u6216\u8005\u4e00\u53e5\u8bdd\uff09\uff0c\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u751f\u6210\uff08\u9884\u6d4b\uff09\u63a5\u4e0b\u6765\u7684\u4e00\u4e2a\u8bcd\u3002 \u8bed\u8a00\u6a21\u578b\u6280\u672f\u7684\u53d1\u5c55\u53ef\u4ee5\u603b\u7ed3\u4e3a\u56db\u4e2a\u9636\u6bb5\uff1a \u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u8bed\u8a00\u6a21\u578b \u795e\u7ecf\u8bed\u8a00\u6a21\u578b \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b \u5927\u8bed\u8a00\u6a21\u578b","title":"\u8bed\u8a00\u6a21\u578b (Language Model, LM)"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#n-gram","text":"\u7531\u4eba\u5de5\u8bbe\u8ba1\u7279\u5f81\u5e76\u4f7f\u7528\u7edf\u8ba1\u65b9\u6cd5\u5bf9\u56fa\u5b9a\u957f\u5ea6\u7684\u6587\u672c\u7a97\u53e3\u5e8f\u5217\u8fdb\u884c\u5efa\u6a21\u5206\u6790\uff0c\u8fd9\u79cd\u5efa\u6a21\u65b9\u5f0f\u4e5f\u88ab\u79f0\u4e3aN-gram\u8bed\u8a00\u6a21\u578b\u3002\u5728\u4e0a\u8ff0\u4f8b\u5b50\u4e2d\u8ba1\u7b97\u53e5\u5b50\u5e8f\u5217\u6982\u7387\u6211\u4eec\u4f7f\u7528\u94fe\u5f0f\u6cd5\u5219\u8ba1\u7b97\uff0c \u8be5\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u7f3a\u9677\uff1a \u53c2\u6570\u7a7a\u95f4\u8fc7\u5927\uff1a\u6761\u4ef6\u6982\u7387 P(W_n|W_1, W_2,\u2026.W_n) P(W_n|W_1, W_2,\u2026.W_n) \u7684\u53ef\u80fd\u6027\u592a\u591a\uff0c\u65e0\u6cd5\u4f30\u7b97\uff0c\u4e5f\u4e0d\u4e00\u5b9a\u6709\u7528 \u6570\u636e\u7a00\u758f\u4e25\u91cd\uff1a\u8bb8\u591a\u8bcd\u5bf9\u7684\u7ec4\u5408\uff0c\u5728\u8bed\u6599\u5e93\u4e2d\u90fd\u6ca1\u6709\u51fa\u73b0\uff0c\u4f9d\u636e\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5f97\u5230\u7684\u6982\u7387\u4e3a0 \u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u5f15\u5165\u9a6c\u5c14\u79d1\u592b\u5047\u8bbe\uff1a\u968f\u610f\u4e00\u4e2a\u8bcd\u51fa\u73b0\u7684\u6982\u7387\u53ea\u4e0e\u5b83\u524d\u9762\u51fa\u73b0\u7684\u6709\u9650\u7684\u4e00\u4e2a\u6216\u8005\u51e0\u4e2a\u8bcd\u6709\u5173\u3002 \u5982\u679c\u4e00\u4e2a\u8bcd\u7684\u51fa\u73b0\u4e0e\u5b83\u5468\u56f4\u7684\u8bcd\u662f\u72ec\u7acb\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u79f0\u4e4b\u4e3aunigram\u4e5f\u5c31\u662f\u4e00\u5143\u8bed\u8a00\u6a21\u578b. P(S) = P(W_1)*P(W_2)*....*P(W_n) P(S) = P(W_1)*P(W_2)*....*P(W_n) \u5982\u679c\u4e00\u4e2a\u8bcd\u7684\u51fa\u73b0\u4ec5\u4f9d\u8d56\u4e8e\u5b83\u524d\u9762\u51fa\u73b0\u7684\u4e00\u4e2a\u8bcd\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u79f0\u4e4b\u4e3abigram. P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2)*...*P(W_n|W_{n-1}) P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2)*...*P(W_n|W_{n-1}) \u5982\u679c\u4e00\u4e2a\u8bcd\u7684\u51fa\u73b0\u4ec5\u4f9d\u8d56\u4e8e\u5b83\u524d\u9762\u51fa\u73b0\u7684\u4e24\u4e2a\u8bcd\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u79f0\u4e4b\u4e3atrigram. P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2,W_1)*...*P(W_n|W_{n-1},W_{n-2}) P(S) = P(W_1)*P(W_2|W_1)*P(W_3|W_2,W_1)*...*P(W_n|W_{n-1},W_{n-2}) \u4e00\u822c\u6765\u8bf4\uff0cN\u5143\u6a21\u578b\u5c31\u662f\u5047\u8bbe\u5f53\u524d\u8bcd\u7684\u51fa\u73b0\u6982\u7387\u53ea\u4e0e\u5b83\u524d\u9762\u7684N-1\u4e2a\u8bcd\u6709\u5173\uff0c\u800c\u8fd9\u4e9b\u6982\u7387\u53c2\u6570\u90fd\u662f\u53ef\u4ee5\u901a\u8fc7\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u6765\u8ba1\u7b97\uff0c\u6bd4\u5982\u4e09\u5143\u6982\u7387\uff1a $$ P(W_i|W_{i-1},W_{i-2}) = Count(W_{i-2}W_{i-1}W_i)/Count(W_{i-2}W_{i-1}) $$ \u5728\u5b9e\u8df5\u4e2d\u7528\u7684\u6700\u591a\u7684\u5c31\u662fbigram\u548ctrigram\uff0c\u63a5\u4e0b\u6765\u4ee5bigram\u8bed\u8a00\u6a21\u578b\u4e3a\u4f8b\uff0c\u7406\u89e3\u5176\u5de5\u4f5c\u539f\u7406\uff1a \u9996\u5148\u6211\u4eec\u51c6\u5907\u4e00\u4e2a\u8bed\u6599\u5e93\uff08\u7b80\u5355\u7406\u89e3\u8ba9\u6a21\u578b\u5b66\u4e60\u7684\u6570\u636e\u96c6\uff09\uff0c\u4e3a\u4e86\u8ba1\u7b97\u5bf9\u5e94\u7684\u4e8c\u5143\u6a21\u578b\u7684\u53c2\u6570\uff0c\u5373 P(W_i|W_{i-1}) P(W_i|W_{i-1}) \uff0c\u6211\u4eec\u8981\u5148\u8ba1\u6570\u5373 C(W_{i-1},W_i) C(W_{i-1},W_i) \uff0c\u7136\u540e\u8ba1\u6570 C(W_{i-1}) C(W_{i-1}) , \u518d\u7528\u9664\u6cd5\u53ef\u5f97\u5230\u6982\u7387\u3002 C(W_{i-1}, W_i)\u200b C(W_{i-1}, W_i)\u200b \u8ba1\u6570\u7ed3\u679c\u5982\u4e0b\uff1a C(W_{i-1})\u200b C(W_{i-1})\u200b \u7684\u8ba1\u6570\u7ed3\u679c\u5982\u4e0b\uff1a \u90a3\u4e48bigram\u8bed\u8a00\u6a21\u578b\u9488\u5bf9\u4e0a\u8ff0\u8bed\u6599\u7684\u53c2\u6570\u8ba1\u7b97\u7ed3\u679c\u5982\u4f55\u5b9e\u73b0\uff1f\u5047\u5982\uff0c\u6211\u60f3\u8ba1\u7b97 P(\u60f3\uff5c\u6211)\\approx0.38\u200b P(\u60f3\uff5c\u6211)\\approx0.38\u200b ,\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\u663e\u793a\uff1a\uff08\u5176\u4ed6\u53c2\u6570\u8ba1\u7b97\u8fc7\u7a0b\u7c7b\u4f3c\uff09 $$ P(\u60f3\uff5c\u6211) = \\frac{C(\u6211,\u60f3)}{C(\u6211)} = \\frac{800}{2100}\\approx0.38 $$ \u5982\u679c\u9488\u5bf9\u8fd9\u4e2a\u8bed\u6599\u5e93\u7684\u4e8c\u5143\u6a21\u578b\uff08bigram\uff09\u5efa\u7acb\u597d\u4e4b\u540e\uff0c\u5c31\u53ef\u4ee5\u5b9e\u73b0\u6211\u4eec\u7684\u76ee\u6807\u8ba1\u7b97\u3002 \u8ba1\u7b97\u4e00\u4e2a\u53e5\u5b50\u7684\u6982\u7387\uff0c\u4e3e\u4f8b\u5982\u4e0b\uff1a P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = P(\u60f3\uff5c\u6211)*P(\u53bb\uff5c\u60f3)*P(\u6253\uff5c\u53bb)*P(\u7bee\u7403\uff5c\u6253)=\\frac{800}{2100}*\\frac{600}{900}*\\frac{690}{2000}*\\frac{20}{800} \\approx0.0022 P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = P(\u60f3\uff5c\u6211)*P(\u53bb\uff5c\u60f3)*P(\u6253\uff5c\u53bb)*P(\u7bee\u7403\uff5c\u6253)=\\frac{800}{2100}*\\frac{600}{900}*\\frac{690}{2000}*\\frac{20}{800} \\approx0.0022 \u9884\u6d4b\u4e00\u53e5\u8bdd\u6700\u53ef\u80fd\u51fa\u73b0\u7684\u4e0b\u4e00\u4e2a\u8bcd\u6c47\uff0c\u6bd4\u5982\uff1a\u6211\u60f3\u53bb\u6253\u3010mask\u3011? \u601d\u8003\uff1amask = \u7bee\u7403 \u6216\u8005 mask = \u665a\u996d P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = \\approx0.0022 P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) = \\approx0.0022 P(\u6211\u60f3\u53bb\u6253\u665a\u996d) =\\approx0.00022 P(\u6211\u60f3\u53bb\u6253\u665a\u996d) =\\approx0.00022 \u53ef\u4ee5\u770b\u51fa P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) > P(\u6211\u60f3\u53bb\u6253\u665a\u996d) P(\u6211\u60f3\u53bb\u6253\u7bee\u7403) > P(\u6211\u60f3\u53bb\u6253\u665a\u996d) \uff0c\u56e0\u6b64mask = \u7bee\u7403\uff0c\u5bf9\u6bd4\u771f\u5b9e\u8bed\u5883\u4e0b\uff0c\u4e5f\u7b26\u5408\u4eba\u7c7b\u4e60\u60ef\u3002 N-gram\u8bed\u8a00\u6a21\u578b\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u91c7\u7528\u6781\u5927\u4f3c\u7136\u4f30\u8ba1, \u53c2\u6570\u6613\u8bad\u7ec3; \u5b8c\u5168\u5305\u542b\u4e86\u524dn-1\u4e2a\u8bcd\u7684\u5168\u90e8\u4fe1\u606f; \u53ef\u89e3\u91ca\u6027\u5f3a, \u76f4\u89c2\u6613\u7406\u89e3\u3002 \u7f3a\u70b9\uff1a\u7f3a\u4e4f\u957f\u671f\u4ee5\u6765\uff0c\u53ea\u80fd\u5efa\u6a21\u5230\u524dn-1\u4e2a\u8bcd; \u968f\u7740n\u7684\u589e\u5927\uff0c\u53c2\u6570\u7a7a\u95f4\u5448\u6307\u6570\u589e\u957f3.\u6570\u636e\u7a00\u758f\uff0c\u96be\u514d\u4f1a\u51fa\u73b0OOV\u95ee\u9898; \u5355\u7eaf\u7684\u57fa\u4e8e\u7edf\u8ba1\u9891\u6b21\uff0c\u6cdb\u5316\u80fd\u529b\u5dee.","title":"\u57fa\u4e8e\u89c4\u5219\u548c\u7edf\u8ba1\u7684\u8bed\u8a00\u6a21\u578b\uff08N-gram\uff09"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#_2","text":"\u57fa\u4e8eN-gram\u8bed\u8a00\u6a21\u578b\u4ee5\u4e0a\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u968f\u7740\u795e\u7ecf\u7f51\u7edc\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4eba\u4eec\u5f00\u59cb\u5c1d\u8bd5\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u6765\u5efa\u7acb\u8bed\u8a00\u6a21\u578b\u3002 \u6a21\u578b\u7684\u8f93\u5165\uff1a w_{t-n+1}, \u2026, w_{t-2}, w_{t-1} w_{t-n+1}, \u2026, w_{t-2}, w_{t-1} \u5c31\u662f\u524dn-1\u4e2a\u8bcd\u3002\u73b0\u5728\u9700\u8981\u6839\u636e\u8fd9\u5df2\u77e5\u7684n-1\u4e2a\u8bcd\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd w_t w_t \u3002 C(w) C(w) \u8868\u793a w w \u6240\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf. \u7f51\u7edc\u7684\u7b2c\u4e00\u5c42\uff08\u8f93\u5165\u5c42\uff09\u662f\u5c06 C(w_{t-n+1}),\u2026,C(w_{t-2}), C(w_{t-1})\u200b C(w_{t-n+1}),\u2026,C(w_{t-2}), C(w_{t-1})\u200b \u8fd9n-1\u4e2a\u5411\u91cf\u9996\u5c3e\u62fc\u63a5\u8d77\u6765\u5f62\u6210\u4e00\u4e2a (n-1)*m\u200b (n-1)*m\u200b \u5927\u5c0f\u7684\u5411\u91cf\uff0c\u8bb0\u4f5c x\u200b x\u200b . \u7f51\u7edc\u7684\u7b2c\u4e8c\u5c42\uff08\u9690\u85cf\u5c42\uff09\u5c31\u5982\u540c\u666e\u901a\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u76f4\u63a5\u4f7f\u7528\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42, \u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u540e\u518d\u4f7f\u7528 tanh\u200b tanh\u200b \u8fd9\u4e2a\u6fc0\u6d3b\u51fd\u6570\u8fdb\u884c\u5904\u7406\u3002 \u7f51\u7edc\u7684\u7b2c\u4e09\u5c42\uff08\u8f93\u51fa\u5c42\uff09\u4e00\u5171\u6709 V V \u4e2a\u8282\u70b9 ( V V \u4ee3\u8868\u8bed\u6599\u7684\u8bcd\u6c47)\uff0c\u672c\u8d28\u4e0a\u8fd9\u4e2a\u8f93\u51fa\u5c42\u4e5f\u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\u3002\u6bcf\u4e2a\u8f93\u51fa\u8282\u70b9 y_i y_i \u8868\u793a\u4e0b\u4e00\u4e2a\u8bcd\u8bed\u4e3a i i \u7684\u672a\u5f52\u4e00\u5316log \u6982\u7387\u3002\u6700\u540e\u4f7f\u7528 softmax \u6fc0\u6d3b\u51fd\u6570\u5c06\u8f93\u51fa\u503c y y \u8fdb\u884c\u5f52\u4e00\u5316\u3002\u5f97\u5230\u6700\u5927\u6982\u7387\u503c\uff0c\u5c31\u662f\u6211\u4eec\u9700\u8981\u9884\u6d4b\u7684\u7ed3\u679c\u3002 \u795e\u7ecf\u7f51\u7edc\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u53bb\u5efa\u6a21\u5f53\u524d\u8bcd\u51fa\u73b0\u7684\u6982\u7387\u4e0e\u5176\u524d n-1 \u4e2a\u8bcd\u4e4b\u95f4\u7684\u7ea6\u675f\u5173\u7cfb\uff0c\u5f88\u663e\u7136\u8fd9\u79cd\u65b9\u5f0f\u76f8\u6bd4 n-gram \u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53ea\u8981\u8bcd\u8868\u5f81\u8db3\u591f\u597d\u3002\u4ece\u800c\u5f88\u5927\u7a0b\u5ea6\u5730\u964d\u4f4e\u4e86\u6570\u636e\u7a00\u758f\u5e26\u6765\u7684\u95ee\u9898\u3002 \u7f3a\u70b9\uff1a\u5bf9\u957f\u5e8f\u5217\u7684\u5efa\u6a21\u80fd\u529b\u6709\u9650\uff0c\u53ef\u80fd\u4f1a\u51fa\u73b0\u957f\u8ddd\u79bb\u9057\u5fd8\u4ee5\u53ca\u8bad\u7ec3\u65f6\u7684\u68af\u5ea6\u6d88\u5931\u7b49\u95ee\u9898\uff0c\u6784\u5efa\u7684\u6a21\u578b\u96be\u4ee5\u8fdb\u884c\u7a33\u5b9a\u7684\u957f\u6587\u672c\u8f93\u51fa\u3002","title":"\u795e\u7ecf\u7f51\u7edc\u8bed\u8a00\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#transformer","text":"Transformer\u6a21\u578b\u7531\u4e00\u4e9b\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5c42\u7ec4\u6210\uff08\u89c1\u56fe\uff09\uff0c\u5b66\u4e60\u590d\u6742\u8bed\u4e49\u4fe1\u606f\u7684\u80fd\u529b\u5f3a\uff0c\u5f88\u591a\u4e3b\u6d41\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u63d0\u53d6\u7279\u5f81\u65f6\u90fd\u4f1a\u9009\u62e9Transformer\u7ed3\u6784\uff0c\u5e76\u4ea7\u751f\u4e86\u4e00\u7cfb\u5217\u7684\u57fa\u4e8eTransformer\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5305\u62ecGPT\u3001BERT\u3001T5\u7b49.\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u4ece\u5927\u91cf\u7684\u901a\u7528\u6587\u672c\u6570\u636e\u4e2d\u5b66\u4e60\u5927\u91cf\u7684\u8bed\u8a00\u8868\u793a\uff0c\u5e76\u5c06\u8fd9\u4e9b\u77e5\u8bc6\u8fd0\u7528\u5230\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u83b7\u5f97\u4e86\u8f83\u597d\u7684\u6548\u679c. \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u4f7f\u7528\u65b9\u5f0f\uff1a 1.\u9884\u8bad\u7ec3\uff1a\u9884\u8bad\u7ec3\u6307\u5efa\u7acb\u57fa\u672c\u7684\u6a21\u578b\uff0c\u5148\u5728\u4e00\u4e9b\u6bd4\u8f83\u57fa\u7840\u7684\u6570\u636e\u96c6\u3001\u8bed\u6599\u5e93\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u7136\u540e\u6309\u7167\u5177\u4f53\u4efb\u52a1\u8bad\u7ec3\uff0c\u5b66\u4e60\u6570\u636e\u7684\u666e\u904d\u7279\u5f81\u3002 2.\u5fae\u8c03\uff1a\u5fae\u8c03\u6307\u5728\u5177\u4f53\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4f7f\u7528\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u8fdb\u884c\u8fc1\u79fb\u5b66\u4e60\uff0c\u4ee5\u83b7\u53d6\u66f4\u597d\u7684\u6cdb\u5316\u6548\u679c\u3002 \u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u66f4\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e30\u5bcc\u7684\u8bed\u4e49\u8868\u793a\uff0c\u53ef\u4ee5\u6709\u6548\u9632\u6b62\u8fc7\u62df\u5408\u3002 \u7f3a\u70b9\uff1a\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u53ef\u89e3\u91ca\u6027\u5dee\u7b49","title":"\u57fa\u4e8eTransformer\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#_3","text":"\u968f\u7740\u5bf9\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u7684\u5f00\u5c55\uff0c\u4eba\u4eec\u9010\u6e10\u53d1\u73b0\u53ef\u80fd\u5b58\u5728\u4e00\u79cd\u6807\u5ea6\u5b9a\u5f8b\uff08Scaling Law\uff09\uff0c\u5373\u968f\u7740\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u7684\u6307\u6570\u7ea7\u63d0\u5347\uff0c\u5176\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u4e5f\u4f1a\u7ebf\u6027\u4e0a\u5347\u30022020\u5e74\uff0cOpenAI\u53d1\u5e03\u4e86\u53c2\u6570\u91cf\u9ad8\u8fbe1750\u4ebf\u7684GPT-3\uff0c\u9996\u6b21\u5c55\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002 \u76f8\u8f83\u4e8e\u6b64\u524d\u7684\u53c2\u6570\u91cf\u8f83\u5c0f\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u4f8b\u5982\uff0c3.3\u4ebf\u53c2\u6570\u7684Bert-large\u548c17\u4ebf\u53c2\u6570\u7684GPT-2\uff0cGPT-3\u5c55\u73b0\u4e86\u5728Few-shot\u8bed\u8a00\u4efb\u52a1\u80fd\u529b\u4e0a\u7684\u98de\u8dc3\uff0c\u5e76\u5177\u5907\u4e86\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0d\u5177\u5907\u7684\u4e00\u4e9b\u80fd\u529b\u3002\u540e\u7eed\u5c06\u8fd9\u79cd\u73b0\u8c61\u79f0\u4e3a\u80fd\u529b\u6d8c\u73b0\u3002\u4f8b\u5982\uff0cGPT-3\u80fd\u8fdb\u884c\u4e0a\u4e0b\u6587\u5b66\u4e60\uff0c\u5728\u4e0d\u8c03\u6574\u6743\u91cd\u7684\u60c5\u51b5\u4e0b\u4ec5\u4f9d\u636e\u7528\u6237\u7ed9\u51fa\u7684\u4efb\u52a1\u793a\u4f8b\u5b8c\u6210\u540e\u7eed\u4efb\u52a1\u3002\u8fd9\u79cd\u80fd\u529b\u65b9\u9762\u7684\u98de\u8dc3\u5f15\u53d1\u7814\u7a76\u754c\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u7814\u7a76\u70ed\u6f6e\uff0c\u5404\u5927\u79d1\u6280\u5de8\u5934\u7eb7\u7eb7\u63a8\u51fa\u53c2\u6570\u91cf\u5de8\u5927\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u4f8b\u5982\uff0cMeta\u516c\u53f81300\u4ebf\u53c2\u6570\u91cf\u7684LLaMA\u6a21\u578b\u4ee5\u53ca\u8c37\u6b4c\u516c\u53f85400\u4ebf\u53c2\u6570\u91cf\u7684PaLM\u3002\u56fd\u5185\u5982\u767e\u5ea6\u63a8\u51fa\u7684\u6587\u5fc3\u4e00\u8a00ERNIE\u7cfb\u5217\u3001\u6e05\u534e\u5927\u5b66\u56e2\u961f\u63a8\u51fa\u7684GLM\u7cfb\u5217\uff0c\u7b49\u7b49\u3002 \u5927\u8bed\u8a00\u6a21\u578b\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a\u50cf\u201c\u4eba\u7c7b\u201d\u4e00\u6837\u667a\u80fd\uff0c\u5177\u5907\u4e86\u80fd\u4e0e\u4eba\u7c7b\u6c9f\u901a\u804a\u5929\u7684\u80fd\u529b\uff0c\u751a\u81f3\u5177\u5907\u4e86\u4f7f\u7528\u63d2\u4ef6\u8fdb\u884c\u81ea\u52a8\u4fe1\u606f\u68c0\u7d22\u7684\u80fd\u529b \u7f3a\u70b9\uff1a\u53c2\u6570\u91cf\u5927\uff0c\u7b97\u529b\u8981\u6c42\u9ad8\u3001\u751f\u6210\u90e8\u5206\u6709\u5bb3\u7684\u3001\u6709\u504f\u89c1\u7684\u5185\u5bb9\u7b49\u7b49","title":"\u5927\u8bed\u8a00\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#_4","text":"","title":"\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u6307\u6807"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#bleu","text":"BLEU\uff1aBLEU \uff08\u53cc\u8bed\u8bc4\u4f30\u66ff\u8865\uff09\u5206\u6570\u662f\u8bc4\u4f30\u4e00\u79cd\u8bed\u8a00\u7ffb\u8bd1\u6210\u53e6\u4e00\u79cd\u8bed\u8a00\u7684\u6587\u672c\u8d28\u91cf\u7684\u6307\u6807\u3002\u5b83\u5c06\u201c\u8d28\u91cf\u201d\u7684\u597d\u574f\u5b9a\u4e49\u4e3a\u4e0e\u4eba\u7c7b\u7ffb\u8bd1\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u7a0b\u5ea6\u3002 BLEU\u7b97\u6cd5\u5b9e\u9645\u4e0a\u5c31\u662f\u5728\u5224\u65ad\u4e24\u4e2a\u53e5\u5b50\u7684\u76f8\u4f3c\u7a0b\u5ea6. BLEU \u7684\u5206\u6570\u53d6\u503c\u8303\u56f4\u662f 0\uff5e1\uff0c\u5206\u6570\u8d8a\u63a5\u8fd11\uff0c\u8bf4\u660e\u7ffb\u8bd1\u7684\u8d28\u91cf\u8d8a\u9ad8\u3002 BLEU\u6709\u8bb8\u591a\u53d8\u79cd\uff0c\u6839\u636e n-gram \u53ef\u4ee5\u5212\u5206\u6210\u591a\u79cd\u8bc4\u4ef7\u6307\u6807\uff0c\u5e38\u89c1\u7684\u8bc4\u4ef7\u6307\u6807\u6709BLEU-1\u3001BLEU-2\u3001BLEU-3\u3001BLEU-4\u56db\u79cd\uff0c\u5176\u4e2d n-gram \u6307\u7684\u662f\u8fde\u7eed\u7684\u5355\u8bcd\u4e2a\u6570\u4e3an\uff0cBLEU-1\u8861\u91cf\u7684\u662f\u5355\u8bcd\u7ea7\u522b\u7684\u51c6\u786e\u6027\uff0c\u66f4\u9ad8\u9636\u7684BLEU\u53ef\u4ee5\u8861\u91cf\u53e5\u5b50\u7684\u6d41\u7545\u6027.\u5b9e\u8df5\u4e2d\uff0c\u901a\u5e38\u662f\u53d6N=1~4\uff0c\u7136\u540e\u5bf9\u8fdb\u884c\u52a0\u6743\u5e73\u5747 \u4e0b\u9762\u4e3e\u4f8b\u8bf4\u8ba1\u7b97\u8fc7\u7a0b\uff1a \u57fa\u672c\u6b65\u9aa4\uff1a \u5206\u522b\u8ba1\u7b97candidate\u53e5\u548creference\u53e5\u7684N-grams\u6a21\u578b\uff0c\u7136\u540e\u7edf\u8ba1\u5176\u5339\u914d\u7684\u4e2a\u6570\uff0c\u8ba1\u7b97\u5339\u914d\u5ea6: \u516c\u5f0f\uff1acandidate\u548creference\u4e2d\u5339\u914d\u7684 n\u2212gram \u7684\u4e2a\u6570 /candidate\u4e2dn\u2212gram \u7684\u4e2a\u6570 \u5047\u8bbe\u673a\u5668\u7ffb\u8bd1\u7684\u8bd1\u6587candidate\u548c\u4e00\u4e2a\u53c2\u8003\u7ffb\u8bd1reference\u5982\u4e0b\uff1a candidate : It is a nice day today reference : Today is a nice day \u4f7f\u75281-gram\u8fdb\u884c\u5339\u914d candidate : {it, is, a, nice, day, today} reference : {today, is, a, nice, day} \u7ed3\u679c : \u5176\u4e2d{today, is, a, nice, day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a5/6 - \u4f7f\u75282-gram\u8fdb\u884c\u5339\u914d candidate : {it is, is a, a nice, nice day, day today} reference : {today is, is a, a nice, nice day} \u7ed3\u679c : \u5176\u4e2d{is a, a nice, nice day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a3/5 \u4f7f\u75283-gram\u8fdb\u884c\u5339\u914d candidate : {it is a, is a nice, a nice day, nice day today} reference : {today is a, is a nice, a nice day} \u7ed3\u679c : \u5176\u4e2d{is a nice, a nice day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a2/4 \u4f7f\u75284-gram\u8fdb\u884c\u5339\u914d candidate : {it is a nice, is a nice day, a nice day today} reference : {today is a nice, is a nice day} \u7ed3\u679c : \u5176\u4e2d{is a nice day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a1/3 \u901a\u8fc7\u4e0a\u9762\u7684\u4f8b\u5b50\u5206\u6790\u53ef\u4ee5\u53d1\u73b0\uff0c\u5339\u914d\u7684\u4e2a\u6570\u8d8a\u591a\uff0cBLEU\u503c\u8d8a\u5927\uff0c\u5219\u8bf4\u660e\u5019\u9009\u53e5\u5b50\u66f4\u597d. \u4f46\u662f\u4e5f\u4f1a\u51fa\u73b0\u4e0b\u9762\u7684\u6781\u7aef\u60c5\u51b5\uff1a \u4e3e\u4f8b\u8bf4\u660e\uff1a candidate : the the the the reference : The cat is standing on the ground \u5982\u679c\u6309\u71671-gram\u7684\u65b9\u6cd5\u8fdb\u884c\u5339\u914d\uff0c\u5219\u5339\u914d\u5ea6\u4e3a1\uff0c\u663e\u7136\u662f\u4e0d\u5408\u7406\u7684\uff0c\u6240\u4ee5\u8ba1\u7b97\u67d0\u4e2a\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\u8fdb\u884c\u6539\u8fdb \u5c06\u8ba1\u7b97\u67d0\u4e2a\u8bcd\u7684\u51fa\u73b0\u6b21\u6570\u7684\u65b9\u6cd5\u6539\u4e3a\u8ba1\u7b97**\u67d0\u4e2a\u8bcd\u5728\u8bd1\u6587\u4e2d\u51fa\u73b0\u7684\u6700\u5c0f\u6b21\u6570**,\u5982\u4e0b\u6240\u793a\u7684\u516c\u5f0f\uff1a count_k=min(c_k,s_k) count_k=min(c_k,s_k) \u5176\u4e2d k k \u8868\u793a\u5728\u673a\u5668\u8bd1\u6587\uff08candidate\uff09\u4e2d\u51fa\u73b0\u7684\u7b2c k k \u4e2a\u8bcd\u8bed, c_k c_k \u5219\u4ee3\u8868\u5728\u673a\u5668\u8bd1\u6587\u4e2d\u8fd9\u4e2a\u8bcd\u8bed\u51fa\u73b0\u7684\u6b21\u6570\uff0c\u800c s_k s_k \u5219\u4ee3\u8868\u5728\u4eba\u5de5\u8bd1\u6587\uff08reference\uff09\u4e2d\u8fd9\u4e2a\u8bcd\u8bed\u51fa\u73b0\u7684\u6b21\u6570\u3002 python\u4ee3\u7801\u5b9e\u73b0\uff1a # \u7b2c\u4e00\u6b65\u5b89\u88c5nltk\u7684\u5305-->pip install nltk from nltk.translate.bleu_score import sentence_bleu def cumulative_bleu ( reference , candidate ): bleu_1_gram = sentence_bleu ( reference , candidate , weights = ( 1 , 0 , 0 , 0 )) bleu_2_gram = sentence_bleu ( reference , candidate , weights = ( 0.5 , 0.5 , 0 , 0 )) bleu_3_gram = sentence_bleu ( reference , candidate , weights = ( 0.33 , 0.33 , 0.33 , 0 )) bleu_4_gram = sentence_bleu ( reference , candidate , weights = ( 0.25 , 0.25 , 0.25 , 0.25 )) # print('bleu 1-gram: %f' % bleu_1_gram) # print('bleu 2-gram: %f' % bleu_2_gram) # print('bleu 3-gram: %f' % bleu_3_gram) # print('bleu 4-gram: %f' % bleu_4_gram) return bleu_1_gram , bleu_2_gram , bleu_3_gram , bleu_4_gram # \u751f\u6210\u6587\u672c generated_text = \"This is some generated text.\" # \u53c2\u8003\u6587\u672c\u5217\u8868 reference_texts = [ \"This is a reference text.\" , \"This is another reference text.\" ] # \u8ba1\u7b97 Bleu \u6307\u6807 c_bleu = cumulative_bleu ( reference_texts , generated_text ) # \u6253\u5370\u7ed3\u679c print ( \"The Bleu score is:\" , c_bleu ) # The Bleu score is: (0.8571, 0.6900, 0.5711, 0.4920)","title":"BLEU"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#rouge","text":"ROUGE\u6307\u6807\u662f\u5728\u673a\u5668\u7ffb\u8bd1\u3001\u81ea\u52a8\u6458\u8981\u3001\u95ee\u7b54\u751f\u6210\u7b49\u9886\u57df\u5e38\u89c1\u7684\u8bc4\u4f30\u6307\u6807\u3002ROUGE\u901a\u8fc7\u5c06\u6a21\u578b\u751f\u6210\u7684\u6458\u8981\u6216\u8005\u56de\u7b54\u4e0e\u53c2\u8003\u7b54\u6848\uff08\u4e00\u822c\u662f\u4eba\u5de5\u751f\u6210\u7684\uff09\u8fdb\u884c\u6bd4\u8f83\u8ba1\u7b97\uff0c\u5f97\u5230\u5bf9\u5e94\u7684\u5f97\u5206\u3002 ROUGE\u6307\u6807\u4e0eBLEU\u6307\u6807\u975e\u5e38\u7c7b\u4f3c\uff0c\u5747\u53ef\u7528\u6765\u8861\u91cf\u751f\u6210\u7ed3\u679c\u548c\u6807\u51c6\u7ed3\u679c\u7684\u5339\u914d\u7a0b\u5ea6\uff0c\u4e0d\u540c\u7684\u662fROUGE\u57fa\u4e8e\u53ec\u56de\u7387\uff0cBLEU\u66f4\u770b\u91cd\u51c6\u786e\u7387\u3002 ROUGE\u5206\u4e3a\u56db\u79cd\u65b9\u6cd5\uff1aROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S. \u4e0b\u9762\u4e3e\u4f8b\u8bf4\u8ba1\u7b97\u8fc7\u7a0b\uff08\u8fd9\u91cc\u53ea\u4ecb\u7ecdROUGE_N\uff09\uff1a \u57fa\u672c\u6b65\u9aa4\uff1a Rouge-N\u5b9e\u9645\u4e0a\u662f\u5c06\u6a21\u578b\u751f\u6210\u7684\u7ed3\u679c\u548c\u6807\u51c6\u7ed3\u679c\u6309N-gram\u62c6\u5206\u540e\uff0c\u8ba1\u7b97\u53ec\u56de\u7387 \u5047\u8bbe\u6a21\u578b\u751f\u6210\u7684\u6587\u672ccandidate\u548c\u4e00\u4e2a\u53c2\u8003\u6587\u672creference\u5982\u4e0b\uff1a candidate : It is a nice day today reference : Today is a nice day \u4f7f\u7528ROUGE-1\u8fdb\u884c\u5339\u914d candidate : {it, is, a, nice, day, today} reference : {today, is, a, nice, day} \u7ed3\u679c : : \u5176\u4e2d{today, is, a, nice, day}\u5339\u914d\uff0c\u6240\u4ee5\u5339\u914d\u5ea6\u4e3a5/5=1,\u8fd9\u8bf4\u660e\u751f\u6210\u7684\u5185\u5bb9\u5b8c\u5168\u8986\u76d6\u4e86\u53c2\u8003\u6587\u672c\u4e2d\u7684\u6240\u6709\u5355\u8bcd\uff0c\u8d28\u91cf\u8f83\u9ad8\u3002 \u901a\u8fc7\u7c7b\u4f3c\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u8ba1\u7b97\u51fa\u5176\u4ed6ROUGE\u6307\u6807\uff08\u5982ROUGE-2\u3001ROUGE-L\u3001ROUGE-S\uff09\u7684\u8bc4\u5206\uff0c\u4ece\u800c\u7efc\u5408\u8bc4\u4f30\u7cfb\u7edf\u751f\u6210\u7684\u6587\u672c\u8d28\u91cf\u3002 python\u4ee3\u7801\u5b9e\u73b0\uff1a # \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5rouge-->pip install rouge import Rouge # \u751f\u6210\u6587\u672c generated_text = \"This is some generated text.\" # \u53c2\u8003\u6587\u672c\u5217\u8868 reference_texts = [ \"This is a reference text.\" , \"This is another generated reference text.\" ] # \u8ba1\u7b97 ROUGE \u6307\u6807 rouge = Rouge () scores = rouge . get_scores ( generated_text , reference_texts [ 1 ]) # \u6253\u5370\u7ed3\u679c print ( \"ROUGE-1 precision:\" , scores [ 0 ][ \"rouge-1\" ][ \"p\" ]) print ( \"ROUGE-1 recall:\" , scores [ 0 ][ \"rouge-1\" ][ \"r\" ]) print ( \"ROUGE-1 F1 score:\" , scores [ 0 ][ \"rouge-1\" ][ \"f\" ]) # ROUGE-1 precision: 0.8 # ROUGE-1 recall: 0.6666666666666666 # ROUGE-1 F1 score: 0.7272727223140496","title":"ROUGE"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#pplperplexity","text":"PPL\u7528\u6765\u5ea6\u91cf\u4e00\u4e2a\u6982\u7387\u5206\u5e03\u6216\u6982\u7387\u6a21\u578b\u9884\u6d4b\u6837\u672c\u7684\u597d\u574f\u7a0b\u5ea6\u3002 PPL\u57fa\u672c\u601d\u60f3: \u7ed9\u6d4b\u8bd5\u96c6\u7684\u53e5\u5b50\u8d4b\u4e88\u8f83\u9ad8\u6982\u7387\u503c\u7684\u8bed\u8a00\u6a21\u578b\u8f83\u597d,\u5f53\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u5b8c\u4e4b\u540e\uff0c\u6d4b\u8bd5\u96c6\u4e2d\u7684\u53e5\u5b50\u90fd\u662f\u6b63\u5e38\u7684\u53e5\u5b50\uff0c\u90a3\u4e48\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5c31\u662f\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6982\u7387\u8d8a\u9ad8\u8d8a\u597d. \u57fa\u672c\u516c\u5f0f\uff08\u4e24\u79cd\u65b9\u5f0f\uff09\uff1a \u7531\u516c\u5f0f\u53ef\u77e5\uff0c \u53e5\u5b50\u6982\u7387\u8d8a\u5927\uff0c\u8bed\u8a00\u6a21\u578b\u8d8a\u597d\uff0c\u8ff7\u60d1\u5ea6\u8d8a\u5c0f\u3002 python\u4ee3\u7801\u5b9e\u73b0\uff1a import math # \u5b9a\u4e49\u8bed\u6599\u5e93 sentences = [ [ 'I' , 'have' , 'a' , 'pen' ], [ 'He' , 'has' , 'a' , 'book' ], [ 'She' , 'has' , 'a' , 'cat' ] ] # \u5b9a\u4e49\u8bed\u8a00\u6a21\u578b unigram = { 'I' : 1 / 11 , 'have' : 1 / 11 , 'a' : 3 / 11 , 'pen' : 1 / 11 , 'He' : 1 / 11 , 'has' : 2 / 11 , 'book' : 1 / 11 , 'She' : 1 / 11 , 'cat' : 1 / 11 } # \u8ba1\u7b97\u56f0\u60d1\u5ea6 perplexity = 0 for sentence in sentences : sentence_prob = 1 for word in sentence : sentence_prob *= unigram [ word ] temp = - math . log ( sentence_prob , 2 ) / len ( sentence ) perplexity += 2 ** temp perplexity = perplexity / len ( sentences ) print ( '\u56f0\u60d1\u5ea6\u4e3a\uff1a' , perplexity ) # \u56f0\u60d1\u5ea6\u4e3a\uff1a 7.47","title":"\u56f0\u60d1\u5ea6PPL(perplexity)"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/01-LLM%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86.html#_5","text":"\u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecdLLM\u7684\u80cc\u666f\u77e5\u8bc6\uff0c\u4e86\u89e3\u76ee\u524dLLM\u53d1\u5c55\u57fa\u672c\u5386\u7a0b \u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u7c7b\u522b\u5206\u522b\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u5982\u57fa\u4e8e\u7edf\u8ba1\u7684N-gram\u6a21\u578b\uff0c\u4ee5\u53ca\u6df1\u5ea6\u5b66\u4e60\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html","text":"LLM\u4e3b\u8981\u7c7b\u522b\u67b6\u6784\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3LLM\u4e3b\u8981\u7c7b\u522b\u67b6\u6784. \u638c\u63e1BERT\u3001GPT\u3001T5\u7b49\u6a21\u578b\u539f\u7406 LLM\u4e3b\u8981\u7c7b\u522b \u00b6 LLM\u672c\u8eab\u57fa\u4e8etransformer\u67b6\u6784\u3002\u81ea2017\u5e74\uff0cattention is all you need\u8bde\u751f\u8d77\uff0c\u539f\u59cb\u7684transformer\u6a21\u578b\u4e3a\u4e0d\u540c\u9886\u57df\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u7075\u611f\u548c\u542f\u53d1\u3002\u57fa\u4e8e\u539f\u59cb\u7684Transformer\u6846\u67b6\uff0c\u884d\u751f\u51fa\u4e86\u4e00\u7cfb\u5217\u6a21\u578b\uff0c\u4e00\u4e9b\u6a21\u578b\u4ec5\u4ec5\u4f7f\u7528encoder\u6216decoder\uff0c\u6709\u4e9b\u6a21\u578b\u540c\u65f6\u4f7f\u7528encoder+decoder\u3002 LLM\u5206\u7c7b\u4e00\u822c\u5206\u4e3a\u4e09\u79cd\uff1a\u81ea\u7f16\u7801\u6a21\u578b\uff08encoder\uff09\u3001\u81ea\u56de\u5f52\u6a21\u578b(decoder)\u548c\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b(encoder-decoder)\u3002 \u81ea\u7f16\u7801\u6a21\u578b (AutoEncoder model\uff0cAE) \u00b6 AE\u6a21\u578b\uff0c\u4ee3\u8868\u4f5cBERT\uff0c\u5176\u7279\u70b9\u4e3a\uff1aEncoder-Only, \u57fa\u672c\u539f\u7406\uff1a\u662f\u5728\u8f93\u5165\u4e2d\u968f\u673aMASK\u6389\u4e00\u90e8\u5206\u5355\u8bcd\uff0c\u6839\u636e\u4e0a\u4e0b\u6587\u9884\u6d4b\u8fd9\u4e2a\u8bcd\u3002AE\u6a21\u578b\u901a\u5e38\u7528\u4e8e\u5185\u5bb9\u7406\u89e3\u4efb\u52a1\uff0c\u6bd4\u5982\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff08NLU\uff09\u4e2d\u7684\u5206\u7c7b\u4efb\u52a1\uff1a\u60c5\u611f\u5206\u6790\u3001\u63d0\u53d6\u5f0f\u95ee\u7b54\u3002 1. \u4ee3\u8868\u6a21\u578b BERT \u00b6 BERT\u662f2018\u5e7410\u6708\u7531Google AI\u7814\u7a76\u9662\u63d0\u51fa\u7684\u4e00\u79cd\u9884\u8bad\u7ec3\u6a21\u578b. BERT\u7684\u5168\u79f0\u662fBidirectional Encoder Representation from Transformers. BERT\u5728\u673a\u5668\u9605\u8bfb\u7406\u89e3\u9876\u7ea7\u6c34\u5e73\u6d4b\u8bd5SQuAD1.1\u4e2d\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u6210\u7ee9: \u5168\u90e8\u4e24\u4e2a\u8861\u91cf\u6307\u6807\u4e0a\u5168\u9762\u8d85\u8d8a\u4eba\u7c7b, \u5e76\u4e14\u572811\u79cd\u4e0d\u540cNLP\u6d4b\u8bd5\u4e2d\u521b\u51faSOTA\u8868\u73b0. \u5305\u62ec\u5c06GLUE\u57fa\u51c6\u63a8\u9ad8\u81f380.4% (\u7edd\u5bf9\u6539\u8fdb7.6%), MultiNLI\u51c6\u786e\u5ea6\u8fbe\u523086.7% (\u7edd\u5bf9\u6539\u8fdb5.6%). \u6210\u4e3aNLP\u53d1\u5c55\u53f2\u4e0a\u7684\u91cc\u7a0b\u7891\u5f0f\u7684\u6a21\u578b\u6210\u5c31. 1.1 BERT\u7684\u67b6\u6784 \u00b6 \u603b\u4f53\u67b6\u6784: \u5982\u4e0b\u56fe\u6240\u793a, \u6700\u5de6\u8fb9\u7684\u5c31\u662fBERT\u7684\u67b6\u6784\u56fe, \u53ef\u4ee5\u5f88\u6e05\u695a\u7684\u770b\u5230BERT\u91c7\u7528\u4e86Transformer Encoder block\u8fdb\u884c\u8fde\u63a5, \u56e0\u4e3a\u662f\u4e00\u4e2a\u5178\u578b\u7684\u53cc\u5411\u7f16\u7801\u6a21\u578b. \u4ece\u4e0a\u9762\u7684\u67b6\u6784\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230, \u5b8f\u89c2\u4e0aBERT\u5206\u4e09\u4e2a\u4e3b\u8981\u6a21\u5757: \u6700\u5e95\u5c42\u9ec4\u8272\u6807\u8bb0\u7684Embedding\u6a21\u5757. \u4e2d\u95f4\u5c42\u84dd\u8272\u6807\u8bb0\u7684Transformer\u6a21\u5757. \u6700\u4e0a\u5c42\u7eff\u8272\u6807\u8bb0\u7684\u9884\u5fae\u8c03\u6a21\u5757. 1.2 Embedding\u6a21\u5757 \u00b6 BERT\u4e2d\u7684\u8be5\u6a21\u5757\u662f\u7531\u4e09\u79cdEmbedding\u5171\u540c\u7ec4\u6210\u800c\u6210, \u5982\u4e0b\u56fe Token Embeddings \u662f\u8bcd\u5d4c\u5165\u5f20\u91cf, \u7b2c\u4e00\u4e2a\u5355\u8bcd\u662fCLS\u6807\u5fd7, \u53ef\u4ee5\u7528\u4e8e\u4e4b\u540e\u7684\u5206\u7c7b\u4efb\u52a1. Segment Embeddings \u662f\u53e5\u5b50\u5206\u6bb5\u5d4c\u5165\u5f20\u91cf, \u662f\u4e3a\u4e86\u670d\u52a1\u540e\u7eed\u7684\u4e24\u4e2a\u53e5\u5b50\u4e3a\u8f93\u5165\u7684\u9884\u8bad\u7ec3\u4efb\u52a1. Position Embeddings \u662f\u4f4d\u7f6e\u7f16\u7801\u5f20\u91cf, \u6b64\u5904\u6ce8\u610f\u548c\u4f20\u7edf\u7684Transformer\u4e0d\u540c, \u4e0d\u662f\u4e09\u89d2\u51fd\u6570\u8ba1\u7b97\u7684\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801, \u800c\u662f\u901a\u8fc7\u5b66\u4e60\u5f97\u51fa\u6765\u7684. \u6574\u4e2aEmbedding\u6a21\u5757\u7684\u8f93\u51fa\u5f20\u91cf\u5c31\u662f\u8fd93\u4e2a\u5f20\u91cf\u7684\u76f4\u63a5\u52a0\u548c\u7ed3\u679c. 1.3 \u53cc\u5411Transformer\u6a21\u5757 \u00b6 BERT\u4e2d\u53ea\u4f7f\u7528\u4e86\u7ecf\u5178Transformer\u67b6\u6784\u4e2d\u7684Encoder\u90e8\u5206, \u5b8c\u5168\u820d\u5f03\u4e86Decoder\u90e8\u5206. \u800c\u4e24\u5927\u9884\u8bad\u7ec3\u4efb\u52a1\u4e5f\u96c6\u4e2d\u4f53\u73b0\u5728\u8bad\u7ec3Transformer\u6a21\u5757\u4e2d. 1.4 \u9884\u5fae\u8c03\u6a21\u5757 \u00b6 \u7ecf\u8fc7\u4e2d\u95f4\u5c42Transformer\u7684\u5904\u7406\u540e, BERT\u7684\u6700\u540e\u4e00\u5c42\u6839\u636e\u4efb\u52a1\u7684\u4e0d\u540c\u9700\u6c42\u800c\u505a\u4e0d\u540c\u7684\u8c03\u6574\u5373\u53ef. \u6bd4\u5982\u5bf9\u4e8esequence-level\u7684\u5206\u7c7b\u4efb\u52a1, BERT\u76f4\u63a5\u53d6\u7b2c\u4e00\u4e2a[CLS] token \u7684final hidden state, \u518d\u52a0\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u540e\u8fdb\u884csoftmax\u6765\u9884\u6d4b\u6700\u7ec8\u7684\u6807\u7b7e. \u5bf9\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1, \u5fae\u8c03\u90fd\u96c6\u4e2d\u5728\u9884\u5fae\u8c03\u6a21\u5757, \u51e0\u79cd\u91cd\u8981\u7684NLP\u5fae\u8c03\u4efb\u52a1\u67b6\u6784\u56fe\u5c55\u793a\u5982\u4e0b \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0, \u5728\u9762\u5bf9\u7279\u5b9a\u4efb\u52a1\u65f6, \u53ea\u9700\u8981\u5bf9\u9884\u5fae\u8c03\u5c42\u8fdb\u884c\u5fae\u8c03, \u5c31\u53ef\u4ee5\u5229\u7528Transformer\u5f3a\u5927\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u6a21\u62df\u5f88\u591a\u4e0b\u6e38\u4efb\u52a1, \u5e76\u5f97\u5230SOTA\u7684\u7ed3\u679c. (\u53e5\u5b50\u5bf9\u5173\u7cfb\u5224\u65ad, \u5355\u6587\u672c\u4e3b\u9898\u5206\u7c7b, \u95ee\u7b54\u4efb\u52a1(QA), \u5355\u53e5\u8d34\u6807\u7b7e(NER)) \u82e5\u5e72\u53ef\u9009\u7684\u8d85\u53c2\u6570\u5efa\u8bae\u5982\u4e0b: Batch size: 16, 32 Learning rate (Adam): 5e-5, 3e-5, 2e-5 Epochs: 3, 4 1.5 BERT\u7684\u9884\u8bad\u7ec3\u4efb\u52a1 \u00b6 BERT\u5305\u542b\u4e24\u4e2a\u9884\u8bad\u7ec3\u4efb\u52a1: \u4efb\u52a1\u4e00: Masked LM (\u5e26mask\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3) \u4efb\u52a1\u4e8c: Next Sentence Prediction (\u4e0b\u4e00\u53e5\u8bdd\u9884\u6d4b\u4efb\u52a1) 1.5.1 \u4efb\u52a1\u4e00: Masked LM \u00b6 \u5e26mask\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3 \u5173\u4e8e\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3, \u90fd\u662f\u91c7\u7528left-to-right, \u6216\u8005left-to-right + right-to-left\u7ed3\u5408\u7684\u65b9\u5f0f, \u4f46\u8fd9\u79cd\u5355\u5411\u65b9\u5f0f\u6216\u8005\u62fc\u63a5\u7684\u65b9\u5f0f\u63d0\u53d6\u7279\u5f81\u7684\u80fd\u529b\u6709\u9650. \u4e3a\u6b64BERT\u63d0\u51fa\u4e00\u4e2a\u6df1\u5ea6\u53cc\u5411\u8868\u8fbe\u6a21\u578b(deep bidirectional representation). \u5373\u91c7\u7528MASK\u4efb\u52a1\u6765\u8bad\u7ec3\u6a21\u578b. 1: \u5728\u539f\u59cb\u8bad\u7ec3\u6587\u672c\u4e2d, \u968f\u673a\u7684\u62bd\u53d615%\u7684token\u4f5c\u4e3a\u53c2\u4e0eMASK\u4efb\u52a1\u7684\u5bf9\u8c61. 2: \u5728\u8fd9\u4e9b\u88ab\u9009\u4e2d\u7684token\u4e2d, \u6570\u636e\u751f\u6210\u5668\u5e76\u4e0d\u662f\u628a\u5b83\u4eec\u5168\u90e8\u53d8\u6210[MASK], \u800c\u662f\u6709\u4e0b\u52173\u79cd\u60c5\u51b5. 2.1: \u572880%\u7684\u6982\u7387\u4e0b, \u7528[MASK]\u6807\u8bb0\u66ff\u6362\u8be5token, \u6bd4\u5982my dog is hairy -> my dog is [MASK] 2.2: \u572810%\u7684\u6982\u7387\u4e0b, \u7528\u4e00\u4e2a\u968f\u673a\u7684\u5355\u8bcd\u66ff\u6362token, \u6bd4\u5982my dog is hairy -> my dog is apple 2.3: \u572810%\u7684\u6982\u7387\u4e0b, \u4fdd\u6301\u8be5token\u4e0d\u53d8, \u6bd4\u5982my dog is hairy -> my dog is hairy 3: \u6a21\u578b\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d, \u5e76\u4e0d\u77e5\u9053\u5b83\u5c06\u8981\u9884\u6d4b\u54ea\u4e9b\u5355\u8bcd? \u54ea\u4e9b\u5355\u8bcd\u662f\u539f\u59cb\u7684\u6837\u5b50? \u54ea\u4e9b\u5355\u8bcd\u88ab\u906e\u63a9\u6210\u4e86[MASK]? \u54ea\u4e9b\u5355\u8bcd\u88ab\u66ff\u6362\u6210\u4e86\u5176\u4ed6\u5355\u8bcd? \u6b63\u662f\u5728\u8fd9\u6837\u4e00\u79cd\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b, \u53cd\u5012\u903c\u7740\u6a21\u578b\u5feb\u901f\u5b66\u4e60\u8be5token\u7684\u5206\u5e03\u5f0f\u4e0a\u4e0b\u6587\u7684\u8bed\u4e49, \u5c3d\u6700\u5927\u52aa\u529b\u5b66\u4e60\u539f\u59cb\u8bed\u8a00\u8bf4\u8bdd\u7684\u6837\u5b50. \u540c\u65f6\u56e0\u4e3a\u539f\u59cb\u6587\u672c\u4e2d\u53ea\u670915%\u7684token\u53c2\u4e0e\u4e86MASK\u64cd\u4f5c, \u5e76\u4e0d\u4f1a\u7834\u574f\u539f\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u548c\u8bed\u8a00\u89c4\u5219. 1.5.2 \u4efb\u52a1\u4e8c: Next Sentence Prediction \u00b6 \u4e0b\u4e00\u53e5\u8bdd\u9884\u6d4b\u4efb\u52a1 \u5728NLP\u4e2d\u6709\u4e00\u7c7b\u91cd\u8981\u7684\u95ee\u9898\u6bd4\u5982QA(Quention-Answer), NLI(Natural Language Inference), \u9700\u8981\u6a21\u578b\u80fd\u591f\u5f88\u597d\u7684\u7406\u89e3\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u5173\u7cfb, \u4ece\u800c\u9700\u8981\u5728\u6a21\u578b\u7684\u8bad\u7ec3\u4e2d\u5f15\u5165\u5bf9\u5e94\u7684\u4efb\u52a1. \u5728BERT\u4e2d\u5f15\u5165\u7684\u5c31\u662fNext Sentence Prediction\u4efb\u52a1. \u91c7\u7528\u7684\u65b9\u5f0f\u662f\u8f93\u5165\u53e5\u5b50\u5bf9(A, B), \u6a21\u578b\u6765\u9884\u6d4b\u53e5\u5b50B\u662f\u4e0d\u662f\u53e5\u5b50A\u7684\u771f\u5b9e\u7684\u4e0b\u4e00\u53e5\u8bdd. 1: \u6240\u6709\u53c2\u4e0e\u4efb\u52a1\u8bad\u7ec3\u7684\u8bed\u53e5\u90fd\u88ab\u9009\u4e2d\u4f5c\u4e3a\u53e5\u5b50A. 1.1: \u5176\u4e2d50%\u7684B\u662f\u539f\u59cb\u6587\u672c\u4e2d\u771f\u5b9e\u8ddf\u968fA\u7684\u4e0b\u4e00\u53e5\u8bdd. (\u6807\u8bb0\u4e3aIsNext, \u4ee3\u8868\u6b63\u6837\u672c) 1.2: \u5176\u4e2d50%\u7684B\u662f\u539f\u59cb\u6587\u672c\u4e2d\u968f\u673a\u62bd\u53d6\u7684\u4e00\u53e5\u8bdd. (\u6807\u8bb0\u4e3aNotNext, \u4ee3\u8868\u8d1f\u6837\u672c) 2: \u5728\u4efb\u52a1\u4e8c\u4e2d, BERT\u6a21\u578b\u53ef\u4ee5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f9797%-98%\u7684\u51c6\u786e\u7387. 1.6 \u6570\u636e\u96c6 \u00b6 BooksCorpus (800M words) + English Wikipedia (2,500M words) 1.7 BERT\u6a21\u578b\u7684\u7279\u70b9 \u00b6 \u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 12 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 1.15 \u4ebf 2. AE\u6a21\u578b\u603b\u7ed3 \u00b6 \u4f18\u70b9\uff1aBERT\u4f7f\u7528\u53cc\u5411transformer\uff0c\u5728\u8bed\u8a00\u7406\u89e3\u76f8\u5173\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u5f88\u597d\u3002 \u7f3a\u70b9\uff1a \u8f93\u5165\u566a\u58f0\uff1aBERT\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u3010mask\u3011\u7b26\u53f7\u5bf9\u8f93\u5165\u8fdb\u884c\u5904\u7406\uff0c\u8fd9\u4e9b\u7b26\u53f7\u5728\u4e0b\u6e38\u7684finetune\u4efb\u52a1\u4e2d\u6c38\u8fdc\u4e0d\u4f1a\u51fa\u73b0\uff0c\u8fd9\u4f1a\u5bfc\u81f4**\u9884\u8bad\u7ec3-\u5fae\u8c03\u5dee\u5f02**\u3002\u800cAR\u6a21\u578b\u4e0d\u4f1a\u4f9d\u8d56\u4e8e\u4efb\u4f55\u88abmask\u7684\u8f93\u5165\uff0c\u56e0\u6b64\u4e0d\u4f1a\u9047\u5230\u8fd9\u7c7b\u95ee\u9898\u3002 \u66f4\u9002\u5408\u7528\u4e8e\u8bed\u8a00\u5d4c\u5165\u8868\u8fbe, \u8bed\u8a00\u7406\u89e3\u65b9\u9762\u7684\u4efb\u52a1, \u4e0d\u9002\u5408\u7528\u4e8e\u751f\u6210\u5f0f\u7684\u4efb\u52a1 \u81ea\u56de\u5f52\u6a21\u578b (Autoregressive model\uff0cAR) \u00b6 AR\u6a21\u578b\uff0c\u4ee3\u8868\u4f5cGPT\uff0c\u5176\u7279\u70b9\u4e3a\uff1aDecoder-Only\uff0c\u57fa\u672c\u539f\u7406\uff1a\u4ece\u5de6\u5f80\u53f3\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u53ea\u80fd\u5229\u7528\u4e0a\u6587\u6216\u8005\u4e0b\u6587\u7684\u4fe1\u606f\uff0c\u6bd4\u5982\uff1aAR\u6a21\u578b\u4ece\u4e00\u7cfb\u5217time steps\u4e2d\u5b66\u4e60\uff0c\u5e76\u5c06\u4e0a\u4e00\u6b65\u7684\u7ed3\u679c\u4f5c\u4e3a\u56de\u5f52\u6a21\u578b\u7684\u8f93\u5165\uff0c\u4ee5\u9884\u6d4b\u4e0b\u4e00\u4e2atime step\u7684\u503c\u3002AR\u6a21\u578b\u901a\u5e38\u7528\u4e8e\u751f\u6210\u5f0f\u4efb\u52a1\uff0c\u5728\u957f\u6587\u672c\u7684\u751f\u6210\u80fd\u529b\u5f88\u5f3a\uff0c\u6bd4\u5982\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u9886\u57df\u7684\u4efb\u52a1\uff1a\u6458\u8981\u3001\u7ffb\u8bd1\u6216\u62bd\u8c61\u95ee\u7b54\u3002 1. \u4ee3\u8868\u6a21\u578b GPT \u00b6 2018\u5e746\u6708, OpenAI\u516c\u53f8\u53d1\u8868\u4e86\u8bba\u6587\u201cImproving Language Understanding by Generative Pre-training\u201d\u300a\u7528\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u63d0\u9ad8\u6a21\u578b\u7684\u8bed\u8a00\u7406\u89e3\u529b\u300b, \u63a8\u51fa\u4e86\u5177\u67091.17\u4ebf\u4e2a\u53c2\u6570\u7684GPT\uff08Generative Pre-training , \u751f\u6210\u5f0f\u9884\u8bad\u7ec3\uff09\u6a21\u578b. \u4e0eBERT\u6700\u5927\u7684\u533a\u522b\u5728\u4e8eGPT\u91c7\u7528\u4e86\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u8fdb\u884c\u9884\u8bad\u7ec3, \u5373\u4f7f\u7528\u5355\u8bcd\u7684\u4e0a\u6587\u6765\u9884\u6d4b\u5355\u8bcd, \u800cBERT\u662f\u91c7\u7528\u4e86\u53cc\u5411\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\u5171\u540c\u6765\u9884\u6d4b\u5355\u8bcd.\u6b63\u662f\u56e0\u4e3a\u8bad\u7ec3\u65b9\u6cd5\u4e0a\u7684\u533a\u522b, \u4f7f\u5f97GPT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4efb\u52a1(NLG), \u800cBERT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1(NLU). 1.1 GPT\u6a21\u578b\u67b6\u6784 \u00b6 \u770b\u4e09\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6bd4\u67b6\u6784\u56fe, \u4e2d\u95f4\u7684\u5c31\u662fGPT: \u4ece\u4e0a\u56fe\u53ef\u4ee5\u5f88\u6e05\u695a\u7684\u770b\u5230GPT\u91c7\u7528\u7684\u662f\u5355\u5411Transformer\u6a21\u578b, \u4f8b\u5982\u7ed9\u5b9a\u4e00\u4e2a\u53e5\u5b50[u1, u2, ..., un], GPT\u5728\u9884\u6d4b\u5355\u8bcdui\u7684\u65f6\u5019\u53ea\u4f1a\u5229\u7528[u1, u2, ..., u(i-1)]\u7684\u4fe1\u606f, \u800cBERT\u4f1a\u540c\u65f6\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f[u1, u2, ..., u(i-1), u(i+1), ..., un]. \u4f5c\u4e3a\u4e24\u5927\u6a21\u578b\u7684\u76f4\u63a5\u5bf9\u6bd4, BERT\u91c7\u7528\u4e86Transformer\u7684Encoder\u6a21\u5757, \u800cGPT\u91c7\u7528\u4e86Transformer\u7684Decoder\u6a21\u5757. \u5e76\u4e14GPT\u7684Decoder Block\u548c\u7ecf\u5178Transformer Decoder Block\u8fd8\u6709\u6240\u4e0d\u540c, \u5982\u4e0b\u56fe\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, \u7ecf\u5178\u7684Transformer Decoder Block\u5305\u542b3\u4e2a\u5b50\u5c42, \u5206\u522b\u662fMasked Multi-Head Attention\u5c42, encoder-decoder attention\u5c42, \u4ee5\u53caFeed Forward\u5c42. \u4f46\u662f\u5728GPT\u4e2d\u53d6\u6d88\u4e86\u7b2c\u4e8c\u4e2aencoder-decoder attention\u5b50\u5c42, \u53ea\u4fdd\u7559Masked Multi-Head Attention\u5c42, \u548cFeed Forward\u5c42. \u6ce8\u610f: \u5bf9\u6bd4\u4e8e\u7ecf\u5178\u7684Transformer\u67b6\u6784, \u89e3\u7801\u5668\u6a21\u5757\u91c7\u7528\u4e866\u4e2aDecoder Block; GPT\u7684\u67b6\u6784\u4e2d\u91c7\u7528\u4e8612\u4e2aDecoder Block. 1.2 GPT\u8bad\u7ec3\u8fc7\u7a0b \u00b6 GPT\u7684\u8bad\u7ec3\u5305\u62ec\u4e24\u9636\u6bb5\u8fc7\u7a0b: \u9884\u8bad\u7ec3 + \u5fae\u8c03 \u7b2c\u4e00\u9636\u6bb5: \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b. \u7b2c\u4e8c\u9636\u6bb5: \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning. 1.2.1 \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b \u00b6 \u7ed9\u5b9a\u53e5\u5b50U = [u1, u2, ..., un], GPT\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u4f3c\u7136\u51fd\u6570: L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) \u4e0a\u8ff0\u516c\u5f0f\u5177\u4f53\u6765\u8bf4\u662f\u8981\u9884\u6d4b\u6bcf\u4e2a\u8bcdui\u7684\u6982\u7387\uff0c\u8fd9\u4e2a\u6982\u7387\u662f\u57fa\u4e8e\u5b83\u524d\u9762 ui-k \u5230 ui\u22121 \u4e2a\u8bcd\uff0c\u4ee5\u53ca\u6a21\u578b \u0398\u3002\u8fd9\u91cc\u7684 k \u8868\u793a\u4e0a\u6587\u7684\u7a97\u53e3\u5927\u5c0f\uff0c\u7406\u8bba\u4e0a\u6765\u8bb2 k \u53d6\u7684\u8d8a\u5927\uff0c\u6a21\u578b\u6240\u80fd\u83b7\u53d6\u7684\u4e0a\u6587\u4fe1\u606f\u8d8a\u5145\u8db3\uff0c\u6a21\u578b\u7684\u80fd\u529b\u8d8a\u5f3a\u3002 GPT\u662f\u4e00\u4e2a\u5355\u5411\u8bed\u8a00\u6a21\u578b,\u6a21\u578b\u5bf9\u8f93\u5165U \u8fdb\u884c\u7279\u5f81\u5d4c\u5165\u5f97\u5230 transformer \u7b2c\u4e00\u5c42\u7684\u8f93h0\uff0c\u518d\u7ecf\u8fc7\u591a\u5c42 transformer \u7279\u5f81\u7f16\u7801\uff0c\u4f7f\u7528\u6700\u540e\u4e00\u5c42\u7684\u8f93\u51fa\u5373\u53ef\u5f97\u5230\u5f53\u524d\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff0c\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\uff1a h_0 = UW_e + W_p h_0 = UW_e + W_p \u5176\u4e2dWp\u662f\u5355\u8bcd\u7684\u4f4d\u7f6e\u7f16\u7801, We\u662f\u5355\u8bcd\u672c\u8eab\u7684word embedding. Wp\u7684\u5f62\u72b6\u662f[max_seq_len, embedding_dim], We\u7684\u5f62\u72b6\u662f[vocab_size, embedding_dim]. \u5f97\u5230\u8f93\u5165\u5f20\u91cfh0\u540e, \u8981\u5c06h0\u4f20\u5165GPT\u7684Decoder Block\u4e2d, \u4f9d\u6b21\u5f97\u5230ht: h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] \u6700\u540e\u901a\u8fc7\u5f97\u5230\u7684ht\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5355\u8bcd: P(u)=softmax(h_tW_e^T) P(u)=softmax(h_tW_e^T) 1.2.2 \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning \u00b6 GPT\u7ecf\u8fc7\u9884\u8bad\u7ec3\u540e, \u4f1a\u9488\u5bf9\u5177\u4f53\u7684\u4e0b\u6e38\u4efb\u52a1\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03. \u5fae\u8c03\u91c7\u7528\u7684\u662f\u6709\u76d1\u7763\u5b66\u4e60, \u8bad\u7ec3\u6837\u672c\u5305\u62ec\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u548clabel y. GPT\u5fae\u8c03\u7684\u76ee\u6807\u4efb\u52a1\u662f\u6839\u636e\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u9884\u6d4b\u6807\u7b7ey. P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) \u5176\u4e2d W_y W_y \u8868\u793a\u9884\u6d4b\u8f93\u51fa\u7684\u77e9\u9635\u53c2\u6570, \u5fae\u8c03\u4efb\u52a1\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u51fd\u6570: L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) \u7efc\u5408\u4e24\u4e2a\u9636\u6bb5\u7684\u76ee\u6807\u4efb\u52a1\u51fd\u6570, \u53ef\u77e5GPT\u7684\u6700\u7ec8\u4f18\u5316\u51fd\u6570\u4e3a: L_3 = L_2 + \\lambda L_1 L_3 = L_2 + \\lambda L_1 1.2.3 \u6574\u4f53\u8bad\u7ec3\u8fc7\u7a0b\u67b6\u6784\u56fe \u00b6 \u6839\u636e\u4e0b\u6e38\u4efb\u52a1\u9002\u914d\u7684\u8fc7\u7a0b\u5206\u4e24\u6b65: 1\u3001\u6839\u636e\u4efb\u52a1\u5b9a\u4e49\u4e0d\u540c\u8f93\u5165, 2\u3001\u5bf9\u4e0d\u540c\u4efb\u52a1\u589e\u52a0\u4e0d\u540c\u7684\u5206\u7c7b\u5c42. \u5177\u4f53\u5b9a\u4e49\u53ef\u4ee5\u53c2\u89c1\u4e0b\u56fe: \u5206\u7c7b\u4efb\u52a1\uff08Classification\uff09: \u5c06\u8d77\u59cb\u548c\u7ec8\u6b62token\u52a0\u5165\u5230\u539f\u59cb\u5e8f\u5217\u4e24\u7aef, \u8f93\u5165transformer\u4e2d\u5f97\u5230\u7279\u5f81\u5411\u91cf, \u6700\u540e\u7ecf\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff1b \u6587\u672c\u8574\u6db5\uff08Entailment\uff09: \u5c06\u524d\u63d0\uff08premise\uff09\u548c\u5047\u8bbe\uff08hypothesis\uff09\u901a\u8fc7\u5206\u9694\u7b26\uff08Delimiter\uff09\u9694\u5f00, \u4e24\u7aef\u52a0\u4e0a\u8d77\u59cb\u548c\u7ec8\u6b62token. \u518d\u4f9d\u6b21\u901a\u8fc7transformer\u548c\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u6587\u672c\u76f8\u4f3c\u5ea6\uff08Similarity\uff09: \u8f93\u5165\u7684\u4e24\u4e2a\u53e5\u5b50, \u6b63\u5411\u548c\u53cd\u5411\u5404\u62fc\u63a5\u4e00\u6b21, \u7136\u540e\u5206\u522b\u8f93\u5165\u7ed9transformer, \u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u62fc\u63a5\u540e\u518d\u9001\u7ed9\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u95ee\u7b54\u548c\u5e38\u8bc6\u63a8\u7406\uff08Multiple-Choice\uff09: \u5c06 N\u4e2a\u9009\u9879\u7684\u95ee\u9898\u62bd\u8c61\u5316\u4e3aN\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898, \u5373\u6bcf\u4e2a\u9009\u9879\u5206\u522b\u548c\u5185\u5bb9\u8fdb\u884c\u62fc\u63a5, \u7136\u540e\u5404\u9001\u5165transformer\u548c\u5168\u8fde\u63a5\u4e2d, \u6700\u540e\u9009\u62e9\u7f6e\u4fe1\u5ea6\u6700\u9ad8\u7684\u4f5c\u4e3a\u9884\u6d4b\u7ed3\u679c \u603b\u7684\u6765\u8bf4\uff0c\u90fd\u662f\u901a\u8fc7\u5728\u5e8f\u5217\u524d\u540e\u6dfb\u52a0 Start \u548c Extract \u7279\u6b8a\u6807\u8bc6\u7b26\u6765\u8868\u793a\u5f00\u59cb\u548c\u7ed3\u675f\uff0c\u5e8f\u5217\u4e4b\u95f4\u6dfb\u52a0\u5fc5\u8981\u7684 Delim \u6807\u8bc6\u7b26\u6765\u8868\u793a\u5206\u9694\uff0c\u5f53\u7136\u5b9e\u9645\u4f7f\u7528\u65f6\u4e0d\u4f1a\u76f4\u63a5\u7528 \u201cStart/Extract/Delim\u201d \u8fd9\u51e0\u4e2a\u8bcd\uff0c\u800c\u662f\u4f7f\u7528\u67d0\u4e9b\u7279\u6b8a\u7b26\u53f7\u3002\u57fa\u4e8e\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u6784\u9020\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684 GPT \u6a21\u578b\u8fdb\u884c\u7279\u5f81\u7f16\u7801\uff0c\u7136\u540e\u4f7f\u7528\u5e8f\u5217\u6700\u540e\u4e00\u4e2a token \u7684\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u9884\u6d4b\u3002 \u53ef\u4ee5\u770b\u5230\uff0c\u4e0d\u8bba\u4e0b\u6e38\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u600e\u4e48\u53d8\uff0c\u6700\u540e\u7684\u9884\u6d4b\u5c42\u600e\u4e48\u53d8\uff0c\u4e2d\u95f4\u7684\u7279\u5f81\u62bd\u53d6\u6a21\u5757\u90fd\u662f\u4e0d\u53d8\u7684\uff0c\u5177\u6709\u5f88\u597d\u7684\u8fc1\u79fb\u80fd\u529b\u3002 1.3 GPT\u6570\u636e\u96c6 \u00b6 GPT\u4f7f\u7528\u4e86BooksCorpus\u6570\u636e\u96c6, \u6587\u672c\u5927\u5c0f\u7ea6 5 GB\uff0c\u5305\u542b 7400w+ \u7684\u53e5\u5b50\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u7531 7000 \u672c\u72ec\u7acb\u7684\u3001\u4e0d\u540c\u98ce\u683c\u7c7b\u578b\u7684\u4e66\u7c4d\u7ec4\u6210, \u9009\u62e9\u8be5\u90e8\u5206\u6570\u636e\u96c6\u7684\u539f\u56e0: \u4e66\u7c4d\u6587\u672c\u5305\u542b\u5927\u91cf\u9ad8\u8d28\u91cf\u957f\u53e5\uff0c\u4fdd\u8bc1\u6a21\u578b\u5b66\u4e60\u957f\u8ddd\u79bb\u4fe1\u606f\u4f9d\u8d56\u3002 \u8fd9\u4e9b\u4e66\u7c4d\u56e0\u4e3a\u6ca1\u6709\u53d1\u5e03, \u6240\u4ee5\u5f88\u96be\u5728\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u89c1\u5230, \u66f4\u80fd\u9a8c\u8bc1\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b. 1.4 GPT\u6a21\u578b\u7684\u7279\u70b9 \u00b6 \u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 12 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 1.17 \u4ebf \u4f18\u70b9 \u5728\u6709\u76d1\u7763\u5b66\u4e60\u768412\u4e2a\u4efb\u52a1\u4e2d, GPT\u57289\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8d85\u8fc7\u4e86state-of-the-art\u7684\u6a21\u578b \u5229\u7528Transformer\u505a\u7279\u5f81\u62bd\u53d6, \u80fd\u591f\u6355\u6349\u5230\u66f4\u957f\u7684\u8bb0\u5fc6\u4fe1\u606f, \u4e14\u8f83\u4f20\u7edf\u7684 RNN \u66f4\u6613\u4e8e\u5e76\u884c\u5316 \u7f3a\u70b9 GPT \u6700\u5927\u7684\u95ee\u9898\u5c31\u662f\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u662f\u5355\u5411\u7684. \u9488\u5bf9\u4e0d\u540c\u7684\u4efb\u52a1, \u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u5fae\u8c03, \u76f8\u5bf9\u6bd4\u8f83\u9ebb\u70e6 2. AR\u6a21\u578b\u603b\u7ed3 \u00b6 \u4f18\u70b9\uff1aAR\u6a21\u578b\u64c5\u957f\u751f\u6210\u5f0fNLP\u4efb\u52a1\u3002AR\u6a21\u578b\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2atoken\uff0c\u56e0\u6b64\u81ea\u7136\u9002\u7528\u4e8e\u6587\u672c\u751f\u6210\u3002\u6b64\u5916\uff0cAR\u6a21\u578b\u53ef\u4ee5\u7b80\u5355\u5730\u5c06\u8bad\u7ec3\u76ee\u6807\u8bbe\u7f6e\u4e3a\u9884\u6d4b\u8bed\u6599\u5e93\u4e2d\u7684\u4e0b\u4e00\u4e2atoken\uff0c\u56e0\u6b64\u751f\u6210\u6570\u636e\u76f8\u5bf9\u5bb9\u6613\u3002 \u7f3a\u70b9\uff1aAR\u6a21\u578b\u53ea\u80fd\u7528\u4e8e\u524d\u5411\u6216\u8005\u540e\u5411\u5efa\u6a21\uff0c\u4e0d\u80fd\u540c\u65f6\u4f7f\u7528\u53cc\u5411\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4e0d\u80fd\u5b8c\u5168\u6355\u6349token\u7684\u5185\u5728\u8054\u7cfb\u3002 \u5e8f\u5217\u5230\u5e8f\u5217\uff08Sequence to Sequence Model\uff09 \u00b6 encoder-decoder\u6a21\u578b\u540c\u65f6\u4f7f\u7528\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u3002\u5b83\u5c06\u6bcf\u4e2atask\u89c6\u4f5c\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u8f6c\u6362/\u751f\u6210\uff08\u6bd4\u5982\uff0c\u6587\u672c\u5230\u6587\u672c\uff0c\u6587\u672c\u5230\u56fe\u50cf\u6216\u8005\u56fe\u50cf\u5230\u6587\u672c\u7684\u591a\u6a21\u6001\u4efb\u52a1\uff09\u3002\u5bf9\u4e8e\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u6765\u8bf4\uff0c\u7f16\u7801\u5668\u5c06\u6587\u672c\u4f5c\u4e3a\u8f93\u5165\uff0c\u89e3\u7801\u5668\u751f\u6210\u6587\u672c\u6807\u7b7e\u3002Encoder-decoder\u6a21\u578b\u901a\u5e38\u7528\u4e8e\u9700\u8981\u5185\u5bb9\u7406\u89e3\u548c\u751f\u6210\u7684\u4efb\u52a1\uff0c\u6bd4\u5982\u673a\u5668\u7ffb\u8bd1\u3002 1. \u4ee3\u8868\u6a21\u578bT5 \u00b6 T5 \u7531\u8c37\u6b4c\u7684 Raffel \u7b49\u4eba\u4e8e 2020\u5e747\u6708\u63d0\u51fa\uff0c\u76f8\u5173\u8bba\u6587\u4e3a\u201cExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\u201d. \u8be5\u6a21\u578b\u7684\u76ee\u7684\u4e3a\u6784\u5efa\u4efb\u52a1\u7edf\u4e00\u6846\u67b6\uff1a\u5c06\u6240\u6709NLP\u4efb\u52a1\u90fd\u89c6\u4e3a\u6587\u672c\u8f6c\u6362\u4efb\u52a1\u3002 \u6bd4\u5982\u82f1\u5fb7\u7ffb\u8bd1\uff0c\u53ea\u9700\u5c06\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u8f93\u5165\u90e8\u5206\u524d\u52a0\u4e0a\u201ctranslate English to German\uff08\u7ed9\u6211\u4ece\u82f1\u8bed\u7ffb\u8bd1\u6210\u5fb7\u8bed\uff09\u201d \u5c31\u884c\u3002\u5047\u8bbe\u9700\u8981\u7ffb\u8bd1\"That is good\"\uff0c\u90a3\u4e48\u5148\u8f6c\u6362\u6210 \"translate English to German\uff1aThat is good.\" \u8f93\u5165\u6a21\u578b\uff0c\u4e4b\u540e\u5c31\u53ef\u4ee5\u76f4\u63a5\u8f93\u51fa\u5fb7\u8bed\u7ffb\u8bd1 \u201cDas ist gut.\u201d\u3002 \u5bf9\u4e8e\u9700\u8981\u8f93\u51fa\u8fde\u7eed\u503c\u7684 STS-B\uff08\u6587\u672c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u4efb\u52a1\uff09\uff0c \u4e5f\u662f\u76f4\u63a5\u8f93\u51fa\u6587\u672c\u3002 \u901a\u8fc7\u8fd9\u6837\u7684\u65b9\u5f0f\u5c31\u80fd\u5c06 NLP \u4efb\u52a1\u90fd\u8f6c\u6362\u6210 Text-to-Text \u5f62\u5f0f\uff0c\u4e5f\u5c31\u53ef\u4ee5**\u7528\u540c\u6837\u7684\u6a21\u578b\uff0c\u540c\u6837\u7684\u635f\u5931\u51fd\u6570\uff0c\u540c\u6837\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u540c\u6837\u7684\u89e3\u7801\u8fc7\u7a0b\u6765\u5b8c\u6210\u6240\u6709 NLP \u4efb\u52a1\u3002** 1.1 T5\u6a21\u578b\u67b6\u6784 \u00b6 T5\u6a21\u578b\u7ed3\u6784\u4e0e\u539f\u59cb\u7684Transformer\u57fa\u672c\u4e00\u81f4,\u9664\u4e86\u505a\u4e86\u4ee5\u4e0b\u51e0\u70b9\u6539\u52a8\uff1a \u4f5c\u8005\u91c7\u7528\u4e86\u4e00\u79cd\u7b80\u5316\u7248\u7684Layer Normalization\uff0c\u53bb\u9664\u4e86Layer Norm \u7684bias\uff1b\u5c06Layer Norm\u653e\u5728\u6b8b\u5dee\u8fde\u63a5\u5916\u9762\u3002 \u4f4d\u7f6e\u7f16\u7801\uff1aT5\u4f7f\u7528\u4e86\u4e00\u79cd\u7b80\u5316\u7248\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u5373\u6bcf\u4e2a\u4f4d\u7f6e\u7f16\u7801\u90fd\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u88ab\u52a0\u5230 logits \u4e0a\u7528\u4e8e\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u3002\u5404\u5c42\u5171\u4eab\u4f4d\u7f6e\u7f16\u7801\uff0c\u4f46\u662f\u5728\u540c\u4e00\u5c42\u5185\uff0c\u4e0d\u540c\u7684\u6ce8\u610f\u529b\u5934\u7684\u4f4d\u7f6e\u7f16\u7801\u90fd\u662f\u72ec\u7acb\u5b66\u4e60\u7684\u3002\u4e00\u5b9a\u6570\u91cf\u7684\u4f4d\u7f6eEmbedding\uff0c\u6bcf\u4e00\u4e2a\u5bf9\u5e94\u4e00\u4e2a\u53ef\u80fd\u7684 key-query \u4f4d\u7f6e\u5dee\u3002\u4f5c\u8005\u5b66\u4e60\u4e8632\u4e2aEmbedding\uff0c\u81f3\u591a\u9002\u7528\u4e8e\u957f\u5ea6\u4e3a128\u7684\u4f4d\u7f6e\u5dee\uff0c\u8d85\u8fc7\u4f4d\u7f6e\u5dee\u7684\u4f4d\u7f6e\u7f16\u7801\u90fd\u4f7f\u7528\u76f8\u540c\u7684Embedding\u3002 1.2 T5 \u8bad\u7ec3\u8fc7\u7a0b \u00b6 \u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff1a\u91c7\u7528\u7c7b\u4f3c\u4e8eBERT\u6a21\u578b\u7684MLM\u9884\u8bad\u7ec3\u4efb\u52a1\u3002 \u591a\u4efb\u52a1\u9884\u8bad\u7ec3\uff1a\u9664\u4e86\u4f7f\u7528\u5927\u89c4\u6a21\u6570\u636e\u8fdb\u884c\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\uff0cT5\u6a21\u578b\u8fd8\u53ef\u4ee5\u5229\u7528\u4e0d\u540c\u4efb\u52a1\u7684\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u6709\u76d1\u7763\u7684\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\uff0c\u4f8b\u5982SQuAD\u95ee\u7b54\u548c\u673a\u5668\u7ffb\u8bd1\u7b49\u4efb\u52a1\u3002 1.3 T5\u6570\u636e\u96c6 \u00b6 \u4f5c\u8005\u5bf9\u516c\u5f00\u722c\u53d6\u7684\u7f51\u9875\u6570\u636e\u96c6Common Crawl\u8fdb\u884c\u4e86\u8fc7\u6ee4\uff0c\u53bb\u6389\u4e00\u4e9b\u91cd\u590d\u7684\u3001\u4f4e\u8d28\u91cf\u7684\uff0c\u770b\u7740\u50cf\u4ee3\u7801\u7684\u6587\u672c\u7b49\uff0c\u5e76\u4e14\u6700\u540e\u53ea\u4fdd\u7559\u82f1\u6587\u6587\u672c\uff0c\u5f97\u5230\u6570\u636e\u96c6**C4: the Colossal Clean Crawled Corpus**\u3002 1.4 T5\u6a21\u578b\u7684\u7279\u70b9 \u00b6 \u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 24 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 2.2 \u4ebf 2. encoder-decoder\u6a21\u578b\u603b\u7ed3 \u00b6 \u4f18\u70b9\uff1aT5\u6a21\u578b\u53ef\u4ee5\u5904\u7406\u591a\u79cdNLP\u4efb\u52a1\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u6765\u9002\u5e94\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff1b\u76f8\u6bd4\u5176\u4ed6\u8bed\u8a00\u751f\u6210\u6a21\u578b\uff08\u5982GPT-2\u3001GPT3\u7b49\uff09\uff0cT5\u6a21\u578b\u7684\u53c2\u6570\u6570\u91cf\u76f8\u5bf9\u8f83\u5c11\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\uff0c\u4e14\u53ef\u4ee5\u5728\u76f8\u5bf9\u8f83\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002 \u7f3a\u70b9\uff1a\u7531\u4e8eT5\u6a21\u578b\u4f7f\u7528\u4e86\u5927\u91cf\u7684Transformer\u7ed3\u6784\uff0c\u5728\u8bad\u7ec3\u65f6\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u65f6\u95f4; \u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002 \u76ee\u524d\u5927\u6a21\u578b\u4e3b\u6d41\u6a21\u578b\u67b6\u6784-Decoder-only \u00b6 LLM\u4e4b\u6240\u4ee5\u4e3b\u8981\u90fd\u7528Decoder-only\u67b6\u6784\uff0c\u9664\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u5de5\u7a0b\u5b9e\u73b0\u4e0a\u7684\u4f18\u52bf\u5916\uff0c\u5728\u7406\u8bba\u4e0a\u662f\u56e0\u4e3aEncoder\u7684\u53cc\u5411\u6ce8\u610f\u529b\u4f1a\u5b58\u5728\u4f4e\u79e9\u95ee\u9898\uff0c\u8fd9\u53ef\u80fd\u4f1a\u524a\u5f31\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u5c31\u751f\u6210\u4efb\u52a1\u800c\u8a00\uff0c\u5f15\u5165\u53cc\u5411\u6ce8\u610f\u529b\u5e76\u65e0\u5b9e\u8d28\u597d\u5904\u3002\u800cEncoder-Decoder\u67b6\u6784\u4e4b\u6240\u4ee5\u80fd\u591f\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u8868\u73b0\u66f4\u597d\uff0c\u5927\u6982\u53ea\u662f\u56e0\u4e3a\u5b83\u591a\u4e86\u4e00\u500d\u53c2\u6570\u3002\u6240\u4ee5\uff0c\u5728\u540c\u7b49\u53c2\u6570\u91cf\u3001\u540c\u7b49\u63a8\u7406\u6210\u672c\u4e0b\uff0cDecoder-only\u67b6\u6784\u5c31\u662f\u6700\u4f18\u9009\u62e9\u4e86\u3002 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecdLLM\u7684\u4e3b\u8981\u7c7b\u522b\u67b6\u6784\uff1a\u81ea\u56de\u5f52\u6a21\u578b\u3001\u81ea\u7f16\u7801\u6a21\u578b\u548c\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u3002 \u5206\u522b\u5bf9\u4e0d\u540c\u7c7b\u578b\u67b6\u6784\u7684\u4ee3\u8868\u6a21\u578b\u5982\uff1aBERT\u3001GPT\u3001T5\u7b49\u76f8\u5173\u6a21\u578b\u8fdb\u884c\u4ecb\u7ecd","title":"1.2 LLM\u4e3b\u8981\u67b6\u6784\u7c7b\u522b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#llm","text":"","title":"LLM\u4e3b\u8981\u7c7b\u522b\u67b6\u6784\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#_1","text":"\u4e86\u89e3LLM\u4e3b\u8981\u7c7b\u522b\u67b6\u6784. \u638c\u63e1BERT\u3001GPT\u3001T5\u7b49\u6a21\u578b\u539f\u7406","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#llm_1","text":"LLM\u672c\u8eab\u57fa\u4e8etransformer\u67b6\u6784\u3002\u81ea2017\u5e74\uff0cattention is all you need\u8bde\u751f\u8d77\uff0c\u539f\u59cb\u7684transformer\u6a21\u578b\u4e3a\u4e0d\u540c\u9886\u57df\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u7075\u611f\u548c\u542f\u53d1\u3002\u57fa\u4e8e\u539f\u59cb\u7684Transformer\u6846\u67b6\uff0c\u884d\u751f\u51fa\u4e86\u4e00\u7cfb\u5217\u6a21\u578b\uff0c\u4e00\u4e9b\u6a21\u578b\u4ec5\u4ec5\u4f7f\u7528encoder\u6216decoder\uff0c\u6709\u4e9b\u6a21\u578b\u540c\u65f6\u4f7f\u7528encoder+decoder\u3002 LLM\u5206\u7c7b\u4e00\u822c\u5206\u4e3a\u4e09\u79cd\uff1a\u81ea\u7f16\u7801\u6a21\u578b\uff08encoder\uff09\u3001\u81ea\u56de\u5f52\u6a21\u578b(decoder)\u548c\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b(encoder-decoder)\u3002","title":"LLM\u4e3b\u8981\u7c7b\u522b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#autoencoder-modelae","text":"AE\u6a21\u578b\uff0c\u4ee3\u8868\u4f5cBERT\uff0c\u5176\u7279\u70b9\u4e3a\uff1aEncoder-Only, \u57fa\u672c\u539f\u7406\uff1a\u662f\u5728\u8f93\u5165\u4e2d\u968f\u673aMASK\u6389\u4e00\u90e8\u5206\u5355\u8bcd\uff0c\u6839\u636e\u4e0a\u4e0b\u6587\u9884\u6d4b\u8fd9\u4e2a\u8bcd\u3002AE\u6a21\u578b\u901a\u5e38\u7528\u4e8e\u5185\u5bb9\u7406\u89e3\u4efb\u52a1\uff0c\u6bd4\u5982\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff08NLU\uff09\u4e2d\u7684\u5206\u7c7b\u4efb\u52a1\uff1a\u60c5\u611f\u5206\u6790\u3001\u63d0\u53d6\u5f0f\u95ee\u7b54\u3002","title":"\u81ea\u7f16\u7801\u6a21\u578b (AutoEncoder  model\uff0cAE)"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#1-bert","text":"BERT\u662f2018\u5e7410\u6708\u7531Google AI\u7814\u7a76\u9662\u63d0\u51fa\u7684\u4e00\u79cd\u9884\u8bad\u7ec3\u6a21\u578b. BERT\u7684\u5168\u79f0\u662fBidirectional Encoder Representation from Transformers. BERT\u5728\u673a\u5668\u9605\u8bfb\u7406\u89e3\u9876\u7ea7\u6c34\u5e73\u6d4b\u8bd5SQuAD1.1\u4e2d\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u6210\u7ee9: \u5168\u90e8\u4e24\u4e2a\u8861\u91cf\u6307\u6807\u4e0a\u5168\u9762\u8d85\u8d8a\u4eba\u7c7b, \u5e76\u4e14\u572811\u79cd\u4e0d\u540cNLP\u6d4b\u8bd5\u4e2d\u521b\u51faSOTA\u8868\u73b0. \u5305\u62ec\u5c06GLUE\u57fa\u51c6\u63a8\u9ad8\u81f380.4% (\u7edd\u5bf9\u6539\u8fdb7.6%), MultiNLI\u51c6\u786e\u5ea6\u8fbe\u523086.7% (\u7edd\u5bf9\u6539\u8fdb5.6%). \u6210\u4e3aNLP\u53d1\u5c55\u53f2\u4e0a\u7684\u91cc\u7a0b\u7891\u5f0f\u7684\u6a21\u578b\u6210\u5c31.","title":"1. \u4ee3\u8868\u6a21\u578b BERT"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#11-bert","text":"\u603b\u4f53\u67b6\u6784: \u5982\u4e0b\u56fe\u6240\u793a, \u6700\u5de6\u8fb9\u7684\u5c31\u662fBERT\u7684\u67b6\u6784\u56fe, \u53ef\u4ee5\u5f88\u6e05\u695a\u7684\u770b\u5230BERT\u91c7\u7528\u4e86Transformer Encoder block\u8fdb\u884c\u8fde\u63a5, \u56e0\u4e3a\u662f\u4e00\u4e2a\u5178\u578b\u7684\u53cc\u5411\u7f16\u7801\u6a21\u578b. \u4ece\u4e0a\u9762\u7684\u67b6\u6784\u56fe\u4e2d\u53ef\u4ee5\u770b\u5230, \u5b8f\u89c2\u4e0aBERT\u5206\u4e09\u4e2a\u4e3b\u8981\u6a21\u5757: \u6700\u5e95\u5c42\u9ec4\u8272\u6807\u8bb0\u7684Embedding\u6a21\u5757. \u4e2d\u95f4\u5c42\u84dd\u8272\u6807\u8bb0\u7684Transformer\u6a21\u5757. \u6700\u4e0a\u5c42\u7eff\u8272\u6807\u8bb0\u7684\u9884\u5fae\u8c03\u6a21\u5757.","title":"1.1 BERT\u7684\u67b6\u6784"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#12-embedding","text":"BERT\u4e2d\u7684\u8be5\u6a21\u5757\u662f\u7531\u4e09\u79cdEmbedding\u5171\u540c\u7ec4\u6210\u800c\u6210, \u5982\u4e0b\u56fe Token Embeddings \u662f\u8bcd\u5d4c\u5165\u5f20\u91cf, \u7b2c\u4e00\u4e2a\u5355\u8bcd\u662fCLS\u6807\u5fd7, \u53ef\u4ee5\u7528\u4e8e\u4e4b\u540e\u7684\u5206\u7c7b\u4efb\u52a1. Segment Embeddings \u662f\u53e5\u5b50\u5206\u6bb5\u5d4c\u5165\u5f20\u91cf, \u662f\u4e3a\u4e86\u670d\u52a1\u540e\u7eed\u7684\u4e24\u4e2a\u53e5\u5b50\u4e3a\u8f93\u5165\u7684\u9884\u8bad\u7ec3\u4efb\u52a1. Position Embeddings \u662f\u4f4d\u7f6e\u7f16\u7801\u5f20\u91cf, \u6b64\u5904\u6ce8\u610f\u548c\u4f20\u7edf\u7684Transformer\u4e0d\u540c, \u4e0d\u662f\u4e09\u89d2\u51fd\u6570\u8ba1\u7b97\u7684\u56fa\u5b9a\u4f4d\u7f6e\u7f16\u7801, \u800c\u662f\u901a\u8fc7\u5b66\u4e60\u5f97\u51fa\u6765\u7684. \u6574\u4e2aEmbedding\u6a21\u5757\u7684\u8f93\u51fa\u5f20\u91cf\u5c31\u662f\u8fd93\u4e2a\u5f20\u91cf\u7684\u76f4\u63a5\u52a0\u548c\u7ed3\u679c.","title":"1.2 Embedding\u6a21\u5757"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#13-transformer","text":"BERT\u4e2d\u53ea\u4f7f\u7528\u4e86\u7ecf\u5178Transformer\u67b6\u6784\u4e2d\u7684Encoder\u90e8\u5206, \u5b8c\u5168\u820d\u5f03\u4e86Decoder\u90e8\u5206. \u800c\u4e24\u5927\u9884\u8bad\u7ec3\u4efb\u52a1\u4e5f\u96c6\u4e2d\u4f53\u73b0\u5728\u8bad\u7ec3Transformer\u6a21\u5757\u4e2d.","title":"1.3 \u53cc\u5411Transformer\u6a21\u5757"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#14","text":"\u7ecf\u8fc7\u4e2d\u95f4\u5c42Transformer\u7684\u5904\u7406\u540e, BERT\u7684\u6700\u540e\u4e00\u5c42\u6839\u636e\u4efb\u52a1\u7684\u4e0d\u540c\u9700\u6c42\u800c\u505a\u4e0d\u540c\u7684\u8c03\u6574\u5373\u53ef. \u6bd4\u5982\u5bf9\u4e8esequence-level\u7684\u5206\u7c7b\u4efb\u52a1, BERT\u76f4\u63a5\u53d6\u7b2c\u4e00\u4e2a[CLS] token \u7684final hidden state, \u518d\u52a0\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\u540e\u8fdb\u884csoftmax\u6765\u9884\u6d4b\u6700\u7ec8\u7684\u6807\u7b7e. \u5bf9\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1, \u5fae\u8c03\u90fd\u96c6\u4e2d\u5728\u9884\u5fae\u8c03\u6a21\u5757, \u51e0\u79cd\u91cd\u8981\u7684NLP\u5fae\u8c03\u4efb\u52a1\u67b6\u6784\u56fe\u5c55\u793a\u5982\u4e0b \u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u53d1\u73b0, \u5728\u9762\u5bf9\u7279\u5b9a\u4efb\u52a1\u65f6, \u53ea\u9700\u8981\u5bf9\u9884\u5fae\u8c03\u5c42\u8fdb\u884c\u5fae\u8c03, \u5c31\u53ef\u4ee5\u5229\u7528Transformer\u5f3a\u5927\u7684\u6ce8\u610f\u529b\u673a\u5236\u6765\u6a21\u62df\u5f88\u591a\u4e0b\u6e38\u4efb\u52a1, \u5e76\u5f97\u5230SOTA\u7684\u7ed3\u679c. (\u53e5\u5b50\u5bf9\u5173\u7cfb\u5224\u65ad, \u5355\u6587\u672c\u4e3b\u9898\u5206\u7c7b, \u95ee\u7b54\u4efb\u52a1(QA), \u5355\u53e5\u8d34\u6807\u7b7e(NER)) \u82e5\u5e72\u53ef\u9009\u7684\u8d85\u53c2\u6570\u5efa\u8bae\u5982\u4e0b: Batch size: 16, 32 Learning rate (Adam): 5e-5, 3e-5, 2e-5 Epochs: 3, 4","title":"1.4 \u9884\u5fae\u8c03\u6a21\u5757"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#15-bert","text":"BERT\u5305\u542b\u4e24\u4e2a\u9884\u8bad\u7ec3\u4efb\u52a1: \u4efb\u52a1\u4e00: Masked LM (\u5e26mask\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3) \u4efb\u52a1\u4e8c: Next Sentence Prediction (\u4e0b\u4e00\u53e5\u8bdd\u9884\u6d4b\u4efb\u52a1)","title":"1.5 BERT\u7684\u9884\u8bad\u7ec3\u4efb\u52a1"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#151-masked-lm","text":"\u5e26mask\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3 \u5173\u4e8e\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3, \u90fd\u662f\u91c7\u7528left-to-right, \u6216\u8005left-to-right + right-to-left\u7ed3\u5408\u7684\u65b9\u5f0f, \u4f46\u8fd9\u79cd\u5355\u5411\u65b9\u5f0f\u6216\u8005\u62fc\u63a5\u7684\u65b9\u5f0f\u63d0\u53d6\u7279\u5f81\u7684\u80fd\u529b\u6709\u9650. \u4e3a\u6b64BERT\u63d0\u51fa\u4e00\u4e2a\u6df1\u5ea6\u53cc\u5411\u8868\u8fbe\u6a21\u578b(deep bidirectional representation). \u5373\u91c7\u7528MASK\u4efb\u52a1\u6765\u8bad\u7ec3\u6a21\u578b. 1: \u5728\u539f\u59cb\u8bad\u7ec3\u6587\u672c\u4e2d, \u968f\u673a\u7684\u62bd\u53d615%\u7684token\u4f5c\u4e3a\u53c2\u4e0eMASK\u4efb\u52a1\u7684\u5bf9\u8c61. 2: \u5728\u8fd9\u4e9b\u88ab\u9009\u4e2d\u7684token\u4e2d, \u6570\u636e\u751f\u6210\u5668\u5e76\u4e0d\u662f\u628a\u5b83\u4eec\u5168\u90e8\u53d8\u6210[MASK], \u800c\u662f\u6709\u4e0b\u52173\u79cd\u60c5\u51b5. 2.1: \u572880%\u7684\u6982\u7387\u4e0b, \u7528[MASK]\u6807\u8bb0\u66ff\u6362\u8be5token, \u6bd4\u5982my dog is hairy -> my dog is [MASK] 2.2: \u572810%\u7684\u6982\u7387\u4e0b, \u7528\u4e00\u4e2a\u968f\u673a\u7684\u5355\u8bcd\u66ff\u6362token, \u6bd4\u5982my dog is hairy -> my dog is apple 2.3: \u572810%\u7684\u6982\u7387\u4e0b, \u4fdd\u6301\u8be5token\u4e0d\u53d8, \u6bd4\u5982my dog is hairy -> my dog is hairy 3: \u6a21\u578b\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d, \u5e76\u4e0d\u77e5\u9053\u5b83\u5c06\u8981\u9884\u6d4b\u54ea\u4e9b\u5355\u8bcd? \u54ea\u4e9b\u5355\u8bcd\u662f\u539f\u59cb\u7684\u6837\u5b50? \u54ea\u4e9b\u5355\u8bcd\u88ab\u906e\u63a9\u6210\u4e86[MASK]? \u54ea\u4e9b\u5355\u8bcd\u88ab\u66ff\u6362\u6210\u4e86\u5176\u4ed6\u5355\u8bcd? \u6b63\u662f\u5728\u8fd9\u6837\u4e00\u79cd\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u60c5\u51b5\u4e0b, \u53cd\u5012\u903c\u7740\u6a21\u578b\u5feb\u901f\u5b66\u4e60\u8be5token\u7684\u5206\u5e03\u5f0f\u4e0a\u4e0b\u6587\u7684\u8bed\u4e49, \u5c3d\u6700\u5927\u52aa\u529b\u5b66\u4e60\u539f\u59cb\u8bed\u8a00\u8bf4\u8bdd\u7684\u6837\u5b50. \u540c\u65f6\u56e0\u4e3a\u539f\u59cb\u6587\u672c\u4e2d\u53ea\u670915%\u7684token\u53c2\u4e0e\u4e86MASK\u64cd\u4f5c, \u5e76\u4e0d\u4f1a\u7834\u574f\u539f\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u548c\u8bed\u8a00\u89c4\u5219.","title":"1.5.1 \u4efb\u52a1\u4e00: Masked LM"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#152-next-sentence-prediction","text":"\u4e0b\u4e00\u53e5\u8bdd\u9884\u6d4b\u4efb\u52a1 \u5728NLP\u4e2d\u6709\u4e00\u7c7b\u91cd\u8981\u7684\u95ee\u9898\u6bd4\u5982QA(Quention-Answer), NLI(Natural Language Inference), \u9700\u8981\u6a21\u578b\u80fd\u591f\u5f88\u597d\u7684\u7406\u89e3\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u5173\u7cfb, \u4ece\u800c\u9700\u8981\u5728\u6a21\u578b\u7684\u8bad\u7ec3\u4e2d\u5f15\u5165\u5bf9\u5e94\u7684\u4efb\u52a1. \u5728BERT\u4e2d\u5f15\u5165\u7684\u5c31\u662fNext Sentence Prediction\u4efb\u52a1. \u91c7\u7528\u7684\u65b9\u5f0f\u662f\u8f93\u5165\u53e5\u5b50\u5bf9(A, B), \u6a21\u578b\u6765\u9884\u6d4b\u53e5\u5b50B\u662f\u4e0d\u662f\u53e5\u5b50A\u7684\u771f\u5b9e\u7684\u4e0b\u4e00\u53e5\u8bdd. 1: \u6240\u6709\u53c2\u4e0e\u4efb\u52a1\u8bad\u7ec3\u7684\u8bed\u53e5\u90fd\u88ab\u9009\u4e2d\u4f5c\u4e3a\u53e5\u5b50A. 1.1: \u5176\u4e2d50%\u7684B\u662f\u539f\u59cb\u6587\u672c\u4e2d\u771f\u5b9e\u8ddf\u968fA\u7684\u4e0b\u4e00\u53e5\u8bdd. (\u6807\u8bb0\u4e3aIsNext, \u4ee3\u8868\u6b63\u6837\u672c) 1.2: \u5176\u4e2d50%\u7684B\u662f\u539f\u59cb\u6587\u672c\u4e2d\u968f\u673a\u62bd\u53d6\u7684\u4e00\u53e5\u8bdd. (\u6807\u8bb0\u4e3aNotNext, \u4ee3\u8868\u8d1f\u6837\u672c) 2: \u5728\u4efb\u52a1\u4e8c\u4e2d, BERT\u6a21\u578b\u53ef\u4ee5\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f9797%-98%\u7684\u51c6\u786e\u7387.","title":"1.5.2 \u4efb\u52a1\u4e8c: Next Sentence Prediction"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#16","text":"BooksCorpus (800M words) + English Wikipedia (2,500M words)","title":"1.6 \u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#17-bert","text":"\u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 12 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 1.15 \u4ebf","title":"1.7 BERT\u6a21\u578b\u7684\u7279\u70b9"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#2-ae","text":"\u4f18\u70b9\uff1aBERT\u4f7f\u7528\u53cc\u5411transformer\uff0c\u5728\u8bed\u8a00\u7406\u89e3\u76f8\u5173\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u5f88\u597d\u3002 \u7f3a\u70b9\uff1a \u8f93\u5165\u566a\u58f0\uff1aBERT\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u3010mask\u3011\u7b26\u53f7\u5bf9\u8f93\u5165\u8fdb\u884c\u5904\u7406\uff0c\u8fd9\u4e9b\u7b26\u53f7\u5728\u4e0b\u6e38\u7684finetune\u4efb\u52a1\u4e2d\u6c38\u8fdc\u4e0d\u4f1a\u51fa\u73b0\uff0c\u8fd9\u4f1a\u5bfc\u81f4**\u9884\u8bad\u7ec3-\u5fae\u8c03\u5dee\u5f02**\u3002\u800cAR\u6a21\u578b\u4e0d\u4f1a\u4f9d\u8d56\u4e8e\u4efb\u4f55\u88abmask\u7684\u8f93\u5165\uff0c\u56e0\u6b64\u4e0d\u4f1a\u9047\u5230\u8fd9\u7c7b\u95ee\u9898\u3002 \u66f4\u9002\u5408\u7528\u4e8e\u8bed\u8a00\u5d4c\u5165\u8868\u8fbe, \u8bed\u8a00\u7406\u89e3\u65b9\u9762\u7684\u4efb\u52a1, \u4e0d\u9002\u5408\u7528\u4e8e\u751f\u6210\u5f0f\u7684\u4efb\u52a1","title":"2. AE\u6a21\u578b\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#autoregressive-modelar","text":"AR\u6a21\u578b\uff0c\u4ee3\u8868\u4f5cGPT\uff0c\u5176\u7279\u70b9\u4e3a\uff1aDecoder-Only\uff0c\u57fa\u672c\u539f\u7406\uff1a\u4ece\u5de6\u5f80\u53f3\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u53ea\u80fd\u5229\u7528\u4e0a\u6587\u6216\u8005\u4e0b\u6587\u7684\u4fe1\u606f\uff0c\u6bd4\u5982\uff1aAR\u6a21\u578b\u4ece\u4e00\u7cfb\u5217time steps\u4e2d\u5b66\u4e60\uff0c\u5e76\u5c06\u4e0a\u4e00\u6b65\u7684\u7ed3\u679c\u4f5c\u4e3a\u56de\u5f52\u6a21\u578b\u7684\u8f93\u5165\uff0c\u4ee5\u9884\u6d4b\u4e0b\u4e00\u4e2atime step\u7684\u503c\u3002AR\u6a21\u578b\u901a\u5e38\u7528\u4e8e\u751f\u6210\u5f0f\u4efb\u52a1\uff0c\u5728\u957f\u6587\u672c\u7684\u751f\u6210\u80fd\u529b\u5f88\u5f3a\uff0c\u6bd4\u5982\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u9886\u57df\u7684\u4efb\u52a1\uff1a\u6458\u8981\u3001\u7ffb\u8bd1\u6216\u62bd\u8c61\u95ee\u7b54\u3002","title":"\u81ea\u56de\u5f52\u6a21\u578b (Autoregressive model\uff0cAR)"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#1-gpt","text":"2018\u5e746\u6708, OpenAI\u516c\u53f8\u53d1\u8868\u4e86\u8bba\u6587\u201cImproving Language Understanding by Generative Pre-training\u201d\u300a\u7528\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u63d0\u9ad8\u6a21\u578b\u7684\u8bed\u8a00\u7406\u89e3\u529b\u300b, \u63a8\u51fa\u4e86\u5177\u67091.17\u4ebf\u4e2a\u53c2\u6570\u7684GPT\uff08Generative Pre-training , \u751f\u6210\u5f0f\u9884\u8bad\u7ec3\uff09\u6a21\u578b. \u4e0eBERT\u6700\u5927\u7684\u533a\u522b\u5728\u4e8eGPT\u91c7\u7528\u4e86\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u8fdb\u884c\u9884\u8bad\u7ec3, \u5373\u4f7f\u7528\u5355\u8bcd\u7684\u4e0a\u6587\u6765\u9884\u6d4b\u5355\u8bcd, \u800cBERT\u662f\u91c7\u7528\u4e86\u53cc\u5411\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\u5171\u540c\u6765\u9884\u6d4b\u5355\u8bcd.\u6b63\u662f\u56e0\u4e3a\u8bad\u7ec3\u65b9\u6cd5\u4e0a\u7684\u533a\u522b, \u4f7f\u5f97GPT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4efb\u52a1(NLG), \u800cBERT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1(NLU).","title":"1. \u4ee3\u8868\u6a21\u578b GPT"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#11-gpt","text":"\u770b\u4e09\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6bd4\u67b6\u6784\u56fe, \u4e2d\u95f4\u7684\u5c31\u662fGPT: \u4ece\u4e0a\u56fe\u53ef\u4ee5\u5f88\u6e05\u695a\u7684\u770b\u5230GPT\u91c7\u7528\u7684\u662f\u5355\u5411Transformer\u6a21\u578b, \u4f8b\u5982\u7ed9\u5b9a\u4e00\u4e2a\u53e5\u5b50[u1, u2, ..., un], GPT\u5728\u9884\u6d4b\u5355\u8bcdui\u7684\u65f6\u5019\u53ea\u4f1a\u5229\u7528[u1, u2, ..., u(i-1)]\u7684\u4fe1\u606f, \u800cBERT\u4f1a\u540c\u65f6\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f[u1, u2, ..., u(i-1), u(i+1), ..., un]. \u4f5c\u4e3a\u4e24\u5927\u6a21\u578b\u7684\u76f4\u63a5\u5bf9\u6bd4, BERT\u91c7\u7528\u4e86Transformer\u7684Encoder\u6a21\u5757, \u800cGPT\u91c7\u7528\u4e86Transformer\u7684Decoder\u6a21\u5757. \u5e76\u4e14GPT\u7684Decoder Block\u548c\u7ecf\u5178Transformer Decoder Block\u8fd8\u6709\u6240\u4e0d\u540c, \u5982\u4e0b\u56fe\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, \u7ecf\u5178\u7684Transformer Decoder Block\u5305\u542b3\u4e2a\u5b50\u5c42, \u5206\u522b\u662fMasked Multi-Head Attention\u5c42, encoder-decoder attention\u5c42, \u4ee5\u53caFeed Forward\u5c42. \u4f46\u662f\u5728GPT\u4e2d\u53d6\u6d88\u4e86\u7b2c\u4e8c\u4e2aencoder-decoder attention\u5b50\u5c42, \u53ea\u4fdd\u7559Masked Multi-Head Attention\u5c42, \u548cFeed Forward\u5c42. \u6ce8\u610f: \u5bf9\u6bd4\u4e8e\u7ecf\u5178\u7684Transformer\u67b6\u6784, \u89e3\u7801\u5668\u6a21\u5757\u91c7\u7528\u4e866\u4e2aDecoder Block; GPT\u7684\u67b6\u6784\u4e2d\u91c7\u7528\u4e8612\u4e2aDecoder Block.","title":"1.1 GPT\u6a21\u578b\u67b6\u6784"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#12-gpt","text":"GPT\u7684\u8bad\u7ec3\u5305\u62ec\u4e24\u9636\u6bb5\u8fc7\u7a0b: \u9884\u8bad\u7ec3 + \u5fae\u8c03 \u7b2c\u4e00\u9636\u6bb5: \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b. \u7b2c\u4e8c\u9636\u6bb5: \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning.","title":"1.2 GPT\u8bad\u7ec3\u8fc7\u7a0b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#121","text":"\u7ed9\u5b9a\u53e5\u5b50U = [u1, u2, ..., un], GPT\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u4f3c\u7136\u51fd\u6570: L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) \u4e0a\u8ff0\u516c\u5f0f\u5177\u4f53\u6765\u8bf4\u662f\u8981\u9884\u6d4b\u6bcf\u4e2a\u8bcdui\u7684\u6982\u7387\uff0c\u8fd9\u4e2a\u6982\u7387\u662f\u57fa\u4e8e\u5b83\u524d\u9762 ui-k \u5230 ui\u22121 \u4e2a\u8bcd\uff0c\u4ee5\u53ca\u6a21\u578b \u0398\u3002\u8fd9\u91cc\u7684 k \u8868\u793a\u4e0a\u6587\u7684\u7a97\u53e3\u5927\u5c0f\uff0c\u7406\u8bba\u4e0a\u6765\u8bb2 k \u53d6\u7684\u8d8a\u5927\uff0c\u6a21\u578b\u6240\u80fd\u83b7\u53d6\u7684\u4e0a\u6587\u4fe1\u606f\u8d8a\u5145\u8db3\uff0c\u6a21\u578b\u7684\u80fd\u529b\u8d8a\u5f3a\u3002 GPT\u662f\u4e00\u4e2a\u5355\u5411\u8bed\u8a00\u6a21\u578b,\u6a21\u578b\u5bf9\u8f93\u5165U \u8fdb\u884c\u7279\u5f81\u5d4c\u5165\u5f97\u5230 transformer \u7b2c\u4e00\u5c42\u7684\u8f93h0\uff0c\u518d\u7ecf\u8fc7\u591a\u5c42 transformer \u7279\u5f81\u7f16\u7801\uff0c\u4f7f\u7528\u6700\u540e\u4e00\u5c42\u7684\u8f93\u51fa\u5373\u53ef\u5f97\u5230\u5f53\u524d\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff0c\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\uff1a h_0 = UW_e + W_p h_0 = UW_e + W_p \u5176\u4e2dWp\u662f\u5355\u8bcd\u7684\u4f4d\u7f6e\u7f16\u7801, We\u662f\u5355\u8bcd\u672c\u8eab\u7684word embedding. Wp\u7684\u5f62\u72b6\u662f[max_seq_len, embedding_dim], We\u7684\u5f62\u72b6\u662f[vocab_size, embedding_dim]. \u5f97\u5230\u8f93\u5165\u5f20\u91cfh0\u540e, \u8981\u5c06h0\u4f20\u5165GPT\u7684Decoder Block\u4e2d, \u4f9d\u6b21\u5f97\u5230ht: h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] \u6700\u540e\u901a\u8fc7\u5f97\u5230\u7684ht\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5355\u8bcd: P(u)=softmax(h_tW_e^T) P(u)=softmax(h_tW_e^T)","title":"1.2.1 \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#122-fine-tunning","text":"GPT\u7ecf\u8fc7\u9884\u8bad\u7ec3\u540e, \u4f1a\u9488\u5bf9\u5177\u4f53\u7684\u4e0b\u6e38\u4efb\u52a1\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03. \u5fae\u8c03\u91c7\u7528\u7684\u662f\u6709\u76d1\u7763\u5b66\u4e60, \u8bad\u7ec3\u6837\u672c\u5305\u62ec\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u548clabel y. GPT\u5fae\u8c03\u7684\u76ee\u6807\u4efb\u52a1\u662f\u6839\u636e\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u9884\u6d4b\u6807\u7b7ey. P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) \u5176\u4e2d W_y W_y \u8868\u793a\u9884\u6d4b\u8f93\u51fa\u7684\u77e9\u9635\u53c2\u6570, \u5fae\u8c03\u4efb\u52a1\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u51fd\u6570: L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) \u7efc\u5408\u4e24\u4e2a\u9636\u6bb5\u7684\u76ee\u6807\u4efb\u52a1\u51fd\u6570, \u53ef\u77e5GPT\u7684\u6700\u7ec8\u4f18\u5316\u51fd\u6570\u4e3a: L_3 = L_2 + \\lambda L_1 L_3 = L_2 + \\lambda L_1","title":"1.2.2 \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#123","text":"\u6839\u636e\u4e0b\u6e38\u4efb\u52a1\u9002\u914d\u7684\u8fc7\u7a0b\u5206\u4e24\u6b65: 1\u3001\u6839\u636e\u4efb\u52a1\u5b9a\u4e49\u4e0d\u540c\u8f93\u5165, 2\u3001\u5bf9\u4e0d\u540c\u4efb\u52a1\u589e\u52a0\u4e0d\u540c\u7684\u5206\u7c7b\u5c42. \u5177\u4f53\u5b9a\u4e49\u53ef\u4ee5\u53c2\u89c1\u4e0b\u56fe: \u5206\u7c7b\u4efb\u52a1\uff08Classification\uff09: \u5c06\u8d77\u59cb\u548c\u7ec8\u6b62token\u52a0\u5165\u5230\u539f\u59cb\u5e8f\u5217\u4e24\u7aef, \u8f93\u5165transformer\u4e2d\u5f97\u5230\u7279\u5f81\u5411\u91cf, \u6700\u540e\u7ecf\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff1b \u6587\u672c\u8574\u6db5\uff08Entailment\uff09: \u5c06\u524d\u63d0\uff08premise\uff09\u548c\u5047\u8bbe\uff08hypothesis\uff09\u901a\u8fc7\u5206\u9694\u7b26\uff08Delimiter\uff09\u9694\u5f00, \u4e24\u7aef\u52a0\u4e0a\u8d77\u59cb\u548c\u7ec8\u6b62token. \u518d\u4f9d\u6b21\u901a\u8fc7transformer\u548c\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u6587\u672c\u76f8\u4f3c\u5ea6\uff08Similarity\uff09: \u8f93\u5165\u7684\u4e24\u4e2a\u53e5\u5b50, \u6b63\u5411\u548c\u53cd\u5411\u5404\u62fc\u63a5\u4e00\u6b21, \u7136\u540e\u5206\u522b\u8f93\u5165\u7ed9transformer, \u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u62fc\u63a5\u540e\u518d\u9001\u7ed9\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u95ee\u7b54\u548c\u5e38\u8bc6\u63a8\u7406\uff08Multiple-Choice\uff09: \u5c06 N\u4e2a\u9009\u9879\u7684\u95ee\u9898\u62bd\u8c61\u5316\u4e3aN\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898, \u5373\u6bcf\u4e2a\u9009\u9879\u5206\u522b\u548c\u5185\u5bb9\u8fdb\u884c\u62fc\u63a5, \u7136\u540e\u5404\u9001\u5165transformer\u548c\u5168\u8fde\u63a5\u4e2d, \u6700\u540e\u9009\u62e9\u7f6e\u4fe1\u5ea6\u6700\u9ad8\u7684\u4f5c\u4e3a\u9884\u6d4b\u7ed3\u679c \u603b\u7684\u6765\u8bf4\uff0c\u90fd\u662f\u901a\u8fc7\u5728\u5e8f\u5217\u524d\u540e\u6dfb\u52a0 Start \u548c Extract \u7279\u6b8a\u6807\u8bc6\u7b26\u6765\u8868\u793a\u5f00\u59cb\u548c\u7ed3\u675f\uff0c\u5e8f\u5217\u4e4b\u95f4\u6dfb\u52a0\u5fc5\u8981\u7684 Delim \u6807\u8bc6\u7b26\u6765\u8868\u793a\u5206\u9694\uff0c\u5f53\u7136\u5b9e\u9645\u4f7f\u7528\u65f6\u4e0d\u4f1a\u76f4\u63a5\u7528 \u201cStart/Extract/Delim\u201d \u8fd9\u51e0\u4e2a\u8bcd\uff0c\u800c\u662f\u4f7f\u7528\u67d0\u4e9b\u7279\u6b8a\u7b26\u53f7\u3002\u57fa\u4e8e\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u6784\u9020\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684 GPT \u6a21\u578b\u8fdb\u884c\u7279\u5f81\u7f16\u7801\uff0c\u7136\u540e\u4f7f\u7528\u5e8f\u5217\u6700\u540e\u4e00\u4e2a token \u7684\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u9884\u6d4b\u3002 \u53ef\u4ee5\u770b\u5230\uff0c\u4e0d\u8bba\u4e0b\u6e38\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u600e\u4e48\u53d8\uff0c\u6700\u540e\u7684\u9884\u6d4b\u5c42\u600e\u4e48\u53d8\uff0c\u4e2d\u95f4\u7684\u7279\u5f81\u62bd\u53d6\u6a21\u5757\u90fd\u662f\u4e0d\u53d8\u7684\uff0c\u5177\u6709\u5f88\u597d\u7684\u8fc1\u79fb\u80fd\u529b\u3002","title":"1.2.3 \u6574\u4f53\u8bad\u7ec3\u8fc7\u7a0b\u67b6\u6784\u56fe"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#13-gpt","text":"GPT\u4f7f\u7528\u4e86BooksCorpus\u6570\u636e\u96c6, \u6587\u672c\u5927\u5c0f\u7ea6 5 GB\uff0c\u5305\u542b 7400w+ \u7684\u53e5\u5b50\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u7531 7000 \u672c\u72ec\u7acb\u7684\u3001\u4e0d\u540c\u98ce\u683c\u7c7b\u578b\u7684\u4e66\u7c4d\u7ec4\u6210, \u9009\u62e9\u8be5\u90e8\u5206\u6570\u636e\u96c6\u7684\u539f\u56e0: \u4e66\u7c4d\u6587\u672c\u5305\u542b\u5927\u91cf\u9ad8\u8d28\u91cf\u957f\u53e5\uff0c\u4fdd\u8bc1\u6a21\u578b\u5b66\u4e60\u957f\u8ddd\u79bb\u4fe1\u606f\u4f9d\u8d56\u3002 \u8fd9\u4e9b\u4e66\u7c4d\u56e0\u4e3a\u6ca1\u6709\u53d1\u5e03, \u6240\u4ee5\u5f88\u96be\u5728\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u89c1\u5230, \u66f4\u80fd\u9a8c\u8bc1\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b.","title":"1.3  GPT\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#14-gpt","text":"\u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 12 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 1.17 \u4ebf \u4f18\u70b9 \u5728\u6709\u76d1\u7763\u5b66\u4e60\u768412\u4e2a\u4efb\u52a1\u4e2d, GPT\u57289\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8d85\u8fc7\u4e86state-of-the-art\u7684\u6a21\u578b \u5229\u7528Transformer\u505a\u7279\u5f81\u62bd\u53d6, \u80fd\u591f\u6355\u6349\u5230\u66f4\u957f\u7684\u8bb0\u5fc6\u4fe1\u606f, \u4e14\u8f83\u4f20\u7edf\u7684 RNN \u66f4\u6613\u4e8e\u5e76\u884c\u5316 \u7f3a\u70b9 GPT \u6700\u5927\u7684\u95ee\u9898\u5c31\u662f\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u662f\u5355\u5411\u7684. \u9488\u5bf9\u4e0d\u540c\u7684\u4efb\u52a1, \u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u5fae\u8c03, \u76f8\u5bf9\u6bd4\u8f83\u9ebb\u70e6","title":"1.4 GPT\u6a21\u578b\u7684\u7279\u70b9"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#2-ar","text":"\u4f18\u70b9\uff1aAR\u6a21\u578b\u64c5\u957f\u751f\u6210\u5f0fNLP\u4efb\u52a1\u3002AR\u6a21\u578b\u4f7f\u7528\u6ce8\u610f\u529b\u673a\u5236\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2atoken\uff0c\u56e0\u6b64\u81ea\u7136\u9002\u7528\u4e8e\u6587\u672c\u751f\u6210\u3002\u6b64\u5916\uff0cAR\u6a21\u578b\u53ef\u4ee5\u7b80\u5355\u5730\u5c06\u8bad\u7ec3\u76ee\u6807\u8bbe\u7f6e\u4e3a\u9884\u6d4b\u8bed\u6599\u5e93\u4e2d\u7684\u4e0b\u4e00\u4e2atoken\uff0c\u56e0\u6b64\u751f\u6210\u6570\u636e\u76f8\u5bf9\u5bb9\u6613\u3002 \u7f3a\u70b9\uff1aAR\u6a21\u578b\u53ea\u80fd\u7528\u4e8e\u524d\u5411\u6216\u8005\u540e\u5411\u5efa\u6a21\uff0c\u4e0d\u80fd\u540c\u65f6\u4f7f\u7528\u53cc\u5411\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4e0d\u80fd\u5b8c\u5168\u6355\u6349token\u7684\u5185\u5728\u8054\u7cfb\u3002","title":"2. AR\u6a21\u578b\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#sequence-to-sequence-model","text":"encoder-decoder\u6a21\u578b\u540c\u65f6\u4f7f\u7528\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u3002\u5b83\u5c06\u6bcf\u4e2atask\u89c6\u4f5c\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u8f6c\u6362/\u751f\u6210\uff08\u6bd4\u5982\uff0c\u6587\u672c\u5230\u6587\u672c\uff0c\u6587\u672c\u5230\u56fe\u50cf\u6216\u8005\u56fe\u50cf\u5230\u6587\u672c\u7684\u591a\u6a21\u6001\u4efb\u52a1\uff09\u3002\u5bf9\u4e8e\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u6765\u8bf4\uff0c\u7f16\u7801\u5668\u5c06\u6587\u672c\u4f5c\u4e3a\u8f93\u5165\uff0c\u89e3\u7801\u5668\u751f\u6210\u6587\u672c\u6807\u7b7e\u3002Encoder-decoder\u6a21\u578b\u901a\u5e38\u7528\u4e8e\u9700\u8981\u5185\u5bb9\u7406\u89e3\u548c\u751f\u6210\u7684\u4efb\u52a1\uff0c\u6bd4\u5982\u673a\u5668\u7ffb\u8bd1\u3002","title":"\u5e8f\u5217\u5230\u5e8f\u5217\uff08Sequence to Sequence Model\uff09"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#1-t5","text":"T5 \u7531\u8c37\u6b4c\u7684 Raffel \u7b49\u4eba\u4e8e 2020\u5e747\u6708\u63d0\u51fa\uff0c\u76f8\u5173\u8bba\u6587\u4e3a\u201cExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\u201d. \u8be5\u6a21\u578b\u7684\u76ee\u7684\u4e3a\u6784\u5efa\u4efb\u52a1\u7edf\u4e00\u6846\u67b6\uff1a\u5c06\u6240\u6709NLP\u4efb\u52a1\u90fd\u89c6\u4e3a\u6587\u672c\u8f6c\u6362\u4efb\u52a1\u3002 \u6bd4\u5982\u82f1\u5fb7\u7ffb\u8bd1\uff0c\u53ea\u9700\u5c06\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u8f93\u5165\u90e8\u5206\u524d\u52a0\u4e0a\u201ctranslate English to German\uff08\u7ed9\u6211\u4ece\u82f1\u8bed\u7ffb\u8bd1\u6210\u5fb7\u8bed\uff09\u201d \u5c31\u884c\u3002\u5047\u8bbe\u9700\u8981\u7ffb\u8bd1\"That is good\"\uff0c\u90a3\u4e48\u5148\u8f6c\u6362\u6210 \"translate English to German\uff1aThat is good.\" \u8f93\u5165\u6a21\u578b\uff0c\u4e4b\u540e\u5c31\u53ef\u4ee5\u76f4\u63a5\u8f93\u51fa\u5fb7\u8bed\u7ffb\u8bd1 \u201cDas ist gut.\u201d\u3002 \u5bf9\u4e8e\u9700\u8981\u8f93\u51fa\u8fde\u7eed\u503c\u7684 STS-B\uff08\u6587\u672c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u4efb\u52a1\uff09\uff0c \u4e5f\u662f\u76f4\u63a5\u8f93\u51fa\u6587\u672c\u3002 \u901a\u8fc7\u8fd9\u6837\u7684\u65b9\u5f0f\u5c31\u80fd\u5c06 NLP \u4efb\u52a1\u90fd\u8f6c\u6362\u6210 Text-to-Text \u5f62\u5f0f\uff0c\u4e5f\u5c31\u53ef\u4ee5**\u7528\u540c\u6837\u7684\u6a21\u578b\uff0c\u540c\u6837\u7684\u635f\u5931\u51fd\u6570\uff0c\u540c\u6837\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u540c\u6837\u7684\u89e3\u7801\u8fc7\u7a0b\u6765\u5b8c\u6210\u6240\u6709 NLP \u4efb\u52a1\u3002**","title":"1. \u4ee3\u8868\u6a21\u578bT5"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#11-t5","text":"T5\u6a21\u578b\u7ed3\u6784\u4e0e\u539f\u59cb\u7684Transformer\u57fa\u672c\u4e00\u81f4,\u9664\u4e86\u505a\u4e86\u4ee5\u4e0b\u51e0\u70b9\u6539\u52a8\uff1a \u4f5c\u8005\u91c7\u7528\u4e86\u4e00\u79cd\u7b80\u5316\u7248\u7684Layer Normalization\uff0c\u53bb\u9664\u4e86Layer Norm \u7684bias\uff1b\u5c06Layer Norm\u653e\u5728\u6b8b\u5dee\u8fde\u63a5\u5916\u9762\u3002 \u4f4d\u7f6e\u7f16\u7801\uff1aT5\u4f7f\u7528\u4e86\u4e00\u79cd\u7b80\u5316\u7248\u7684\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u5373\u6bcf\u4e2a\u4f4d\u7f6e\u7f16\u7801\u90fd\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u88ab\u52a0\u5230 logits \u4e0a\u7528\u4e8e\u8ba1\u7b97\u6ce8\u610f\u529b\u6743\u91cd\u3002\u5404\u5c42\u5171\u4eab\u4f4d\u7f6e\u7f16\u7801\uff0c\u4f46\u662f\u5728\u540c\u4e00\u5c42\u5185\uff0c\u4e0d\u540c\u7684\u6ce8\u610f\u529b\u5934\u7684\u4f4d\u7f6e\u7f16\u7801\u90fd\u662f\u72ec\u7acb\u5b66\u4e60\u7684\u3002\u4e00\u5b9a\u6570\u91cf\u7684\u4f4d\u7f6eEmbedding\uff0c\u6bcf\u4e00\u4e2a\u5bf9\u5e94\u4e00\u4e2a\u53ef\u80fd\u7684 key-query \u4f4d\u7f6e\u5dee\u3002\u4f5c\u8005\u5b66\u4e60\u4e8632\u4e2aEmbedding\uff0c\u81f3\u591a\u9002\u7528\u4e8e\u957f\u5ea6\u4e3a128\u7684\u4f4d\u7f6e\u5dee\uff0c\u8d85\u8fc7\u4f4d\u7f6e\u5dee\u7684\u4f4d\u7f6e\u7f16\u7801\u90fd\u4f7f\u7528\u76f8\u540c\u7684Embedding\u3002","title":"1.1 T5\u6a21\u578b\u67b6\u6784"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#12-t5","text":"\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff1a\u91c7\u7528\u7c7b\u4f3c\u4e8eBERT\u6a21\u578b\u7684MLM\u9884\u8bad\u7ec3\u4efb\u52a1\u3002 \u591a\u4efb\u52a1\u9884\u8bad\u7ec3\uff1a\u9664\u4e86\u4f7f\u7528\u5927\u89c4\u6a21\u6570\u636e\u8fdb\u884c\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\uff0cT5\u6a21\u578b\u8fd8\u53ef\u4ee5\u5229\u7528\u4e0d\u540c\u4efb\u52a1\u7684\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u6709\u76d1\u7763\u7684\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\uff0c\u4f8b\u5982SQuAD\u95ee\u7b54\u548c\u673a\u5668\u7ffb\u8bd1\u7b49\u4efb\u52a1\u3002","title":"1.2 T5 \u8bad\u7ec3\u8fc7\u7a0b"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#13-t5","text":"\u4f5c\u8005\u5bf9\u516c\u5f00\u722c\u53d6\u7684\u7f51\u9875\u6570\u636e\u96c6Common Crawl\u8fdb\u884c\u4e86\u8fc7\u6ee4\uff0c\u53bb\u6389\u4e00\u4e9b\u91cd\u590d\u7684\u3001\u4f4e\u8d28\u91cf\u7684\uff0c\u770b\u7740\u50cf\u4ee3\u7801\u7684\u6587\u672c\u7b49\uff0c\u5e76\u4e14\u6700\u540e\u53ea\u4fdd\u7559\u82f1\u6587\u6587\u672c\uff0c\u5f97\u5230\u6570\u636e\u96c6**C4: the Colossal Clean Crawled Corpus**\u3002","title":"1.3 T5\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#14-t5","text":"\u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 24 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 2.2 \u4ebf","title":"1.4 T5\u6a21\u578b\u7684\u7279\u70b9"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#2-encoder-decoder","text":"\u4f18\u70b9\uff1aT5\u6a21\u578b\u53ef\u4ee5\u5904\u7406\u591a\u79cdNLP\u4efb\u52a1\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u5fae\u8c03\u6765\u9002\u5e94\u4e0d\u540c\u7684\u5e94\u7528\u573a\u666f\uff0c\u5177\u6709\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff1b\u76f8\u6bd4\u5176\u4ed6\u8bed\u8a00\u751f\u6210\u6a21\u578b\uff08\u5982GPT-2\u3001GPT3\u7b49\uff09\uff0cT5\u6a21\u578b\u7684\u53c2\u6570\u6570\u91cf\u76f8\u5bf9\u8f83\u5c11\uff0c\u8bad\u7ec3\u901f\u5ea6\u66f4\u5feb\uff0c\u4e14\u53ef\u4ee5\u5728\u76f8\u5bf9\u8f83\u5c0f\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002 \u7f3a\u70b9\uff1a\u7531\u4e8eT5\u6a21\u578b\u4f7f\u7528\u4e86\u5927\u91cf\u7684Transformer\u7ed3\u6784\uff0c\u5728\u8bad\u7ec3\u65f6\u9700\u8981\u5927\u91cf\u7684\u8ba1\u7b97\u8d44\u6e90\u548c\u65f6\u95f4; \u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002","title":"2. encoder-decoder\u6a21\u578b\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#-decoder-only","text":"LLM\u4e4b\u6240\u4ee5\u4e3b\u8981\u90fd\u7528Decoder-only\u67b6\u6784\uff0c\u9664\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u5de5\u7a0b\u5b9e\u73b0\u4e0a\u7684\u4f18\u52bf\u5916\uff0c\u5728\u7406\u8bba\u4e0a\u662f\u56e0\u4e3aEncoder\u7684\u53cc\u5411\u6ce8\u610f\u529b\u4f1a\u5b58\u5728\u4f4e\u79e9\u95ee\u9898\uff0c\u8fd9\u53ef\u80fd\u4f1a\u524a\u5f31\u6a21\u578b\u8868\u8fbe\u80fd\u529b\uff0c\u5c31\u751f\u6210\u4efb\u52a1\u800c\u8a00\uff0c\u5f15\u5165\u53cc\u5411\u6ce8\u610f\u529b\u5e76\u65e0\u5b9e\u8d28\u597d\u5904\u3002\u800cEncoder-Decoder\u67b6\u6784\u4e4b\u6240\u4ee5\u80fd\u591f\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u8868\u73b0\u66f4\u597d\uff0c\u5927\u6982\u53ea\u662f\u56e0\u4e3a\u5b83\u591a\u4e86\u4e00\u500d\u53c2\u6570\u3002\u6240\u4ee5\uff0c\u5728\u540c\u7b49\u53c2\u6570\u91cf\u3001\u540c\u7b49\u63a8\u7406\u6210\u672c\u4e0b\uff0cDecoder-only\u67b6\u6784\u5c31\u662f\u6700\u4f18\u9009\u62e9\u4e86\u3002","title":"\u76ee\u524d\u5927\u6a21\u578b\u4e3b\u6d41\u6a21\u578b\u67b6\u6784-Decoder-only"},{"location":"%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%8C%E6%99%AF%E7%AE%80%E4%BB%8B/02-LLM%E4%B8%BB%E8%A6%81%E7%B1%BB%E5%88%AB%E6%9E%B6%E6%9E%84.html#_2","text":"\u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecdLLM\u7684\u4e3b\u8981\u7c7b\u522b\u67b6\u6784\uff1a\u81ea\u56de\u5f52\u6a21\u578b\u3001\u81ea\u7f16\u7801\u6a21\u578b\u548c\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u3002 \u5206\u522b\u5bf9\u4e0d\u540c\u7c7b\u578b\u67b6\u6784\u7684\u4ee3\u8868\u6a21\u578b\u5982\uff1aBERT\u3001GPT\u3001T5\u7b49\u76f8\u5173\u6a21\u578b\u8fdb\u884c\u4ecb\u7ecd","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html","text":"\u57fa\u4e8eChatGLM-6B\u5b8c\u6210\u591a\u4efb\u52a1\u9879\u76ee\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u9879\u76ee\u80cc\u666f \u7406\u89e3ChatGLM-6B\u6a21\u578b\u67b6\u6784\u539f\u7406 \u5b89\u88c5\u9879\u76ee\u5fc5\u5907\u7684\u5de5\u5177\u5305 \u4e86\u89e3\u6574\u4f53\u9879\u76ee\u67b6\u6784 1. \u9879\u76ee\u7b80\u4ecb \u00b6 LLM\uff08Large Language Model\uff09\u901a\u5e38\u62e5\u6709\u5927\u91cf\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u4f7f\u5f97\u5176\u5728\u8bb8\u591a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0a\u90fd\u6709\u7740\u4e0d\u9519\u7684\u6027\u80fd\u3002\u4f46\uff0c\u60f3\u8981\u76f4\u63a5\u5229\u7528 LLM \u5b8c\u6210\u4e00\u4e9b\u4efb\u52a1\u4f1a\u5b58\u5728\u4e00\u4e9b\u7b54\u6848\u89e3\u6790\u4e0a\u7684\u56f0\u96be\uff0c\u5982\u89c4\u8303\u5316\u8f93\u51fa\u683c\u5f0f\uff0c\u4e25\u683c\u670d\u4ece\u8f93\u5165\u4fe1\u606f\u7b49\u3002\u56e0\u6b64\uff0c\u5728\u8fd9\u4e2a\u9879\u76ee\u4e2d\u6211\u4eec\u5bf9\u5927\u6a21\u578b ChatGLM-6B \u8fdb\u884c Finetune\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u597d\u7684\u5bf9\u9f50\u6211\u4eec\u6240\u9700\u8981\u7684\u8f93\u51fa\u683c\u5f0f\u3002 2. ChatGLM-6B\u6a21\u578b \u00b6 ChatGLM-6B \u662f\u6e05\u534e\u5927\u5b66\u63d0\u51fa\u7684\u4e00\u4e2a\u5f00\u6e90\u3001\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u7684\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e General Language Model (GLM) \u67b6\u6784\uff0c\u5177\u6709 62 \u4ebf\u53c2\u6570\u3002\u8be5\u6a21\u578b\u4f7f\u7528\u4e86\u548c ChatGPT \u76f8\u4f3c\u7684\u6280\u672f\uff0c\u7ecf\u8fc7\u7ea6 1T \u6807\u8bc6\u7b26\u7684\u4e2d\u82f1\u53cc\u8bed\u8bad\u7ec3(\u4e2d\u82f1\u6587\u6bd4\u4f8b\u4e3a 1:1)\uff0c\u8f85\u4ee5\u76d1\u7763\u5fae\u8c03\u3001\u53cd\u9988\u81ea\u52a9\u3001\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u7b49\u6280\u672f\u7684\u52a0\u6301\uff0c62 \u4ebf\u53c2\u6570\u7684 ChatGLM-6B \u5df2\u7ecf\u80fd\u751f\u6210\u76f8\u5f53\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u7684\u56de\u7b54\uff08\u76ee\u524d\u4e2d\u6587\u652f\u6301\u6700\u597d\uff09\u3002 \u76f8\u6bd4\u539f\u59cbDecoder\u6a21\u5757\uff0cChatGLM-6B\u6a21\u578b\u7ed3\u6784\u6709\u5982\u4e0b\u6539\u52a8\u70b9\uff1a embedding \u5c42\u68af\u5ea6\u7f29\u51cf \uff1a\u4e3a\u4e86\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u51cf\u5c0f\u4e86 embedding \u5c42\u7684\u68af\u5ea6\u3002\u68af\u5ea6\u7f29\u51cf\u7684\u6548\u679c\u76f8\u5f53\u4e8e\u628a embedding \u5c42\u7684\u68af\u5ea6\u7f29\u5c0f\u4e86 10 \u500d\uff0c\u51cf\u5c0f\u4e86\u68af\u5ea6\u7684\u8303\u6570\u3002 layer normalization \uff1a\u91c7\u7528\u4e86\u57fa\u4e8e Deep Norm \u7684 post layer norm\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u66ff\u6362ReLU\u6fc0\u6d3b\u51fd\u6570\u91c7\u7528\u4e86 GeGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002 2.2 \u6a21\u578b\u914d\u7f6e(6B) \u00b6 \u914d\u7f6e \u6570\u636e \u53c2\u6570 6.2B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 28 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1T \u8bcd\u8868\u5927\u5c0f 130528 \u6700\u5927\u957f\u5ea6 2048 2.3 \u786c\u4ef6\u8981\u6c42(\u5b98\u7f51\u4ecb\u7ecd) \u00b6 \u91cf\u5316\u7b49\u7ea7 \u6700\u4f4eGPU\u663e\u5b58\uff08\u63a8\u7406\uff09 \u6700\u4f4eGPU\u663e\u5b58\uff08\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\uff09 FP16(\u65e0\u91cf\u5316) 13GB 14GB INT8 10GB 9GB INT4 6GB 7GB \u6ce8\u610f\uff1a\u663e\u5b58\u7684\u5360\u7528\u9664\u4e86\u8ddf\u6a21\u578b\u53c2\u6570\u5927\u5c0f\u6709\u5173\u7cfb\u5916\uff0c\u8fd8\u548c\u6587\u672c\u652f\u6301\u6700\u5927\u957f\u5ea6\u6709\u5173 2.4 \u6a21\u578b\u7279\u70b9 \u00b6 \u4f18\u70b9 1.\u8f83\u4f4e\u7684\u90e8\u7f72\u95e8\u69db\uff1a INT4 \u7cbe\u5ea6\u4e0b\uff0c\u53ea\u97006GB\u663e\u5b58\uff0c\u4f7f\u5f97 ChatGLM-6B \u53ef\u4ee5\u90e8\u7f72\u5728\u6d88\u8d39\u7ea7\u663e\u5361\u4e0a\u8fdb\u884c\u63a8\u7406\u3002 2.\u66f4\u957f\u7684\u5e8f\u5217\u957f\u5ea6\uff1a \u76f8\u6bd4 GLM-10B\uff08\u5e8f\u5217\u957f\u5ea61024\uff09\uff0cChatGLM2-6B \u5e8f\u5217\u957f\u5ea6\u8fbe32K\uff0c\u652f\u6301\u66f4\u957f\u5bf9\u8bdd\u548c\u5e94\u7528\u3002 \u4eba\u7c7b\u7c7b\u610f\u56fe\u5bf9\u9f50\u8bad\u7ec3 \u7f3a\u70b9\uff1a \u6a21\u578b\u5bb9\u91cf\u5c0f\uff0c\u76f8\u5bf9\u8f83\u5f31\u7684\u6a21\u578b\u8bb0\u5fc6\u548c\u8bed\u8a00\u80fd\u529b\u3002 \u8f83\u5f31\u7684\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u3002 3. \u73af\u5883\u914d\u7f6e \u00b6 3.1 \u57fa\u7840\u73af\u5883\u914d\u7f6e\uff1a \u00b6 \u672c\u6b21\u73af\u5883\u4f9d\u8d56\u4e8e\u8d8b\u52a8\u4e91https://platform.virtaicloud.com/\u7b97\u529b \u64cd\u4f5c\u7cfb\u7edf: CentOS 7 CPUs: 8 core(s)\uff0c\u5185\u5b58\uff1a48G GPUs: 1\u5361\uff0c A800\uff0c 80GB GPUs Python: 3.9 Pytorh: 1.11.0 Cuda: 11.3.1 \u4ef7\u683c\uff1a13.58\u5143/\u5c0f\u65f6 3.2 \u5b89\u88c5\u4f9d\u8d56\u5305\uff1a \u00b6 \u521b\u5efa\u4e00\u4e2a\u865a\u62df\u73af\u5883\uff0c\u60a8\u53ef\u4ee5\u628a llm_env \u4fee\u6539\u4e3a\u4efb\u610f\u4f60\u60f3\u8981\u65b0\u5efa\u7684\u73af\u5883\u540d\u79f0\uff1a conda create -n llm_env python = 3 .9 \u6fc0\u6d3b\u65b0\u5efa\u865a\u62df\u73af\u5883\u5e76\u5b89\u88c5\u54cd\u5e94\u7684\u4f9d\u8d56\u5305\uff1a conda activate llm_env pip install -r requirements.txt protobuf >= 3.19.5 , < 3.20.1 transformers >= 4.26.1 icetk cpm_kernels streamlit == 1.17.0 matplotlib datasets == 2.10.1 accelerate == 0.17.1 packaging >= 20.0 , psutil , pyyaml , peft requirements.txt\u6587\u4ef6\u5185\u5bb9\u5982\u4e0a\u6240\u793a 4. \u9879\u76ee\u67b6\u6784 \u00b6 \u9879\u76ee\u67b6\u6784\u6d41\u7a0b\u56fe\uff1a \u9879\u76ee\u4ee3\u7801\u67b6\u6784\u56fe\uff1a \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u7684\u80cc\u666f\u3001\u9879\u76ee\u7684\u9002\u914d\u73af\u5883\u4ee5\u53ca\u9879\u76ee\u7684\u6574\u4f53\u67b6\u6784\u6d41\u7a0b\uff0c\u4ee5\u6b64\u6765\u65b9\u4fbf\u6211\u4eec\u6574\u4e2a\u9879\u76ee\u7684\u5f00\u53d1\u3002","title":"7.1 \u9879\u76ee\u6574\u4f53\u7b80\u4ecb"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#chatglm-6b","text":"","title":"\u57fa\u4e8eChatGLM-6B\u5b8c\u6210\u591a\u4efb\u52a1\u9879\u76ee\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#_1","text":"\u4e86\u89e3\u9879\u76ee\u80cc\u666f \u7406\u89e3ChatGLM-6B\u6a21\u578b\u67b6\u6784\u539f\u7406 \u5b89\u88c5\u9879\u76ee\u5fc5\u5907\u7684\u5de5\u5177\u5305 \u4e86\u89e3\u6574\u4f53\u9879\u76ee\u67b6\u6784","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#1","text":"LLM\uff08Large Language Model\uff09\u901a\u5e38\u62e5\u6709\u5927\u91cf\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u4f7f\u5f97\u5176\u5728\u8bb8\u591a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e0a\u90fd\u6709\u7740\u4e0d\u9519\u7684\u6027\u80fd\u3002\u4f46\uff0c\u60f3\u8981\u76f4\u63a5\u5229\u7528 LLM \u5b8c\u6210\u4e00\u4e9b\u4efb\u52a1\u4f1a\u5b58\u5728\u4e00\u4e9b\u7b54\u6848\u89e3\u6790\u4e0a\u7684\u56f0\u96be\uff0c\u5982\u89c4\u8303\u5316\u8f93\u51fa\u683c\u5f0f\uff0c\u4e25\u683c\u670d\u4ece\u8f93\u5165\u4fe1\u606f\u7b49\u3002\u56e0\u6b64\uff0c\u5728\u8fd9\u4e2a\u9879\u76ee\u4e2d\u6211\u4eec\u5bf9\u5927\u6a21\u578b ChatGLM-6B \u8fdb\u884c Finetune\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u597d\u7684\u5bf9\u9f50\u6211\u4eec\u6240\u9700\u8981\u7684\u8f93\u51fa\u683c\u5f0f\u3002","title":"1. \u9879\u76ee\u7b80\u4ecb"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#2-chatglm-6b","text":"ChatGLM-6B \u662f\u6e05\u534e\u5927\u5b66\u63d0\u51fa\u7684\u4e00\u4e2a\u5f00\u6e90\u3001\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u7684\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e General Language Model (GLM) \u67b6\u6784\uff0c\u5177\u6709 62 \u4ebf\u53c2\u6570\u3002\u8be5\u6a21\u578b\u4f7f\u7528\u4e86\u548c ChatGPT \u76f8\u4f3c\u7684\u6280\u672f\uff0c\u7ecf\u8fc7\u7ea6 1T \u6807\u8bc6\u7b26\u7684\u4e2d\u82f1\u53cc\u8bed\u8bad\u7ec3(\u4e2d\u82f1\u6587\u6bd4\u4f8b\u4e3a 1:1)\uff0c\u8f85\u4ee5\u76d1\u7763\u5fae\u8c03\u3001\u53cd\u9988\u81ea\u52a9\u3001\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u7b49\u6280\u672f\u7684\u52a0\u6301\uff0c62 \u4ebf\u53c2\u6570\u7684 ChatGLM-6B \u5df2\u7ecf\u80fd\u751f\u6210\u76f8\u5f53\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u7684\u56de\u7b54\uff08\u76ee\u524d\u4e2d\u6587\u652f\u6301\u6700\u597d\uff09\u3002 \u76f8\u6bd4\u539f\u59cbDecoder\u6a21\u5757\uff0cChatGLM-6B\u6a21\u578b\u7ed3\u6784\u6709\u5982\u4e0b\u6539\u52a8\u70b9\uff1a embedding \u5c42\u68af\u5ea6\u7f29\u51cf \uff1a\u4e3a\u4e86\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u51cf\u5c0f\u4e86 embedding \u5c42\u7684\u68af\u5ea6\u3002\u68af\u5ea6\u7f29\u51cf\u7684\u6548\u679c\u76f8\u5f53\u4e8e\u628a embedding \u5c42\u7684\u68af\u5ea6\u7f29\u5c0f\u4e86 10 \u500d\uff0c\u51cf\u5c0f\u4e86\u68af\u5ea6\u7684\u8303\u6570\u3002 layer normalization \uff1a\u91c7\u7528\u4e86\u57fa\u4e8e Deep Norm \u7684 post layer norm\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u66ff\u6362ReLU\u6fc0\u6d3b\u51fd\u6570\u91c7\u7528\u4e86 GeGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002","title":"2. ChatGLM-6B\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#22-6b","text":"\u914d\u7f6e \u6570\u636e \u53c2\u6570 6.2B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 28 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1T \u8bcd\u8868\u5927\u5c0f 130528 \u6700\u5927\u957f\u5ea6 2048","title":"2.2 \u6a21\u578b\u914d\u7f6e(6B)"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#23","text":"\u91cf\u5316\u7b49\u7ea7 \u6700\u4f4eGPU\u663e\u5b58\uff08\u63a8\u7406\uff09 \u6700\u4f4eGPU\u663e\u5b58\uff08\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\uff09 FP16(\u65e0\u91cf\u5316) 13GB 14GB INT8 10GB 9GB INT4 6GB 7GB \u6ce8\u610f\uff1a\u663e\u5b58\u7684\u5360\u7528\u9664\u4e86\u8ddf\u6a21\u578b\u53c2\u6570\u5927\u5c0f\u6709\u5173\u7cfb\u5916\uff0c\u8fd8\u548c\u6587\u672c\u652f\u6301\u6700\u5927\u957f\u5ea6\u6709\u5173","title":"2.3 \u786c\u4ef6\u8981\u6c42(\u5b98\u7f51\u4ecb\u7ecd)"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#24","text":"\u4f18\u70b9 1.\u8f83\u4f4e\u7684\u90e8\u7f72\u95e8\u69db\uff1a INT4 \u7cbe\u5ea6\u4e0b\uff0c\u53ea\u97006GB\u663e\u5b58\uff0c\u4f7f\u5f97 ChatGLM-6B \u53ef\u4ee5\u90e8\u7f72\u5728\u6d88\u8d39\u7ea7\u663e\u5361\u4e0a\u8fdb\u884c\u63a8\u7406\u3002 2.\u66f4\u957f\u7684\u5e8f\u5217\u957f\u5ea6\uff1a \u76f8\u6bd4 GLM-10B\uff08\u5e8f\u5217\u957f\u5ea61024\uff09\uff0cChatGLM2-6B \u5e8f\u5217\u957f\u5ea6\u8fbe32K\uff0c\u652f\u6301\u66f4\u957f\u5bf9\u8bdd\u548c\u5e94\u7528\u3002 \u4eba\u7c7b\u7c7b\u610f\u56fe\u5bf9\u9f50\u8bad\u7ec3 \u7f3a\u70b9\uff1a \u6a21\u578b\u5bb9\u91cf\u5c0f\uff0c\u76f8\u5bf9\u8f83\u5f31\u7684\u6a21\u578b\u8bb0\u5fc6\u548c\u8bed\u8a00\u80fd\u529b\u3002 \u8f83\u5f31\u7684\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u3002","title":"2.4 \u6a21\u578b\u7279\u70b9"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#3","text":"","title":"3. \u73af\u5883\u914d\u7f6e"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#31","text":"\u672c\u6b21\u73af\u5883\u4f9d\u8d56\u4e8e\u8d8b\u52a8\u4e91https://platform.virtaicloud.com/\u7b97\u529b \u64cd\u4f5c\u7cfb\u7edf: CentOS 7 CPUs: 8 core(s)\uff0c\u5185\u5b58\uff1a48G GPUs: 1\u5361\uff0c A800\uff0c 80GB GPUs Python: 3.9 Pytorh: 1.11.0 Cuda: 11.3.1 \u4ef7\u683c\uff1a13.58\u5143/\u5c0f\u65f6","title":"3.1 \u57fa\u7840\u73af\u5883\u914d\u7f6e\uff1a"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#32","text":"\u521b\u5efa\u4e00\u4e2a\u865a\u62df\u73af\u5883\uff0c\u60a8\u53ef\u4ee5\u628a llm_env \u4fee\u6539\u4e3a\u4efb\u610f\u4f60\u60f3\u8981\u65b0\u5efa\u7684\u73af\u5883\u540d\u79f0\uff1a conda create -n llm_env python = 3 .9 \u6fc0\u6d3b\u65b0\u5efa\u865a\u62df\u73af\u5883\u5e76\u5b89\u88c5\u54cd\u5e94\u7684\u4f9d\u8d56\u5305\uff1a conda activate llm_env pip install -r requirements.txt protobuf >= 3.19.5 , < 3.20.1 transformers >= 4.26.1 icetk cpm_kernels streamlit == 1.17.0 matplotlib datasets == 2.10.1 accelerate == 0.17.1 packaging >= 20.0 , psutil , pyyaml , peft requirements.txt\u6587\u4ef6\u5185\u5bb9\u5982\u4e0a\u6240\u793a","title":"3.2 \u5b89\u88c5\u4f9d\u8d56\u5305\uff1a"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#4","text":"\u9879\u76ee\u67b6\u6784\u6d41\u7a0b\u56fe\uff1a \u9879\u76ee\u4ee3\u7801\u67b6\u6784\u56fe\uff1a","title":"4. \u9879\u76ee\u67b6\u6784"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/01-%E9%A1%B9%E7%9B%AE%E6%95%B4%E4%BD%93%E4%BB%8B%E7%BB%8D.html#_2","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u7684\u80cc\u666f\u3001\u9879\u76ee\u7684\u9002\u914d\u73af\u5883\u4ee5\u53ca\u9879\u76ee\u7684\u6574\u4f53\u67b6\u6784\u6d41\u7a0b\uff0c\u4ee5\u6b64\u6765\u65b9\u4fbf\u6211\u4eec\u6574\u4e2a\u9879\u76ee\u7684\u5f00\u53d1\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html","text":"\u591a\u4efb\u52a1\u6570\u636e\u9884\u5904\u7406\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u672c\u9879\u76ee\u4e2d\u591a\u4efb\u52a1\u6570\u636e\u96c6\u7684\u683c\u5f0f \u638c\u63e1\u5b9e\u73b0\u6570\u636e\u9884\u5904\u7406\u7684\u51fd\u6570\u4ee3\u7801 \u6570\u636e\u9884\u5904\u7406\u8fc7\u7a0b \u00b6 \u672c\u9879\u76ee\u4e2d\u5bf9\u6570\u636e\u90e8\u5206\u7684\u9884\u5904\u7406\u6b65\u9aa4\u5982\u4e0b: \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801 1 \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u00b6 \u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b3\u4e2ajsonl\u6587\u6863\uff0c\u5206\u522b\u4e3a\uff1amixed_train_dataset.jsonl\u3001mixed_dev_dataset.jsonl\u3001dataset.jsonl 1.1 train.jsonl \u00b6 mixed_train_dataset.jsonl\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u56e0\u4e3a\u6211\u4eec\u672c\u6b21\u9879\u76ee\u540c\u65f6\u8fdb\u884c\u300c\u4fe1\u606f\u62bd\u53d6+\u6587\u672c\u5206\u7c7b\u300d\u4e24\u9879\u4efb\u52a1\uff0c\u56e0\u6b64\u6570\u636e\u4e2d\u6df7\u5408\u4e86\u4e24\u79cd\u4efb\u52a1\u6570\u636e\u7c7b\u578b\u3002\u4e3e\u4f8b\u5c55\u793a\u5982\u4e0b\uff1a \u4fe1\u606f\u62bd\u53d6\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u627e\u5230\u53e5\u5b50\u4e2d\u7684\u4e09\u5143\u7ec4\u4fe1\u606f\u5e76\u8f93\u51fa\u6210json\u7ed9\u6211:\\n\\n\u4e5d\u7384\u73e0\u662f\u5728\u7eb5\u6a2a\u4e2d\u6587\u7f51\u8fde\u8f7d\u7684\u4e00\u90e8\u5c0f\u8bf4\uff0c\u4f5c\u8005\u662f\u9f99\u9a6c\u3002\\nAnswer: \" , \"target\" : \"```json\\n[{\\\"predicate\\\": \\\"\u8fde\u8f7d\u7f51\u7ad9\\\", \\\"object_type\\\": \\\"\u7f51\u7ad9\\\", \\\"subject_type\\\": \\\"\u7f51\u7edc\u5c0f\u8bf4\\\", \\\"object\\\": \\\"\u7eb5\u6a2a\u4e2d\u6587\u7f51\\\", \\\"subject\\\": \\\"\u4e5d\u7384\u73e0\\\"}, {\\\"predicate\\\": \\\"\u4f5c\u8005\\\", \\\"object_type\\\": \\\"\u4eba\u7269\\\", \\\"subject_type\\\": \\\"\u56fe\u4e66\u4f5c\u54c1\\\", \\\"object\\\": \\\"\u9f99\u9a6c\\\", \\\"subject\\\": \\\"\u4e5d\u7384\u73e0\\\"}]\\n```\" } \u6587\u672c\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u4e0b\u9762\u53e5\u5b50\u53ef\u80fd\u662f\u4e00\u6761\u5173\u4e8e\u4ec0\u4e48\u7684\u8bc4\u8bba\uff0c\u7528\u5217\u8868\u5f62\u5f0f\u56de\u7b54\uff1a\\n\\n\u5f88\u4e0d\u9519\uff0c\u5f88\u65b0\u9c9c\uff0c\u5feb\u9012\u5c0f\u54e5\u670d\u52a1\u5f88\u597d\uff0c\u6c34\u679c\u4e5f\u633a\u751c\u633a\u8106\u7684\\nAnswer: \" , \"target\" : \"[\\\"\u6c34\u679c\\\"]\" } \u8bad\u7ec3\u96c6\u4e2d\u4e00\u5171\u5305\u542b902\u6761\u6570\u636e\uff0c\u6bcf\u4e00\u6761\u6570\u636e\u90fd\u5206\u4e3a context \u548c target \u4e24\u90e8\u5206\uff1a context \u90e8\u5206\u662f\u63a5\u53d7\u7528\u6237\u7684\u8f93\u5165\u30022. target \u90e8\u5206\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u7684\u8f93\u51fa\u3002 \u5728 context \u4e2d\u53c8\u5305\u62ec 2 \u4e2a\u90e8\u5206\uff1a Instruction\uff1a\u7528\u4e8e\u544a\u77e5\u6a21\u578b\u7684\u5177\u4f53\u6307\u4ee4\uff0c\u5f53\u9700\u8981\u4e00\u4e2a\u6a21\u578b\u540c\u65f6\u89e3\u51b3\u591a\u4e2a\u4efb\u52a1\u65f6\u53ef\u4ee5\u8bbe\u5b9a\u4e0d\u540c\u7684 Instruction \u6765\u5e2e\u52a9\u6a21\u578b\u5224\u522b\u5f53\u524d\u5e94\u5f53\u505a\u4ec0\u4e48\u4efb\u52a1\u3002 Input\uff1a\u5f53\u524d\u7528\u6237\u7684\u8f93\u5165\u3002 1.2 dev.jsonl \u00b6 mixed_dev_dataset.jsonl\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u56e0\u4e3a\u6211\u4eec\u672c\u6b21\u9879\u76ee\u540c\u65f6\u8fdb\u884c\u300c\u4fe1\u606f\u62bd\u53d6+\u6587\u672c\u5206\u7c7b\u300d\u4e24\u9879\u4efb\u52a1\uff0c\u56e0\u6b64\u6570\u636e\u4e2d\u6df7\u5408\u4e86\u4e24\u79cd\u4efb\u52a1\u6570\u636e\u7c7b\u578b\u3002\u4e3e\u4f8b\u5c55\u793a\u5982\u4e0b\uff1a \u4fe1\u606f\u62bd\u53d6\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u4e0b\u9762\u53e5\u5b50\u5305\u542b\u4e86\u54ea\u4e9b\u4e09\u5143\u7ec4\uff0c\u53ea\u7528json\u7684\u683c\u5f0f\u56de\u7b54\uff1a\\n\\n\u300a\u5168\u56fd\u516c\u5171\u82f1\u8bed\u7b49\u7ea7\u8003\u8bd5\u56db\u7ea7\u8bcd\u6c47\u79d1\u5b66\u8bb0\u5fc6\uff08\u78c1\u5e261--5\uff09\u300b\u662f\u7531\u4eba\u6c11\u5927\u5b66\u51fa\u7248\u793e\u51fa\u7248\u7684\u4e00\u90e8\u6559\u80b2\u4f5c\u54c1\uff0c\u4f5c\u8005\u662f\u949f\u9053\u9686\u3002\\nAnswer: \" , \"target\" : \"```json\\n[{\\\"predicate\\\": \\\"\u51fa\u7248\u793e\\\", \\\"object_type\\\": \\\"\u51fa\u7248\u793e\\\", \\\"subject_type\\\": \\\"\u4e66\u7c4d\\\", \\\"object\\\": \\\"\u4eba\u6c11\u5927\u5b66\\\", \\\"subject\\\": \\\"\u5168\u56fd\u516c\u5171\u82f1\u8bed\u7b49\u7ea7\u8003\u8bd5\u56db\u7ea7\u8bcd\u6c47\u79d1\u5b66\u8bb0\u5fc6\uff08\u78c1\u5e261--5\uff09\\\"}, {\\\"predicate\\\": \\\"\u4f5c\u8005\\\", \\\"object_type\\\": \\\"\u4eba\u7269\\\", \\\"subject_type\\\": \\\"\u56fe\u4e66\u4f5c\u54c1\\\", \\\"object\\\": \\\"\u949f\u9053\u9686\\\", \\\"subject\\\": \\\"\u5168\u56fd\u516c\u5171\u82f1\u8bed\u7b49\u7ea7\u8003\u8bd5\u56db\u7ea7\u8bcd\u6c47\u79d1\u5b66\u8bb0\u5fc6\uff08\u78c1\u5e261--5\uff09\\\"}]\\n```\" } \u6587\u672c\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u4e0b\u9762\u53e5\u5b50\u4e2d\u63cf\u8ff0\u7684\u662f\u4e00\u4e2a\u4ec0\u4e48\uff1f\u7528\u5217\u8868\u7684\u65b9\u5f0f\u56de\u7b54\u3002\\n\\n\u4ec0\u4e48\u82f9\u679c\u554a\uff0c\u90fd\u6ca1\u6709\u82f9\u679c\u5473\uff0c\u602a\u602a\u7684\u5473\u9053\uff0c\u800c\u4e14\u4e00\u70b9\u90fd\u4e0d\u751c\uff0c\u8d85\u7ea7\u96be\u5403\uff01\\nAnswer: \" , \"target\" : \"[\\\"\u6c34\u679c\\\"]\" } \u8bad\u7ec3\u96c6\u4e2d\u4e00\u5171\u5305\u542b122\u6761\u6570\u636e\uff0c\u6bcf\u4e00\u6761\u6570\u636e\u90fd\u5206\u4e3a context \u548c target \u4e24\u90e8\u5206\uff1a context \u90e8\u5206\u662f\u63a5\u53d7\u7528\u6237\u7684\u8f93\u5165\u30022. target \u90e8\u5206\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u7684\u8f93\u51fa\u3002 \u5728 context \u4e2d\u53c8\u5305\u62ec 2 \u4e2a\u90e8\u5206\uff1a Instruction\uff1a\u7528\u4e8e\u544a\u77e5\u6a21\u578b\u7684\u5177\u4f53\u6307\u4ee4\uff0c\u5f53\u9700\u8981\u4e00\u4e2a\u6a21\u578b\u540c\u65f6\u89e3\u51b3\u591a\u4e2a\u4efb\u52a1\u65f6\u53ef\u4ee5\u8bbe\u5b9a\u4e0d\u540c\u7684 Instruction \u6765\u5e2e\u52a9\u6a21\u578b\u5224\u522b\u5f53\u524d\u5e94\u5f53\u505a\u4ec0\u4e48\u4efb\u52a1\u3002 Input\uff1a\u5f53\u524d\u7528\u6237\u7684\u8f93\u5165\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002 2 \u7f16\u5199\u9879\u76eeConfig\u7c7b\u914d\u7f6e\u6587\u4ef6 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/glm_config.py config\u6587\u4ef6\u76ee\u7684\uff1a\u914d\u7f6e\u9879\u76ee\u5e38\u7528\u53d8\u91cf\uff0c\u4e00\u822c\u8fd9\u4e9b\u53d8\u91cf\u5c5e\u4e8e\u4e0d\u7ecf\u5e38\u6539\u53d8\u7684\uff0c\u6bd4\u5982\uff1a\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\u3001\u6a21\u578b\u8bad\u7ec3\u6b21\u6570\u3001\u6a21\u578b\u8d85\u53c2\u6570\u7b49\u7b49 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a # -*- coding:utf-8 -*- import torch class ProjectConfig ( object ): def __init__ ( self ): self . device = 'cuda:0' if torch . cuda . is_available () else 'cpu' self . pre_model = './llm/ChatGLM-6B/THUDM/chatglm-6b' self . train_path = './llm/ptune_chatglm/data/mixed_train_dataset.jsonl' self . dev_path = './llm/ptune_chatglm/data/mixed_dev_dataset.jsonl' self . use_lora = True self . use_ptuning = False # \u4f4e\u79e9\u77e9\u9635\u7684\u79e9\u662f8 self . lora_rank = 8 self . batch_size = 1 self . epochs = 2 self . learning_rate = 3e-5 self . weight_decay = 0 self . warmup_ratio = 0.06 self . max_source_seq_len = 400 self . max_target_seq_len = 300 self . logging_steps = 10 self . save_freq = 200 self . pre_seq_len = 128 self . prefix_projection = False # \u9ed8\u8ba4\u4e3aFalse,\u5373p-tuning,\u5982\u679c\u4e3aTrue\uff0c\u5373p-tuning-v2 self . save_dir = './llm/ptune_chatglm/checkpoints/ptune' if __name__ == '__main__' : pc = ProjectConfig () print ( pc . save_dir ) 3 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/data_handle. data_handle\u6587\u4ef6\u5939\u4e2d\u4e00\u5171\u5305\u542b\u4e24\u4e2apy\u811a\u672c\uff1adata_preprocess.py\u3001data_loader.py 3.1 data_preprocess.py \u00b6 \u76ee\u7684: \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import json # \u8fd4\u56de\u7684\u5b57\u7b26\u4e32\u5305\u542b\u6709\u5173\u5f02\u5e38\u7684\u8be6\u7ec6\u4fe1 import traceback import numpy as np from tqdm import tqdm from datasets import load_dataset from transformers import AutoTokenizer from functools import partial import sys sys . path . append ( '..' ) from glm_config import * \u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u65b9\u6cd5convert_example() def convert_example ( examples : dict , tokenizer , max_source_seq_len : int , max_target_seq_len : int , ): \"\"\" \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3aPtuning\u6a21\u578b\u63a5\u6536\u7684\u8f93\u5165\u6570\u636e\u3002 Args: examples (dict): \u8bad\u7ec3\u6570\u636e\u6837\u672c, e.g. -> { \"text\": [ '{\"context\": \"\u5e74\u57fa\u51c6\u5229\u73874.35%\u3002\u4ece\u5b9e\u9645\u770b...\", \"target\": \"2017\u5e74\u94f6\u884c\u8d37\u6b3e\u57fa\u51c6\u5229\u7387\"}', ... ] } max_source_seq_len (int): prompt\u6700\u5927\u957f\u5ea6 max_target_seq_len (int): \u7b54\u6848\u6700\u5927\u957f\u5ea6 Returns: dict (str: np.array) -> tokenized_output = { 'input_ids': [[1525, 10, ...], [758, 2345, ...]], 'labels': [[822, 10, ...], [125, 58...]] } \"\"\" tokenized_output = { 'input_ids' : [], 'labels' : [] } max_seq_length = max_source_seq_len + max_target_seq_len for example in examples [ 'text' ]: try : example = json . loads ( example ) context = example [ \"context\" ] target = example [ \"target\" ] # print(f'context-->{context}') # print(f'target-->{target}') prompts_ids = tokenizer . encode ( text = context , add_special_tokens = False ) # print(f'prompts_ids--\u300b{prompts_ids}\\n{len(prompts_ids)}') target_ids = tokenizer . encode ( text = target , add_special_tokens = False ) # print(f'target_ids--\u300b{target_ids}\\n{len(target_ids)}') if len ( prompts_ids ) >= max_source_seq_len : # source \u9700\u8981\u7559\u4e00\u4e2a [gMASK] token \u5728\u7ed3\u5c3e prompts_ids = prompts_ids [: max_source_seq_len - 1 ] if len ( target_ids ) >= max_target_seq_len - 1 : # target \u9700\u8981\u7559\u4e00\u4e2a <sop> \u5728\u5f00\u5934\u548c\u4e00\u4e2a <eop> token \u5728\u7ed3\u5c3e target_ids = target_ids [: max_target_seq_len - 2 ] # source_ids + [gMASK] + <sop> + target_ids + <eop> input_ids = tokenizer . build_inputs_with_special_tokens ( prompts_ids , target_ids ) # print(f'input_ids-->{input_ids}') # bos \u5728 target \u7684\u7b2c\u4e00\u4f4d context_length = input_ids . index ( tokenizer . bos_token_id ) # print(f'context_length-->{context_length}') # [gMASK] \u5728 source \u7684\u6700\u540e\u4e00\u4f4d mask_position = context_length - 1 # \u4ece bos \u5f00\u59cb\u5230\u540e\u9762\u6240\u6709\u7684 target \u5230 eos \u90fd\u4e3a label labels = [ - 100 ] * context_length + input_ids [ mask_position + 1 :] # print(f'labels-->{labels}') pad_len = max_seq_length - len ( input_ids ) # print(f'pad_len-->{pad_len}') input_ids = input_ids + [ tokenizer . pad_token_id ] * pad_len # print(f'input_ids-->{input_ids}\\n{len(input_ids)}') labels = labels + [ - 100 ] * pad_len # print(f'labels-->{labels}\\n{len(labels)}') tokenized_output [ 'input_ids' ] . append ( input_ids ) tokenized_output [ 'labels' ] . append ( labels ) except : print ( f '\" { example } \" -> { traceback . format_exc () } ' ) continue for k , v in tokenized_output . items (): tokenized_output [ k ] = np . array ( v ) return tokenized_output \u5b9a\u4e49\u83b7\u53d6\u8bad\u7ec3\u6216\u9a8c\u8bc1\u6570\u636e\u6700\u5927\u957f\u5ea6\u65b9\u6cd5get_max_length() def get_max_length ( tokenizer , dataset_file : str ): \"\"\" \u6d4b\u8bd5\u6570\u636e\u96c6\u6700\u5927\u7684\u8f93\u5165/\u8f93\u51fatokens\u662f\u591a\u5c11\u3002 Args: dataset_file (str): _description_ \"\"\" source_seq_len_list = [] target_seq_len_list = [] with open ( dataset_file , 'r' ) as f : for line in tqdm ( f . readlines ()): line = json . loads ( line ) source_len = tokenizer . encode ( line [ 'context' ]) source_seq_len_list . append ( len ( source_len )) target_len = tokenizer . encode ( line [ 'target' ]) target_seq_len_list . append ( len ( target_len )) print ( dataset_file ) print ( f \"\u3010Source Sequence\u3011 Max: { max ( source_seq_len_list ) } , Avg: { int ( sum ( source_seq_len_list ) / len ( source_seq_len_list )) } , Middle: { sorted ( source_seq_len_list )[ int ( len ( source_seq_len_list ) / 2 )] } .\" ) print ( f \"\u3010Target Sequence\u3011 Max: { max ( target_seq_len_list ) } , Avg: { int ( sum ( target_seq_len_list ) / len ( target_seq_len_list )) } , Middle: { sorted ( target_seq_len_list )[ int ( len ( target_seq_len_list ) / 2 )] } .\" ) 3.3 data_loader.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u52a0\u8f7d\u5668 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # coding:utf-8 from torch.utils.data import DataLoader from transformers import default_data_collator , AutoTokenizer from data_handle.data_preprocess import * from glm_config import * pc = ProjectConfig () # \u5b9e\u4f8b\u5316\u9879\u76ee\u914d\u7f6e\u6587\u4ef6 tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model , trust_remote_code = True ) \u5b9a\u4e49\u83b7\u53d6\u6570\u636e\u52a0\u8f7d\u5668\u7684\u65b9\u6cd5get_data() def get_data (): dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path , 'dev' : pc . dev_path }) new_func = partial ( convert_example , tokenizer = tokenizer , max_source_seq_len = 100 , max_target_seq_len = 100 ) dataset = dataset . map ( new_func , batched = True ) train_dataset = dataset [ \"train\" ] dev_dataset = dataset [ \"dev\" ] train_dataloader = DataLoader ( train_dataset , shuffle = True , collate_fn = default_data_collator , batch_size = pc . batch_size ) dev_dataloader = DataLoader ( dev_dataset , collate_fn = default_data_collator , batch_size = pc . batch_size ) return train_dataloader , dev_dataloader if __name__ == '__main__' : train_dataloader , dev_dataloader = get_data () print ( len ( train_dataloader )) print ( len ( dev_dataloader )) for i , value in enumerate ( train_dataloader ): print ( value ) print ( value [ 'input_ids' ] . shape ) print ( value [ 'labels' ] . shape ) break \u6253\u5370\u7ed3\u679c\uff1a 902 122 { 'input_ids' : tensor ([[ 37010 , 12 , 5 , 76331 , 83362 , 92831 , 103593 , 64464 , 6 , 77115 , 65077 , 72863 , 63891 , 66207 , 63823 , 4 , 3430 , 12 , 68327 , 74351 , 77756 , 66263 , 81577 , 64536 , 6 , 82145 , 2031 , 63825 , 69574 , 66207 , 12 , 4 , 4 , 64590 , 67748 , 69958 , 66152 , 63923 , 65024 , 64676 , 65102 , 66089 , 64101 , 73127 , 64025 , 64236 , 6 , 72996 , 73518 , 64236 , 82273 , 63823 , 4 , 13049 , 12 , 130001 , 130004 , 5 , 125827 , 2031 , 4 , 127903 , 38861 , 83 , 28 , 66845 , 67541 , 57 , 28 , 1932 , 24 , 317 , 83 , 28 , 64069 , 57 , 28 , 9832 , 24 , 317 , 83 , 28 , 65210 , 57 , 28 , 1932 , 83 , 28 , 73127 , 64025 , 64236 , 57 , 28 , 9832 , 83 , 28 , 64590 , 67748 , 69958 , 66152 , 127731 , 4 , 125827 , 130005 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ]]), 'labels' : tensor ([[ - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , 130004 , 5 , 125827 , 2031 , 4 , 127903 , 38861 , 83 , 28 , 66845 , 67541 , 57 , 28 , 1932 , 24 , 317 , 83 , 28 , 64069 , 57 , 28 , 9832 , 24 , 317 , 83 , 28 , 65210 , 57 , 28 , 1932 , 83 , 28 , 73127 , 64025 , 64236 , 57 , 28 , 9832 , 83 , 28 , 64590 , 67748 , 69958 , 66152 , 127731 , 4 , 125827 , 130005 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 ]]) } torch . Size ([ 1 , 200 ]) torch . Size ([ 1 , 200 ])","title":"7.2 \u591a\u4efb\u52a1\u6570\u636e\u9884\u5904\u7406\u65b9\u5f0f"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#_1","text":"","title":"\u591a\u4efb\u52a1\u6570\u636e\u9884\u5904\u7406\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#_2","text":"\u4e86\u89e3\u672c\u9879\u76ee\u4e2d\u591a\u4efb\u52a1\u6570\u636e\u96c6\u7684\u683c\u5f0f \u638c\u63e1\u5b9e\u73b0\u6570\u636e\u9884\u5904\u7406\u7684\u51fd\u6570\u4ee3\u7801","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#_3","text":"\u672c\u9879\u76ee\u4e2d\u5bf9\u6570\u636e\u90e8\u5206\u7684\u9884\u5904\u7406\u6b65\u9aa4\u5982\u4e0b: \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801","title":"\u6570\u636e\u9884\u5904\u7406\u8fc7\u7a0b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#1","text":"\u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b3\u4e2ajsonl\u6587\u6863\uff0c\u5206\u522b\u4e3a\uff1amixed_train_dataset.jsonl\u3001mixed_dev_dataset.jsonl\u3001dataset.jsonl","title":"1 \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#11-trainjsonl","text":"mixed_train_dataset.jsonl\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u56e0\u4e3a\u6211\u4eec\u672c\u6b21\u9879\u76ee\u540c\u65f6\u8fdb\u884c\u300c\u4fe1\u606f\u62bd\u53d6+\u6587\u672c\u5206\u7c7b\u300d\u4e24\u9879\u4efb\u52a1\uff0c\u56e0\u6b64\u6570\u636e\u4e2d\u6df7\u5408\u4e86\u4e24\u79cd\u4efb\u52a1\u6570\u636e\u7c7b\u578b\u3002\u4e3e\u4f8b\u5c55\u793a\u5982\u4e0b\uff1a \u4fe1\u606f\u62bd\u53d6\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u627e\u5230\u53e5\u5b50\u4e2d\u7684\u4e09\u5143\u7ec4\u4fe1\u606f\u5e76\u8f93\u51fa\u6210json\u7ed9\u6211:\\n\\n\u4e5d\u7384\u73e0\u662f\u5728\u7eb5\u6a2a\u4e2d\u6587\u7f51\u8fde\u8f7d\u7684\u4e00\u90e8\u5c0f\u8bf4\uff0c\u4f5c\u8005\u662f\u9f99\u9a6c\u3002\\nAnswer: \" , \"target\" : \"```json\\n[{\\\"predicate\\\": \\\"\u8fde\u8f7d\u7f51\u7ad9\\\", \\\"object_type\\\": \\\"\u7f51\u7ad9\\\", \\\"subject_type\\\": \\\"\u7f51\u7edc\u5c0f\u8bf4\\\", \\\"object\\\": \\\"\u7eb5\u6a2a\u4e2d\u6587\u7f51\\\", \\\"subject\\\": \\\"\u4e5d\u7384\u73e0\\\"}, {\\\"predicate\\\": \\\"\u4f5c\u8005\\\", \\\"object_type\\\": \\\"\u4eba\u7269\\\", \\\"subject_type\\\": \\\"\u56fe\u4e66\u4f5c\u54c1\\\", \\\"object\\\": \\\"\u9f99\u9a6c\\\", \\\"subject\\\": \\\"\u4e5d\u7384\u73e0\\\"}]\\n```\" } \u6587\u672c\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u4e0b\u9762\u53e5\u5b50\u53ef\u80fd\u662f\u4e00\u6761\u5173\u4e8e\u4ec0\u4e48\u7684\u8bc4\u8bba\uff0c\u7528\u5217\u8868\u5f62\u5f0f\u56de\u7b54\uff1a\\n\\n\u5f88\u4e0d\u9519\uff0c\u5f88\u65b0\u9c9c\uff0c\u5feb\u9012\u5c0f\u54e5\u670d\u52a1\u5f88\u597d\uff0c\u6c34\u679c\u4e5f\u633a\u751c\u633a\u8106\u7684\\nAnswer: \" , \"target\" : \"[\\\"\u6c34\u679c\\\"]\" } \u8bad\u7ec3\u96c6\u4e2d\u4e00\u5171\u5305\u542b902\u6761\u6570\u636e\uff0c\u6bcf\u4e00\u6761\u6570\u636e\u90fd\u5206\u4e3a context \u548c target \u4e24\u90e8\u5206\uff1a context \u90e8\u5206\u662f\u63a5\u53d7\u7528\u6237\u7684\u8f93\u5165\u30022. target \u90e8\u5206\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u7684\u8f93\u51fa\u3002 \u5728 context \u4e2d\u53c8\u5305\u62ec 2 \u4e2a\u90e8\u5206\uff1a Instruction\uff1a\u7528\u4e8e\u544a\u77e5\u6a21\u578b\u7684\u5177\u4f53\u6307\u4ee4\uff0c\u5f53\u9700\u8981\u4e00\u4e2a\u6a21\u578b\u540c\u65f6\u89e3\u51b3\u591a\u4e2a\u4efb\u52a1\u65f6\u53ef\u4ee5\u8bbe\u5b9a\u4e0d\u540c\u7684 Instruction \u6765\u5e2e\u52a9\u6a21\u578b\u5224\u522b\u5f53\u524d\u5e94\u5f53\u505a\u4ec0\u4e48\u4efb\u52a1\u3002 Input\uff1a\u5f53\u524d\u7528\u6237\u7684\u8f93\u5165\u3002","title":"1.1 train.jsonl"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#12-devjsonl","text":"mixed_dev_dataset.jsonl\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u56e0\u4e3a\u6211\u4eec\u672c\u6b21\u9879\u76ee\u540c\u65f6\u8fdb\u884c\u300c\u4fe1\u606f\u62bd\u53d6+\u6587\u672c\u5206\u7c7b\u300d\u4e24\u9879\u4efb\u52a1\uff0c\u56e0\u6b64\u6570\u636e\u4e2d\u6df7\u5408\u4e86\u4e24\u79cd\u4efb\u52a1\u6570\u636e\u7c7b\u578b\u3002\u4e3e\u4f8b\u5c55\u793a\u5982\u4e0b\uff1a \u4fe1\u606f\u62bd\u53d6\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u4e0b\u9762\u53e5\u5b50\u5305\u542b\u4e86\u54ea\u4e9b\u4e09\u5143\u7ec4\uff0c\u53ea\u7528json\u7684\u683c\u5f0f\u56de\u7b54\uff1a\\n\\n\u300a\u5168\u56fd\u516c\u5171\u82f1\u8bed\u7b49\u7ea7\u8003\u8bd5\u56db\u7ea7\u8bcd\u6c47\u79d1\u5b66\u8bb0\u5fc6\uff08\u78c1\u5e261--5\uff09\u300b\u662f\u7531\u4eba\u6c11\u5927\u5b66\u51fa\u7248\u793e\u51fa\u7248\u7684\u4e00\u90e8\u6559\u80b2\u4f5c\u54c1\uff0c\u4f5c\u8005\u662f\u949f\u9053\u9686\u3002\\nAnswer: \" , \"target\" : \"```json\\n[{\\\"predicate\\\": \\\"\u51fa\u7248\u793e\\\", \\\"object_type\\\": \\\"\u51fa\u7248\u793e\\\", \\\"subject_type\\\": \\\"\u4e66\u7c4d\\\", \\\"object\\\": \\\"\u4eba\u6c11\u5927\u5b66\\\", \\\"subject\\\": \\\"\u5168\u56fd\u516c\u5171\u82f1\u8bed\u7b49\u7ea7\u8003\u8bd5\u56db\u7ea7\u8bcd\u6c47\u79d1\u5b66\u8bb0\u5fc6\uff08\u78c1\u5e261--5\uff09\\\"}, {\\\"predicate\\\": \\\"\u4f5c\u8005\\\", \\\"object_type\\\": \\\"\u4eba\u7269\\\", \\\"subject_type\\\": \\\"\u56fe\u4e66\u4f5c\u54c1\\\", \\\"object\\\": \\\"\u949f\u9053\u9686\\\", \\\"subject\\\": \\\"\u5168\u56fd\u516c\u5171\u82f1\u8bed\u7b49\u7ea7\u8003\u8bd5\u56db\u7ea7\u8bcd\u6c47\u79d1\u5b66\u8bb0\u5fc6\uff08\u78c1\u5e261--5\uff09\\\"}]\\n```\" } \u6587\u672c\u6570\u636e\u793a\u4f8b Instruction \u90e8\u5206\u544a\u8bc9\u6a21\u578b\u73b0\u5728\u9700\u8981\u505a\u300c\u9605\u8bfb\u7406\u89e3\u300d\u4efb\u52a1\uff0cInput \u90e8\u5206\u544a\u77e5\u6a21\u578b\u8981\u62bd\u53d6\u7684\u53e5\u5b50\u4ee5\u53ca\u8f93\u51fa\u7684\u683c\u5f0f\u3002 { \"context\" : \"Instruction: \u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\\nInput: \u4e0b\u9762\u53e5\u5b50\u4e2d\u63cf\u8ff0\u7684\u662f\u4e00\u4e2a\u4ec0\u4e48\uff1f\u7528\u5217\u8868\u7684\u65b9\u5f0f\u56de\u7b54\u3002\\n\\n\u4ec0\u4e48\u82f9\u679c\u554a\uff0c\u90fd\u6ca1\u6709\u82f9\u679c\u5473\uff0c\u602a\u602a\u7684\u5473\u9053\uff0c\u800c\u4e14\u4e00\u70b9\u90fd\u4e0d\u751c\uff0c\u8d85\u7ea7\u96be\u5403\uff01\\nAnswer: \" , \"target\" : \"[\\\"\u6c34\u679c\\\"]\" } \u8bad\u7ec3\u96c6\u4e2d\u4e00\u5171\u5305\u542b122\u6761\u6570\u636e\uff0c\u6bcf\u4e00\u6761\u6570\u636e\u90fd\u5206\u4e3a context \u548c target \u4e24\u90e8\u5206\uff1a context \u90e8\u5206\u662f\u63a5\u53d7\u7528\u6237\u7684\u8f93\u5165\u30022. target \u90e8\u5206\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u7684\u8f93\u51fa\u3002 \u5728 context \u4e2d\u53c8\u5305\u62ec 2 \u4e2a\u90e8\u5206\uff1a Instruction\uff1a\u7528\u4e8e\u544a\u77e5\u6a21\u578b\u7684\u5177\u4f53\u6307\u4ee4\uff0c\u5f53\u9700\u8981\u4e00\u4e2a\u6a21\u578b\u540c\u65f6\u89e3\u51b3\u591a\u4e2a\u4efb\u52a1\u65f6\u53ef\u4ee5\u8bbe\u5b9a\u4e0d\u540c\u7684 Instruction \u6765\u5e2e\u52a9\u6a21\u578b\u5224\u522b\u5f53\u524d\u5e94\u5f53\u505a\u4ec0\u4e48\u4efb\u52a1\u3002 Input\uff1a\u5f53\u524d\u7528\u6237\u7684\u8f93\u5165\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002","title":"1.2 dev.jsonl"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#2-config","text":"\u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/glm_config.py config\u6587\u4ef6\u76ee\u7684\uff1a\u914d\u7f6e\u9879\u76ee\u5e38\u7528\u53d8\u91cf\uff0c\u4e00\u822c\u8fd9\u4e9b\u53d8\u91cf\u5c5e\u4e8e\u4e0d\u7ecf\u5e38\u6539\u53d8\u7684\uff0c\u6bd4\u5982\uff1a\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\u3001\u6a21\u578b\u8bad\u7ec3\u6b21\u6570\u3001\u6a21\u578b\u8d85\u53c2\u6570\u7b49\u7b49 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a # -*- coding:utf-8 -*- import torch class ProjectConfig ( object ): def __init__ ( self ): self . device = 'cuda:0' if torch . cuda . is_available () else 'cpu' self . pre_model = './llm/ChatGLM-6B/THUDM/chatglm-6b' self . train_path = './llm/ptune_chatglm/data/mixed_train_dataset.jsonl' self . dev_path = './llm/ptune_chatglm/data/mixed_dev_dataset.jsonl' self . use_lora = True self . use_ptuning = False # \u4f4e\u79e9\u77e9\u9635\u7684\u79e9\u662f8 self . lora_rank = 8 self . batch_size = 1 self . epochs = 2 self . learning_rate = 3e-5 self . weight_decay = 0 self . warmup_ratio = 0.06 self . max_source_seq_len = 400 self . max_target_seq_len = 300 self . logging_steps = 10 self . save_freq = 200 self . pre_seq_len = 128 self . prefix_projection = False # \u9ed8\u8ba4\u4e3aFalse,\u5373p-tuning,\u5982\u679c\u4e3aTrue\uff0c\u5373p-tuning-v2 self . save_dir = './llm/ptune_chatglm/checkpoints/ptune' if __name__ == '__main__' : pc = ProjectConfig () print ( pc . save_dir )","title":"2 \u7f16\u5199\u9879\u76eeConfig\u7c7b\u914d\u7f6e\u6587\u4ef6"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#3","text":"\u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/data_handle. data_handle\u6587\u4ef6\u5939\u4e2d\u4e00\u5171\u5305\u542b\u4e24\u4e2apy\u811a\u672c\uff1adata_preprocess.py\u3001data_loader.py","title":"3 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#31-data_preprocesspy","text":"\u76ee\u7684: \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import json # \u8fd4\u56de\u7684\u5b57\u7b26\u4e32\u5305\u542b\u6709\u5173\u5f02\u5e38\u7684\u8be6\u7ec6\u4fe1 import traceback import numpy as np from tqdm import tqdm from datasets import load_dataset from transformers import AutoTokenizer from functools import partial import sys sys . path . append ( '..' ) from glm_config import * \u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u65b9\u6cd5convert_example() def convert_example ( examples : dict , tokenizer , max_source_seq_len : int , max_target_seq_len : int , ): \"\"\" \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3aPtuning\u6a21\u578b\u63a5\u6536\u7684\u8f93\u5165\u6570\u636e\u3002 Args: examples (dict): \u8bad\u7ec3\u6570\u636e\u6837\u672c, e.g. -> { \"text\": [ '{\"context\": \"\u5e74\u57fa\u51c6\u5229\u73874.35%\u3002\u4ece\u5b9e\u9645\u770b...\", \"target\": \"2017\u5e74\u94f6\u884c\u8d37\u6b3e\u57fa\u51c6\u5229\u7387\"}', ... ] } max_source_seq_len (int): prompt\u6700\u5927\u957f\u5ea6 max_target_seq_len (int): \u7b54\u6848\u6700\u5927\u957f\u5ea6 Returns: dict (str: np.array) -> tokenized_output = { 'input_ids': [[1525, 10, ...], [758, 2345, ...]], 'labels': [[822, 10, ...], [125, 58...]] } \"\"\" tokenized_output = { 'input_ids' : [], 'labels' : [] } max_seq_length = max_source_seq_len + max_target_seq_len for example in examples [ 'text' ]: try : example = json . loads ( example ) context = example [ \"context\" ] target = example [ \"target\" ] # print(f'context-->{context}') # print(f'target-->{target}') prompts_ids = tokenizer . encode ( text = context , add_special_tokens = False ) # print(f'prompts_ids--\u300b{prompts_ids}\\n{len(prompts_ids)}') target_ids = tokenizer . encode ( text = target , add_special_tokens = False ) # print(f'target_ids--\u300b{target_ids}\\n{len(target_ids)}') if len ( prompts_ids ) >= max_source_seq_len : # source \u9700\u8981\u7559\u4e00\u4e2a [gMASK] token \u5728\u7ed3\u5c3e prompts_ids = prompts_ids [: max_source_seq_len - 1 ] if len ( target_ids ) >= max_target_seq_len - 1 : # target \u9700\u8981\u7559\u4e00\u4e2a <sop> \u5728\u5f00\u5934\u548c\u4e00\u4e2a <eop> token \u5728\u7ed3\u5c3e target_ids = target_ids [: max_target_seq_len - 2 ] # source_ids + [gMASK] + <sop> + target_ids + <eop> input_ids = tokenizer . build_inputs_with_special_tokens ( prompts_ids , target_ids ) # print(f'input_ids-->{input_ids}') # bos \u5728 target \u7684\u7b2c\u4e00\u4f4d context_length = input_ids . index ( tokenizer . bos_token_id ) # print(f'context_length-->{context_length}') # [gMASK] \u5728 source \u7684\u6700\u540e\u4e00\u4f4d mask_position = context_length - 1 # \u4ece bos \u5f00\u59cb\u5230\u540e\u9762\u6240\u6709\u7684 target \u5230 eos \u90fd\u4e3a label labels = [ - 100 ] * context_length + input_ids [ mask_position + 1 :] # print(f'labels-->{labels}') pad_len = max_seq_length - len ( input_ids ) # print(f'pad_len-->{pad_len}') input_ids = input_ids + [ tokenizer . pad_token_id ] * pad_len # print(f'input_ids-->{input_ids}\\n{len(input_ids)}') labels = labels + [ - 100 ] * pad_len # print(f'labels-->{labels}\\n{len(labels)}') tokenized_output [ 'input_ids' ] . append ( input_ids ) tokenized_output [ 'labels' ] . append ( labels ) except : print ( f '\" { example } \" -> { traceback . format_exc () } ' ) continue for k , v in tokenized_output . items (): tokenized_output [ k ] = np . array ( v ) return tokenized_output \u5b9a\u4e49\u83b7\u53d6\u8bad\u7ec3\u6216\u9a8c\u8bc1\u6570\u636e\u6700\u5927\u957f\u5ea6\u65b9\u6cd5get_max_length() def get_max_length ( tokenizer , dataset_file : str ): \"\"\" \u6d4b\u8bd5\u6570\u636e\u96c6\u6700\u5927\u7684\u8f93\u5165/\u8f93\u51fatokens\u662f\u591a\u5c11\u3002 Args: dataset_file (str): _description_ \"\"\" source_seq_len_list = [] target_seq_len_list = [] with open ( dataset_file , 'r' ) as f : for line in tqdm ( f . readlines ()): line = json . loads ( line ) source_len = tokenizer . encode ( line [ 'context' ]) source_seq_len_list . append ( len ( source_len )) target_len = tokenizer . encode ( line [ 'target' ]) target_seq_len_list . append ( len ( target_len )) print ( dataset_file ) print ( f \"\u3010Source Sequence\u3011 Max: { max ( source_seq_len_list ) } , Avg: { int ( sum ( source_seq_len_list ) / len ( source_seq_len_list )) } , Middle: { sorted ( source_seq_len_list )[ int ( len ( source_seq_len_list ) / 2 )] } .\" ) print ( f \"\u3010Target Sequence\u3011 Max: { max ( target_seq_len_list ) } , Avg: { int ( sum ( target_seq_len_list ) / len ( target_seq_len_list )) } , Middle: { sorted ( target_seq_len_list )[ int ( len ( target_seq_len_list ) / 2 )] } .\" )","title":"3.1 data_preprocess.py"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/02-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86.html#33-data_loaderpy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u52a0\u8f7d\u5668 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # coding:utf-8 from torch.utils.data import DataLoader from transformers import default_data_collator , AutoTokenizer from data_handle.data_preprocess import * from glm_config import * pc = ProjectConfig () # \u5b9e\u4f8b\u5316\u9879\u76ee\u914d\u7f6e\u6587\u4ef6 tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model , trust_remote_code = True ) \u5b9a\u4e49\u83b7\u53d6\u6570\u636e\u52a0\u8f7d\u5668\u7684\u65b9\u6cd5get_data() def get_data (): dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path , 'dev' : pc . dev_path }) new_func = partial ( convert_example , tokenizer = tokenizer , max_source_seq_len = 100 , max_target_seq_len = 100 ) dataset = dataset . map ( new_func , batched = True ) train_dataset = dataset [ \"train\" ] dev_dataset = dataset [ \"dev\" ] train_dataloader = DataLoader ( train_dataset , shuffle = True , collate_fn = default_data_collator , batch_size = pc . batch_size ) dev_dataloader = DataLoader ( dev_dataset , collate_fn = default_data_collator , batch_size = pc . batch_size ) return train_dataloader , dev_dataloader if __name__ == '__main__' : train_dataloader , dev_dataloader = get_data () print ( len ( train_dataloader )) print ( len ( dev_dataloader )) for i , value in enumerate ( train_dataloader ): print ( value ) print ( value [ 'input_ids' ] . shape ) print ( value [ 'labels' ] . shape ) break \u6253\u5370\u7ed3\u679c\uff1a 902 122 { 'input_ids' : tensor ([[ 37010 , 12 , 5 , 76331 , 83362 , 92831 , 103593 , 64464 , 6 , 77115 , 65077 , 72863 , 63891 , 66207 , 63823 , 4 , 3430 , 12 , 68327 , 74351 , 77756 , 66263 , 81577 , 64536 , 6 , 82145 , 2031 , 63825 , 69574 , 66207 , 12 , 4 , 4 , 64590 , 67748 , 69958 , 66152 , 63923 , 65024 , 64676 , 65102 , 66089 , 64101 , 73127 , 64025 , 64236 , 6 , 72996 , 73518 , 64236 , 82273 , 63823 , 4 , 13049 , 12 , 130001 , 130004 , 5 , 125827 , 2031 , 4 , 127903 , 38861 , 83 , 28 , 66845 , 67541 , 57 , 28 , 1932 , 24 , 317 , 83 , 28 , 64069 , 57 , 28 , 9832 , 24 , 317 , 83 , 28 , 65210 , 57 , 28 , 1932 , 83 , 28 , 73127 , 64025 , 64236 , 57 , 28 , 9832 , 83 , 28 , 64590 , 67748 , 69958 , 66152 , 127731 , 4 , 125827 , 130005 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ]]), 'labels' : tensor ([[ - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , 130004 , 5 , 125827 , 2031 , 4 , 127903 , 38861 , 83 , 28 , 66845 , 67541 , 57 , 28 , 1932 , 24 , 317 , 83 , 28 , 64069 , 57 , 28 , 9832 , 24 , 317 , 83 , 28 , 65210 , 57 , 28 , 1932 , 83 , 28 , 73127 , 64025 , 64236 , 57 , 28 , 9832 , 83 , 28 , 64590 , 67748 , 69958 , 66152 , 127731 , 4 , 125827 , 130005 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 , - 100 ]]) } torch . Size ([ 1 , 200 ]) torch . Size ([ 1 , 200 ])","title":"3.3 data_loader.py"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html","text":"\u57fa\u4e8eChatGLM+LoRA\u65b9\u5f0f\u6a21\u578b\u642d\u5efa \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1\u57fa\u4e8eChatGLM+LoRA\u65b9\u5f0f\u6a21\u578b\u642d\u5efa\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u6a21\u578b\u7684\u8bad\u7ec3,\u9a8c\u8bc1\u53ca\u76f8\u5173\u5de5\u5177\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0. \u6a21\u578b\u642d\u5efa \u00b6 \u672c\u9879\u76ee\u4e2d\u5b8c\u6210ChatGLM+LoRA\u6a21\u578b\u642d\u5efa\u3001\u8bad\u7ec3\u53ca\u5e94\u7528\u7684\u6b65\u9aa4\u5982\u4e0b\uff08\u6ce8\u610f\uff1a\u56e0\u4e3a\u672c\u9879\u76ee\u4e2d\u4f7f\u7528\u7684\u662fChatGLM\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6240\u4ee5\u76f4\u63a5\u52a0\u8f7d\u5373\u53ef\uff0c\u65e0\u9700\u91cd\u590d\u642d\u5efa\u6a21\u578b\u67b6\u6784\uff09: \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570 \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u6a21\u578b\u5728\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u9884\u6d4b\u65f6\u9700\u8981\u7684\u51fd\u6570 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/utils utils\u6587\u4ef6\u5939\u5171\u5305\u542b1\u4e2apy\u811a\u672c\uff1acommon_utils.py 1. common_utils.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u7c7b\u578b\u8f6c\u6362\u7c7b\u3001\u5206\u79d2\u65f6\u4e4b\u95f4\u8f6c\u6362\u4ee5\u53ca\u6a21\u578b\u4fdd\u5b58\u51fd\u6570\u3002 \u811a\u672c\u91cc\u9762\u5305\u542b\u4e00\u4e2a\u7c7b\u4ee5\u53ca\u4e24\u4e2a\u51fd\u6570\uff1aCastOutputToFloat\u3001second2time()\u4ee5\u53casave_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch import torch.nn as nn from glm_config import * import copy pc = ProjectConfig () \u5b9a\u4e49CastOutputToFloat\u7c7b class CastOutputToFloat ( nn . Sequential ): def forward ( self , x ): return super () . forward ( x ) . to ( torch . float32 ) \u5b9a\u4e49second2time()\u51fd\u6570 def second2time ( seconds : int ): \"\"\" \u5c06\u79d2\u8f6c\u6362\u6210\u65f6\u5206\u79d2\u3002 Args: seconds (int): _description_ \"\"\" m , s = divmod ( seconds , 60 ) h , m = divmod ( m , 60 ) return \" %02d : %02d : %02d \" % ( h , m , s ) \u5b9a\u4e49save_model() def save_model ( model , cur_save_dir : str ): \"\"\" \u5b58\u50a8\u5f53\u524d\u6a21\u578b\u3002 Args: cur_save_path (str): \u5b58\u50a8\u8def\u5f84\u3002 \"\"\" if pc . use_lora : # merge lora params with origin model merged_model = copy . deepcopy ( model ) merged_model = merged_model . merge_and_unload () merged_model . save_pretrained ( cur_save_dir ) else : model . save_pretrained ( cur_save_dir ) \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u5b9e\u73b0\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/train.py \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amodel2train()\u548cevaluate_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import os import time import copy import argparse from functools import partial import peft # autocast\u662fPyTorch\u4e2d\u4e00\u79cd\u6df7\u5408\u7cbe\u5ea6\u7684\u6280\u672f\uff0c\u53ef\u5728\u4fdd\u6301\u6570\u503c\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6\u548c\u51cf\u5c11\u663e\u5b58\u5360\u7528\u3002 # \u8be5\u65b9\u6cd5\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u5982\u679c\u5728CPU\u73af\u5883\u4e2d\u4e0d\u8d77\u4efb\u4f55\u4f5c\u7528 from torch.cuda.amp import autocast as autocast from transformers import AutoTokenizer , AutoConfig , AutoModel , get_scheduler from utils.common_utils import * from data_handle.data_loader import * from glm_config import * pc = ProjectConfig () \u5b9a\u4e49model2train()\u51fd\u6570 def model2train (): tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model , trust_remote_code = True ) config = AutoConfig . from_pretrained ( pc . pre_model , trust_remote_code = True ) if pc . use_ptuning : config . pre_seq_len = pc . pre_seq_len config . prefix_projection = pc . prefix_projection model = AutoModel . from_pretrained ( pc . pre_model , config = config , trust_remote_code = True ) #model.half()\u5c06\u6a21\u578b\u6570\u636e\u7c7b\u578b\u4ece\u9ed8\u8ba4\u7684float32\u7cbe\u5ea6\u8f6c\u6362\u4e3a\u66f4\u4f4e\u7684float16\u7cbe\u5ea6\uff0c\u51cf\u5c11\u5185\u5b58 model = model . float () # \u68af\u5ea6\u68c0\u67e5\u70b9\u662f\u4e00\u79cd\u4f18\u5316\u6280\u672f\uff0c\u7528\u4e8e\u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u964d\u4f4e\u5185\u5b58\u4f7f\u7528 model . gradient_checkpointing_enable () model . enable_input_require_grads () # \u4e0d\u8fdb\u884c\u7f13\u5b58\uff0c\u51cf\u5c11\u5185\u5b58 model . config . use_cache = False if pc . use_ptuning : model . transformer . prefix_encoder . float () if pc . use_lora : model . lm_head = CastOutputToFloat ( model . lm_head ) peft_config = peft . LoraConfig ( task_type = peft . TaskType . CAUSAL_LM , inference_mode = False , # \u63a8\u7406\u65f6\u4e3aTrue\uff0c\u6bd4\u5982\u7edd\u5b9a\u662f\u5426\u4f7f\u7528dropout r = pc . lora_rank , # \u4f4e\u79e9\u77e9\u9635\u7ef4\u5ea6 lora_alpha = 32 , # \u7f29\u653e\u7cfb\u6570 lora_dropout = 0.1 , ) model = peft . get_peft_model ( model , peft_config ) model = model . to ( pc . device ) no_decay = [ \"bias\" , \"LayerNorm.weight\" ] optimizer_grouped_parameters = [ { \"params\" : [ p for n , p in model . named_parameters () if not any ( nd in n for nd in no_decay )], \"weight_decay\" : pc . weight_decay , }, { \"params\" : [ p for n , p in model . named_parameters () if any ( nd in n for nd in no_decay )], \"weight_decay\" : 0.0 , }, ] optimizer = torch . optim . AdamW ( optimizer_grouped_parameters , lr = pc . learning_rate ) # model.to(pc.device) # train_dataloader , dev_dataloader = get_data () # \u6839\u636e\u8bad\u7ec3\u8f6e\u6570\u8ba1\u7b97\u6700\u5927\u8bad\u7ec3\u6b65\u6570\uff0c\u4ee5\u4fbf\u4e8escheduler\u52a8\u6001\u8c03\u6574lr num_update_steps_per_epoch = len ( train_dataloader ) #\u6307\u5b9a\u603b\u7684\u8bad\u7ec3\u6b65\u6570\uff0c\u5b83\u4f1a\u88ab\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u7528\u6765\u786e\u5b9a\u5b66\u4e60\u7387\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u786e\u4fdd\u5b66\u4e60\u7387\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f97\u4ee5\u5408\u7406\u5730\u8c03\u8282 max_train_steps = pc . epochs * num_update_steps_per_epoch warm_steps = int ( pc . warmup_ratio * max_train_steps ) # \u9884\u70ed\u9636\u6bb5\u7684\u8bad\u7ec3\u6b65\u6570 lr_scheduler = get_scheduler ( name = 'linear' , optimizer = optimizer , num_warmup_steps = warm_steps , num_training_steps = max_train_steps , ) # loss_list = [] tic_train = time . time () global_step , best_eval_loss = 0 , float ( 'inf' ) for epoch in range ( 1 , pc . epochs + 1 ): for batch in train_dataloader : if pc . use_lora : with autocast (): loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss else : loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss optimizer . zero_grad () loss . backward () optimizer . step () lr_scheduler . step () loss_list . append ( float ( loss . cpu () . detach ())) global_step += 1 if global_step % pc . logging_steps == 0 : time_diff = time . time () - tic_train loss_avg = sum ( loss_list ) / len ( loss_list ) print ( \"global step %d ( %02.2f%% ) , epoch: %d , loss: %.5f , speed: %.2f step/s, ETA: %s \" % ( global_step , global_step / max_train_steps * 100 , epoch , loss_avg , pc . logging_steps / time_diff , second2time ( int ( max_train_steps - global_step ) / ( pc . logging_steps / time_diff )))) tic_train = time . time () if global_step % pc . save_freq == 0 : cur_save_dir = os . path . join ( pc . save_dir , \"model_ %d \" % global_step ) save_model ( model , cur_save_dir ) tokenizer . save_pretrained ( cur_save_dir ) print ( f 'Model has saved at { cur_save_dir } .' ) eval_loss = evaluate_model ( model , dev_dataloader ) print ( \"Evaluation Loss: %.5f \" % ( eval_loss )) if eval_loss < best_eval_loss : print ( f \"Min eval loss has been updated: { best_eval_loss : .5f } --> { eval_loss : .5f } \" ) best_eval_loss = eval_loss cur_save_dir = os . path . join ( pc . save_dir , \"model_best\" ) save_model ( model , cur_save_dir ) tokenizer . save_pretrained ( cur_save_dir ) print ( f 'Best model has saved at { cur_save_dir } .' ) tic_train = time . time () \u5b9a\u4e49evaluate_model()\u51fd\u6570 def evaluate_model ( model , dev_dataloader ): \"\"\" \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u5f53\u524d\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002 Args: model: \u5f53\u524d\u6a21\u578b data_loader: \u6d4b\u8bd5\u96c6\u7684dataloader \"\"\" model . eval () loss_list = [] with torch . no_grad (): for batch in dev_dataloader : if pc . use_lora : with autocast (): loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss else : loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss loss_list . append ( float ( loss . cpu () . detach ())) model . train () return sum ( loss_list ) / len ( loss_list ) \u8c03\u7528: cd /Users/**/PycharmProjects/llm/ptune_chatglm # \u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3 python train.py \u8f93\u51fa\u7ed3\u679c: \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e76\u6d4b\u8bd5\u6548\u679c \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/ptune_chatglm/inference.py \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import time import torch from transformers import AutoTokenizer , AutoModel # torch.set_default_tensor_type(torch.cuda.HalfTensor) \u9884\u6d4b\u4ee3\u7801\u5177\u4f53\u5b9e\u73b0 def inference ( model , tokenizer , instuction : str , sentence : str ): \"\"\" \u6a21\u578b inference \u51fd\u6570\u3002 Args: instuction (str): _description_ sentence (str): _description_ Returns: _type_: _description_ \"\"\" with torch . no_grad (): input_text = f \"Instruction: { instuction } \\n \" if sentence : input_text += f \"Input: { sentence } \\n \" input_text += f \"Answer: \" batch = tokenizer ( input_text , return_tensors = \"pt\" ) out = model . generate ( input_ids = batch [ \"input_ids\" ] . to ( device ), max_new_tokens = max_new_tokens , temperature = 0 ) out_text = tokenizer . decode ( out [ 0 ]) answer = out_text . split ( 'Answer: ' )[ - 1 ] return answer if __name__ == '__main__' : from rich import print device = 'mps:0' max_new_tokens = 300 model_path = \"./llm/ptune_chatglm/checkpoints/model_1800\" tokenizer = AutoTokenizer . from_pretrained ( model_path , trust_remote_code = True ) model = AutoModel . from_pretrained ( model_path , trust_remote_code = True ) . half () . to ( device ) samples = [ { 'instruction' : \"\u73b0\u5728\u4f60\u662f\u4e00\u4e2a\u975e\u5e38\u5389\u5bb3\u7684SPO\u62bd\u53d6\u5668\u3002\" , \"input\" : \"\u4e0b\u9762\u8fd9\u53e5\u4e2d\u5305\u542b\u4e86\u54ea\u4e9b\u4e09\u5143\u7ec4\uff0c\u7528json\u5217\u8868\u7684\u5f62\u5f0f\u56de\u7b54\uff0c\u4e0d\u8981\u8f93\u51fa\u9664json\u5916\u7684\u5176\u4ed6\u7b54\u6848\u3002 \\n\\n 73\u83b7\u5956\u8bb0\u5f55\u4eba\u7269\u8bc4\u4ef7\uff1a\u9ec4\u78ca\u662f\u4e00\u4e2a\u7279\u522b\u5e78\u8fd0\u7684\u6f14\u5458\uff0c\u62cd\u7b2c\u4e00\u90e8\u620f\u5c31\u78b0\u5230\u4e86\u5bfc\u6f14\u9648\u51ef\u6b4c\uff0c\u800c\u4e14\u5728\u4ed6\u7684\u4e0b\u4e00\u90e8\u7535\u5f71\u300a\u591c\u534a\u6b4c\u58f0\u300b\u4e2d\u6f14\u5bf9\u624b\u620f\u7684\u5f20\u56fd\u8363\u3001\u5434\u5029\u83b2\u3001\u9ece\u660e\u7b49\u90fd\u662f\u8457\u540d\u7684\u6e2f\u53f0\u6f14\u5458\u3002\" , }, { 'instruction' : \"\u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\" , \"input\" : \"\u4e0b\u9762\u5b50\u4e2d\u7684\u4e3b\u8bed\u662f\u4ec0\u4e48\u7c7b\u522b\uff0c\u8f93\u51fa\u6210\u5217\u8868\u5f62\u5f0f\u3002 \\n\\n \u7b2cN\u6b21\u5165\u4f4f\u4e86\uff0c\u5c31\u662f\u65b9\u4fbf\u53bb\u5ba2\u6237\u90a3\u91cc\u54c8\u54c8\u3002\u8fd8\u6709\u5565\u8bf4\u7684\" } ] start = time . time () for i , sample in enumerate ( samples ): res = inference ( model , tokenizer , sample [ 'instruction' ], sample [ 'input' ] ) print ( f 'res { i } : ' ) print ( res ) print ( f 'Used { round ( time . time () - start , 2 ) } s.' ) \u7ed3\u679c\u5c55\u793a \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b9e\u73b0\u4e86\u57fa\u4e8eBERT+PET\u6a21\u578b\u7684\u6784\u5efa, \u5e76\u5b8c\u6210\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8bc4\u4f30.","title":"7.3 LoRA\u65b9\u5f0f\u5fae\u8c03ChatGLM\u6a21\u578b\u4ee3\u7801\u5b9e\u73b0\u548c\u8bad\u7ec3"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#chatglmlora","text":"","title":"\u57fa\u4e8eChatGLM+LoRA\u65b9\u5f0f\u6a21\u578b\u642d\u5efa"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_1","text":"\u638c\u63e1\u57fa\u4e8eChatGLM+LoRA\u65b9\u5f0f\u6a21\u578b\u642d\u5efa\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u6a21\u578b\u7684\u8bad\u7ec3,\u9a8c\u8bc1\u53ca\u76f8\u5173\u5de5\u5177\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_2","text":"\u672c\u9879\u76ee\u4e2d\u5b8c\u6210ChatGLM+LoRA\u6a21\u578b\u642d\u5efa\u3001\u8bad\u7ec3\u53ca\u5e94\u7528\u7684\u6b65\u9aa4\u5982\u4e0b\uff08\u6ce8\u610f\uff1a\u56e0\u4e3a\u672c\u9879\u76ee\u4e2d\u4f7f\u7528\u7684\u662fChatGLM\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6240\u4ee5\u76f4\u63a5\u52a0\u8f7d\u5373\u53ef\uff0c\u65e0\u9700\u91cd\u590d\u642d\u5efa\u6a21\u578b\u67b6\u6784\uff09: \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570","title":"\u6a21\u578b\u642d\u5efa"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_3","text":"\u76ee\u7684\uff1a\u6a21\u578b\u5728\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u9884\u6d4b\u65f6\u9700\u8981\u7684\u51fd\u6570 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/utils utils\u6587\u4ef6\u5939\u5171\u5305\u542b1\u4e2apy\u811a\u672c\uff1acommon_utils.py","title":"\u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#1-common_utilspy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u7c7b\u578b\u8f6c\u6362\u7c7b\u3001\u5206\u79d2\u65f6\u4e4b\u95f4\u8f6c\u6362\u4ee5\u53ca\u6a21\u578b\u4fdd\u5b58\u51fd\u6570\u3002 \u811a\u672c\u91cc\u9762\u5305\u542b\u4e00\u4e2a\u7c7b\u4ee5\u53ca\u4e24\u4e2a\u51fd\u6570\uff1aCastOutputToFloat\u3001second2time()\u4ee5\u53casave_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch import torch.nn as nn from glm_config import * import copy pc = ProjectConfig () \u5b9a\u4e49CastOutputToFloat\u7c7b class CastOutputToFloat ( nn . Sequential ): def forward ( self , x ): return super () . forward ( x ) . to ( torch . float32 ) \u5b9a\u4e49second2time()\u51fd\u6570 def second2time ( seconds : int ): \"\"\" \u5c06\u79d2\u8f6c\u6362\u6210\u65f6\u5206\u79d2\u3002 Args: seconds (int): _description_ \"\"\" m , s = divmod ( seconds , 60 ) h , m = divmod ( m , 60 ) return \" %02d : %02d : %02d \" % ( h , m , s ) \u5b9a\u4e49save_model() def save_model ( model , cur_save_dir : str ): \"\"\" \u5b58\u50a8\u5f53\u524d\u6a21\u578b\u3002 Args: cur_save_path (str): \u5b58\u50a8\u8def\u5f84\u3002 \"\"\" if pc . use_lora : # merge lora params with origin model merged_model = copy . deepcopy ( model ) merged_model = merged_model . merge_and_unload () merged_model . save_pretrained ( cur_save_dir ) else : model . save_pretrained ( cur_save_dir )","title":"1. common_utils.py"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_4","text":"\u76ee\u7684\uff1a\u5b9e\u73b0\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/train.py \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amodel2train()\u548cevaluate_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import os import time import copy import argparse from functools import partial import peft # autocast\u662fPyTorch\u4e2d\u4e00\u79cd\u6df7\u5408\u7cbe\u5ea6\u7684\u6280\u672f\uff0c\u53ef\u5728\u4fdd\u6301\u6570\u503c\u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u8bad\u7ec3\u901f\u5ea6\u548c\u51cf\u5c11\u663e\u5b58\u5360\u7528\u3002 # \u8be5\u65b9\u6cd5\u6df7\u5408\u7cbe\u5ea6\u8bad\u7ec3\uff0c\u5982\u679c\u5728CPU\u73af\u5883\u4e2d\u4e0d\u8d77\u4efb\u4f55\u4f5c\u7528 from torch.cuda.amp import autocast as autocast from transformers import AutoTokenizer , AutoConfig , AutoModel , get_scheduler from utils.common_utils import * from data_handle.data_loader import * from glm_config import * pc = ProjectConfig () \u5b9a\u4e49model2train()\u51fd\u6570 def model2train (): tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model , trust_remote_code = True ) config = AutoConfig . from_pretrained ( pc . pre_model , trust_remote_code = True ) if pc . use_ptuning : config . pre_seq_len = pc . pre_seq_len config . prefix_projection = pc . prefix_projection model = AutoModel . from_pretrained ( pc . pre_model , config = config , trust_remote_code = True ) #model.half()\u5c06\u6a21\u578b\u6570\u636e\u7c7b\u578b\u4ece\u9ed8\u8ba4\u7684float32\u7cbe\u5ea6\u8f6c\u6362\u4e3a\u66f4\u4f4e\u7684float16\u7cbe\u5ea6\uff0c\u51cf\u5c11\u5185\u5b58 model = model . float () # \u68af\u5ea6\u68c0\u67e5\u70b9\u662f\u4e00\u79cd\u4f18\u5316\u6280\u672f\uff0c\u7528\u4e8e\u5728\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u964d\u4f4e\u5185\u5b58\u4f7f\u7528 model . gradient_checkpointing_enable () model . enable_input_require_grads () # \u4e0d\u8fdb\u884c\u7f13\u5b58\uff0c\u51cf\u5c11\u5185\u5b58 model . config . use_cache = False if pc . use_ptuning : model . transformer . prefix_encoder . float () if pc . use_lora : model . lm_head = CastOutputToFloat ( model . lm_head ) peft_config = peft . LoraConfig ( task_type = peft . TaskType . CAUSAL_LM , inference_mode = False , # \u63a8\u7406\u65f6\u4e3aTrue\uff0c\u6bd4\u5982\u7edd\u5b9a\u662f\u5426\u4f7f\u7528dropout r = pc . lora_rank , # \u4f4e\u79e9\u77e9\u9635\u7ef4\u5ea6 lora_alpha = 32 , # \u7f29\u653e\u7cfb\u6570 lora_dropout = 0.1 , ) model = peft . get_peft_model ( model , peft_config ) model = model . to ( pc . device ) no_decay = [ \"bias\" , \"LayerNorm.weight\" ] optimizer_grouped_parameters = [ { \"params\" : [ p for n , p in model . named_parameters () if not any ( nd in n for nd in no_decay )], \"weight_decay\" : pc . weight_decay , }, { \"params\" : [ p for n , p in model . named_parameters () if any ( nd in n for nd in no_decay )], \"weight_decay\" : 0.0 , }, ] optimizer = torch . optim . AdamW ( optimizer_grouped_parameters , lr = pc . learning_rate ) # model.to(pc.device) # train_dataloader , dev_dataloader = get_data () # \u6839\u636e\u8bad\u7ec3\u8f6e\u6570\u8ba1\u7b97\u6700\u5927\u8bad\u7ec3\u6b65\u6570\uff0c\u4ee5\u4fbf\u4e8escheduler\u52a8\u6001\u8c03\u6574lr num_update_steps_per_epoch = len ( train_dataloader ) #\u6307\u5b9a\u603b\u7684\u8bad\u7ec3\u6b65\u6570\uff0c\u5b83\u4f1a\u88ab\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u7528\u6765\u786e\u5b9a\u5b66\u4e60\u7387\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u786e\u4fdd\u5b66\u4e60\u7387\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f97\u4ee5\u5408\u7406\u5730\u8c03\u8282 max_train_steps = pc . epochs * num_update_steps_per_epoch warm_steps = int ( pc . warmup_ratio * max_train_steps ) # \u9884\u70ed\u9636\u6bb5\u7684\u8bad\u7ec3\u6b65\u6570 lr_scheduler = get_scheduler ( name = 'linear' , optimizer = optimizer , num_warmup_steps = warm_steps , num_training_steps = max_train_steps , ) # loss_list = [] tic_train = time . time () global_step , best_eval_loss = 0 , float ( 'inf' ) for epoch in range ( 1 , pc . epochs + 1 ): for batch in train_dataloader : if pc . use_lora : with autocast (): loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss else : loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss optimizer . zero_grad () loss . backward () optimizer . step () lr_scheduler . step () loss_list . append ( float ( loss . cpu () . detach ())) global_step += 1 if global_step % pc . logging_steps == 0 : time_diff = time . time () - tic_train loss_avg = sum ( loss_list ) / len ( loss_list ) print ( \"global step %d ( %02.2f%% ) , epoch: %d , loss: %.5f , speed: %.2f step/s, ETA: %s \" % ( global_step , global_step / max_train_steps * 100 , epoch , loss_avg , pc . logging_steps / time_diff , second2time ( int ( max_train_steps - global_step ) / ( pc . logging_steps / time_diff )))) tic_train = time . time () if global_step % pc . save_freq == 0 : cur_save_dir = os . path . join ( pc . save_dir , \"model_ %d \" % global_step ) save_model ( model , cur_save_dir ) tokenizer . save_pretrained ( cur_save_dir ) print ( f 'Model has saved at { cur_save_dir } .' ) eval_loss = evaluate_model ( model , dev_dataloader ) print ( \"Evaluation Loss: %.5f \" % ( eval_loss )) if eval_loss < best_eval_loss : print ( f \"Min eval loss has been updated: { best_eval_loss : .5f } --> { eval_loss : .5f } \" ) best_eval_loss = eval_loss cur_save_dir = os . path . join ( pc . save_dir , \"model_best\" ) save_model ( model , cur_save_dir ) tokenizer . save_pretrained ( cur_save_dir ) print ( f 'Best model has saved at { cur_save_dir } .' ) tic_train = time . time () \u5b9a\u4e49evaluate_model()\u51fd\u6570 def evaluate_model ( model , dev_dataloader ): \"\"\" \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u5f53\u524d\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002 Args: model: \u5f53\u524d\u6a21\u578b data_loader: \u6d4b\u8bd5\u96c6\u7684dataloader \"\"\" model . eval () loss_list = [] with torch . no_grad (): for batch in dev_dataloader : if pc . use_lora : with autocast (): loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss else : loss = model ( input_ids = batch [ 'input_ids' ] . to ( dtype = torch . long , device = pc . device ), labels = batch [ 'labels' ] . to ( dtype = torch . long , device = pc . device ) ) . loss loss_list . append ( float ( loss . cpu () . detach ())) model . train () return sum ( loss_list ) / len ( loss_list ) \u8c03\u7528: cd /Users/**/PycharmProjects/llm/ptune_chatglm # \u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3 python train.py \u8f93\u51fa\u7ed3\u679c:","title":"\u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_5","text":"\u76ee\u7684\uff1a\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e76\u6d4b\u8bd5\u6548\u679c \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/ptune_chatglm/inference.py \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import time import torch from transformers import AutoTokenizer , AutoModel # torch.set_default_tensor_type(torch.cuda.HalfTensor) \u9884\u6d4b\u4ee3\u7801\u5177\u4f53\u5b9e\u73b0 def inference ( model , tokenizer , instuction : str , sentence : str ): \"\"\" \u6a21\u578b inference \u51fd\u6570\u3002 Args: instuction (str): _description_ sentence (str): _description_ Returns: _type_: _description_ \"\"\" with torch . no_grad (): input_text = f \"Instruction: { instuction } \\n \" if sentence : input_text += f \"Input: { sentence } \\n \" input_text += f \"Answer: \" batch = tokenizer ( input_text , return_tensors = \"pt\" ) out = model . generate ( input_ids = batch [ \"input_ids\" ] . to ( device ), max_new_tokens = max_new_tokens , temperature = 0 ) out_text = tokenizer . decode ( out [ 0 ]) answer = out_text . split ( 'Answer: ' )[ - 1 ] return answer if __name__ == '__main__' : from rich import print device = 'mps:0' max_new_tokens = 300 model_path = \"./llm/ptune_chatglm/checkpoints/model_1800\" tokenizer = AutoTokenizer . from_pretrained ( model_path , trust_remote_code = True ) model = AutoModel . from_pretrained ( model_path , trust_remote_code = True ) . half () . to ( device ) samples = [ { 'instruction' : \"\u73b0\u5728\u4f60\u662f\u4e00\u4e2a\u975e\u5e38\u5389\u5bb3\u7684SPO\u62bd\u53d6\u5668\u3002\" , \"input\" : \"\u4e0b\u9762\u8fd9\u53e5\u4e2d\u5305\u542b\u4e86\u54ea\u4e9b\u4e09\u5143\u7ec4\uff0c\u7528json\u5217\u8868\u7684\u5f62\u5f0f\u56de\u7b54\uff0c\u4e0d\u8981\u8f93\u51fa\u9664json\u5916\u7684\u5176\u4ed6\u7b54\u6848\u3002 \\n\\n 73\u83b7\u5956\u8bb0\u5f55\u4eba\u7269\u8bc4\u4ef7\uff1a\u9ec4\u78ca\u662f\u4e00\u4e2a\u7279\u522b\u5e78\u8fd0\u7684\u6f14\u5458\uff0c\u62cd\u7b2c\u4e00\u90e8\u620f\u5c31\u78b0\u5230\u4e86\u5bfc\u6f14\u9648\u51ef\u6b4c\uff0c\u800c\u4e14\u5728\u4ed6\u7684\u4e0b\u4e00\u90e8\u7535\u5f71\u300a\u591c\u534a\u6b4c\u58f0\u300b\u4e2d\u6f14\u5bf9\u624b\u620f\u7684\u5f20\u56fd\u8363\u3001\u5434\u5029\u83b2\u3001\u9ece\u660e\u7b49\u90fd\u662f\u8457\u540d\u7684\u6e2f\u53f0\u6f14\u5458\u3002\" , }, { 'instruction' : \"\u4f60\u73b0\u5728\u662f\u4e00\u4e2a\u5f88\u5389\u5bb3\u7684\u9605\u8bfb\u7406\u89e3\u5668\uff0c\u4e25\u683c\u6309\u7167\u4eba\u7c7b\u6307\u4ee4\u8fdb\u884c\u56de\u7b54\u3002\" , \"input\" : \"\u4e0b\u9762\u5b50\u4e2d\u7684\u4e3b\u8bed\u662f\u4ec0\u4e48\u7c7b\u522b\uff0c\u8f93\u51fa\u6210\u5217\u8868\u5f62\u5f0f\u3002 \\n\\n \u7b2cN\u6b21\u5165\u4f4f\u4e86\uff0c\u5c31\u662f\u65b9\u4fbf\u53bb\u5ba2\u6237\u90a3\u91cc\u54c8\u54c8\u3002\u8fd8\u6709\u5565\u8bf4\u7684\" } ] start = time . time () for i , sample in enumerate ( samples ): res = inference ( model , tokenizer , sample [ 'instruction' ], sample [ 'input' ] ) print ( f 'res { i } : ' ) print ( res ) print ( f 'Used { round ( time . time () - start , 2 ) } s.' ) \u7ed3\u679c\u5c55\u793a","title":"\u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/03-LoRA%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_6","text":"\u672c\u5c0f\u8282\u5b9e\u73b0\u4e86\u57fa\u4e8eBERT+PET\u6a21\u578b\u7684\u6784\u5efa, \u5e76\u5b8c\u6210\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8bc4\u4f30.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html","text":"\u8d8b\u52a8\u4e91\u4f7f\u7528\u300a\u8865\u5145\u300b \u00b6 \u4e00\u3001\u6ce8\u518c\u767b\u9646 \u00b6 1.1 \u8fdb\u5165\u5b98\u7f51\u5730\u5740 \u00b6 \u7f51\u5740\uff1a https://virtaicloud.com/ \u6ce8\u610f\uff1a\u7f51\u5740\u6253\u5f00\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u65e0\u75d5\u7a97\u53e3\u6a21\u5f0f 1.2 \u624b\u673a\u53f7\u6ce8\u518c\u3001\u767b\u9646 \u00b6 1.3 \u663e\u793a\u767b\u5f55\u6210\u529f \u00b6 1.4 \u67e5\u770b\u8d26\u6237\u4fe1\u606f \u00b6 \u9996\u6b21\u6ce8\u518c\u767b\u5f55\u7684\u7528\u6237\u6709\u514d\u8d39\u7684168\u5143\u7b97\u529b\u70b9\u3002 \u4e8c\u3001\u521b\u5efa\u9879\u76ee \u00b6 \u6ce8\u610f\u6211\u4eec\u60f3\u8981\u4f7f\u7528\u8d8b\u52a8\u4e91\u8fdb\u884c\u6a21\u578b\u4ee3\u7801\u7684\u5fae\u8c03\u5b9e\u73b0\uff0c\u9700\u8981\u521b\u5efa\u9879\u76ee\u8fdb\u884c\u8fd0\u884c\u3002\u4f46\u662f\u56e0\u4e3a\u6211\u4eec\u4f7f\u7528\u7684\u6570\u636e\u96c6\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u90fd\u5c5e\u4e8e\u672c\u5730\u81ea\u5df1\u62e5\u6709\u7684\uff0c\u6240\u4ee5\u9700\u8981\u5728\u8d8b\u52a8\u4e91\u4e0a\u9996\u5148\u300c\u6dfb\u52a0\u6570\u636e\u6e90\u300d\u548c\u300c\u6dfb\u52a0\u9884\u8bad\u7ec3\u6a21\u578b\u300d 2.1 \u6dfb\u52a0\u6570\u636e\u6e90 \u00b6 2.1.1 \u9009\u62e9\"\u6570\u636e\"\u5de5\u5177 \u00b6 2.1.2 \u521b\u5efa\u6570\u636e \u00b6 2.1.3 \u914d\u7f6e\u6570\u636e\u4fe1\u606f \u00b6 2.1.4 \u9009\u62e9\u7f51\u9875\u4e0a\u4f20\u65b9\u5f0f\u8fdb\u884c\u6570\u636e\u4f20\u8f93 \u00b6 2.1.5 \u62d6\u62fd\u672c\u5730\u6570\u636e\u4e0a\u4f20 \u00b6 2.1.6 \u6570\u636e\u4e0a\u4f20\u6210\u529f\u5c55\u793a \u00b6 \u6b64\u65f6\uff0c\u91cd\u65b0\u5237\u65b0\u9875\u9762\uff0c\u4f1a\u5728\u6570\u636e\u5de5\u5177\u680f\u663e\u793a\uff0c\u5df2\u7ecf\u521b\u5efa\u597d\u7684\u6570\u636e\u6e90 2.2 \u6dfb\u52a0\u9884\u8bad\u7ec3\u6a21\u578b \u00b6 2.2.1 \u9009\u62e9\"\u6a21\u578b\"\u5de5\u5177\uff0c\u521b\u5efa\u6a21\u578b \u00b6 2.2.2 \u914d\u7f6e\u6a21\u578b\u4fe1\u606f \u00b6 2.2.3 \u9009\u62e9SFTP\u65b9\u5f0f\u8fdb\u884c\u6570\u636e\u4f20\u8f93 \u00b6 \u56e0\u4e3a\u6a21\u578b\u6587\u4ef6\u8fc7\u5927 2.2.4 \u70b9\u51fbSFTP\u65b9\u5f0f\u4e4b\u540e, \u9009\u62e9\u6587\u4ef6\u4f20\u8f93 \u00b6 2.2.5 \u83b7\u53d6SFTP\u914d\u7f6e\u4fe1\u606f \u00b6 2.2.6 \u4f7f\u7528CMD\u4f20\u8f93\u6570\u636e(Windows) \u00b6 windows10 \u6700\u65b0\u7248\u53ca\u4ee5\u4e0a\u7248\u672c\u90fd\u652f\u6301 CMD \u4f20\u8f93\u6570\u636e\u3002 \u8f93\u5165 win+r \u952e\uff0c\u7cfb\u7edf\u5de6\u4e0b\u89d2\u5f39\u51fa\u8fd0\u884c\u6846\u3002 \u8f93\u5165 cmd \u5e76\u56de\u8f66\uff0c\u8fdb\u5165\u547d\u4ee4\u884c\u3002 \u53bb\u590d\u5236 \u8fde\u63a5\u5b57\u7b26 \u3002 \u5728\u547d\u4ee4\u884c\u4e2d\u7c98\u8d34 \u8fde\u63a5\u5b57\u7b26 \u5e76\u56de\u8f66\u3002 \u5982\u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\uff0c\u5219\u8f93\u5165 yes \u3002 Are you sure you want to continue connecting (yes/no/[fingerprint])? \u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8f93\u5165 \u5bc6\u7801 \u5e76\u56de\u8f66\uff0c \u5bc6\u7801 \u4ece\u4e0a\u8ff0\u56fe\u7247\u5904\u83b7\u53d6\u3002 roif48iKYp@cluster1-dev4.virtaicloud.com's password: \u6700\u540e\u8fd4\u56de sftp \u547d\u4ee4\u884c\u5373\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8868\u793a\u8fde\u63a5\u6210\u529f\u3002 sftp> \u5728 sftp \u547d\u4ee4\u884c\u4e2d\u8f93\u5165\u4f20\u8f93\u547d\u4ee4\u3002 put -r D:\\Git\\tool\\ /upload \u6ce8\u610f\uff1a\u60a8\u53ea\u9700\u4fee\u6539\u547d\u4ee4\u4e2d D:\\Git\\tool\\ \u4e3a\u60a8\u5b9e\u9645\u8981\u4e0a\u4f20\u7684\u6570\u636e\u5728\u60a8\u672c\u5730\u7684\u5b58\u50a8\u8def\u5f84\u3002 2.2.6 \u4f7f\u7528Mac\u7ec8\u7aef\u4f20\u8f93\u6570\u636e \u00b6 \u6309 Command + \u7a7a\u683c \u6253\u5f00\u641c\u7d22\u680f\u3002 \u641c\u7d22\u680f\u4e2d\u8f93\u5165 \u7ec8\u7aef \u5e76\u56de\u8f66\uff0c\u6253\u5f00\u7ec8\u7aef\u3002 \u53bb\u590d\u5236 \u8fde\u63a5\u5b57\u7b26 \u3002 \u5728\u547d\u4ee4\u884c\u4e2d\u7c98\u8d34 \u8fde\u63a5\u5b57\u7b26 \u5e76\u56de\u8f66\u3002 \u5982\u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\uff0c\u5219\u8f93\u5165 yes \u3002 Are you sure you want to continue connecting (yes/no/[fingerprint])? \u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8f93\u5165 \u5bc6\u7801 \u5e76\u56de\u8f66\uff0c \u5bc6\u7801 \u4ece\u4e0a\u8ff0\u56fe\u7247\u5904\u83b7\u53d6\u3002 roif48iKYp@cluster1-dev4.virtaicloud.com's password: \u6700\u540e\u8fd4\u56de sftp \u547d\u4ee4\u884c\u5373\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8868\u793a\u8fde\u63a5\u6210\u529f\u3002 sftp> \u5728 sftp \u547d\u4ee4\u884c\u4e2d\u8f93\u5165\u4f20\u8f93\u547d\u4ee4\u3002 put -r D:\\Git\\tool\\ /upload \u6ce8\u610f\uff1a\u60a8\u53ea\u9700\u4fee\u6539\u547d\u4ee4\u4e2d D:\\Git\\tool\\ \u4e3a\u60a8\u5b9e\u9645\u8981\u4e0a\u4f20\u7684\u6570\u636e\u5728\u60a8\u672c\u5730\u7684\u5b58\u50a8\u8def\u5f84\u3002 2.2.7 \u8fde\u63a5\u6210\u529f\u4e0a\u4f20\u6570\u636e\u5c55\u793a \u00b6 \u6ce8\u610f\uff1a\u5f53\u4f60\u7684\u6a21\u578b\u6570\u636e\u4f20\u8f93\u5b8c\u6210\u540e\uff0c\u53ef\u4ee5\u5173\u95ed\u901a\u9053\u3002 2.3 \u521b\u5efa\u9879\u76ee \u00b6 2.3.1 \u70b9\u51fb\u53f3\u4e0a\u89d2\u521b\u5efa\u9879\u76ee \u00b6 2.3.2 \u4f9d\u6b21\u914d\u7f6e\u9879\u76ee\u5185\u5bb9 \u00b6 \u6ce8\u610f\uff1a\u521b\u5efa\u9879\u76ee\u540e\uff0c\u6570\u636e\u4f1a\u9ed8\u8ba4\u4fdd\u5b58\u7684\u8def\u5f84\u4e3a\uff1a/gemini/data1\u4e0b\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4f1a\u81ea\u52a8\u4fdd\u5b58\u5728/genmini/pretrain\u4e0b 2.3.3 \u955c\u50cf\u73af\u5883\u9009\u62e9 \u00b6 2.3.4 \u521b\u5efa\u5b8c\u9879\u76ee\u540e\uff0c\u8981\u6c42\u4e0a\u4f20\u672c\u5730\u4ee3\u7801\uff08\u62d6\u62fd\u5f0f\uff09 \u00b6 \u6ce8\u610f\uff1a\u4e0a\u4f20\u7684\u4ee3\u7801\u6587\u4ef6\uff0c\u9700\u8981\u8fdb\u884c\u538b\u7f29\u540e\u4e0a\u4f20 2.3.5 \u9879\u76ee\u521b\u5efa\u6210\u529f\u5c55\u793a \u00b6 \u4e09\u3001\u8fd0\u884c\u670d\u52a1\u73af\u5883\u3001\u8bad\u7ec3\u6a21\u578b \u00b6 3.1 \u521d\u59cb\u5316\u5f00\u53d1\u73af\u5883 \u00b6 3.1.1 \u70b9\u51fb\u5f00\u53d1\u5de5\u5177\uff0c\u8fdb\u5165\u5f00\u53d1\u73af\u5883\u5b9e\u4f8b\u914d\u7f6e\u754c\u9762 \u00b6 3.1.2 \u8fdb\u884c\u5f00\u53d1\u73af\u5883\u5b9e\u4f8b\u914d\u7f6e \u00b6 3.1.3 \u7b49\u5f85\u8d44\u6e90\u914d\u7f6e \u00b6 3.1.4 \u8d44\u6e90\u914d\u7f6e\u5b8c\u6210\uff0c\u7b49\u5f85\u8fdb\u5165\u5f00\u53d1\u73af\u5883 \u00b6 3.2 \u914d\u7f6e\u5f00\u53d1\u73af\u5883 \u00b6 3.2.1 \u8fdb\u5165\u5f00\u53d1\u73af\u5883 \u00b6 3.2.2 \u5f00\u53d1\u73af\u5883\u5c55\u793a \u00b6 3.2.3 \u8fdb\u5165\u7f51\u9875\u7ec8\u7aef\u64cd\u4f5c \u00b6 3.2.4 \u67e5\u770b\u4ee3\u7801\u3001\u6570\u636e\u3001\u9884\u8bad\u7ec3\u6a21\u578b \u00b6 3.2.5 \u5b89\u88c5\u4f9d\u8d56\u5e93 \u00b6 \u9ed8\u8ba4\u5b89\u88c5\u7684\u6709pytorch=2.0.1\uff0c\u5e76\u4e14\u652f\u6301cuda \u5b89\u88c5\u5176\u4ed6\u7b2c\u4e09\u65b9\u5e93 pip install protobuf == 3.20.0 transformers == 4.27.1 icetk cpm_kernels pip install peft 3.3 \u8bad\u7ec3\u6a21\u578b \u00b6 3.3.1 \u8def\u5f84\u4fee\u6539 \u00b6 \u56e0\u4e3a\u5728\u8d8b\u52a8\u4e91\u670d\u52a1\u4e0b\uff0c\u6570\u636e\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u4ee3\u7801\u7684\u4f4d\u7f6e\u90fd\u53d1\u751f\u4e86\u6539\u53d8\uff0c\u6240\u4ee5\u8981\u6539\u53d8\u76f8\u5e94\u7684\u5f15\u7528\u6570\u636e\u4f4d\u7f6e config\u6587\u4ef6\u7c7b\u7684\u8def\u5f84\u4fee\u6539 \u8fd8\u9700\u8981\u5c06train.py\uff0cmodel=model.float()\u6539\u4e3amodel=model.half()\uff0c\u52a0\u5feb\u6a21\u578b\u8bad\u7ec3 3.3.2 \u8bad\u7ec3\u811a\u672c \u00b6 \u547d\u4ee4 python train . py \u6267\u884c\u7ed3\u679c \u8d44\u6e90\u76d1\u63a7 \u8017\u65f6 1h20min 3.4 \u6a21\u578b\u9884\u6d4b \u00b6 \u6ce8\u610f\u4fee\u6539inference.py\u811a\u672c\u91cc\u6a21\u578b\u7684\u8def\u5f84 \u7ed3\u679c\u5c55\u793a 3.5 \u6a21\u578b\u4e0b\u8f7d\u672c\u5730\u5b9e\u73b0\u9884\u6d4b \u00b6 3.5.1 SSH\u914d\u7f6e \u00b6 \u8fdb\u5165 \u201c\u5e73\u53f0\u8bbe\u7f6e\u201d \u9875\u9762 \u767b\u5f55\u5e73\u53f0\u3002 \u4e0b\u62c9\u53f3\u4e0a\u89d2\u8d26\u6237\u5904\uff0c\u9009\u62e9 \u5e73\u53f0\u8bbe\u7f6e \u3002 \u70b9\u51fb\u5e73\u53f0\u8bbe\u7f6e \u5728 \u5e73\u53f0\u8bbe\u7f6e \u9875\u9762\u7684 SSH Key \u5904\uff0c\u60a8\u53ef\u7ba1\u7406 \u5bc6\u7801\u51ed\u8bc1 \u548c \u79d8\u94a5\u51ed\u8bc1 \uff08SSH Key\uff09\u3002 \u6ce8\u610f\uff1a\u9700\u8981\u81ea\u5df1\u8bbe\u5b9a\u7528\u6237\u540d\u548c\u5bc6\u7801\u3001ssh key\u81ea\u52a8\u751f\u6210\u5373\u53ef \u5728\u5177\u4f53\u9879\u76ee\u4e2d\u9009\u62e9 \u5f00\u53d1 \uff0c\u8fdb\u5165 \u5f00\u53d1\u73af\u5883\u5b9e\u4f8b \u9875 \u83b7\u53d6\u5f00\u53d1\u73af\u5883\u7684 ssh \u8fde\u63a5\u4e32\u7528\u4e8e\u8fde\u63a5\u5f00\u53d1\u73af\u5883\u3002 \u6ce8\u610f\uff1a\u5728\u4fee\u6539SSH\u914d\u7f6e\u4e2d\uff0c\u9009\u62e9\u5f00\u542f\uff0c\u7136\u540e\u518d\u542f\u52a8\u73af\u5883 \u6ce8\u610f\u53ea\u8981\u8fdb\u5165\u5f00\u53d1\u73af\u5883\uff0c\u5c31\u4f1a\u4ea7\u751f\u8d39\u7528\uff0c\u4e3a\u4e86\u8282\u7701\u8d44\u6e90\uff0c\u53ef\u4ee5\u5c06\u5b9e\u4f8b\u89c4\u683c\u8fdb\u884c\u51cf\u914d\uff0c\u8282\u7701\u7b97\u529b \u542f\u52a8\u73af\u5883\u540e\uff0c\u51fa\u73b0ssh\u8fde\u63a5\u4e32 3.5.2 \u7ec8\u7aef\u64cd\u4f5c\u8fde\u63a5\u4e91\u670d\u52a1 \u00b6 \u590d\u5236ssh\u8fde\u63a5\u4e32\uff0c\u8fdb\u884c\u4fee\u6539 ssh - p 30022 itheima @root@ssh - 736 af97802ac911f1b7f454489821925 . swwutgwduthw @ssh . virtaicloud . com \u4e3b\u673a\u540d \uff1a ssh . virtaicloud . com \u7aef\u53e3\u53f7 \uff1a 30022 \u7528\u6237\u540d \uff1a itheima @root@ssh - 736 af97802ac911f1b7f454489821925 . swwutgwduthw @ \u83b7\u53d6\u6a21\u578b\u4fdd\u5b58\u8def\u5f84 / gemini / code / checkpoints / ptune / model_best \u5c06\u6a21\u578b\u4e0b\u8f7d\u5230\u672c\u5730\u684c\u9762 \u547d\u4ee4 scp - p 30022 - r itheima @root@ssh - 736 af97802ac911f1b7f454489821925 . swwutgwduthw @ssh . virtaicloud . com : / gemini / code / checkpoints / ptune / model_best ~/ Desktop","title":"7.4 \u8d8b\u52a8\u4e91\u4f7f\u7528\u300a\u6269\u5c55\u300b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#_1","text":"","title":"\u8d8b\u52a8\u4e91\u4f7f\u7528\u300a\u8865\u5145\u300b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#_2","text":"","title":"\u4e00\u3001\u6ce8\u518c\u767b\u9646"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#11","text":"\u7f51\u5740\uff1a https://virtaicloud.com/ \u6ce8\u610f\uff1a\u7f51\u5740\u6253\u5f00\u7684\u65f6\u5019\uff0c\u4f7f\u7528\u65e0\u75d5\u7a97\u53e3\u6a21\u5f0f","title":"1.1 \u8fdb\u5165\u5b98\u7f51\u5730\u5740"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#12","text":"","title":"1.2 \u624b\u673a\u53f7\u6ce8\u518c\u3001\u767b\u9646"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#13","text":"","title":"1.3 \u663e\u793a\u767b\u5f55\u6210\u529f"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#14","text":"\u9996\u6b21\u6ce8\u518c\u767b\u5f55\u7684\u7528\u6237\u6709\u514d\u8d39\u7684168\u5143\u7b97\u529b\u70b9\u3002","title":"1.4 \u67e5\u770b\u8d26\u6237\u4fe1\u606f"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#_3","text":"\u6ce8\u610f\u6211\u4eec\u60f3\u8981\u4f7f\u7528\u8d8b\u52a8\u4e91\u8fdb\u884c\u6a21\u578b\u4ee3\u7801\u7684\u5fae\u8c03\u5b9e\u73b0\uff0c\u9700\u8981\u521b\u5efa\u9879\u76ee\u8fdb\u884c\u8fd0\u884c\u3002\u4f46\u662f\u56e0\u4e3a\u6211\u4eec\u4f7f\u7528\u7684\u6570\u636e\u96c6\u548c\u9884\u8bad\u7ec3\u6a21\u578b\u90fd\u5c5e\u4e8e\u672c\u5730\u81ea\u5df1\u62e5\u6709\u7684\uff0c\u6240\u4ee5\u9700\u8981\u5728\u8d8b\u52a8\u4e91\u4e0a\u9996\u5148\u300c\u6dfb\u52a0\u6570\u636e\u6e90\u300d\u548c\u300c\u6dfb\u52a0\u9884\u8bad\u7ec3\u6a21\u578b\u300d","title":"\u4e8c\u3001\u521b\u5efa\u9879\u76ee"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#21","text":"","title":"2.1 \u6dfb\u52a0\u6570\u636e\u6e90"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#211","text":"","title":"2.1.1 \u9009\u62e9\"\u6570\u636e\"\u5de5\u5177"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#212","text":"","title":"2.1.2 \u521b\u5efa\u6570\u636e"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#213","text":"","title":"2.1.3 \u914d\u7f6e\u6570\u636e\u4fe1\u606f"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#214","text":"","title":"2.1.4 \u9009\u62e9\u7f51\u9875\u4e0a\u4f20\u65b9\u5f0f\u8fdb\u884c\u6570\u636e\u4f20\u8f93"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#215","text":"","title":"2.1.5 \u62d6\u62fd\u672c\u5730\u6570\u636e\u4e0a\u4f20"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#216","text":"\u6b64\u65f6\uff0c\u91cd\u65b0\u5237\u65b0\u9875\u9762\uff0c\u4f1a\u5728\u6570\u636e\u5de5\u5177\u680f\u663e\u793a\uff0c\u5df2\u7ecf\u521b\u5efa\u597d\u7684\u6570\u636e\u6e90","title":"2.1.6 \u6570\u636e\u4e0a\u4f20\u6210\u529f\u5c55\u793a"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#22","text":"","title":"2.2 \u6dfb\u52a0\u9884\u8bad\u7ec3\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#221","text":"","title":"2.2.1 \u9009\u62e9\"\u6a21\u578b\"\u5de5\u5177\uff0c\u521b\u5efa\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#222","text":"","title":"2.2.2 \u914d\u7f6e\u6a21\u578b\u4fe1\u606f"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#223-sftp","text":"\u56e0\u4e3a\u6a21\u578b\u6587\u4ef6\u8fc7\u5927","title":"2.2.3 \u9009\u62e9SFTP\u65b9\u5f0f\u8fdb\u884c\u6570\u636e\u4f20\u8f93"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#224-sftp","text":"","title":"2.2.4 \u70b9\u51fbSFTP\u65b9\u5f0f\u4e4b\u540e, \u9009\u62e9\u6587\u4ef6\u4f20\u8f93"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#225-sftp","text":"","title":"2.2.5 \u83b7\u53d6SFTP\u914d\u7f6e\u4fe1\u606f"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#226-cmdwindows","text":"windows10 \u6700\u65b0\u7248\u53ca\u4ee5\u4e0a\u7248\u672c\u90fd\u652f\u6301 CMD \u4f20\u8f93\u6570\u636e\u3002 \u8f93\u5165 win+r \u952e\uff0c\u7cfb\u7edf\u5de6\u4e0b\u89d2\u5f39\u51fa\u8fd0\u884c\u6846\u3002 \u8f93\u5165 cmd \u5e76\u56de\u8f66\uff0c\u8fdb\u5165\u547d\u4ee4\u884c\u3002 \u53bb\u590d\u5236 \u8fde\u63a5\u5b57\u7b26 \u3002 \u5728\u547d\u4ee4\u884c\u4e2d\u7c98\u8d34 \u8fde\u63a5\u5b57\u7b26 \u5e76\u56de\u8f66\u3002 \u5982\u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\uff0c\u5219\u8f93\u5165 yes \u3002 Are you sure you want to continue connecting (yes/no/[fingerprint])? \u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8f93\u5165 \u5bc6\u7801 \u5e76\u56de\u8f66\uff0c \u5bc6\u7801 \u4ece\u4e0a\u8ff0\u56fe\u7247\u5904\u83b7\u53d6\u3002 roif48iKYp@cluster1-dev4.virtaicloud.com's password: \u6700\u540e\u8fd4\u56de sftp \u547d\u4ee4\u884c\u5373\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8868\u793a\u8fde\u63a5\u6210\u529f\u3002 sftp> \u5728 sftp \u547d\u4ee4\u884c\u4e2d\u8f93\u5165\u4f20\u8f93\u547d\u4ee4\u3002 put -r D:\\Git\\tool\\ /upload \u6ce8\u610f\uff1a\u60a8\u53ea\u9700\u4fee\u6539\u547d\u4ee4\u4e2d D:\\Git\\tool\\ \u4e3a\u60a8\u5b9e\u9645\u8981\u4e0a\u4f20\u7684\u6570\u636e\u5728\u60a8\u672c\u5730\u7684\u5b58\u50a8\u8def\u5f84\u3002","title":"2.2.6 \u4f7f\u7528CMD\u4f20\u8f93\u6570\u636e(Windows)"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#226-mac","text":"\u6309 Command + \u7a7a\u683c \u6253\u5f00\u641c\u7d22\u680f\u3002 \u641c\u7d22\u680f\u4e2d\u8f93\u5165 \u7ec8\u7aef \u5e76\u56de\u8f66\uff0c\u6253\u5f00\u7ec8\u7aef\u3002 \u53bb\u590d\u5236 \u8fde\u63a5\u5b57\u7b26 \u3002 \u5728\u547d\u4ee4\u884c\u4e2d\u7c98\u8d34 \u8fde\u63a5\u5b57\u7b26 \u5e76\u56de\u8f66\u3002 \u5982\u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\uff0c\u5219\u8f93\u5165 yes \u3002 Are you sure you want to continue connecting (yes/no/[fingerprint])? \u8fd4\u56de\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8f93\u5165 \u5bc6\u7801 \u5e76\u56de\u8f66\uff0c \u5bc6\u7801 \u4ece\u4e0a\u8ff0\u56fe\u7247\u5904\u83b7\u53d6\u3002 roif48iKYp@cluster1-dev4.virtaicloud.com's password: \u6700\u540e\u8fd4\u56de sftp \u547d\u4ee4\u884c\u5373\u5982\u4e0b\u4fe1\u606f\u65f6\uff0c\u8868\u793a\u8fde\u63a5\u6210\u529f\u3002 sftp> \u5728 sftp \u547d\u4ee4\u884c\u4e2d\u8f93\u5165\u4f20\u8f93\u547d\u4ee4\u3002 put -r D:\\Git\\tool\\ /upload \u6ce8\u610f\uff1a\u60a8\u53ea\u9700\u4fee\u6539\u547d\u4ee4\u4e2d D:\\Git\\tool\\ \u4e3a\u60a8\u5b9e\u9645\u8981\u4e0a\u4f20\u7684\u6570\u636e\u5728\u60a8\u672c\u5730\u7684\u5b58\u50a8\u8def\u5f84\u3002","title":"2.2.6 \u4f7f\u7528Mac\u7ec8\u7aef\u4f20\u8f93\u6570\u636e"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#227","text":"\u6ce8\u610f\uff1a\u5f53\u4f60\u7684\u6a21\u578b\u6570\u636e\u4f20\u8f93\u5b8c\u6210\u540e\uff0c\u53ef\u4ee5\u5173\u95ed\u901a\u9053\u3002","title":"2.2.7 \u8fde\u63a5\u6210\u529f\u4e0a\u4f20\u6570\u636e\u5c55\u793a"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#23","text":"","title":"2.3 \u521b\u5efa\u9879\u76ee"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#231","text":"","title":"2.3.1 \u70b9\u51fb\u53f3\u4e0a\u89d2\u521b\u5efa\u9879\u76ee"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#232","text":"\u6ce8\u610f\uff1a\u521b\u5efa\u9879\u76ee\u540e\uff0c\u6570\u636e\u4f1a\u9ed8\u8ba4\u4fdd\u5b58\u7684\u8def\u5f84\u4e3a\uff1a/gemini/data1\u4e0b\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4f1a\u81ea\u52a8\u4fdd\u5b58\u5728/genmini/pretrain\u4e0b","title":"2.3.2 \u4f9d\u6b21\u914d\u7f6e\u9879\u76ee\u5185\u5bb9"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#233","text":"","title":"2.3.3 \u955c\u50cf\u73af\u5883\u9009\u62e9"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#234","text":"\u6ce8\u610f\uff1a\u4e0a\u4f20\u7684\u4ee3\u7801\u6587\u4ef6\uff0c\u9700\u8981\u8fdb\u884c\u538b\u7f29\u540e\u4e0a\u4f20","title":"2.3.4 \u521b\u5efa\u5b8c\u9879\u76ee\u540e\uff0c\u8981\u6c42\u4e0a\u4f20\u672c\u5730\u4ee3\u7801\uff08\u62d6\u62fd\u5f0f\uff09"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#235","text":"","title":"2.3.5 \u9879\u76ee\u521b\u5efa\u6210\u529f\u5c55\u793a"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#_4","text":"","title":"\u4e09\u3001\u8fd0\u884c\u670d\u52a1\u73af\u5883\u3001\u8bad\u7ec3\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#31","text":"","title":"3.1 \u521d\u59cb\u5316\u5f00\u53d1\u73af\u5883"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#311","text":"","title":"3.1.1 \u70b9\u51fb\u5f00\u53d1\u5de5\u5177\uff0c\u8fdb\u5165\u5f00\u53d1\u73af\u5883\u5b9e\u4f8b\u914d\u7f6e\u754c\u9762"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#312","text":"","title":"3.1.2 \u8fdb\u884c\u5f00\u53d1\u73af\u5883\u5b9e\u4f8b\u914d\u7f6e"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#313","text":"","title":"3.1.3 \u7b49\u5f85\u8d44\u6e90\u914d\u7f6e"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#314","text":"","title":"3.1.4  \u8d44\u6e90\u914d\u7f6e\u5b8c\u6210\uff0c\u7b49\u5f85\u8fdb\u5165\u5f00\u53d1\u73af\u5883"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#32","text":"","title":"3.2 \u914d\u7f6e\u5f00\u53d1\u73af\u5883"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#321","text":"","title":"3.2.1 \u8fdb\u5165\u5f00\u53d1\u73af\u5883"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#322","text":"","title":"3.2.2 \u5f00\u53d1\u73af\u5883\u5c55\u793a"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#323","text":"","title":"3.2.3 \u8fdb\u5165\u7f51\u9875\u7ec8\u7aef\u64cd\u4f5c"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#324","text":"","title":"3.2.4 \u67e5\u770b\u4ee3\u7801\u3001\u6570\u636e\u3001\u9884\u8bad\u7ec3\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#325","text":"\u9ed8\u8ba4\u5b89\u88c5\u7684\u6709pytorch=2.0.1\uff0c\u5e76\u4e14\u652f\u6301cuda \u5b89\u88c5\u5176\u4ed6\u7b2c\u4e09\u65b9\u5e93 pip install protobuf == 3.20.0 transformers == 4.27.1 icetk cpm_kernels pip install peft","title":"3.2.5 \u5b89\u88c5\u4f9d\u8d56\u5e93"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#33","text":"","title":"3.3 \u8bad\u7ec3\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#331","text":"\u56e0\u4e3a\u5728\u8d8b\u52a8\u4e91\u670d\u52a1\u4e0b\uff0c\u6570\u636e\u3001\u9884\u8bad\u7ec3\u6a21\u578b\u3001\u4ee3\u7801\u7684\u4f4d\u7f6e\u90fd\u53d1\u751f\u4e86\u6539\u53d8\uff0c\u6240\u4ee5\u8981\u6539\u53d8\u76f8\u5e94\u7684\u5f15\u7528\u6570\u636e\u4f4d\u7f6e config\u6587\u4ef6\u7c7b\u7684\u8def\u5f84\u4fee\u6539 \u8fd8\u9700\u8981\u5c06train.py\uff0cmodel=model.float()\u6539\u4e3amodel=model.half()\uff0c\u52a0\u5feb\u6a21\u578b\u8bad\u7ec3","title":"3.3.1 \u8def\u5f84\u4fee\u6539"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#332","text":"\u547d\u4ee4 python train . py \u6267\u884c\u7ed3\u679c \u8d44\u6e90\u76d1\u63a7 \u8017\u65f6 1h20min","title":"3.3.2 \u8bad\u7ec3\u811a\u672c"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#34","text":"\u6ce8\u610f\u4fee\u6539inference.py\u811a\u672c\u91cc\u6a21\u578b\u7684\u8def\u5f84 \u7ed3\u679c\u5c55\u793a","title":"3.4 \u6a21\u578b\u9884\u6d4b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#35","text":"","title":"3.5 \u6a21\u578b\u4e0b\u8f7d\u672c\u5730\u5b9e\u73b0\u9884\u6d4b"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#351-ssh","text":"\u8fdb\u5165 \u201c\u5e73\u53f0\u8bbe\u7f6e\u201d \u9875\u9762 \u767b\u5f55\u5e73\u53f0\u3002 \u4e0b\u62c9\u53f3\u4e0a\u89d2\u8d26\u6237\u5904\uff0c\u9009\u62e9 \u5e73\u53f0\u8bbe\u7f6e \u3002 \u70b9\u51fb\u5e73\u53f0\u8bbe\u7f6e \u5728 \u5e73\u53f0\u8bbe\u7f6e \u9875\u9762\u7684 SSH Key \u5904\uff0c\u60a8\u53ef\u7ba1\u7406 \u5bc6\u7801\u51ed\u8bc1 \u548c \u79d8\u94a5\u51ed\u8bc1 \uff08SSH Key\uff09\u3002 \u6ce8\u610f\uff1a\u9700\u8981\u81ea\u5df1\u8bbe\u5b9a\u7528\u6237\u540d\u548c\u5bc6\u7801\u3001ssh key\u81ea\u52a8\u751f\u6210\u5373\u53ef \u5728\u5177\u4f53\u9879\u76ee\u4e2d\u9009\u62e9 \u5f00\u53d1 \uff0c\u8fdb\u5165 \u5f00\u53d1\u73af\u5883\u5b9e\u4f8b \u9875 \u83b7\u53d6\u5f00\u53d1\u73af\u5883\u7684 ssh \u8fde\u63a5\u4e32\u7528\u4e8e\u8fde\u63a5\u5f00\u53d1\u73af\u5883\u3002 \u6ce8\u610f\uff1a\u5728\u4fee\u6539SSH\u914d\u7f6e\u4e2d\uff0c\u9009\u62e9\u5f00\u542f\uff0c\u7136\u540e\u518d\u542f\u52a8\u73af\u5883 \u6ce8\u610f\u53ea\u8981\u8fdb\u5165\u5f00\u53d1\u73af\u5883\uff0c\u5c31\u4f1a\u4ea7\u751f\u8d39\u7528\uff0c\u4e3a\u4e86\u8282\u7701\u8d44\u6e90\uff0c\u53ef\u4ee5\u5c06\u5b9e\u4f8b\u89c4\u683c\u8fdb\u884c\u51cf\u914d\uff0c\u8282\u7701\u7b97\u529b \u542f\u52a8\u73af\u5883\u540e\uff0c\u51fa\u73b0ssh\u8fde\u63a5\u4e32","title":"3.5.1 SSH\u914d\u7f6e"},{"location":"%E7%AC%AC%E4%B8%83%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EChatGLM%E5%BE%AE%E8%B0%83%E5%AE%9E%E7%8E%B0%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96%2B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AE%9E%E6%88%98/%E8%B6%8B%E5%8A%A8%E4%BA%91%E4%BD%BF%E7%94%A8%E3%80%8A%E8%A1%A5%E5%85%85%E3%80%8B.html#352","text":"\u590d\u5236ssh\u8fde\u63a5\u4e32\uff0c\u8fdb\u884c\u4fee\u6539 ssh - p 30022 itheima @root@ssh - 736 af97802ac911f1b7f454489821925 . swwutgwduthw @ssh . virtaicloud . com \u4e3b\u673a\u540d \uff1a ssh . virtaicloud . com \u7aef\u53e3\u53f7 \uff1a 30022 \u7528\u6237\u540d \uff1a itheima @root@ssh - 736 af97802ac911f1b7f454489821925 . swwutgwduthw @ \u83b7\u53d6\u6a21\u578b\u4fdd\u5b58\u8def\u5f84 / gemini / code / checkpoints / ptune / model_best \u5c06\u6a21\u578b\u4e0b\u8f7d\u5230\u672c\u5730\u684c\u9762 \u547d\u4ee4 scp - p 30022 - r itheima @root@ssh - 736 af97802ac911f1b7f454489821925 . swwutgwduthw @ssh . virtaicloud . com : / gemini / code / checkpoints / ptune / model_best ~/ Desktop","title":"3.5.2 \u7ec8\u7aef\u64cd\u4f5c\u8fde\u63a5\u4e91\u670d\u52a1"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html","text":"Prompt-Tuning\u65b9\u6cd5 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3LLM\u8fdb\u9636\u5386\u7a0b\u56db\u79cd\u8303\u5f0f. \u638c\u63e1Fine-Tuning\u6a21\u578b\u5fae\u8c03\u7684\u57fa\u672c\u539f\u7406 \u638c\u63e1Prompt_Tuning\u6a21\u578b\u5fae\u8c03\u7684\u57fa\u672c\u539f\u7406 1 NLP\u4efb\u52a1\u56db\u79cd\u8303\u5f0f \u00b6 \u76ee\u524d\u5b66\u672f\u754c\u4e00\u822c\u5c06NLP\u4efb\u52a1\u7684\u53d1\u5c55\u5206\u4e3a\u56db\u4e2a\u9636\u6bb5\uff0c\u5373NLP\u56db\u8303\u5f0f\uff1a \u7b2c\u4e00\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u300d\u7684\u8303\u5f0f\uff0c\u5982TF-IDF\u7279\u5f81+\u6734\u7d20\u8d1d\u53f6\u65af\u7b49\u673a\u5668\u7b97\u6cd5\uff1b \u7b2c\u4e8c\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u300d\u7684\u8303\u5f0f\uff0c\u5982word2vec\u7279\u5f81+LSTM\u7b49\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4e8e\u7b2c\u4e00\u8303\u5f0f\uff0c\u6a21\u578b\u51c6\u786e\u6709\u6240\u63d0\u9ad8\uff0c\u7279\u5f81\u5de5\u7a0b\u7684\u5de5\u4f5c\u4e5f\u6709\u6240\u51cf\u5c11\uff1b \u7b2c\u4e09\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u9884\u8bad\u7ec3\u6a21\u578b+fine-tuning\u300d\u7684\u8303\u5f0f\uff0c\u5982Bert+fine-tuning\u7684NLP\u4efb\u52a1\uff0c\u76f8\u6bd4\u4e8e\u7b2c\u4e8c\u8303\u5f0f\uff0c\u6a21\u578b\u51c6\u786e\u5ea6\u663e\u8457\u63d0\u9ad8\uff0c\u6a21\u578b\u4e5f\u968f\u4e4b\u53d8\u5f97\u66f4\u5927\uff0c\u4f46\u5c0f\u6570\u636e\u96c6\u5c31\u53ef\u8bad\u7ec3\u51fa\u597d\u6a21\u578b\uff1b \u7b2c\u56db\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u9884\u8bad\u7ec3\u6a21\u578b+Prompt+\u9884\u6d4b\u300d\u7684\u8303\u5f0f\uff0c\u5982Bert+Prompt\u7684\u8303\u5f0f\u76f8\u6bd4\u4e8e\u7b2c\u4e09\u8303\u5f0f\uff0c\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u7684\u8bad\u7ec3\u6570\u636e\u663e\u8457\u51cf\u5c11\u3002 \u5728\u6574\u4e2aNLP\u9886\u57df\uff0c\u6574\u4e2a\u53d1\u5c55\u5386\u7a0b\u662f\u671d\u7740\u7cbe\u5ea6\u66f4\u9ad8\u3001\u5c11\u76d1\u7763\uff0c\u751a\u81f3\u65e0\u76d1\u7763\u7684\u65b9\u5411\u53d1\u5c55\u7684\u3002\u800c Prompt-Tuning\u662f\u76ee\u524d\u5b66\u672f\u754c\u5411\u8fd9\u4e2a\u65b9\u5411\u8fdb\u519b\u6700\u65b0\u4e5f\u662f\u6700\u706b\u7684\u7814\u7a76\u6210\u679c\u3002 2 Fine-Tuning(\u5fae\u8c03) \u00b6 Fine-Tuning\u5c5e\u4e8e\u4e00\u79cd\u8fc1\u79fb\u5b66\u4e60\u65b9\u5f0f\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4e2d\uff0cFine-Tuning\u662f\u7528\u4e8e\u5c06\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u4e8e\u7279\u5b9a\u4efb\u52a1\u6216\u9886\u57df\u3002Fine-Tuning\u7684\u57fa\u672c\u601d\u60f3\u662f\u91c7\u7528\u5df2\u7ecf\u5728\u5927\u91cf\u6587\u672c\u4e0a\u8fdb\u884c\u8bad\u7ec3\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u7136\u540e\u5728\u5c0f\u89c4\u6a21\u7684\u4efb\u52a1\u7279\u5b9a\u6587\u672c\u4e0a\u7ee7\u7eed\u8bad\u7ec3\u5b83. \u7ecf\u5178\u7684Fine-Tuning\u65b9\u6cd5\u5305\u62ec\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u4e0e\u5c11\u91cf\u7279\u5b9a\u4efb\u52a1\u6570\u636e\u4e00\u8d77\u7ee7\u7eed\u8bad\u7ec3\u3002\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6743\u91cd\u88ab\u66f4\u65b0\uff0c\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u4efb\u52a1\u3002\u6240\u9700\u7684Fine-Tuning\u91cf\u53d6\u51b3\u4e8e\u9884\u8bad\u7ec3\u8bed\u6599\u5e93\u548c\u4efb\u52a1\u7279\u5b9a\u8bed\u6599\u5e93\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002\u5982\u679c\u4e24\u8005\u76f8\u4f3c\uff0c\u53ef\u80fd\u53ea\u9700\u8981\u5c11\u91cf\u7684Fine-Tuning\uff0c\u5982\u679c\u4e24\u8005\u4e0d\u76f8\u4f3c\uff0c\u5219\u53ef\u80fd\u9700\u8981\u66f4\u591a\u7684Fine-Tuning. \u4f46\u662f\uff0c\u5728\u5927\u591a\u6570\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u65f6\uff0c\u4e0b\u6e38\u4efb\u52a1\u7684\u76ee\u6807\u548c\u9884\u8bad\u7ec3\u7684\u76ee\u6807\u5dee\u8ddd\u8fc7\u5927\u5bfc\u81f4\u63d0\u5347\u6548\u679c\u4e0d\u660e\u663e\uff08\u8fc7\u62df\u5408\uff09\uff0c\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u9700\u8981\u4f9d\u8d56\u5927\u91cf\u7684\u76d1\u7763\u8bed\u6599\u7b49\u7b49\u3002\u81f3\u6b64\uff0c\u4ee5GPT3\u3001PET\u7b49\u4e3a\u9996\u7684\u6a21\u578b\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u7684\u5fae\u8c03\u8303\u5f0f--Prompt-Tuning.\u8be5\u65b9\u6cd5\u7684\u76ee\u7684\u662f\u901a\u8fc7\u6dfb\u52a0\u6a21\u677f\u7684\u65b9\u6cd5\u6765\u907f\u514d\u5f15\u5165\u989d\u5916\u7684\u53c2\u6570\uff0c\u4ece\u800c\u8ba9\u6a21\u578b\u53ef\u4ee5\u5728\u5c0f\u6837\u672c\uff08few-shot\uff09\u6216\u8005\u96f6\u6837\u672c\uff08zero-shot\uff09\u573a\u666f\u4e0b\u8fbe\u5230\u7406\u60f3\u7684\u6548\u679c\u3002 Prompt-Tuning\u4e3b\u8981\u89e3\u51b3\u4f20\u7edfFine-Tuning\u65b9\u5f0f\u7684\u4e24\u4e2a\u75db\u70b9\uff1a \u964d\u4f4e\u8bed\u4e49\u504f\u5dee\uff1a\u9884\u8bad\u7ec3\u4efb\u52a1\u4e3b\u8981\u4ee5MLM\u4e3a\u4e3b\uff0c\u800c\u4e0b\u6e38\u4efb\u52a1\u5219\u91cd\u65b0\u5f15\u5165\u65b0\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u56e0\u6b64\u4e24\u4e2a\u9636\u6bb5\u76ee\u6807\u5dee\u5f02\u8f83\u5927\u3002\u56e0\u6b64\u9700\u8981\u89e3\u51b3Pre-Training\u548cFine-Tuning\u4e4b\u95f4\u7684Gap\u3002 \u907f\u514d\u8fc7\u62df\u5408\uff1a\u7531\u4e8eFine-Tuning\u9636\u6bb5\u9700\u8981\u5f15\u5165\u65b0\u7684\u53c2\u6570\u9002\u914d\u76f8\u5e94\u4efb\u52a1\uff0c\u56e0\u6b64\u5728\u6837\u672c\u6570\u91cf\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5bb9\u6613\u53d1\u751f\u8fc7\u62df\u5408\uff0c\u964d\u4f4e\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8fc7\u62df\u5408\u80fd\u529b\u3002 3 Prompt-Tuning(\u63d0\u793a\u5fae\u8c03) \u00b6 3.1 \u4ec0\u4e48\u662fPrompt? \u00b6 prompt\u987e\u540d\u601d\u4e49\u5c31\u662f\u201c\u63d0\u793a\u201d\u7684\u610f\u601d\uff0c\u5e94\u8be5\u6709\u4eba\u73a9\u8fc7\u4f60\u753b\u6211\u731c\u8fd9\u4e2a\u6e38\u620f\u5427\uff0c\u5bf9\u65b9\u6839\u636e\u4e00\u4e2a\u8bcd\u8bed\u753b\u4e00\u5e45\u753b\uff0c\u6211\u4eec\u6765\u731c\u4ed6\u753b\u7684\u662f\u4ec0\u4e48\uff0c\u56e0\u4e3a\u6709\u592a\u591a\u7075\u9b42\u753b\u624b\u4e86\uff0c\u753b\u98ce\u6e05\u5947\uff0c\u6216\u8005\u4f60\u4eec\u6ca1\u6709\u5fc3\u6709\u7075\u7280\uff0c\u6839\u672c\u5c31\u4e0d\u597d\u731c\u554a\uff01\u8fd9\u65f6\u5019\u5c4f\u5e55\u4e0a\u4f1a\u51fa\u73b0\u4e00\u4e9b\u63d0\u793a\u8bcd\u6bd4\u59823\u4e2a\u5b57\uff0c\u6c34\u679c\uff0c\u90a3\u5c82\u4e0d\u662f\u597d\u731c\u4e00\u70b9\u4e86\u561b\uff0c\u6bd5\u7adf3\u4e2a\u5b57\u7684\u6c34\u679c\u4e5f\u4e0d\u591a\u5440\u3002\u770b\u5230\u4e86\u5427\uff0c\u8fd9\u5c31\u662fprompt\u7684\u9b45\u529b. 3.2 Prompt-Tuing\u5b9a\u4e49 \u00b6 \u57fa\u4e8eFine-Tuning\u7684\u65b9\u6cd5\u662f\u8ba9\u9884\u8bad\u7ec3\u6a21\u578b\u53bb\u8fc1\u5c31\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u57fa\u4e8ePrompt-Tuning\u7684\u65b9\u6cd5\u53ef\u4ee5\u8ba9\u4e0b\u6e38\u4efb\u52a1\u53bb\u8fc1\u5c31\u9884\u8bad\u7ec3\u6a21\u578b, \u5176\u76ee\u7684\u662f\u5c06Fine-tuning\u7684\u4e0b\u6e38\u4efb\u52a1\u76ee\u6807\u8f6c\u6362\u4e3aPre-training\u7684\u4efb\u52a1\u3002\u90a3\u4e48\u5177\u4f53\u5982\u4f55\u5de5\u4f5c\u5462\uff1f\u6211\u4eec\u4ee5\u4e00\u4e2a\u4e8c\u5206\u7c7b\u7684\u60c5\u611f\u5206\u6790\u4e3a\u4f8b\u5b50\uff0c\u8fdb\u884c\u7b80\u5355\u7406\u89e3\uff1a eg: \u5b9a\u4e00\u4e2a\u53e5\u5b50 [CLS] I like the Disney films very much. [SEP] \u4f20\u7edf\u7684Fine-tuning\u65b9\u6cd5: \u5c06\u5176\u901a\u8fc7BERT\u7684Transformer\u83b7\u5f97 [CLS] \u8868\u5f81\u4e4b\u540e\u518d\u5582\u5165\u65b0\u589e\u52a0\u7684MLP\u5206\u7c7b\u5668\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u9884\u6d4b\u8be5\u53e5\u5b50\u662f\u79ef\u6781\u7684\uff08positive\uff09\u8fd8\u662f\u6d88\u6781\u7684\uff08negative\uff09\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u5b9a\u91cf\u7684\u8bad\u7ec3\u6570\u636e\u6765\u8bad\u7ec3\u3002 Prompt-Tuning\u6267\u884c\u6b65\u9aa4\uff1a 1.\u6784\u5efa\u6a21\u677f\uff08Template Construction\uff09: \u901a\u8fc7\u4eba\u5de5\u5b9a\u4e49\u3001\u81ea\u52a8\u641c\u7d22\u3001\u6587\u672c\u751f\u6210\u7b49\u65b9\u6cd5\uff0c\u751f\u6210\u4e0e\u7ed9\u5b9a\u53e5\u5b50\u76f8\u5173\u7684\u4e00\u4e2a\u542b\u6709 [MASK] \u6807\u8bb0\u7684\u6a21\u677f\u3002\u4f8b\u5982 It was [MASK]. \uff0c\u5e76\u62fc\u63a5\u5230\u539f\u59cb\u7684\u6587\u672c\u4e2d\uff0c\u83b7\u5f97Prompt-Tuning\u7684\u8f93\u5165\uff1a [CLS] I like the Disney films very much. [SEP] It was [MASK]. [SEP] \u3002\u5c06\u5176\u5582\u5165BERT\u6a21\u578b\u4e2d\uff0c\u5e76\u590d\u7528\u9884\u8bad\u7ec3\u597d\u7684MLM\u5206\u7c7b\u5668\uff08\u5728huggingface\u4e2d\u4e3aBertForMaskedLM\uff09\uff0c\u5373\u53ef\u76f4\u63a5\u5f97\u5230 [MASK] \u9884\u6d4b\u7684\u5404\u4e2atoken\u7684\u6982\u7387\u5206\u5e03\u3002 2.\u6807\u7b7e\u8bcd\u6620\u5c04\uff08Label Word Verbalizer\uff09 \uff1a\u56e0\u4e3a [MASK] \u90e8\u5206\u6211\u4eec\u53ea\u5bf9\u90e8\u5206\u8bcd\u611f\u5174\u8da3\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6620\u5c04\u5173\u7cfb\u3002\u4f8b\u5982\u5982\u679c [MASK] \u9884\u6d4b\u7684\u8bcd\u662f\u201cgreat\u201d\uff0c\u5219\u8ba4\u4e3a\u662fpositive\u7c7b\uff0c\u5982\u679c\u662f\u201cterrible\u201d\uff0c\u5219\u8ba4\u4e3a\u662fnegative\u7c7b\u3002 3.\u8bad\u7ec3\uff1a\u6839\u636eVerbalizer\uff0c\u5219\u53ef\u4ee5\u83b7\u5f97\u6307\u5b9alabel word\u7684\u9884\u6d4b\u6982\u7387\u5206\u5e03\uff0c\u5e76\u91c7\u7528\u4ea4\u53c9\u4fe1\u606f\u71b5\u8fdb\u884c\u8bad\u7ec3\u3002\u6b64\u65f6\u56e0\u4e3a\u53ea\u5bf9\u9884\u8bad\u7ec3\u597d\u7684MLM head\u8fdb\u884c\u5fae\u8c03\uff0c\u6240\u4ee5\u907f\u514d\u4e86\u8fc7\u62df\u5408\u95ee\u9898\u3002 \u6ce8\u610f\u601d\u8003\uff1a\u4e0d\u540c\u7684\u53e5\u5b50\u5e94\u8be5\u6709\u4e0d\u540c\u7684template\u548clabel word\uff0c\u6ca1\u9519\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u53e5\u5b50\u53ef\u80fd\u671f\u671b\u9884\u6d4b\u51fa\u6765\u7684label word\u90fd\u4e0d\u540c\uff0c\u56e0\u6b64\u5982\u4f55\u6700\u5927\u5316\u7684\u5bfb\u627e\u5f53\u524d\u4efb\u52a1\u66f4\u52a0\u5408\u9002\u7684template\u548clabel word\u662fPrompt-tuning\u975e\u5e38\u91cd\u8981\u7684\u6311\u6218\u3002 \u5176\u5b9e\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\uff0c\u5f15\u5165\u7684\u6a21\u677f\u548c\u6807\u7b7e\u8bcd\u672c\u8d28\u4e0a\u5c5e\u4e8e\u4e00\u79cd\u6570\u636e\u589e\u5f3a\uff0c\u901a\u8fc7\u6dfb\u52a0\u63d0\u793a\u7684\u65b9\u5f0f\u5f15\u5165\u5148\u9a8c\u77e5\u8bc6\u3002 4 Prompt-Tuning\u6280\u672f\u53d1\u5c55\u5386\u7a0b \u00b6 Prompt-Tuning\u81eaGPT-3\u88ab\u63d0\u51fa\u4ee5\u6765\uff0c\u4ece\u4f20\u7edf\u7684\u79bb\u6563\u3001\u8fde\u7eed\u7684Prompt\u6784\u5efa\u3001\u8d70\u5411\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684In-Context Learning\u3001Instruction-tuning\u548cChain_of_Thought. 5 Prompt-Tuning\u7684\u4e3b\u8981\u65b9\u6cd5 \u00b6 Prompt-Tuning\u5177\u4f53\u5982\u4f55\u5b9e\u73b0\uff0c\u5176\u6709\u4ec0\u4e48\u56f0\u96be\u548c\u6311\u6218\uff1f\u8fd9\u91cc\u6211\u4eec\u6311\u9009\u4e00\u4e9b\u5177\u6709\u4ee3\u8868\u6027\u7684. 5.1 Prompt-Tuning\u7684\u9f3b\u7956----GPT3\u548cPET \u00b6 Prompt-Tuning\u6700\u65e9\u662f\u5728GPT-3\u300aLanguage Models are Few-Shot Learners\u300b\u4e2d\u88ab\u63d0\u51fa\u6765\u7684\u3002\u5176\u5f00\u521b\u6027\u7684\u63d0\u51fa\u4e86In-context Learning\uff08ICL, \u60c5\u666f\u5b66\u4e60\uff09\u7684\u601d\u60f3\u3002\u5373\u65e0\u987b\u4fee\u6539\u6a21\u578b\u5373\u53ef\u5b9e\u73b0few-shot\u3001zero-shot\u7684learning\u3002\u540c\u65f6\u5f15\u5165\u4e86Demonstrate Learning, \u5373\u8ba9\u6a21\u578b\u77e5\u9053\u4e0e\u6807\u7b7e\u76f8\u4f3c\u7684\u8bed\u4e49\u63cf\u8ff0\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b. In-context Learning: Prompt\u524d\u8eab\uff0c\u901a\u8fc7\u4ece\u8bad\u7ec3\u96c6\u6311\u9009\u4e00\u4e9b\u6837\u672c\u4f5c\u4e3a\u4efb\u52a1\u7684\u63d0\u793a\uff0c\u6765\u5b9e\u73b0\u514d\u53c2\u6570\u66f4\u65b0\u7684\u6a21\u578b\u9884\u6d4b\u3002 Demonstration Learning\uff1a\u6dfb\u52a0\u4e00\u4e9b\u65b0\u7684\u6837\u672c\u4f5c\u4e3a\u63d0\u793a\u3002\u6a21\u578b\u53ef\u4ee5\u6839\u636e\u65b0\u6dfb\u52a0\u7684\u6837\u4f8b\u53e5\u5b50\u5c31\u53ef\u4ee5\"\u7167\u732b\u753b\u864e\"\u5f0f\u7684\u9884\u6d4b\u7ed3\u679c\u4e86. \u5e38\u7528\u7684In-context learning\u65b9\u6cd5\u5305\u62ec\uff1a zero-shot learning \u5b9a\u4e49: \u7ed9\u51fa\u4efb\u52a1\u7684\u63cf\u8ff0, \u7136\u540e\u63d0\u4f9b\u6d4b\u8bd5\u6570\u636e\u5bf9\u5176\u8fdb\u884c\u9884\u6d4b, \u76f4\u63a5\u8ba9\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53bb\u8fdb\u884c\u4efb\u52a1\u6d4b\u8bd5. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. one-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u4e00\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u4e00\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u82f1\u8bed\u7ffb\u8bd1\u4e3a\u6cd5\u8bed, \u5e94\u8be5\u8fd9\u4e48\u7ffb\u8bd1. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. few-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u591a\u4e2a\u6837\u672c\uff08\u4e00\u822c10-100\u6761\uff09\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u591a\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u5e94\u8be5\u5982\u4f55\u5de5\u4f5c. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u518d\u89c1->goodbye, \u8d2d\u4e70->purchase, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. \u4f46\u662f\u8fd9\u7c7b\u65b9\u6cd5\u6709\u4e00\u4e2a\u660e\u663e\u7684\u7f3a\u9677\u662f\u2014\u2014\u5176\u5efa\u7acb\u5728\u8d85\u5927\u89c4\u6a21\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u6b64\u65f6\u7684\u6a21\u578b\u53c2\u6570\u6570\u91cf\u901a\u5e38\u8d85\u8fc7100\u4ebf\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u5f88\u96be\u5e94\u7528\uff0c\u56e0\u6b64\u4f17\u591a\u7814\u7a76\u8005\u5f00\u59cb\u63a2\u7d22GPT-3\u7684\u8fd9\u5957\u601d\u8def\u5728\u5c0f\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\uff08\u5982Bert\uff09\u4e0a\u8fd8\u662f\u5426\u9002\u7528\uff1f\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u5957\u65b9\u6cd5\u5728\u5c0f\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u4f46\u662f\u9700\u8981\u6ce8\u610f\uff1a \u6a21\u578b\u53c2\u6570\u89c4\u6a21\u5c0f\u4e86\uff0cprompt\u76f4\u63a5\u7528\u5728zero-shot\u4e0a\u6548\u679c\u4f1a\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u8003\u8651\u5c06In-context Learning\u548cDemonstrate Learning\u5e94\u7528\u5728Fine-Tuning\u9636\u6bb5\uff0c\u4e5f\u5c31\u662f\u540e\u9762\u8981\u8bb2\u5230\u7684Prompt-Tuning\u3002 GPT-3\u4e2d\u63d0\u4f9b\u7684\u63d0\u793a\uff08Natural Language Prompt\uff09\u8fc7\u4e8e\u7b80\u5355\uff0c\u6cdb\u5316\u6027\u80fd\u4f4e\u3002 \u56e0\u6b64\uff0cPET\u6a21\u578b\u95ee\u4e16. 5.2 PET\u6a21\u578b \u00b6 PET\uff08Pattern-Exploiting Training\uff09\u51fa\u81ea\u300aExploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference\u300b\uff08EACL2021\uff09\uff0c\u6839\u636e\u8bba\u6587\u9898\u76ee\u5219\u53ef\u4ee5\u731c\u51fa\uff0cPrompt-Tuning\u542f\u53d1\u4e8e\u6587\u672c\u5206\u7c7b\u4efb\u52a1\uff0c\u5e76\u4e14\u8bd5\u56fe\u5c06\u6240\u6709\u7684\u5206\u7c7b\u4efb\u52a1\u8f6c\u6362\u4e3a\u4e0eMLM\u4e00\u81f4\u7684\u5b8c\u5f62\u586b\u7a7a\u3002 PET\u6a21\u578b\u63d0\u51fa\u4e24\u4e2a\u5f88\u91cd\u8981\u7684\u7ec4\u4ef6\uff1a Pattern\uff08Template\uff09 \uff1a\u8bb0\u4f5cT, \u5373\u4e0a\u6587\u63d0\u5230\u7684Template\uff0c\u5176\u4e3a\u989d\u5916\u6dfb\u52a0\u7684\u5e26\u6709 [mask] \u6807\u8bb0\u7684\u77ed\u6587\u672c\uff0c\u901a\u5e38\u4e00\u4e2a\u6837\u672c\u53ea\u6709\u4e00\u4e2aPattern\uff08\u56e0\u4e3a\u6211\u4eec\u5e0c\u671b\u53ea\u67091\u4e2a\u8ba9\u6a21\u578b\u9884\u6d4b\u7684 [mask] \u6807\u8bb0\uff09\u3002\u7531\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1\u3001\u4e0d\u540c\u7684\u6837\u672c\u53ef\u80fd\u4f1a\u6709\u5176\u66f4\u52a0\u5408\u9002\u7684pattern\uff0c \u56e0\u6b64\u5982\u4f55\u6784\u5efa\u5408\u9002\u7684pattern\u662fPrompt-Tuning\u7684\u7814\u7a76\u70b9\u4e4b\u4e00 \uff1b Verbalizer \uff1a\u8bb0\u4f5cV, \u5373\u6807\u7b7e\u8bcd\u7684\u6620\u5c04\uff0c\u5bf9\u4e8e\u5177\u4f53\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u9700\u8981\u9009\u62e9\u6307\u5b9a\u7684\u6807\u7b7e\u8bcd\uff08label word\uff09\u3002\u4f8b\u5982\u60c5\u611f\u5206\u6790\u4e2d\uff0c\u6211\u4eec\u671f\u671bVerbalizer\u53ef\u80fd\u662f \uff08positive\u548cnegative\u662f\u7c7b\u6807\u7b7e\uff09\u3002\u540c\u6837\uff0c\u4e0d\u540c\u7684\u4efb\u52a1\u6709\u5176\u76f8\u5e94\u7684label word\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cVerbalizer\u7684\u6784\u5efa\u9700\u8981\u53d6\u51b3\u4e8e\u5bf9\u5e94\u7684Pattern\u3002\u56e0\u6b64 \u5982\u4f55\u6784\u5efaVerbalizer\u662f\u53e6\u4e00\u4e2a\u7814\u7a76\u6311\u6218 \u3002 \u4e0a\u8ff0\u4e24\u4e2a\u7ec4\u4ef6\u88ab\u79f0\u4e3aPattern-Verbalizer-Pair\uff08PVP\uff09\uff0c\u5728\u540e\u7eed\u7684\u5927\u591a\u6570\u7814\u7a76\u4e2d\u5747\u91c7\u7528\u8fd9\u79cdPVP\u7ec4\u4ef6\u3002\u57fa\u4e8ePVP\u7684\u8bad\u7ec3\u76ee\u6807\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u4e0b\u9762\u5f62\u5f0f\uff1a \u7ed9\u5b9a\u4e00\u4e2a\u53e5\u5b50\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u7ed9\u5b9a\u5b9a\u4e49\u7684PVP\u7ec4\u4ef6\uff0c\u5219\u6709 \u76ee\u524d\u57fa\u4e8ePVP\u6846\u67b6\uff0c\u5f53\u524d\u6700\u9700\u8981\u5173\u6ce8\u7684\u95ee\u9898\u662f\u5982\u4f55\u9009\u62e9\u6216\u6784\u5efa\u5408\u9002\u7684Pattern\u548cVerbalizer \u3002\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u6839\u636e\u7279\u5b9a\u4efb\u52a1\u7684\u6027\u8d28\u548c\u5148\u9a8c\u77e5\u8bc6\u4eba\u5de5\u8bbe\u8ba1\u6a21\u677f\u3002\u4f8b\u5982\u4e0a\u6587\u4f8b\u5b50\u4e2d\u901a\u5e38\u4f1a\u9009\u62e9 It was [mask]. \u4f5c\u4e3a\u60c5\u611f\u5206\u6790\u7c7b\u7684\u6a21\u677f\u3002\u4eba\u5de5\u6784\u5efa\u65b9\u6cd5\u867d\u7136\u76f4\u89c2\u7b80\u5355\uff0c\u4f46\u662f\u81f4\u547d\u95ee\u9898\u4e5f\u5f88\u7a81\u51fa\u3002\u6709\u76f8\u5173\u5de5\u4f5c\u5728\u5b9e\u9a8c\u4e2d\u53d1\u73b0\uff0c\u5728\u540c\u6837\u7684\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6761\u4ef6\u4e0b\uff0c \u9009\u62e9\u4e0d\u540c\u7684Pattern\u548cVerbalizer\u4f1a\u4ea7\u751f\u5dee\u5f02\u5f88\u5927\u7684\u7ed3\u679c \uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0cTemplate\u7b49\u540c\u4e8ePattern\uff0cVerbalizer\u7b49\u540c\u4e8eLabel word\uff09\uff1a \u4ece\u4e0a\u56fe\u7ed3\u679c\u53ef\u53d1\u73b0\uff0c\u5728\u76f8\u540cPattern\u65f6\uff0c\u9009\u62e9\u4e0d\u540c\u7684label word\u5bf9\u7ed3\u679c\u5f71\u54cd\u5f88\u5927\uff0c\u540c\u7406\uff0c\u4e0d\u540c\u7684Pattern\u5bf9\u7ed3\u679c\u5f71\u54cd\u4e5f\u5f88\u660e\u663e\uff0c\u5728\u771f\u6b63\u5e94\u7528\u4e2d\uff0c\u8c03\u53c2\u8005\u9700\u8981\u5c1d\u8bd5\u591a\u4e2a\u4e0d\u540c\u7684\u6a21\u677f\u548c\u6807\u7b7e\u8bcd\u4ee5\u7a77\u4e3e\u51fa\u6700\u597d\u7684\u7ed3\u679c\uff0c\u5e76\u4e0d\u80fd\u5145\u5206\u53d1\u6325Prompt\u7b80\u5355\u5feb\u6377\u7684\u4f18\u52bf\u3002\u56e0\u6b64\u6211\u4eec\u603b\u7ed3\u4eba\u5de5\u8bbe\u8ba1\u65b9\u6cd5\u7684\u7f3a\u9677\uff1a \u91c7\u7528\u4eba\u5de5\u6784\u5efa\u7684\u65b9\u6cd5\u6210\u672c\u9ad8\uff0c\u9700\u8981\u4e0e\u9886\u57df\u4efb\u52a1\u76f8\u5173\u7684\u5148\u9a8c\u77e5\u8bc6\uff1b \u4eba\u5de5\u8bbe\u8ba1\u7684Pattern\u548cVerbalizer\u4e0d\u80fd\u4fdd\u8bc1\u83b7\u5f97\u6700\u4f18\u89e3\uff0c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u4e0d\u540c\u7684PVP\u5bf9\u7ed3\u679c\u4ea7\u751f\u7684\u5dee\u5f02\u660e\u663e\uff0c\u65b9\u5dee\u5927\uff1b \u5728\u9884\u8bad\u7ec3\u9636\u6bb5MLM\u4efb\u52a1\u5e76\u975e\u5b8c\u5168\u6309\u7167PVP\u7684\u6a21\u5f0f\u8fdb\u884c\u8bad\u7ec3\u7684\uff08\u6bd4\u5982MLM\u8bad\u7ec3\u901a\u5e38\u90fd\u662f\u957f\u6587\u672c\uff0cmask\u7684\u6570\u91cf\u4e5f\u5e76\u975e\u53ea\u67091\u4e2a\uff0c\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\u4e5f\u5e76\u975e\u662f\u6709\u9650\u7684\uff09\uff0c\u56e0\u6b64\u4eba\u5de5\u6784\u5efa\u7684Pattern\u548cVerbalizer\u4f7f\u5f97Prompt-Tuning\u4e0eMLM\u5728\u8bed\u4e49\u548c\u5206\u5e03\u4e0a\u4f9d\u7136\u5b58\u5728\u5dee\u5f02\u3002 \u56e0\u6b64\u5982\u4f55\u80fd\u591f\u81ea\u52a8\u5730\u6311\u9009\u5408\u9002\u7684PVP? \u76ee\u524d\u6784\u5efaVerbalizer\u7684\u65b9\u6cd5\u4e5f\u6709\u5f88\u591a\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u4e0d\u8fdb\u884c\u8be6\u7ec6\u89e3\u91ca\uff0c\u6211\u4eec\u4e3b\u8981\u7740\u91cd\u4ecb\u7ecd\u6784\u5efaPattern\u7684\u65b9\u6cd5\uff1a Prompt-Tuning .\u63a5\u4e0b\u6765\u6211\u4eec\u6839\u636e\u4f7f\u7528\u573a\u666f\u7684\u4e0d\u540c\uff0c\u5206\u522b\u4ecb\u7ecd\u51e0\u79cd\u6210\u719f\u7684Prompt-Tuning\u65b9\u6cd5. 5.3 Prompt-Oriented Fine-Tuning \u00b6 Prompt-Oriented Fine-Tuning\u8bad\u7ec3\u65b9\u6cd5\u7684\u672c\u8d28\u662f\u5c06\u76ee\u6807\u4efb\u52a1\u8f6c\u6362\u4e3a\u9002\u5e94\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u4ee5\u9002\u5e94\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5b66\u4e60\u4f53\u7cfb\u3002 \u4f8b\u5982\u6211\u4eec\u5229\u7528BERT\u6a21\u578b\u6765\u5b9e\u73b0\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\uff1a \u4f20\u7edfFine-Tuning\u65b9\u5f0f: \u5c06\u8bad\u7ec3\u6587\u672c\u7ecf\u8fc7BERT\u7f16\u7801\u540e\uff0c\u751f\u6210\u5411\u91cf\u8868\u5f81\uff0c\u518d\u5229\u7528\u8be5\u5411\u91cf\u8868\u5f81\uff0c\u8fde\u63a5\u5168\u8fde\u63a5\u5c42\uff0c\u5b9e\u73b0\u6700\u7ec8\u7684\u60c5\u611f\u7c7b\u522b\u8bc6\u522b\u3002\u4f46\u662f\u8fd9\u79cd\u65b9\u5f0f\u5b58\u5728\u4e00\u4e2a\u663e\u5f0f\u7684\u5f0a\u7aef\uff1a\u9884\u8bad\u7ec3\u4efb\u52a1\u4e0e\u4e0b\u6e38\u4efb\u52a1\u5b58\u5728gap\u3002\u56de\u5fc6BERT\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\uff1aMLM\u4e0eNSP\uff0c\u7b80\u5355\u6765\u8bf4\uff0cMLM\u4efb\u52a1\u662f\u901a\u8fc7\u5206\u7c7b\u6a21\u578b\u8bc6\u522b\u88abMASK\u6389\u7684\u8bcd\uff0c\u7c7b\u522b\u5927\u5c0f\u5373\u4e3a\u6574\u4e2a\u8bcd\u8868\u5927\u5c0f\uff1bNSP\u4efb\u52a1\u662f\u9884\u6d4b\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u800cPrompt-Oriented Fine-Tuning\u65b9\u5f0f: \u5c06\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u8f6c\u6362\u4e3a\u7c7b\u4f3c\u4e8eMLM\u4efb\u52a1\u7684[MASK]\u9884\u6d4b\u4efb\u52a1\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u6784\u5efa\u5982\u4e0b\u7684prompt\u6587\u672c: prompt = It was [MASK]. \u5c06prompt\u6587\u672c\u4e0e\u8f93\u5165\u6587\u672ctext = The film is attractive.\u8fdb\u884c\u62fc\u63a5\u751f\u6210: It was [MASK].The film is attractive.\uff0c\u8f93\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\uff0c\u8bad\u7ec3\u4efb\u52a1\u76ee\u6807\u548cMLM\u4efb\u52a1\u7684\u76ee\u6807\u4e00\u81f4\uff0c\u5373\u8bc6\u522b\u88ab[MASK]\u6389\u7684\u8bcd\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u53ef\u4ee5\u5c06\u4e0b\u6e38\u4efb\u52a1\u8f6c\u6362\u4e3a\u548c\u9884\u8bad\u7ec3\u4efb\u52a1\u8f83\u4e3a\u4e00\u81f4\u7684\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0cPrompt-Oriented Fine-Tuning\u76f8\u5bf9\u4e8e\u5e38\u89c4\u7684Fine-Tuning\uff0c\u6548\u679c\u4f1a\u5f97\u5230\u660e\u663e\u63d0\u5347\uff08Prompt\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\uff09\u3002 \u57fa\u4e8e\u4e0a\u8ff0\u5185\u5bb9\u53ef\u4ee5\u4e86\u89e3\uff0c\u5728Prompt-Oriented Fine-Tuning\u65b9\u6cd5\u4e2d\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u662f\u53ef\u53d8\u7684\u3002\u5176\u5b9e\u5c06Prompt-Oriented Fine-Tuning\u65b9\u6cd5\u653e\u5728Prompt-Tuning\u8fd9\u4e2a\u90e8\u5206\u5408\u7406\u4e5f\u4e0d\u5408\u7406\uff0c\u56e0\u4e3a\u5b83\u5176\u5b9e\u662fPrompt-Tuning+Fine-Tuning\u7684\u7ed3\u5408\u4f53\uff0c\u5c06\u5b83\u89c6\u4e3aFine-Tuning\u7684\u5347\u7ea7\u7248\u662f\u6700\u5408\u9002\u7684\u3002 Prompt-Oriented Fine-Tuning\u65b9\u6cd5\u5728BERT\u7c7b\u76f8\u5bf9\u8f83\u5c0f\u7684\u6a21\u578b\u4e0a\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u662f\u968f\u7740\u6a21\u578b\u8d8a\u6765\u8d8a\u5927\uff0c\u5982\u679c\u6bcf\u6b21\u9488\u5bf9\u4e0b\u6e38\u4efb\u52a1\uff0c\u90fd\u9700\u8981\u66f4\u65b0\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\uff0c\u8d44\u6e90\u6210\u672c\u53ca\u65f6\u95f4\u6210\u672c\u90fd\u4f1a\u5f88\u9ad8\uff0c\u56e0\u6b64\u540e\u7eed\u9646\u7eed\u63d0\u51fa\u4e86\u4e0d\u66f4\u65b0\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\uff0c\u5355\u7eaf\u53ea\u9488\u5bf9prompt\u8fdb\u884c\u8c03\u4f18\u7684\u65b9\u6cd5\uff0c\u4f8b\u5982**Hard Prompt**\u548c**Soft Prompt**\u3002 \u4e0b\u9762\u662f\u5e38\u89c1\u4e0b\u6e38\u4efb\u52a1\u7684Prompt\u8bbe\u8ba1\uff1a 5.4 Hard Prompt & Soft Prompt \u00b6 Hard Prompt (\u79bb\u6563\u63d0\u793a)\uff1a\u662f\u4e00\u79cd\u56fa\u5b9a\u7684\u63d0\u793a\u6a21\u677f\uff0c\u901a\u8fc7\u5c06\u7279\u5b9a\u7684\u5173\u952e\u8bcd\u6216\u77ed\u8bed(\u771f\u5b9e\u7684\u6587\u672c\u5b57\u7b26\u4e32)\u76f4\u63a5\u5d4c\u5165\u5230\u6587\u672c\u4e2d\uff0c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7b26\u5408\u8981\u6c42\u7684\u6587\u672c\u3002\u8fd9\u79cd\u63d0\u793a\u65b9\u6cd5\u7684\u7279\u70b9\u5728\u4e8e\uff0c\u63d0\u793a\u6a21\u677f\u662f\u56fa\u5b9a\u7684\uff0c\u4e0d\u80fd\u6839\u636e\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u9700\u6c42\u8fdb\u884c\u8c03\u6574\u3002 \u4e0a\u8ff0\u6211\u4eec\u8bb2\u8ff0\u7684PET \u662f\u4e00\u79cd\u8f83\u4e3a\u7ecf\u5178\u7684\u786c\u6a21\u677f\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e3b\u8981\u601d\u60f3\uff1a\u5c06\u95ee\u9898\u5efa\u6a21\u6210\u4e00\u4e2a\u5b8c\u5f62\u586b\u7a7a\u95ee\u9898\uff0c\u7136\u540e\u4f18\u5316\u6700\u7ec8\u7684\u8f93\u51fa\u8bcd\u3002 \u867d\u7136 PET \u4e5f\u662f\u5728\u4f18\u5316\u6574\u4e2a\u6a21\u578b\u7684\u53c2\u6570 \uff0c\u4f46\u662f\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684 Finetuning \u65b9\u6cd5\uff0c \u5bf9\u6570\u636e\u91cf\u9700\u6c42\u66f4\u5c11 \u3002 \u4f46\u662f\u786c\u6a21\u677f\u4ea7\u751f\u4f9d\u8d56\u4e24\u79cd\u65b9\u5f0f\uff1a\u6839\u636e\u7ecf\u9a8c\u7684\u4eba\u5de5\u8bbe\u8ba1 & \u81ea\u52a8\u5316\u641c\u7d22\uff1b\u4ece\u4e0a\u56fe\u4ecb\u7ecd\u4e2d\u53ef\u4ee5\u770b\u51fa\u786c\u6a21\u677f \u5bf9\u4e8eprompt\uff0c\u6539\u53d8prompt\u4e2d\u7684\u5355\u4e2a\u5355\u8bcd \u4f1a\u7ed9\u5b9e\u9a8c\u7ed3\u679c\u5e26\u6765\u5de8\u5927\u7684\u5dee\u5f02\uff0c \u6240\u4ee5\u4e5f\u4e3a\u540e\u7eed\u4f18\u5316\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u5982\u7d22\u6027\u76f4\u63a5\u653e\u5f03\u786c\u6a21\u677f\uff0c\u53bb\u4f18\u5316 prompt token embedding\u5373Soft Prompt\u3002 Soft Prompt (\u8fde\u7eed\u63d0\u793a) \uff1a\u662f\u6307\u901a\u8fc7\u7ed9\u6a21\u578b\u8f93\u5165\u4e00\u4e2a\u53ef\u53c2\u6570\u5316\u7684\u63d0\u793a\u6a21\u677f\uff0c\u4ece\u800c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7b26\u5408\u7279\u5b9a\u8981\u6c42\u7684\u6587\u672c\u3002\u8fd9\u79cd\u63d0\u793a\u65b9\u6cd5\u7684\u7279\u70b9\u5728\u4e8e\uff0c\u63d0\u793a\u6a21\u677f\u4e2d\u7684\u53c2\u6570\u53ef\u4ee5\u6839\u636e\u5177\u4f53\u4efb\u52a1\u548c\u9700\u6c42\u8fdb\u884c\u8c03\u6574\uff0c\u4ee5\u8fbe\u5230\u6700\u4f73\u7684\u751f\u6210\u6548\u679c\u3002 \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4e3b\u8981\u9488\u5bf9soft Prompt\u65b9\u5f0f\u8fdb\u884c\u8bb2\u8ff0\uff1a 5.4.1 \u8fde\u7eed\u63d0\u793a\u6a21\u677f \u00b6 Soft Prompt\u76ee\u7684\u5176\u5c06\u6a21\u677f\u8f6c\u6362\u4e3a\u53ef\u4ee5\u8fdb\u884c\u4f18\u5316\u7684\u8fde\u7eed\u5411\u91cf\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u663e\u5f0f\u5730\u6307\u5b9a\u8fd9\u4e9b\u6a21\u677f\u4e2d\u5404\u4e2atoken\u5177\u4f53\u662f\u4ec0\u4e48\uff0c\u800c\u53ea\u9700\u8981\u5728\u8bed\u4e49\u7a7a\u95f4\u4e2d\u8868\u793a\u4e00\u4e2a\u5411\u91cf\u5373\u53ef\u3002 \u8fd9\u6837\uff0c\u4e0d\u540c\u7684\u4efb\u52a1\u3001\u6570\u636e\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u5728\u8bed\u4e49\u7a7a\u95f4\u4e2d\u5bfb\u627e\u82e5\u5e72\u5408\u9002\u7684\u5411\u91cf\uff0c\u6765\u4ee3\u8868\u6a21\u677f\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8bcd\uff0c\u76f8\u8f83\u4e8e\u663e\u5f0f\u7684token\uff0c\u8fd9\u7c7btoken\u79f0\u4e3a \u4f2a\u6807\u8bb0\uff08Pseudo Token\uff09 \u3002\u4e0b\u9762\u7ed9\u51fa\u57fa\u4e8e\u8fde\u7eed\u63d0\u793a\u7684\u6a21\u677f\u5b9a\u4e49\uff1a \u5047\u8bbe\u9488\u5bf9\u5206\u7c7b\u4efb\u52a1\uff0c\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165\u53e5\u5b50 x x \uff0c\u8fde\u7eed\u63d0\u793a\u7684\u6a21\u677f\u53ef\u4ee5\u5b9a\u4e49\u4e3a T=[x],[v1],[v2],...,[vn][MASK] T=[x],[v1],[v2],...,[vn][MASK] \uff1a\u5176\u4e2d[v1]\u5219\u662f\u4f2a\u6807\u8bb0\uff0c\u5176\u4ec5\u4ee3\u8868\u4e00\u4e2a\u62bd\u8c61\u7684token\uff0c\u5e76\u6ca1\u6709\u5b9e\u9645\u7684\u542b\u4e49\uff0c\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u5411\u91cf\u3002 \u603b\u7ed3\u6765\u8bf4\uff1aSoft Prompt\u65b9\u6cd5\uff0c\u662f\u5c06\u6a21\u677f\u53d8\u4e3a\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u4e0d\u540c\u7684\u6837\u672c\u53ef\u4ee5\u5728\u8fde\u7eed\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u5bfb\u627e\u5408\u9002\u7684\u4f2a\u6807\u8bb0\uff0c\u540c\u65f6\u4e5f\u589e\u52a0\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u8fde\u7eed\u6cd5\u9700\u8981\u5f15\u5165\u5c11\u91cf\u7684\u53c2\u6570\u5e76\u5728\u8bad\u7ec3\u65f6\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u4f46\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u662f\u4e0d\u53d8\u7684\uff0c\u53d8\u7684\u662fprompt token\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\uff08Word Embedding\uff09\u8868\u5f81\u53ca\u5176\u4ed6\u5f15\u5165\u7684\u5c11\u91cf\u53c2\u6570\u3002 \u76ee\u524d\u57fa\u4e8e\u8fde\u7eed\u63d0\u793a\u7684Prompt-Tuning\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4ee5\u4e0b\u5217\u4e09\u7bc7\u8bba\u6587\u4e3a\u4ee3\u8868\uff0c\u5206\u522b\u4f5c\u7b80\u8981\u4ecb\u7ecd\uff1a \u300aThe Power of Scale for Parameter-Efficient Prompt Tuning\u300b\uff1a\u4ee3\u8868\u65b9\u6cd5\u4e3aPrompt Tuning \u300aGPT Understands, Too\u300b\uff1a\u4ee3\u8868\u65b9\u6cd5\u4e3aP-tuning \u300aPPT: Pre-trained Prompt Tuning for Few-shot Learning\u300b\uff1a\u4ee3\u8868\u65b9\u6cd5PPT 5.4.2 Prompt Tuning\uff08NLG\u4efb\u52a1\uff09 \u00b6 Prompt Tuning\uff08\u57fa\u4e8eT5\u6a21\u578b\u6765\u505a\u7684\uff09\u65b9\u6cd5\u4e3a\u6bcf\u4e00\u4e2a\u8f93\u5165\u6587\u672c\u5047\u8bbe\u4e00\u4e2a\u56fa\u5b9a\u524d\u7f00\u63d0\u793a\uff0c\u8be5\u63d0\u793a\u8868\u7531\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u65f6\u8fdb\u884c\u66f4\u65b0\uff0c\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u9884\u8bad\u7ec3\u7684\u5927\u6a21\u578b\u53c2\u6570\u88ab\u51bb\u7ed3\u3002 \u5f62\u5f0f\u5316\u7684\u63cf\u8ff0\u5982\u4e0b\uff1a \u7ed9\u5b9a n n \u4e2atokens\uff0c\u8bb0\u4f5c\u200b x1, ...,xn x1, ...,xn \uff0c\u901a\u8fc7\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u5e94\u7684embedding table\uff0c\u53ef\u4ee5\u5c06\u200b n n \u4e2atoken\u8868\u793a\u4e3a\u4e00\u4e2a\u5411\u91cf\u77e9\u9635\u200b (X_e->R^{n*e}) (X_e->R^{n*e}) \uff0c\u5176\u4e2d\u200b e e \u662f\u5411\u91cf\u7684\u7ef4\u5ea6\uff08\u5176\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u914d\u7f6e\u6709\u5173\uff0c\u4f8b\u5982BERT-base\u662f768\uff09\u3002\u8fde\u7eed\u6a21\u677f\u4e2d\u7684\u6bcf\u4e2a\u4f2a\u6807\u8bb0\u200b v_i v_i \u53ef\u4ee5\u89c6\u4e3a\u53c2\u6570\uff0c\u4e5f\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2atoken\uff0c\u56e0\u6b64\uff0c\u53ef\u4ee5\u901a\u8fc7\u53e6\u4e00\u4e2aembedding table\u83b7\u5f97\u200b p p \u4e2a\u4f2a\u6807\u8bb0token\u6807\u8bb0\u4e3a\u5411\u91cf\u77e9\u9635\u200b (P_e->R^{p*e}) (P_e->R^{p*e}) \uff0c\u7136\u540e\u5c06\u6587\u672c\u548cPrompt\u62fc\u63a5\u83b7\u5f97\u65b0\u7684\u8f93\u5165\u200b [P_e:X_e]->R^{(p+n)*e} [P_e:X_e]->R^{(p+n)*e} .\u8fd9\u4e2a\u65b0\u7684\u8f93\u5165\u5c06\u4f1a\u5582\u5165\u4e00\u4e2aMLP\u83b7\u5f97\u65b0\u7684\u8868\u5f81\u3002\u6ce8\u610f\uff0c\u53ea\u6709prompt\u5bf9\u5e94\u7684\u5411\u91cf\u8868\u5f81\u53c2\u6570P (P_e->R^{p*e}) (P_e->R^{p*e}) \u4f1a\u968f\u7740\u8bad\u7ec3\u8fdb\u884c\u66f4\u65b0 \u6bcf\u4e2a\u4f2a\u6807\u8bb0\u7684\u521d\u59cb\u5316\u53ef\u4ee5\u6709\u4e0b\u5217\u51e0\u79cd\u60c5\u51b5\uff1a \u6700\u7b80\u5355\u7684\u662f\u968f\u673a\u521d\u59cb\u5316\uff1a\u5373\u968f\u673a\u521d\u59cb\u5316\u4e00\u4e2a\u9762\u5411\u6240\u6709\u4f2a\u6807\u8bb0\u7684embedding table\uff0c\u53ef\u91c7\u7528\u6b63\u6001\u5206\u5e03\u6216\u8005\u5747\u5300\u5206\u5e03\u7b49\uff1b \u6bcf\u4e2atoken\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5df2\u6709\u7684embedding table\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u6b64\u65f6\uff0c\u6bcf\u4e00\u4e2a\u4f2a\u6807\u8bb0\u5148\u968f\u673a\u6307\u5b9a\u8bcd\u8868\u4e2d\u7684\u4e00\u4e2a\u8bcd\uff0c\u5e76\u53d6\u5bf9\u5e94\u8bcd\u7684embedding\u4f5c\u4e3a\u8fd9\u4e2a\u4f2a\u6807\u8bb0\u7684\u521d\u59cb\u5316\uff1b \u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528label word\uff08verbalizer\uff09\u5bf9\u5e94\u7684embedding\u4f5c\u4e3a\u521d\u59cb\u5316\uff0c\u53ef\u4ee5\u6709\u6548\u9650\u5236\u6a21\u578b\u8f93\u51fa\u7684\u662f\u9884\u8bbe\u7684\u8f93\u51fa\u7c7b\u5bf9\u5e94\u7684word\u3002 \u56e0\u6b64\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2a\u4f2a\u6807\u8bb0\u4ee5\u53ca\u5bf9\u5e94\u7684MLP\u53c2\u6570\u90fd\u53ef\u4ee5\u5f97\u5230\u8bad\u7ec3\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u8f93\u5165\u53e5\u5b50 \uff0c\u8fd9\u4e9b\u4f2a\u6807\u8bb0\u5bf9\u5e94\u7684embedding\u4e5f\u5404\u4e0d\u76f8\u540c\uff0c\u8fbe\u5230\u4e86\u9884\u671f\u7684\u76ee\u7684\u3002 Prompt Tuning\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u5927\u6a21\u578b\u7684\u5fae\u8c03\u65b0\u8303\u5f0f \u6a21\u578b\u53c2\u6570\u89c4\u6a21\u5927\u4e86\u4e4b\u540e\uff0c\u53ef\u4ee5\u5c06\u5927\u6a21\u578b\u53c2\u6570\u56fa\u5b9a\uff0c\u6307\u5b9a\u9644\u52a0\u53c2\u6570\u6765\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u4e14\u9002\u914d\u6027\u80fd\u57fa\u672c\u548c\u5168\u53c2\u6570\u5fae\u8c03\u76f8\u5f53\u3002 \u7f3a\u70b9\uff1a \u5728\u5c0f\u6837\u672c\u5b66\u4e60\u573a\u666f\u4e0a\u8868\u73b0\u4e0d\u592a\u884c \u6536\u655b\u901f\u5ea6\u6bd4\u8f83\u6162 \u8c03\u53c2\u6bd4\u8f83\u590d\u6742 5.4.3 P-tuning\uff08NLU\u4efb\u52a1\uff09 \u00b6 P-tuning\u7684\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003\u8bba\u6587\u89e3\u8bfb\uff1aGPT Understands, Too\u3002 P-tuning\u662f\u53e6\u4e00\u4e2a\u5177\u6709\u4ee3\u8868\u6027\u7684\u8fde\u7eed\u63d0\u793a\u65b9\u6cd5\uff0c\u4e3b\u8981\u9488\u5bf9\u7684\u662fNLU\u4efb\u52a1\uff0c\u65b9\u6cd5\u56fe\u5982\u4e0b\u6240\u793a\uff08\u56fe\u4e2d\u7684 P_i P_i \u7b49\u4ef7\u4e8e\u4e0a\u6587\u7684 v_i v_i \uff0c\u8868\u793a\u4f2a\u6807\u8bb0\uff09, \u8c37\u6b4c\u4e8e2021\u5e74\u53d1\u8868\u3002 P-Tuning\u65b9\u6cd5\u4e2d\u56db\u4e2a\u6280\u5de7\u70b9\uff1a \u8003\u8651\u5230\u8fd9\u4e9b\u4f2a\u6807\u8bb0\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb \uff1a\u8ba4\u4e3a [P_1] [P_1] \u4e0e [P_2] [P_2] \u662f\u6709\u5148\u540e\u5173\u7cfb\u7684\uff0c\u800ctransformer\u65e0\u6cd5\u663e\u5f0f\u5730\u523b\u753b\u8fd9\u5c42\u5173\u7cfb\uff0c\u56e0\u6b64\u5f15\u5165Prompt Encoder\uff0c\u5b9e\u9645\u8fc7\u7a0b\u4e2d\u91c7\u7528\u4e00\u5c42Bi-LSTM+\u4e24\u4e2a\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7ec4\u6210\uff1b \u6307\u5b9a\u4e0a\u4e0b\u6587\u8bcd \uff1a\u5982\u679c\u6a21\u677f\u5168\u90e8\u662f\u4f2a\u6807\u8bb0\uff0c\u5728\u8bad\u7ec3\u65f6\u65e0\u6cd5\u5f88\u597d\u5730\u63a7\u5236\u8fd9\u4e9b\u6a21\u677f\u671d\u7740\u4e0e\u5bf9\u5e94\u53e5\u5b50\u76f8\u4f3c\u7684\u8bed\u4e49\u4e0a\u4f18\u5316\uff0c\u56e0\u6b64\u9009\u5b9a\u90e8\u5206\u5177\u6709\u4e0e\u5f53\u524d\u53e5\u5b50\u8bed\u4e49\u4ee3\u8868\u6027\u7684\u4e00\u4e9b\u8bcd\u4f5c\u4e3a\u4e00\u4e9b\u4f2a\u6807\u8bb0\u7684\u521d\u59cb\u5316\uff08\u4f8b\u5982\u4e0a\u56fe\u4e2d\u201ccapital\u201d\u3001\u201cBritain\u201d\u7b49\uff09\uff1b \u91cd\u53c2\u6570\uff08Reparameterization\uff09 \uff1a\u5177\u4f53\u5230\u4ee3\u7801\u5b9e\u73b0\u4e0a\uff0cP-tuning\u5148\u901a\u8fc7\u4e00\u4e2aPrompt Encoder\u8868\u5f81\u8fd9\u4e9b\u4f2a\u6807\u8bb0\u540e\uff0c\u76f4\u63a5\u5c06\u8fd9\u4e9b\u65b0\u7684\u8868\u5f81\u8986\u76d6\u5230\u5bf9\u5e94\u7684embedding table\u4e0a\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0cPrompt Encoder\u53ea\u5728\u8bad\u7ec3\u65f6\u5019\u4f1a\u4f7f\u7528\u5230\uff0c\u800c\u5728\u63a8\u7406\u9636\u6bb5\u5219\u4e0d\u518d\u4f7f\u7528\u3002 \u6df7\u5408\u63d0\u793a\uff08Hydride Prompt\uff09 \uff1a\u5c06\u8fde\u7eed\u63d0\u793a\u4e0e\u79bb\u6563token\u8fdb\u884c\u6df7\u5408\uff0c\u4f8b\u5982 [x][it][v1][mask]\u200b [x][it][v1][mask]\u200b P-Tuning V2\u662f\u5347\u7ea7\u7248\u672c\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u7684\u6bcf\u4e00\u5c42\u90fd\u5e94\u7528\u8fde\u7eed\u7684 prompts \u5e76\u5bf9 prompts \u53c2\u6570\u8fdb\u884c\u66f4\u65b0\u4f18\u5316\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u662f\u4e5f\u662f\u9488\u5bf9 NLU \u4efb\u52a1\u4f18\u5316\u548c\u9002\u914d\u7684\u3002 5.4.4 PPT\uff08Pre-trained Prompt Tuning\uff09 \u00b6 Prompt-Tuning\u901a\u5e38\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u573a\u666f\uff0c\u4f46\u662f\u7531\u4e8e\u8fde\u7eed\u7684\u6a21\u677f\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u5373\u5176\u5b58\u5728\u65b0\u7684\u53c2\u6570\uff0c\u5c11\u91cf\u6837\u672c\u53ef\u80fd\u4f9d\u7136\u5f88\u96be\u786e\u4fdd\u8fd9\u4e9b\u6a21\u677f\u88ab\u5f88\u597d\u5730\u4f18\u5316\u3002\u56e0\u6b64\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u5bf9\u8fd9\u4e9b\u8fde\u7eed\u7684\u6a21\u677f\u4e5f\u8fdb\u884c\u9884\u8bad\u7ec3\u3002PPT\u65e8\u5728\u901a\u8fc7\u5148\u8ba9\u8fd9\u4e9b\u8fde\u7eed\u63d0\u793a\u5728\u5927\u91cf\u65e0\u6807\u6ce8\u7684\u9884\u8bad\u7ec3\u8bed\u6599\u8fdb\u884c\u9884\u8bad\u7ec3\uff08\u6ce8\u610f\uff0c\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0cPre-train-model\u53c2\u6570\u56fa\u5b9a\u4e0d\u53d8\uff0c\u53ea\u6539\u53d8soft prompt\uff09\uff0c\u7136\u540e\u5c06\u5176\u52a0\u8f7d\u5230\u5bf9\u5e94\u4e0b\u6e38\u4efb\u52a1\u7684PLM\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff08\u56fe\u4e2d\u7684 P\u200b P\u200b \u5373\u8fde\u7eed\u7684\u63d0\u793a\u6a21\u677f\uff0c <X>\u200b <X>\u200b \u5e76\u8868\u793a\u4e3amask token\uff09\uff1a \u6bcf\u4e00\u7c7b\u4efb\u52a1\u90fd\u4f1a\u9884\u8bad\u7ec3\u4e00\u4e2asoft Prompt, \u9884\u8bad\u7ec3\u540e\u7684soft Prompt\u53ef\u4ee5\u76f4\u63a5\u8fd0\u7528\u5230\u76f8\u4f3c\u4efb\u52a1\u4e2d \u9996\u5148\u5728\u5927\u91cf\u65e0\u6807\u6ce8\u8bed\u6599\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u83b7\u5f97\u8bad\u7ec3\u597d\u7684\u8fde\u7eed\u63d0\u793a\uff08\u521d\u59cb\u5316\u4e0b\u6e38\u5fae\u8c03\u4efb\u52a1\u7684soft prompt\uff09\uff1b \u5bf9\u4e0b\u6e38\u4efb\u52a1\uff08\u662f\u975e\u95ee\u7b54\u3001NLI\u3001\u6587\u672c\u5339\u914d\u7b49\uff09\uff0c\u52a0\u8f7d\u8fd9\u4e9b\u8bad\u7ec3\u597d\u7684\u63d0\u793a\u4e4b\u540e\uff0c\u8fdb\u884c\u5fae\u8c03\uff0c\u6216\u8005\u76f4\u63a5\u8fdb\u884czero-shot\u9884\u6d4b\u3002 PPT\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u9884\u8bad\u7ec3soft-prompt\u5e26\u6765\u4e86 \u5c0f\u6837\u672c\u5b66\u4e60\u573a\u666f\u4e0a\u7684\u663e\u8457\u63d0\u5347 \u7f13\u89e3\u4e86prompt-tuning\u6536\u655b\u6162\u7684\u95ee\u9898 \u7f3a\u70b9 \u5408\u5e76\u540c\u7c7b\u4eba\u7269\u9700\u8981\u4eba\u5de5\u8bbe\u8ba1 \u4e0b\u56fe\u603b\u7ed3\u51e0\u79cdtemplate\u4f18\u5316\u8fdb\u884c\u7684\u5bf9\u6bd4\u3002 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86NLP\u53d1\u5c55\u7684\u56db\u79cd\u8303\u5f0f\u3001Fine-Tuning\u4ee5\u53caPrompt-Tuning\u7684\u57fa\u672c\u601d\u60f3\u548c\u539f\u7406 \u672c\u7ae0\u8282\u5185\u5bb9\u8be6\u7ec6\u4e86\u53d9\u8ff0\u4e86Prompt-Tuning\u4e3b\u8981\u4ee3\u8868\u65b9\u6cd5 \u5206\u522b\u5bf9\u4e0d\u540c\u7c7b\u578b\u67b6\u6784\u7684\u4ee3\u8868\u6a21\u578b\u5982\uff1aBERT\u3001GPT\u3001T5\u7b49\u76f8\u5173\u6a21\u578b\u8fdb\u884c\u4ecb\u7ecd","title":"3.1 \u5927\u6a21\u578bPrompt-Tuning\u6280\u672f\u5165\u95e8"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#prompt-tuning","text":"","title":"Prompt-Tuning\u65b9\u6cd5"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#_1","text":"\u4e86\u89e3LLM\u8fdb\u9636\u5386\u7a0b\u56db\u79cd\u8303\u5f0f. \u638c\u63e1Fine-Tuning\u6a21\u578b\u5fae\u8c03\u7684\u57fa\u672c\u539f\u7406 \u638c\u63e1Prompt_Tuning\u6a21\u578b\u5fae\u8c03\u7684\u57fa\u672c\u539f\u7406","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#1-nlp","text":"\u76ee\u524d\u5b66\u672f\u754c\u4e00\u822c\u5c06NLP\u4efb\u52a1\u7684\u53d1\u5c55\u5206\u4e3a\u56db\u4e2a\u9636\u6bb5\uff0c\u5373NLP\u56db\u8303\u5f0f\uff1a \u7b2c\u4e00\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u300d\u7684\u8303\u5f0f\uff0c\u5982TF-IDF\u7279\u5f81+\u6734\u7d20\u8d1d\u53f6\u65af\u7b49\u673a\u5668\u7b97\u6cd5\uff1b \u7b2c\u4e8c\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u300d\u7684\u8303\u5f0f\uff0c\u5982word2vec\u7279\u5f81+LSTM\u7b49\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff0c\u76f8\u6bd4\u4e8e\u7b2c\u4e00\u8303\u5f0f\uff0c\u6a21\u578b\u51c6\u786e\u6709\u6240\u63d0\u9ad8\uff0c\u7279\u5f81\u5de5\u7a0b\u7684\u5de5\u4f5c\u4e5f\u6709\u6240\u51cf\u5c11\uff1b \u7b2c\u4e09\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u9884\u8bad\u7ec3\u6a21\u578b+fine-tuning\u300d\u7684\u8303\u5f0f\uff0c\u5982Bert+fine-tuning\u7684NLP\u4efb\u52a1\uff0c\u76f8\u6bd4\u4e8e\u7b2c\u4e8c\u8303\u5f0f\uff0c\u6a21\u578b\u51c6\u786e\u5ea6\u663e\u8457\u63d0\u9ad8\uff0c\u6a21\u578b\u4e5f\u968f\u4e4b\u53d8\u5f97\u66f4\u5927\uff0c\u4f46\u5c0f\u6570\u636e\u96c6\u5c31\u53ef\u8bad\u7ec3\u51fa\u597d\u6a21\u578b\uff1b \u7b2c\u56db\u8303\u5f0f\uff1a\u57fa\u4e8e\u300c\u9884\u8bad\u7ec3\u6a21\u578b+Prompt+\u9884\u6d4b\u300d\u7684\u8303\u5f0f\uff0c\u5982Bert+Prompt\u7684\u8303\u5f0f\u76f8\u6bd4\u4e8e\u7b2c\u4e09\u8303\u5f0f\uff0c\u6a21\u578b\u8bad\u7ec3\u6240\u9700\u7684\u8bad\u7ec3\u6570\u636e\u663e\u8457\u51cf\u5c11\u3002 \u5728\u6574\u4e2aNLP\u9886\u57df\uff0c\u6574\u4e2a\u53d1\u5c55\u5386\u7a0b\u662f\u671d\u7740\u7cbe\u5ea6\u66f4\u9ad8\u3001\u5c11\u76d1\u7763\uff0c\u751a\u81f3\u65e0\u76d1\u7763\u7684\u65b9\u5411\u53d1\u5c55\u7684\u3002\u800c Prompt-Tuning\u662f\u76ee\u524d\u5b66\u672f\u754c\u5411\u8fd9\u4e2a\u65b9\u5411\u8fdb\u519b\u6700\u65b0\u4e5f\u662f\u6700\u706b\u7684\u7814\u7a76\u6210\u679c\u3002","title":"1 NLP\u4efb\u52a1\u56db\u79cd\u8303\u5f0f"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#2-fine-tuning","text":"Fine-Tuning\u5c5e\u4e8e\u4e00\u79cd\u8fc1\u79fb\u5b66\u4e60\u65b9\u5f0f\uff0c\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u4e2d\uff0cFine-Tuning\u662f\u7528\u4e8e\u5c06\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u4e8e\u7279\u5b9a\u4efb\u52a1\u6216\u9886\u57df\u3002Fine-Tuning\u7684\u57fa\u672c\u601d\u60f3\u662f\u91c7\u7528\u5df2\u7ecf\u5728\u5927\u91cf\u6587\u672c\u4e0a\u8fdb\u884c\u8bad\u7ec3\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u7136\u540e\u5728\u5c0f\u89c4\u6a21\u7684\u4efb\u52a1\u7279\u5b9a\u6587\u672c\u4e0a\u7ee7\u7eed\u8bad\u7ec3\u5b83. \u7ecf\u5178\u7684Fine-Tuning\u65b9\u6cd5\u5305\u62ec\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u4e0e\u5c11\u91cf\u7279\u5b9a\u4efb\u52a1\u6570\u636e\u4e00\u8d77\u7ee7\u7eed\u8bad\u7ec3\u3002\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6743\u91cd\u88ab\u66f4\u65b0\uff0c\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u4efb\u52a1\u3002\u6240\u9700\u7684Fine-Tuning\u91cf\u53d6\u51b3\u4e8e\u9884\u8bad\u7ec3\u8bed\u6599\u5e93\u548c\u4efb\u52a1\u7279\u5b9a\u8bed\u6599\u5e93\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002\u5982\u679c\u4e24\u8005\u76f8\u4f3c\uff0c\u53ef\u80fd\u53ea\u9700\u8981\u5c11\u91cf\u7684Fine-Tuning\uff0c\u5982\u679c\u4e24\u8005\u4e0d\u76f8\u4f3c\uff0c\u5219\u53ef\u80fd\u9700\u8981\u66f4\u591a\u7684Fine-Tuning. \u4f46\u662f\uff0c\u5728\u5927\u591a\u6570\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u65f6\uff0c\u4e0b\u6e38\u4efb\u52a1\u7684\u76ee\u6807\u548c\u9884\u8bad\u7ec3\u7684\u76ee\u6807\u5dee\u8ddd\u8fc7\u5927\u5bfc\u81f4\u63d0\u5347\u6548\u679c\u4e0d\u660e\u663e\uff08\u8fc7\u62df\u5408\uff09\uff0c\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u9700\u8981\u4f9d\u8d56\u5927\u91cf\u7684\u76d1\u7763\u8bed\u6599\u7b49\u7b49\u3002\u81f3\u6b64\uff0c\u4ee5GPT3\u3001PET\u7b49\u4e3a\u9996\u7684\u6a21\u578b\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u7684\u5fae\u8c03\u8303\u5f0f--Prompt-Tuning.\u8be5\u65b9\u6cd5\u7684\u76ee\u7684\u662f\u901a\u8fc7\u6dfb\u52a0\u6a21\u677f\u7684\u65b9\u6cd5\u6765\u907f\u514d\u5f15\u5165\u989d\u5916\u7684\u53c2\u6570\uff0c\u4ece\u800c\u8ba9\u6a21\u578b\u53ef\u4ee5\u5728\u5c0f\u6837\u672c\uff08few-shot\uff09\u6216\u8005\u96f6\u6837\u672c\uff08zero-shot\uff09\u573a\u666f\u4e0b\u8fbe\u5230\u7406\u60f3\u7684\u6548\u679c\u3002 Prompt-Tuning\u4e3b\u8981\u89e3\u51b3\u4f20\u7edfFine-Tuning\u65b9\u5f0f\u7684\u4e24\u4e2a\u75db\u70b9\uff1a \u964d\u4f4e\u8bed\u4e49\u504f\u5dee\uff1a\u9884\u8bad\u7ec3\u4efb\u52a1\u4e3b\u8981\u4ee5MLM\u4e3a\u4e3b\uff0c\u800c\u4e0b\u6e38\u4efb\u52a1\u5219\u91cd\u65b0\u5f15\u5165\u65b0\u7684\u8bad\u7ec3\u53c2\u6570\uff0c\u56e0\u6b64\u4e24\u4e2a\u9636\u6bb5\u76ee\u6807\u5dee\u5f02\u8f83\u5927\u3002\u56e0\u6b64\u9700\u8981\u89e3\u51b3Pre-Training\u548cFine-Tuning\u4e4b\u95f4\u7684Gap\u3002 \u907f\u514d\u8fc7\u62df\u5408\uff1a\u7531\u4e8eFine-Tuning\u9636\u6bb5\u9700\u8981\u5f15\u5165\u65b0\u7684\u53c2\u6570\u9002\u914d\u76f8\u5e94\u4efb\u52a1\uff0c\u56e0\u6b64\u5728\u6837\u672c\u6570\u91cf\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5bb9\u6613\u53d1\u751f\u8fc7\u62df\u5408\uff0c\u964d\u4f4e\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u8fc7\u62df\u5408\u80fd\u529b\u3002","title":"2 Fine-Tuning(\u5fae\u8c03)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#3-prompt-tuning","text":"","title":"3 Prompt-Tuning(\u63d0\u793a\u5fae\u8c03)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#31-prompt","text":"prompt\u987e\u540d\u601d\u4e49\u5c31\u662f\u201c\u63d0\u793a\u201d\u7684\u610f\u601d\uff0c\u5e94\u8be5\u6709\u4eba\u73a9\u8fc7\u4f60\u753b\u6211\u731c\u8fd9\u4e2a\u6e38\u620f\u5427\uff0c\u5bf9\u65b9\u6839\u636e\u4e00\u4e2a\u8bcd\u8bed\u753b\u4e00\u5e45\u753b\uff0c\u6211\u4eec\u6765\u731c\u4ed6\u753b\u7684\u662f\u4ec0\u4e48\uff0c\u56e0\u4e3a\u6709\u592a\u591a\u7075\u9b42\u753b\u624b\u4e86\uff0c\u753b\u98ce\u6e05\u5947\uff0c\u6216\u8005\u4f60\u4eec\u6ca1\u6709\u5fc3\u6709\u7075\u7280\uff0c\u6839\u672c\u5c31\u4e0d\u597d\u731c\u554a\uff01\u8fd9\u65f6\u5019\u5c4f\u5e55\u4e0a\u4f1a\u51fa\u73b0\u4e00\u4e9b\u63d0\u793a\u8bcd\u6bd4\u59823\u4e2a\u5b57\uff0c\u6c34\u679c\uff0c\u90a3\u5c82\u4e0d\u662f\u597d\u731c\u4e00\u70b9\u4e86\u561b\uff0c\u6bd5\u7adf3\u4e2a\u5b57\u7684\u6c34\u679c\u4e5f\u4e0d\u591a\u5440\u3002\u770b\u5230\u4e86\u5427\uff0c\u8fd9\u5c31\u662fprompt\u7684\u9b45\u529b.","title":"3.1 \u4ec0\u4e48\u662fPrompt?"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#32-prompt-tuing","text":"\u57fa\u4e8eFine-Tuning\u7684\u65b9\u6cd5\u662f\u8ba9\u9884\u8bad\u7ec3\u6a21\u578b\u53bb\u8fc1\u5c31\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u57fa\u4e8ePrompt-Tuning\u7684\u65b9\u6cd5\u53ef\u4ee5\u8ba9\u4e0b\u6e38\u4efb\u52a1\u53bb\u8fc1\u5c31\u9884\u8bad\u7ec3\u6a21\u578b, \u5176\u76ee\u7684\u662f\u5c06Fine-tuning\u7684\u4e0b\u6e38\u4efb\u52a1\u76ee\u6807\u8f6c\u6362\u4e3aPre-training\u7684\u4efb\u52a1\u3002\u90a3\u4e48\u5177\u4f53\u5982\u4f55\u5de5\u4f5c\u5462\uff1f\u6211\u4eec\u4ee5\u4e00\u4e2a\u4e8c\u5206\u7c7b\u7684\u60c5\u611f\u5206\u6790\u4e3a\u4f8b\u5b50\uff0c\u8fdb\u884c\u7b80\u5355\u7406\u89e3\uff1a eg: \u5b9a\u4e00\u4e2a\u53e5\u5b50 [CLS] I like the Disney films very much. [SEP] \u4f20\u7edf\u7684Fine-tuning\u65b9\u6cd5: \u5c06\u5176\u901a\u8fc7BERT\u7684Transformer\u83b7\u5f97 [CLS] \u8868\u5f81\u4e4b\u540e\u518d\u5582\u5165\u65b0\u589e\u52a0\u7684MLP\u5206\u7c7b\u5668\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u9884\u6d4b\u8be5\u53e5\u5b50\u662f\u79ef\u6781\u7684\uff08positive\uff09\u8fd8\u662f\u6d88\u6781\u7684\uff08negative\uff09\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u5b9a\u91cf\u7684\u8bad\u7ec3\u6570\u636e\u6765\u8bad\u7ec3\u3002 Prompt-Tuning\u6267\u884c\u6b65\u9aa4\uff1a 1.\u6784\u5efa\u6a21\u677f\uff08Template Construction\uff09: \u901a\u8fc7\u4eba\u5de5\u5b9a\u4e49\u3001\u81ea\u52a8\u641c\u7d22\u3001\u6587\u672c\u751f\u6210\u7b49\u65b9\u6cd5\uff0c\u751f\u6210\u4e0e\u7ed9\u5b9a\u53e5\u5b50\u76f8\u5173\u7684\u4e00\u4e2a\u542b\u6709 [MASK] \u6807\u8bb0\u7684\u6a21\u677f\u3002\u4f8b\u5982 It was [MASK]. \uff0c\u5e76\u62fc\u63a5\u5230\u539f\u59cb\u7684\u6587\u672c\u4e2d\uff0c\u83b7\u5f97Prompt-Tuning\u7684\u8f93\u5165\uff1a [CLS] I like the Disney films very much. [SEP] It was [MASK]. [SEP] \u3002\u5c06\u5176\u5582\u5165BERT\u6a21\u578b\u4e2d\uff0c\u5e76\u590d\u7528\u9884\u8bad\u7ec3\u597d\u7684MLM\u5206\u7c7b\u5668\uff08\u5728huggingface\u4e2d\u4e3aBertForMaskedLM\uff09\uff0c\u5373\u53ef\u76f4\u63a5\u5f97\u5230 [MASK] \u9884\u6d4b\u7684\u5404\u4e2atoken\u7684\u6982\u7387\u5206\u5e03\u3002 2.\u6807\u7b7e\u8bcd\u6620\u5c04\uff08Label Word Verbalizer\uff09 \uff1a\u56e0\u4e3a [MASK] \u90e8\u5206\u6211\u4eec\u53ea\u5bf9\u90e8\u5206\u8bcd\u611f\u5174\u8da3\uff0c\u56e0\u6b64\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u6620\u5c04\u5173\u7cfb\u3002\u4f8b\u5982\u5982\u679c [MASK] \u9884\u6d4b\u7684\u8bcd\u662f\u201cgreat\u201d\uff0c\u5219\u8ba4\u4e3a\u662fpositive\u7c7b\uff0c\u5982\u679c\u662f\u201cterrible\u201d\uff0c\u5219\u8ba4\u4e3a\u662fnegative\u7c7b\u3002 3.\u8bad\u7ec3\uff1a\u6839\u636eVerbalizer\uff0c\u5219\u53ef\u4ee5\u83b7\u5f97\u6307\u5b9alabel word\u7684\u9884\u6d4b\u6982\u7387\u5206\u5e03\uff0c\u5e76\u91c7\u7528\u4ea4\u53c9\u4fe1\u606f\u71b5\u8fdb\u884c\u8bad\u7ec3\u3002\u6b64\u65f6\u56e0\u4e3a\u53ea\u5bf9\u9884\u8bad\u7ec3\u597d\u7684MLM head\u8fdb\u884c\u5fae\u8c03\uff0c\u6240\u4ee5\u907f\u514d\u4e86\u8fc7\u62df\u5408\u95ee\u9898\u3002 \u6ce8\u610f\u601d\u8003\uff1a\u4e0d\u540c\u7684\u53e5\u5b50\u5e94\u8be5\u6709\u4e0d\u540c\u7684template\u548clabel word\uff0c\u6ca1\u9519\uff0c\u56e0\u4e3a\u6bcf\u4e2a\u53e5\u5b50\u53ef\u80fd\u671f\u671b\u9884\u6d4b\u51fa\u6765\u7684label word\u90fd\u4e0d\u540c\uff0c\u56e0\u6b64\u5982\u4f55\u6700\u5927\u5316\u7684\u5bfb\u627e\u5f53\u524d\u4efb\u52a1\u66f4\u52a0\u5408\u9002\u7684template\u548clabel word\u662fPrompt-tuning\u975e\u5e38\u91cd\u8981\u7684\u6311\u6218\u3002 \u5176\u5b9e\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\uff0c\u5f15\u5165\u7684\u6a21\u677f\u548c\u6807\u7b7e\u8bcd\u672c\u8d28\u4e0a\u5c5e\u4e8e\u4e00\u79cd\u6570\u636e\u589e\u5f3a\uff0c\u901a\u8fc7\u6dfb\u52a0\u63d0\u793a\u7684\u65b9\u5f0f\u5f15\u5165\u5148\u9a8c\u77e5\u8bc6\u3002","title":"3.2 Prompt-Tuing\u5b9a\u4e49"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#4-prompt-tuning","text":"Prompt-Tuning\u81eaGPT-3\u88ab\u63d0\u51fa\u4ee5\u6765\uff0c\u4ece\u4f20\u7edf\u7684\u79bb\u6563\u3001\u8fde\u7eed\u7684Prompt\u6784\u5efa\u3001\u8d70\u5411\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684In-Context Learning\u3001Instruction-tuning\u548cChain_of_Thought.","title":"4 Prompt-Tuning\u6280\u672f\u53d1\u5c55\u5386\u7a0b"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#5-prompt-tuning","text":"Prompt-Tuning\u5177\u4f53\u5982\u4f55\u5b9e\u73b0\uff0c\u5176\u6709\u4ec0\u4e48\u56f0\u96be\u548c\u6311\u6218\uff1f\u8fd9\u91cc\u6211\u4eec\u6311\u9009\u4e00\u4e9b\u5177\u6709\u4ee3\u8868\u6027\u7684.","title":"5 Prompt-Tuning\u7684\u4e3b\u8981\u65b9\u6cd5"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#51-prompt-tuning-gpt3pet","text":"Prompt-Tuning\u6700\u65e9\u662f\u5728GPT-3\u300aLanguage Models are Few-Shot Learners\u300b\u4e2d\u88ab\u63d0\u51fa\u6765\u7684\u3002\u5176\u5f00\u521b\u6027\u7684\u63d0\u51fa\u4e86In-context Learning\uff08ICL, \u60c5\u666f\u5b66\u4e60\uff09\u7684\u601d\u60f3\u3002\u5373\u65e0\u987b\u4fee\u6539\u6a21\u578b\u5373\u53ef\u5b9e\u73b0few-shot\u3001zero-shot\u7684learning\u3002\u540c\u65f6\u5f15\u5165\u4e86Demonstrate Learning, \u5373\u8ba9\u6a21\u578b\u77e5\u9053\u4e0e\u6807\u7b7e\u76f8\u4f3c\u7684\u8bed\u4e49\u63cf\u8ff0\uff0c\u63d0\u5347\u63a8\u7406\u80fd\u529b. In-context Learning: Prompt\u524d\u8eab\uff0c\u901a\u8fc7\u4ece\u8bad\u7ec3\u96c6\u6311\u9009\u4e00\u4e9b\u6837\u672c\u4f5c\u4e3a\u4efb\u52a1\u7684\u63d0\u793a\uff0c\u6765\u5b9e\u73b0\u514d\u53c2\u6570\u66f4\u65b0\u7684\u6a21\u578b\u9884\u6d4b\u3002 Demonstration Learning\uff1a\u6dfb\u52a0\u4e00\u4e9b\u65b0\u7684\u6837\u672c\u4f5c\u4e3a\u63d0\u793a\u3002\u6a21\u578b\u53ef\u4ee5\u6839\u636e\u65b0\u6dfb\u52a0\u7684\u6837\u4f8b\u53e5\u5b50\u5c31\u53ef\u4ee5\"\u7167\u732b\u753b\u864e\"\u5f0f\u7684\u9884\u6d4b\u7ed3\u679c\u4e86. \u5e38\u7528\u7684In-context learning\u65b9\u6cd5\u5305\u62ec\uff1a zero-shot learning \u5b9a\u4e49: \u7ed9\u51fa\u4efb\u52a1\u7684\u63cf\u8ff0, \u7136\u540e\u63d0\u4f9b\u6d4b\u8bd5\u6570\u636e\u5bf9\u5176\u8fdb\u884c\u9884\u6d4b, \u76f4\u63a5\u8ba9\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53bb\u8fdb\u884c\u4efb\u52a1\u6d4b\u8bd5. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. one-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u4e00\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u4e00\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u82f1\u8bed\u7ffb\u8bd1\u4e3a\u6cd5\u8bed, \u5e94\u8be5\u8fd9\u4e48\u7ffb\u8bd1. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. few-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u591a\u4e2a\u6837\u672c\uff08\u4e00\u822c10-100\u6761\uff09\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u591a\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u5e94\u8be5\u5982\u4f55\u5de5\u4f5c. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u518d\u89c1->goodbye, \u8d2d\u4e70->purchase, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. \u4f46\u662f\u8fd9\u7c7b\u65b9\u6cd5\u6709\u4e00\u4e2a\u660e\u663e\u7684\u7f3a\u9677\u662f\u2014\u2014\u5176\u5efa\u7acb\u5728\u8d85\u5927\u89c4\u6a21\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u6b64\u65f6\u7684\u6a21\u578b\u53c2\u6570\u6570\u91cf\u901a\u5e38\u8d85\u8fc7100\u4ebf\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u5f88\u96be\u5e94\u7528\uff0c\u56e0\u6b64\u4f17\u591a\u7814\u7a76\u8005\u5f00\u59cb\u63a2\u7d22GPT-3\u7684\u8fd9\u5957\u601d\u8def\u5728\u5c0f\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\uff08\u5982Bert\uff09\u4e0a\u8fd8\u662f\u5426\u9002\u7528\uff1f\u4e8b\u5b9e\u4e0a\uff0c\u8fd9\u5957\u65b9\u6cd5\u5728\u5c0f\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u4f46\u662f\u9700\u8981\u6ce8\u610f\uff1a \u6a21\u578b\u53c2\u6570\u89c4\u6a21\u5c0f\u4e86\uff0cprompt\u76f4\u63a5\u7528\u5728zero-shot\u4e0a\u6548\u679c\u4f1a\u4e0b\u964d\uff0c\u56e0\u6b64\u9700\u8981\u8003\u8651\u5c06In-context Learning\u548cDemonstrate Learning\u5e94\u7528\u5728Fine-Tuning\u9636\u6bb5\uff0c\u4e5f\u5c31\u662f\u540e\u9762\u8981\u8bb2\u5230\u7684Prompt-Tuning\u3002 GPT-3\u4e2d\u63d0\u4f9b\u7684\u63d0\u793a\uff08Natural Language Prompt\uff09\u8fc7\u4e8e\u7b80\u5355\uff0c\u6cdb\u5316\u6027\u80fd\u4f4e\u3002 \u56e0\u6b64\uff0cPET\u6a21\u578b\u95ee\u4e16.","title":"5.1 Prompt-Tuning\u7684\u9f3b\u7956----GPT3\u548cPET"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#52-pet","text":"PET\uff08Pattern-Exploiting Training\uff09\u51fa\u81ea\u300aExploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference\u300b\uff08EACL2021\uff09\uff0c\u6839\u636e\u8bba\u6587\u9898\u76ee\u5219\u53ef\u4ee5\u731c\u51fa\uff0cPrompt-Tuning\u542f\u53d1\u4e8e\u6587\u672c\u5206\u7c7b\u4efb\u52a1\uff0c\u5e76\u4e14\u8bd5\u56fe\u5c06\u6240\u6709\u7684\u5206\u7c7b\u4efb\u52a1\u8f6c\u6362\u4e3a\u4e0eMLM\u4e00\u81f4\u7684\u5b8c\u5f62\u586b\u7a7a\u3002 PET\u6a21\u578b\u63d0\u51fa\u4e24\u4e2a\u5f88\u91cd\u8981\u7684\u7ec4\u4ef6\uff1a Pattern\uff08Template\uff09 \uff1a\u8bb0\u4f5cT, \u5373\u4e0a\u6587\u63d0\u5230\u7684Template\uff0c\u5176\u4e3a\u989d\u5916\u6dfb\u52a0\u7684\u5e26\u6709 [mask] \u6807\u8bb0\u7684\u77ed\u6587\u672c\uff0c\u901a\u5e38\u4e00\u4e2a\u6837\u672c\u53ea\u6709\u4e00\u4e2aPattern\uff08\u56e0\u4e3a\u6211\u4eec\u5e0c\u671b\u53ea\u67091\u4e2a\u8ba9\u6a21\u578b\u9884\u6d4b\u7684 [mask] \u6807\u8bb0\uff09\u3002\u7531\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1\u3001\u4e0d\u540c\u7684\u6837\u672c\u53ef\u80fd\u4f1a\u6709\u5176\u66f4\u52a0\u5408\u9002\u7684pattern\uff0c \u56e0\u6b64\u5982\u4f55\u6784\u5efa\u5408\u9002\u7684pattern\u662fPrompt-Tuning\u7684\u7814\u7a76\u70b9\u4e4b\u4e00 \uff1b Verbalizer \uff1a\u8bb0\u4f5cV, \u5373\u6807\u7b7e\u8bcd\u7684\u6620\u5c04\uff0c\u5bf9\u4e8e\u5177\u4f53\u7684\u5206\u7c7b\u4efb\u52a1\uff0c\u9700\u8981\u9009\u62e9\u6307\u5b9a\u7684\u6807\u7b7e\u8bcd\uff08label word\uff09\u3002\u4f8b\u5982\u60c5\u611f\u5206\u6790\u4e2d\uff0c\u6211\u4eec\u671f\u671bVerbalizer\u53ef\u80fd\u662f \uff08positive\u548cnegative\u662f\u7c7b\u6807\u7b7e\uff09\u3002\u540c\u6837\uff0c\u4e0d\u540c\u7684\u4efb\u52a1\u6709\u5176\u76f8\u5e94\u7684label word\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cVerbalizer\u7684\u6784\u5efa\u9700\u8981\u53d6\u51b3\u4e8e\u5bf9\u5e94\u7684Pattern\u3002\u56e0\u6b64 \u5982\u4f55\u6784\u5efaVerbalizer\u662f\u53e6\u4e00\u4e2a\u7814\u7a76\u6311\u6218 \u3002 \u4e0a\u8ff0\u4e24\u4e2a\u7ec4\u4ef6\u88ab\u79f0\u4e3aPattern-Verbalizer-Pair\uff08PVP\uff09\uff0c\u5728\u540e\u7eed\u7684\u5927\u591a\u6570\u7814\u7a76\u4e2d\u5747\u91c7\u7528\u8fd9\u79cdPVP\u7ec4\u4ef6\u3002\u57fa\u4e8ePVP\u7684\u8bad\u7ec3\u76ee\u6807\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u4e0b\u9762\u5f62\u5f0f\uff1a \u7ed9\u5b9a\u4e00\u4e2a\u53e5\u5b50\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u7ed9\u5b9a\u5b9a\u4e49\u7684PVP\u7ec4\u4ef6\uff0c\u5219\u6709 \u76ee\u524d\u57fa\u4e8ePVP\u6846\u67b6\uff0c\u5f53\u524d\u6700\u9700\u8981\u5173\u6ce8\u7684\u95ee\u9898\u662f\u5982\u4f55\u9009\u62e9\u6216\u6784\u5efa\u5408\u9002\u7684Pattern\u548cVerbalizer \u3002\u4e00\u79cd\u7b80\u5355\u7684\u65b9\u6cd5\u662f\u6839\u636e\u7279\u5b9a\u4efb\u52a1\u7684\u6027\u8d28\u548c\u5148\u9a8c\u77e5\u8bc6\u4eba\u5de5\u8bbe\u8ba1\u6a21\u677f\u3002\u4f8b\u5982\u4e0a\u6587\u4f8b\u5b50\u4e2d\u901a\u5e38\u4f1a\u9009\u62e9 It was [mask]. \u4f5c\u4e3a\u60c5\u611f\u5206\u6790\u7c7b\u7684\u6a21\u677f\u3002\u4eba\u5de5\u6784\u5efa\u65b9\u6cd5\u867d\u7136\u76f4\u89c2\u7b80\u5355\uff0c\u4f46\u662f\u81f4\u547d\u95ee\u9898\u4e5f\u5f88\u7a81\u51fa\u3002\u6709\u76f8\u5173\u5de5\u4f5c\u5728\u5b9e\u9a8c\u4e2d\u53d1\u73b0\uff0c\u5728\u540c\u6837\u7684\u6570\u636e\u96c6\u548c\u8bad\u7ec3\u6761\u4ef6\u4e0b\uff0c \u9009\u62e9\u4e0d\u540c\u7684Pattern\u548cVerbalizer\u4f1a\u4ea7\u751f\u5dee\u5f02\u5f88\u5927\u7684\u7ed3\u679c \uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff08\u4e00\u822c\u60c5\u51b5\u4e0b\uff0cTemplate\u7b49\u540c\u4e8ePattern\uff0cVerbalizer\u7b49\u540c\u4e8eLabel word\uff09\uff1a \u4ece\u4e0a\u56fe\u7ed3\u679c\u53ef\u53d1\u73b0\uff0c\u5728\u76f8\u540cPattern\u65f6\uff0c\u9009\u62e9\u4e0d\u540c\u7684label word\u5bf9\u7ed3\u679c\u5f71\u54cd\u5f88\u5927\uff0c\u540c\u7406\uff0c\u4e0d\u540c\u7684Pattern\u5bf9\u7ed3\u679c\u5f71\u54cd\u4e5f\u5f88\u660e\u663e\uff0c\u5728\u771f\u6b63\u5e94\u7528\u4e2d\uff0c\u8c03\u53c2\u8005\u9700\u8981\u5c1d\u8bd5\u591a\u4e2a\u4e0d\u540c\u7684\u6a21\u677f\u548c\u6807\u7b7e\u8bcd\u4ee5\u7a77\u4e3e\u51fa\u6700\u597d\u7684\u7ed3\u679c\uff0c\u5e76\u4e0d\u80fd\u5145\u5206\u53d1\u6325Prompt\u7b80\u5355\u5feb\u6377\u7684\u4f18\u52bf\u3002\u56e0\u6b64\u6211\u4eec\u603b\u7ed3\u4eba\u5de5\u8bbe\u8ba1\u65b9\u6cd5\u7684\u7f3a\u9677\uff1a \u91c7\u7528\u4eba\u5de5\u6784\u5efa\u7684\u65b9\u6cd5\u6210\u672c\u9ad8\uff0c\u9700\u8981\u4e0e\u9886\u57df\u4efb\u52a1\u76f8\u5173\u7684\u5148\u9a8c\u77e5\u8bc6\uff1b \u4eba\u5de5\u8bbe\u8ba1\u7684Pattern\u548cVerbalizer\u4e0d\u80fd\u4fdd\u8bc1\u83b7\u5f97\u6700\u4f18\u89e3\uff0c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u4e0d\u540c\u7684PVP\u5bf9\u7ed3\u679c\u4ea7\u751f\u7684\u5dee\u5f02\u660e\u663e\uff0c\u65b9\u5dee\u5927\uff1b \u5728\u9884\u8bad\u7ec3\u9636\u6bb5MLM\u4efb\u52a1\u5e76\u975e\u5b8c\u5168\u6309\u7167PVP\u7684\u6a21\u5f0f\u8fdb\u884c\u8bad\u7ec3\u7684\uff08\u6bd4\u5982MLM\u8bad\u7ec3\u901a\u5e38\u90fd\u662f\u957f\u6587\u672c\uff0cmask\u7684\u6570\u91cf\u4e5f\u5e76\u975e\u53ea\u67091\u4e2a\uff0c\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\u4e5f\u5e76\u975e\u662f\u6709\u9650\u7684\uff09\uff0c\u56e0\u6b64\u4eba\u5de5\u6784\u5efa\u7684Pattern\u548cVerbalizer\u4f7f\u5f97Prompt-Tuning\u4e0eMLM\u5728\u8bed\u4e49\u548c\u5206\u5e03\u4e0a\u4f9d\u7136\u5b58\u5728\u5dee\u5f02\u3002 \u56e0\u6b64\u5982\u4f55\u80fd\u591f\u81ea\u52a8\u5730\u6311\u9009\u5408\u9002\u7684PVP? \u76ee\u524d\u6784\u5efaVerbalizer\u7684\u65b9\u6cd5\u4e5f\u6709\u5f88\u591a\uff0c\u4e0d\u8fc7\u8fd9\u91cc\u4e0d\u8fdb\u884c\u8be6\u7ec6\u89e3\u91ca\uff0c\u6211\u4eec\u4e3b\u8981\u7740\u91cd\u4ecb\u7ecd\u6784\u5efaPattern\u7684\u65b9\u6cd5\uff1a Prompt-Tuning .\u63a5\u4e0b\u6765\u6211\u4eec\u6839\u636e\u4f7f\u7528\u573a\u666f\u7684\u4e0d\u540c\uff0c\u5206\u522b\u4ecb\u7ecd\u51e0\u79cd\u6210\u719f\u7684Prompt-Tuning\u65b9\u6cd5.","title":"5.2 PET\u6a21\u578b"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#53-prompt-oriented-fine-tuning","text":"Prompt-Oriented Fine-Tuning\u8bad\u7ec3\u65b9\u6cd5\u7684\u672c\u8d28\u662f\u5c06\u76ee\u6807\u4efb\u52a1\u8f6c\u6362\u4e3a\u9002\u5e94\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\uff0c\u4ee5\u9002\u5e94\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u5b66\u4e60\u4f53\u7cfb\u3002 \u4f8b\u5982\u6211\u4eec\u5229\u7528BERT\u6a21\u578b\u6765\u5b9e\u73b0\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\uff1a \u4f20\u7edfFine-Tuning\u65b9\u5f0f: \u5c06\u8bad\u7ec3\u6587\u672c\u7ecf\u8fc7BERT\u7f16\u7801\u540e\uff0c\u751f\u6210\u5411\u91cf\u8868\u5f81\uff0c\u518d\u5229\u7528\u8be5\u5411\u91cf\u8868\u5f81\uff0c\u8fde\u63a5\u5168\u8fde\u63a5\u5c42\uff0c\u5b9e\u73b0\u6700\u7ec8\u7684\u60c5\u611f\u7c7b\u522b\u8bc6\u522b\u3002\u4f46\u662f\u8fd9\u79cd\u65b9\u5f0f\u5b58\u5728\u4e00\u4e2a\u663e\u5f0f\u7684\u5f0a\u7aef\uff1a\u9884\u8bad\u7ec3\u4efb\u52a1\u4e0e\u4e0b\u6e38\u4efb\u52a1\u5b58\u5728gap\u3002\u56de\u5fc6BERT\u7684\u9884\u8bad\u7ec3\u4efb\u52a1\uff1aMLM\u4e0eNSP\uff0c\u7b80\u5355\u6765\u8bf4\uff0cMLM\u4efb\u52a1\u662f\u901a\u8fc7\u5206\u7c7b\u6a21\u578b\u8bc6\u522b\u88abMASK\u6389\u7684\u8bcd\uff0c\u7c7b\u522b\u5927\u5c0f\u5373\u4e3a\u6574\u4e2a\u8bcd\u8868\u5927\u5c0f\uff1bNSP\u4efb\u52a1\u662f\u9884\u6d4b\u4e24\u4e2a\u53e5\u5b50\u4e4b\u95f4\u7684\u5173\u7cfb\u3002 \u800cPrompt-Oriented Fine-Tuning\u65b9\u5f0f: \u5c06\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u8f6c\u6362\u4e3a\u7c7b\u4f3c\u4e8eMLM\u4efb\u52a1\u7684[MASK]\u9884\u6d4b\u4efb\u52a1\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u6211\u4eec\u6784\u5efa\u5982\u4e0b\u7684prompt\u6587\u672c: prompt = It was [MASK]. \u5c06prompt\u6587\u672c\u4e0e\u8f93\u5165\u6587\u672ctext = The film is attractive.\u8fdb\u884c\u62fc\u63a5\u751f\u6210: It was [MASK].The film is attractive.\uff0c\u8f93\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\uff0c\u8bad\u7ec3\u4efb\u52a1\u76ee\u6807\u548cMLM\u4efb\u52a1\u7684\u76ee\u6807\u4e00\u81f4\uff0c\u5373\u8bc6\u522b\u88ab[MASK]\u6389\u7684\u8bcd\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u53ef\u4ee5\u5c06\u4e0b\u6e38\u4efb\u52a1\u8f6c\u6362\u4e3a\u548c\u9884\u8bad\u7ec3\u4efb\u52a1\u8f83\u4e3a\u4e00\u81f4\u7684\u4efb\u52a1\uff0c\u5b9e\u9a8c\u8bc1\u660e\uff0cPrompt-Oriented Fine-Tuning\u76f8\u5bf9\u4e8e\u5e38\u89c4\u7684Fine-Tuning\uff0c\u6548\u679c\u4f1a\u5f97\u5230\u660e\u663e\u63d0\u5347\uff08Prompt\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\uff09\u3002 \u57fa\u4e8e\u4e0a\u8ff0\u5185\u5bb9\u53ef\u4ee5\u4e86\u89e3\uff0c\u5728Prompt-Oriented Fine-Tuning\u65b9\u6cd5\u4e2d\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u662f\u53ef\u53d8\u7684\u3002\u5176\u5b9e\u5c06Prompt-Oriented Fine-Tuning\u65b9\u6cd5\u653e\u5728Prompt-Tuning\u8fd9\u4e2a\u90e8\u5206\u5408\u7406\u4e5f\u4e0d\u5408\u7406\uff0c\u56e0\u4e3a\u5b83\u5176\u5b9e\u662fPrompt-Tuning+Fine-Tuning\u7684\u7ed3\u5408\u4f53\uff0c\u5c06\u5b83\u89c6\u4e3aFine-Tuning\u7684\u5347\u7ea7\u7248\u662f\u6700\u5408\u9002\u7684\u3002 Prompt-Oriented Fine-Tuning\u65b9\u6cd5\u5728BERT\u7c7b\u76f8\u5bf9\u8f83\u5c0f\u7684\u6a21\u578b\u4e0a\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u662f\u968f\u7740\u6a21\u578b\u8d8a\u6765\u8d8a\u5927\uff0c\u5982\u679c\u6bcf\u6b21\u9488\u5bf9\u4e0b\u6e38\u4efb\u52a1\uff0c\u90fd\u9700\u8981\u66f4\u65b0\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\uff0c\u8d44\u6e90\u6210\u672c\u53ca\u65f6\u95f4\u6210\u672c\u90fd\u4f1a\u5f88\u9ad8\uff0c\u56e0\u6b64\u540e\u7eed\u9646\u7eed\u63d0\u51fa\u4e86\u4e0d\u66f4\u65b0\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\uff0c\u5355\u7eaf\u53ea\u9488\u5bf9prompt\u8fdb\u884c\u8c03\u4f18\u7684\u65b9\u6cd5\uff0c\u4f8b\u5982**Hard Prompt**\u548c**Soft Prompt**\u3002 \u4e0b\u9762\u662f\u5e38\u89c1\u4e0b\u6e38\u4efb\u52a1\u7684Prompt\u8bbe\u8ba1\uff1a","title":"5.3 Prompt-Oriented Fine-Tuning"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#54-hard-prompt-soft-prompt","text":"Hard Prompt (\u79bb\u6563\u63d0\u793a)\uff1a\u662f\u4e00\u79cd\u56fa\u5b9a\u7684\u63d0\u793a\u6a21\u677f\uff0c\u901a\u8fc7\u5c06\u7279\u5b9a\u7684\u5173\u952e\u8bcd\u6216\u77ed\u8bed(\u771f\u5b9e\u7684\u6587\u672c\u5b57\u7b26\u4e32)\u76f4\u63a5\u5d4c\u5165\u5230\u6587\u672c\u4e2d\uff0c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7b26\u5408\u8981\u6c42\u7684\u6587\u672c\u3002\u8fd9\u79cd\u63d0\u793a\u65b9\u6cd5\u7684\u7279\u70b9\u5728\u4e8e\uff0c\u63d0\u793a\u6a21\u677f\u662f\u56fa\u5b9a\u7684\uff0c\u4e0d\u80fd\u6839\u636e\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u9700\u6c42\u8fdb\u884c\u8c03\u6574\u3002 \u4e0a\u8ff0\u6211\u4eec\u8bb2\u8ff0\u7684PET \u662f\u4e00\u79cd\u8f83\u4e3a\u7ecf\u5178\u7684\u786c\u6a21\u677f\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e3b\u8981\u601d\u60f3\uff1a\u5c06\u95ee\u9898\u5efa\u6a21\u6210\u4e00\u4e2a\u5b8c\u5f62\u586b\u7a7a\u95ee\u9898\uff0c\u7136\u540e\u4f18\u5316\u6700\u7ec8\u7684\u8f93\u51fa\u8bcd\u3002 \u867d\u7136 PET \u4e5f\u662f\u5728\u4f18\u5316\u6574\u4e2a\u6a21\u578b\u7684\u53c2\u6570 \uff0c\u4f46\u662f\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684 Finetuning \u65b9\u6cd5\uff0c \u5bf9\u6570\u636e\u91cf\u9700\u6c42\u66f4\u5c11 \u3002 \u4f46\u662f\u786c\u6a21\u677f\u4ea7\u751f\u4f9d\u8d56\u4e24\u79cd\u65b9\u5f0f\uff1a\u6839\u636e\u7ecf\u9a8c\u7684\u4eba\u5de5\u8bbe\u8ba1 & \u81ea\u52a8\u5316\u641c\u7d22\uff1b\u4ece\u4e0a\u56fe\u4ecb\u7ecd\u4e2d\u53ef\u4ee5\u770b\u51fa\u786c\u6a21\u677f \u5bf9\u4e8eprompt\uff0c\u6539\u53d8prompt\u4e2d\u7684\u5355\u4e2a\u5355\u8bcd \u4f1a\u7ed9\u5b9e\u9a8c\u7ed3\u679c\u5e26\u6765\u5de8\u5927\u7684\u5dee\u5f02\uff0c \u6240\u4ee5\u4e5f\u4e3a\u540e\u7eed\u4f18\u5316\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u5982\u7d22\u6027\u76f4\u63a5\u653e\u5f03\u786c\u6a21\u677f\uff0c\u53bb\u4f18\u5316 prompt token embedding\u5373Soft Prompt\u3002 Soft Prompt (\u8fde\u7eed\u63d0\u793a) \uff1a\u662f\u6307\u901a\u8fc7\u7ed9\u6a21\u578b\u8f93\u5165\u4e00\u4e2a\u53ef\u53c2\u6570\u5316\u7684\u63d0\u793a\u6a21\u677f\uff0c\u4ece\u800c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7b26\u5408\u7279\u5b9a\u8981\u6c42\u7684\u6587\u672c\u3002\u8fd9\u79cd\u63d0\u793a\u65b9\u6cd5\u7684\u7279\u70b9\u5728\u4e8e\uff0c\u63d0\u793a\u6a21\u677f\u4e2d\u7684\u53c2\u6570\u53ef\u4ee5\u6839\u636e\u5177\u4f53\u4efb\u52a1\u548c\u9700\u6c42\u8fdb\u884c\u8c03\u6574\uff0c\u4ee5\u8fbe\u5230\u6700\u4f73\u7684\u751f\u6210\u6548\u679c\u3002 \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u4e3b\u8981\u9488\u5bf9soft Prompt\u65b9\u5f0f\u8fdb\u884c\u8bb2\u8ff0\uff1a","title":"5.4 Hard Prompt &amp; Soft Prompt"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#541","text":"Soft Prompt\u76ee\u7684\u5176\u5c06\u6a21\u677f\u8f6c\u6362\u4e3a\u53ef\u4ee5\u8fdb\u884c\u4f18\u5316\u7684\u8fde\u7eed\u5411\u91cf\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u663e\u5f0f\u5730\u6307\u5b9a\u8fd9\u4e9b\u6a21\u677f\u4e2d\u5404\u4e2atoken\u5177\u4f53\u662f\u4ec0\u4e48\uff0c\u800c\u53ea\u9700\u8981\u5728\u8bed\u4e49\u7a7a\u95f4\u4e2d\u8868\u793a\u4e00\u4e2a\u5411\u91cf\u5373\u53ef\u3002 \u8fd9\u6837\uff0c\u4e0d\u540c\u7684\u4efb\u52a1\u3001\u6570\u636e\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u5728\u8bed\u4e49\u7a7a\u95f4\u4e2d\u5bfb\u627e\u82e5\u5e72\u5408\u9002\u7684\u5411\u91cf\uff0c\u6765\u4ee3\u8868\u6a21\u677f\u4e2d\u7684\u6bcf\u4e00\u4e2a\u8bcd\uff0c\u76f8\u8f83\u4e8e\u663e\u5f0f\u7684token\uff0c\u8fd9\u7c7btoken\u79f0\u4e3a \u4f2a\u6807\u8bb0\uff08Pseudo Token\uff09 \u3002\u4e0b\u9762\u7ed9\u51fa\u57fa\u4e8e\u8fde\u7eed\u63d0\u793a\u7684\u6a21\u677f\u5b9a\u4e49\uff1a \u5047\u8bbe\u9488\u5bf9\u5206\u7c7b\u4efb\u52a1\uff0c\u7ed9\u5b9a\u4e00\u4e2a\u8f93\u5165\u53e5\u5b50 x x \uff0c\u8fde\u7eed\u63d0\u793a\u7684\u6a21\u677f\u53ef\u4ee5\u5b9a\u4e49\u4e3a T=[x],[v1],[v2],...,[vn][MASK] T=[x],[v1],[v2],...,[vn][MASK] \uff1a\u5176\u4e2d[v1]\u5219\u662f\u4f2a\u6807\u8bb0\uff0c\u5176\u4ec5\u4ee3\u8868\u4e00\u4e2a\u62bd\u8c61\u7684token\uff0c\u5e76\u6ca1\u6709\u5b9e\u9645\u7684\u542b\u4e49\uff0c\u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u5411\u91cf\u3002 \u603b\u7ed3\u6765\u8bf4\uff1aSoft Prompt\u65b9\u6cd5\uff0c\u662f\u5c06\u6a21\u677f\u53d8\u4e3a\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\uff0c\u4e0d\u540c\u7684\u6837\u672c\u53ef\u4ee5\u5728\u8fde\u7eed\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\u5bfb\u627e\u5408\u9002\u7684\u4f2a\u6807\u8bb0\uff0c\u540c\u65f6\u4e5f\u589e\u52a0\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u8fde\u7eed\u6cd5\u9700\u8981\u5f15\u5165\u5c11\u91cf\u7684\u53c2\u6570\u5e76\u5728\u8bad\u7ec3\u65f6\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff0c\u4f46\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u662f\u4e0d\u53d8\u7684\uff0c\u53d8\u7684\u662fprompt token\u5bf9\u5e94\u7684\u8bcd\u5411\u91cf\uff08Word Embedding\uff09\u8868\u5f81\u53ca\u5176\u4ed6\u5f15\u5165\u7684\u5c11\u91cf\u53c2\u6570\u3002 \u76ee\u524d\u57fa\u4e8e\u8fde\u7eed\u63d0\u793a\u7684Prompt-Tuning\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u4ee5\u4e0b\u5217\u4e09\u7bc7\u8bba\u6587\u4e3a\u4ee3\u8868\uff0c\u5206\u522b\u4f5c\u7b80\u8981\u4ecb\u7ecd\uff1a \u300aThe Power of Scale for Parameter-Efficient Prompt Tuning\u300b\uff1a\u4ee3\u8868\u65b9\u6cd5\u4e3aPrompt Tuning \u300aGPT Understands, Too\u300b\uff1a\u4ee3\u8868\u65b9\u6cd5\u4e3aP-tuning \u300aPPT: Pre-trained Prompt Tuning for Few-shot Learning\u300b\uff1a\u4ee3\u8868\u65b9\u6cd5PPT","title":"5.4.1 \u8fde\u7eed\u63d0\u793a\u6a21\u677f"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#542-prompt-tuningnlg","text":"Prompt Tuning\uff08\u57fa\u4e8eT5\u6a21\u578b\u6765\u505a\u7684\uff09\u65b9\u6cd5\u4e3a\u6bcf\u4e00\u4e2a\u8f93\u5165\u6587\u672c\u5047\u8bbe\u4e00\u4e2a\u56fa\u5b9a\u524d\u7f00\u63d0\u793a\uff0c\u8be5\u63d0\u793a\u8868\u7531\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u5316\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u65f6\u8fdb\u884c\u66f4\u65b0\uff0c\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u9884\u8bad\u7ec3\u7684\u5927\u6a21\u578b\u53c2\u6570\u88ab\u51bb\u7ed3\u3002 \u5f62\u5f0f\u5316\u7684\u63cf\u8ff0\u5982\u4e0b\uff1a \u7ed9\u5b9a n n \u4e2atokens\uff0c\u8bb0\u4f5c\u200b x1, ...,xn x1, ...,xn \uff0c\u901a\u8fc7\u4e00\u4e2a\u9884\u8bad\u7ec3\u6a21\u578b\u5bf9\u5e94\u7684embedding table\uff0c\u53ef\u4ee5\u5c06\u200b n n \u4e2atoken\u8868\u793a\u4e3a\u4e00\u4e2a\u5411\u91cf\u77e9\u9635\u200b (X_e->R^{n*e}) (X_e->R^{n*e}) \uff0c\u5176\u4e2d\u200b e e \u662f\u5411\u91cf\u7684\u7ef4\u5ea6\uff08\u5176\u4e0e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u914d\u7f6e\u6709\u5173\uff0c\u4f8b\u5982BERT-base\u662f768\uff09\u3002\u8fde\u7eed\u6a21\u677f\u4e2d\u7684\u6bcf\u4e2a\u4f2a\u6807\u8bb0\u200b v_i v_i \u53ef\u4ee5\u89c6\u4e3a\u53c2\u6570\uff0c\u4e5f\u53ef\u4ee5\u89c6\u4e3a\u4e00\u4e2atoken\uff0c\u56e0\u6b64\uff0c\u53ef\u4ee5\u901a\u8fc7\u53e6\u4e00\u4e2aembedding table\u83b7\u5f97\u200b p p \u4e2a\u4f2a\u6807\u8bb0token\u6807\u8bb0\u4e3a\u5411\u91cf\u77e9\u9635\u200b (P_e->R^{p*e}) (P_e->R^{p*e}) \uff0c\u7136\u540e\u5c06\u6587\u672c\u548cPrompt\u62fc\u63a5\u83b7\u5f97\u65b0\u7684\u8f93\u5165\u200b [P_e:X_e]->R^{(p+n)*e} [P_e:X_e]->R^{(p+n)*e} .\u8fd9\u4e2a\u65b0\u7684\u8f93\u5165\u5c06\u4f1a\u5582\u5165\u4e00\u4e2aMLP\u83b7\u5f97\u65b0\u7684\u8868\u5f81\u3002\u6ce8\u610f\uff0c\u53ea\u6709prompt\u5bf9\u5e94\u7684\u5411\u91cf\u8868\u5f81\u53c2\u6570P (P_e->R^{p*e}) (P_e->R^{p*e}) \u4f1a\u968f\u7740\u8bad\u7ec3\u8fdb\u884c\u66f4\u65b0 \u6bcf\u4e2a\u4f2a\u6807\u8bb0\u7684\u521d\u59cb\u5316\u53ef\u4ee5\u6709\u4e0b\u5217\u51e0\u79cd\u60c5\u51b5\uff1a \u6700\u7b80\u5355\u7684\u662f\u968f\u673a\u521d\u59cb\u5316\uff1a\u5373\u968f\u673a\u521d\u59cb\u5316\u4e00\u4e2a\u9762\u5411\u6240\u6709\u4f2a\u6807\u8bb0\u7684embedding table\uff0c\u53ef\u91c7\u7528\u6b63\u6001\u5206\u5e03\u6216\u8005\u5747\u5300\u5206\u5e03\u7b49\uff1b \u6bcf\u4e2atoken\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5df2\u6709\u7684embedding table\u8fdb\u884c\u521d\u59cb\u5316\uff0c\u6b64\u65f6\uff0c\u6bcf\u4e00\u4e2a\u4f2a\u6807\u8bb0\u5148\u968f\u673a\u6307\u5b9a\u8bcd\u8868\u4e2d\u7684\u4e00\u4e2a\u8bcd\uff0c\u5e76\u53d6\u5bf9\u5e94\u8bcd\u7684embedding\u4f5c\u4e3a\u8fd9\u4e2a\u4f2a\u6807\u8bb0\u7684\u521d\u59cb\u5316\uff1b \u5728\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u4f7f\u7528label word\uff08verbalizer\uff09\u5bf9\u5e94\u7684embedding\u4f5c\u4e3a\u521d\u59cb\u5316\uff0c\u53ef\u4ee5\u6709\u6548\u9650\u5236\u6a21\u578b\u8f93\u51fa\u7684\u662f\u9884\u8bbe\u7684\u8f93\u51fa\u7c7b\u5bf9\u5e94\u7684word\u3002 \u56e0\u6b64\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2a\u4f2a\u6807\u8bb0\u4ee5\u53ca\u5bf9\u5e94\u7684MLP\u53c2\u6570\u90fd\u53ef\u4ee5\u5f97\u5230\u8bad\u7ec3\uff0c\u5bf9\u4e8e\u4e0d\u540c\u7684\u8f93\u5165\u53e5\u5b50 \uff0c\u8fd9\u4e9b\u4f2a\u6807\u8bb0\u5bf9\u5e94\u7684embedding\u4e5f\u5404\u4e0d\u76f8\u540c\uff0c\u8fbe\u5230\u4e86\u9884\u671f\u7684\u76ee\u7684\u3002 Prompt Tuning\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u5927\u6a21\u578b\u7684\u5fae\u8c03\u65b0\u8303\u5f0f \u6a21\u578b\u53c2\u6570\u89c4\u6a21\u5927\u4e86\u4e4b\u540e\uff0c\u53ef\u4ee5\u5c06\u5927\u6a21\u578b\u53c2\u6570\u56fa\u5b9a\uff0c\u6307\u5b9a\u9644\u52a0\u53c2\u6570\u6765\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u4e14\u9002\u914d\u6027\u80fd\u57fa\u672c\u548c\u5168\u53c2\u6570\u5fae\u8c03\u76f8\u5f53\u3002 \u7f3a\u70b9\uff1a \u5728\u5c0f\u6837\u672c\u5b66\u4e60\u573a\u666f\u4e0a\u8868\u73b0\u4e0d\u592a\u884c \u6536\u655b\u901f\u5ea6\u6bd4\u8f83\u6162 \u8c03\u53c2\u6bd4\u8f83\u590d\u6742","title":"5.4.2 Prompt Tuning\uff08NLG\u4efb\u52a1\uff09"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#543-p-tuningnlu","text":"P-tuning\u7684\u8be6\u7ec6\u5185\u5bb9\u8bf7\u53c2\u8003\u8bba\u6587\u89e3\u8bfb\uff1aGPT Understands, Too\u3002 P-tuning\u662f\u53e6\u4e00\u4e2a\u5177\u6709\u4ee3\u8868\u6027\u7684\u8fde\u7eed\u63d0\u793a\u65b9\u6cd5\uff0c\u4e3b\u8981\u9488\u5bf9\u7684\u662fNLU\u4efb\u52a1\uff0c\u65b9\u6cd5\u56fe\u5982\u4e0b\u6240\u793a\uff08\u56fe\u4e2d\u7684 P_i P_i \u7b49\u4ef7\u4e8e\u4e0a\u6587\u7684 v_i v_i \uff0c\u8868\u793a\u4f2a\u6807\u8bb0\uff09, \u8c37\u6b4c\u4e8e2021\u5e74\u53d1\u8868\u3002 P-Tuning\u65b9\u6cd5\u4e2d\u56db\u4e2a\u6280\u5de7\u70b9\uff1a \u8003\u8651\u5230\u8fd9\u4e9b\u4f2a\u6807\u8bb0\u7684\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb \uff1a\u8ba4\u4e3a [P_1] [P_1] \u4e0e [P_2] [P_2] \u662f\u6709\u5148\u540e\u5173\u7cfb\u7684\uff0c\u800ctransformer\u65e0\u6cd5\u663e\u5f0f\u5730\u523b\u753b\u8fd9\u5c42\u5173\u7cfb\uff0c\u56e0\u6b64\u5f15\u5165Prompt Encoder\uff0c\u5b9e\u9645\u8fc7\u7a0b\u4e2d\u91c7\u7528\u4e00\u5c42Bi-LSTM+\u4e24\u4e2a\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u7ec4\u6210\uff1b \u6307\u5b9a\u4e0a\u4e0b\u6587\u8bcd \uff1a\u5982\u679c\u6a21\u677f\u5168\u90e8\u662f\u4f2a\u6807\u8bb0\uff0c\u5728\u8bad\u7ec3\u65f6\u65e0\u6cd5\u5f88\u597d\u5730\u63a7\u5236\u8fd9\u4e9b\u6a21\u677f\u671d\u7740\u4e0e\u5bf9\u5e94\u53e5\u5b50\u76f8\u4f3c\u7684\u8bed\u4e49\u4e0a\u4f18\u5316\uff0c\u56e0\u6b64\u9009\u5b9a\u90e8\u5206\u5177\u6709\u4e0e\u5f53\u524d\u53e5\u5b50\u8bed\u4e49\u4ee3\u8868\u6027\u7684\u4e00\u4e9b\u8bcd\u4f5c\u4e3a\u4e00\u4e9b\u4f2a\u6807\u8bb0\u7684\u521d\u59cb\u5316\uff08\u4f8b\u5982\u4e0a\u56fe\u4e2d\u201ccapital\u201d\u3001\u201cBritain\u201d\u7b49\uff09\uff1b \u91cd\u53c2\u6570\uff08Reparameterization\uff09 \uff1a\u5177\u4f53\u5230\u4ee3\u7801\u5b9e\u73b0\u4e0a\uff0cP-tuning\u5148\u901a\u8fc7\u4e00\u4e2aPrompt Encoder\u8868\u5f81\u8fd9\u4e9b\u4f2a\u6807\u8bb0\u540e\uff0c\u76f4\u63a5\u5c06\u8fd9\u4e9b\u65b0\u7684\u8868\u5f81\u8986\u76d6\u5230\u5bf9\u5e94\u7684embedding table\u4e0a\uff0c\u6362\u53e5\u8bdd\u8bf4\uff0cPrompt Encoder\u53ea\u5728\u8bad\u7ec3\u65f6\u5019\u4f1a\u4f7f\u7528\u5230\uff0c\u800c\u5728\u63a8\u7406\u9636\u6bb5\u5219\u4e0d\u518d\u4f7f\u7528\u3002 \u6df7\u5408\u63d0\u793a\uff08Hydride Prompt\uff09 \uff1a\u5c06\u8fde\u7eed\u63d0\u793a\u4e0e\u79bb\u6563token\u8fdb\u884c\u6df7\u5408\uff0c\u4f8b\u5982 [x][it][v1][mask]\u200b [x][it][v1][mask]\u200b P-Tuning V2\u662f\u5347\u7ea7\u7248\u672c\uff0c\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u7684\u6bcf\u4e00\u5c42\u90fd\u5e94\u7528\u8fde\u7eed\u7684 prompts \u5e76\u5bf9 prompts \u53c2\u6570\u8fdb\u884c\u66f4\u65b0\u4f18\u5316\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u662f\u4e5f\u662f\u9488\u5bf9 NLU \u4efb\u52a1\u4f18\u5316\u548c\u9002\u914d\u7684\u3002","title":"5.4.3 P-tuning\uff08NLU\u4efb\u52a1\uff09"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#544-pptpre-trained-prompt-tuning","text":"Prompt-Tuning\u901a\u5e38\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u573a\u666f\uff0c\u4f46\u662f\u7531\u4e8e\u8fde\u7eed\u7684\u6a21\u677f\u662f\u968f\u673a\u521d\u59cb\u5316\u7684\uff0c\u5373\u5176\u5b58\u5728\u65b0\u7684\u53c2\u6570\uff0c\u5c11\u91cf\u6837\u672c\u53ef\u80fd\u4f9d\u7136\u5f88\u96be\u786e\u4fdd\u8fd9\u4e9b\u6a21\u677f\u88ab\u5f88\u597d\u5730\u4f18\u5316\u3002\u56e0\u6b64\u7b80\u5355\u7684\u65b9\u6cd5\u5c31\u662f\u5bf9\u8fd9\u4e9b\u8fde\u7eed\u7684\u6a21\u677f\u4e5f\u8fdb\u884c\u9884\u8bad\u7ec3\u3002PPT\u65e8\u5728\u901a\u8fc7\u5148\u8ba9\u8fd9\u4e9b\u8fde\u7eed\u63d0\u793a\u5728\u5927\u91cf\u65e0\u6807\u6ce8\u7684\u9884\u8bad\u7ec3\u8bed\u6599\u8fdb\u884c\u9884\u8bad\u7ec3\uff08\u6ce8\u610f\uff0c\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0cPre-train-model\u53c2\u6570\u56fa\u5b9a\u4e0d\u53d8\uff0c\u53ea\u6539\u53d8soft prompt\uff09\uff0c\u7136\u540e\u5c06\u5176\u52a0\u8f7d\u5230\u5bf9\u5e94\u4e0b\u6e38\u4efb\u52a1\u7684PLM\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff08\u56fe\u4e2d\u7684 P\u200b P\u200b \u5373\u8fde\u7eed\u7684\u63d0\u793a\u6a21\u677f\uff0c <X>\u200b <X>\u200b \u5e76\u8868\u793a\u4e3amask token\uff09\uff1a \u6bcf\u4e00\u7c7b\u4efb\u52a1\u90fd\u4f1a\u9884\u8bad\u7ec3\u4e00\u4e2asoft Prompt, \u9884\u8bad\u7ec3\u540e\u7684soft Prompt\u53ef\u4ee5\u76f4\u63a5\u8fd0\u7528\u5230\u76f8\u4f3c\u4efb\u52a1\u4e2d \u9996\u5148\u5728\u5927\u91cf\u65e0\u6807\u6ce8\u8bed\u6599\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u83b7\u5f97\u8bad\u7ec3\u597d\u7684\u8fde\u7eed\u63d0\u793a\uff08\u521d\u59cb\u5316\u4e0b\u6e38\u5fae\u8c03\u4efb\u52a1\u7684soft prompt\uff09\uff1b \u5bf9\u4e0b\u6e38\u4efb\u52a1\uff08\u662f\u975e\u95ee\u7b54\u3001NLI\u3001\u6587\u672c\u5339\u914d\u7b49\uff09\uff0c\u52a0\u8f7d\u8fd9\u4e9b\u8bad\u7ec3\u597d\u7684\u63d0\u793a\u4e4b\u540e\uff0c\u8fdb\u884c\u5fae\u8c03\uff0c\u6216\u8005\u76f4\u63a5\u8fdb\u884czero-shot\u9884\u6d4b\u3002 PPT\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u9884\u8bad\u7ec3soft-prompt\u5e26\u6765\u4e86 \u5c0f\u6837\u672c\u5b66\u4e60\u573a\u666f\u4e0a\u7684\u663e\u8457\u63d0\u5347 \u7f13\u89e3\u4e86prompt-tuning\u6536\u655b\u6162\u7684\u95ee\u9898 \u7f3a\u70b9 \u5408\u5e76\u540c\u7c7b\u4eba\u7269\u9700\u8981\u4eba\u5de5\u8bbe\u8ba1 \u4e0b\u56fe\u603b\u7ed3\u51e0\u79cdtemplate\u4f18\u5316\u8fdb\u884c\u7684\u5bf9\u6bd4\u3002","title":"5.4.4 PPT\uff08Pre-trained Prompt Tuning\uff09"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8.html#_2","text":"\u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86NLP\u53d1\u5c55\u7684\u56db\u79cd\u8303\u5f0f\u3001Fine-Tuning\u4ee5\u53caPrompt-Tuning\u7684\u57fa\u672c\u601d\u60f3\u548c\u539f\u7406 \u672c\u7ae0\u8282\u5185\u5bb9\u8be6\u7ec6\u4e86\u53d9\u8ff0\u4e86Prompt-Tuning\u4e3b\u8981\u4ee3\u8868\u65b9\u6cd5 \u5206\u522b\u5bf9\u4e0d\u540c\u7c7b\u578b\u67b6\u6784\u7684\u4ee3\u8868\u6a21\u578b\u5982\uff1aBERT\u3001GPT\u3001T5\u7b49\u76f8\u5173\u6a21\u578b\u8fdb\u884c\u4ecb\u7ecd","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html","text":"LLM\u7684Prompt-Tuning\u4e3b\u6d41\u65b9\u6cd5 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u4f01\u4e1a\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684Prompt-Tuning\u65b9\u6cd5\u7c7b\u578b. \u7406\u89e3Prefix-Tuning\u3001Adapter-Tuning\u3001LoRA\u4e09\u79cd\u5927\u6a21\u578b\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5\u7684\u539f\u7406 \u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684Prompt-Tuning \u00b6 \u8fd1\u4e24\u5e74\u6765\uff0c\u968f\u7740Prompt-Tuning\u6280\u672f\u7684\u53d1\u5c55\uff0c\u6709\u8bf8\u591a\u5de5\u4f5c\u53d1\u73b0\uff0c\u5bf9\u4e8e\u8d85\u8fc710\u4ebf\u53c2\u6570\u91cf\u7684\u6a21\u578b\u6765\u8bf4\uff0cPrompt-Tuning\u6240\u5e26\u6765\u7684\u589e\u76ca\u8fdc\u8fdc\u9ad8\u4e8e\u6807\u51c6\u7684Fine-tuning\uff0c\u5c0f\u6837\u672c\u751a\u81f3\u662f\u96f6\u6837\u672c\u7684\u6027\u80fd\u4e5f\u80fd\u591f\u6781\u5927\u5730\u88ab\u6fc0\u53d1\u51fa\u6765\uff0c\u5f97\u76ca\u4e8e\u8fd9\u4e9b\u6a21\u578b\u7684 \u53c2\u6570\u91cf\u8db3\u591f\u5927 \uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u4e86 \u8db3\u591f\u591a\u7684\u8bed\u6599 \uff0c\u540c\u65f6\u8bbe\u8ba1\u7684 \u9884\u8bad\u7ec3\u4efb\u52a1\u8db3\u591f\u6709\u6548 \u3002\u6700\u4e3a\u7ecf\u5178\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5219\u662f2020\u5e74\u63d0\u51fa\u7684GPT-3\uff0c\u5176\u62e5\u6709\u5927\u7ea61750\u4ebf\u7684\u53c2\u6570\uff0c\u4e14\u53d1\u73b0\u53ea\u9700\u8981\u8bbe\u8ba1\u5408\u9002\u7684\u6a21\u677f\u6216\u6307\u4ee4\u5373\u53ef\u4ee5 \u5b9e\u73b0\u514d\u53c2\u6570\u8bad\u7ec3\u7684\u96f6\u6837\u672c\u5b66\u4e60 \u3002 2022\u5e74\u5e95\u52302023\u5e74\u521d\uff0c\u56fd\u5185\u5916\u4e5f\u6380\u8d77\u4e86AIGC\u7684\u6d6a\u6f6e\uff0c\u5178\u578b\u4ee3\u8868\u662fOpenAI\u53d1\u5e03\u7684ChatGPT\u3001GPT-4\u5927\u6a21\u578b\uff0cGoogle\u53d1\u5e03\u7684Bard\u4ee5\u53ca\u767e\u5ea6\u516c\u53f8\u53d1\u5e03\u7684\u6587\u5fc3\u4e00\u8a00\u7b49\u3002\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u8fdb\u5165\u65b0\u7684\u7eaa\u5143\uff0c\u800c\u8fd9\u4e9b\u8f70\u52a8\u4e16\u754c\u7684\u4ea7\u7269\uff0c\u79bb\u4e0d\u5f00\u5f3a\u5927\u7684Prompt-Tuning\u6280\u672f\u3002\u672c\u6587\u9ed8\u8ba4\u4ee5GPT-3\u4e3a\u4f8b\uff0c\u4ecb\u7ecd\u51e0\u4e2a\u9762\u5411\u8d85\u5927\u89c4\u6a21\u7684Prompt-Tuning\u65b9\u6cd5\uff0c\u5206\u522b\u4e3a\uff1a \u4e0a\u4e0b\u6587\u5b66\u4e60 In-Context Learning\uff08ICL\uff09 \uff1a\u76f4\u63a5\u6311\u9009\u5c11\u91cf\u7684\u8bad\u7ec3\u6837\u672c\u4f5c\u4e3a\u8be5\u4efb\u52a1\u7684\u63d0\u793a\uff1b \u6307\u4ee4\u5b66\u4e60 Instruction-Tuning \uff1a\u6784\u5efa\u4efb\u52a1\u6307\u4ee4\u96c6\uff0c\u4fc3\u4f7f\u6a21\u578b\u6839\u636e\u4efb\u52a1\u6307\u4ee4\u505a\u51fa\u53cd\u9988\uff1b \u601d\u7ef4\u94fe Chain-of-Thought\uff08CoT\uff09 \uff1a\u7ed9\u4e88\u6216\u6fc0\u53d1\u6a21\u578b\u5177\u6709\u63a8\u7406\u548c\u89e3\u91ca\u7684\u4fe1\u606f\uff0c\u901a\u8fc7\u7ebf\u6027\u94fe\u5f0f\u7684\u6a21\u5f0f\u6307\u5bfc\u6a21\u578b\u751f\u6210\u5408\u7406\u7684\u7ed3\u679c\u3002 1. In-Context Learning(\u4e0a\u4e0b\u6587\u5b66\u4e60) \u00b6 In-Context learning\uff08ICL\uff09\u6700\u65e9\u5728GPT-3\u4e2d\u63d0\u51fa\uff0c \u65e8\u5728\u4ece\u8bad\u7ec3\u96c6\u4e2d\u6311\u9009\u5c11\u91cf\u7684\u6807\u6ce8\u6837\u672c\uff0c\u8bbe\u8ba1\u4efb\u52a1\u76f8\u5173\u7684\u6307\u4ee4\u5f62\u6210\u63d0\u793a\u6a21\u677f\uff0c\u7528\u4e8e\u6307\u5bfc\u6d4b\u8bd5\u6837\u672c\u751f\u6210\u76f8\u5e94\u7684\u7ed3\u679c\u3002 \u5e38\u7528\u7684In-context learning\u65b9\u6cd5\u5305\u62ec\uff1a zero-shot learning \u5b9a\u4e49: \u7ed9\u51fa\u4efb\u52a1\u7684\u63cf\u8ff0, \u7136\u540e\u63d0\u4f9b\u6d4b\u8bd5\u6570\u636e\u5bf9\u5176\u8fdb\u884c\u9884\u6d4b, \u76f4\u63a5\u8ba9\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53bb\u8fdb\u884c\u4efb\u52a1\u6d4b\u8bd5. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. one-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u4e00\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u4e00\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u82f1\u8bed\u7ffb\u8bd1\u4e3a\u6cd5\u8bed, \u5e94\u8be5\u8fd9\u4e48\u7ffb\u8bd1. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. few-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u591a\u4e2a\u6837\u672c\uff08\u4e00\u822c10-100\u6761\uff09\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u591a\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u5e94\u8be5\u5982\u4f55\u5de5\u4f5c. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u518d\u89c1->goodbye, \u8d2d\u4e70->purchase, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. \u76ee\u524dIn-context Learning\u4f9d\u7136\u4e0e\u666e\u901a\u7684fine-tuning\u6709\u4e00\u5b9a\u5dee\u8ddd\uff0c\u4e14\u9884\u6d4b\u7684\u7ed3\u679c\u65b9\u5dee\u5f88\u5927\uff0c\u540c\u65f6\u4e5f\u9700\u8981\u82b1\u8d39\u65f6\u95f4\u8003\u8651template\u7684\u6784\u5efa\u3002 2. Instruction-Tuning(\u6307\u4ee4\u5b66\u4e60) \u00b6 \u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7b2c\u4e8c\u4e2aPrompt\u6280\u672f\u662f\u6307\u4ee4\u5b66\u4e60\u3002\u5176\u5b9ePrompt-Tuning\u672c\u8d28\u4e0a\u662f\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u6307\u4ee4\uff0c\u7b80\u5355\u7684\u6765\u8bf4\uff1a\u5c31\u662f\u544a\u8bc9\u6a21\u578b\u9700\u8981\u505a\u4ec0\u4e48\u4efb\u52a1\uff0c\u8f93\u51fa\u4ec0\u4e48\u5185\u5bb9\u3002\u4e0a\u6587\u6211\u4eec\u63d0\u53ca\u5230\u7684\u79bb\u6563\u6216\u8fde\u7eed\u7684\u6a21\u677f\uff0c\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u79cd\u5bf9\u4efb\u52a1\u7684\u63d0\u793a\u3002\u56e0\u6b64\uff0c\u5728\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u53ef\u4ee5\u4e3a\u5404\u79cd\u7c7b\u578b\u7684\u4efb\u52a1\u5b9a\u4e49\u6307\u4ee4\uff0c\u5e76\u8fdb\u884c\u8bad\u7ec3\uff0c\u6765\u63d0\u9ad8\u6a21\u578b\u5bf9\u4e0d\u540c\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u4ec0\u4e48\u662fInstruction-Tuning? \u8ba9\u6211\u4eec\u5148\u629b\u5f00\u8111\u5b50\u91cc\u7684\u4e00\u5207\u6982\u5ff5\uff0c\u628a\u81ea\u5df1\u5f53\u6210\u4e00\u4e2a\u6a21\u578b\u3002\u6211\u7ed9\u4f60\u4e24\u4e2a\u4efb\u52a1\uff1a 1.\u5e26\u5973\u670b\u53cb\u53bb\u4e86\u4e00\u5bb6\u9910\u5385\uff0c\u5979\u5403\u7684\u5f88\u5f00\u5fc3\uff0c\u8fd9\u5bb6\u9910\u5385\u592a__\u4e86\uff01 2.\u5224\u65ad\u8fd9\u53e5\u8bdd\u7684\u60c5\u611f\uff1a\u5e26\u5973\u670b\u53cb\u53bb\u4e86\u4e00\u5bb6\u9910\u5385\uff0c\u5979\u5403\u7684\u5f88\u5f00\u5fc3\u3002\u9009\u9879\uff1aA=\u597d\uff0cB=\u4e00\u822c\uff0cC=\u5dee \u4f60\u89c9\u5f97\u54ea\u4e2a\u4efb\u52a1\u7b80\u5355\uff1f\u60f3\u8c61\u4e00\u4e0b\uff1a\u505a\u5224\u522b\u662f\u4e0d\u662f\u6bd4\u505a\u751f\u6210\u8981\u5bb9\u6613\uff1f Prompt\u5c31\u662f\u7b2c\u4e00\u79cd\u6a21\u5f0f\uff0cInstruction\u5c31\u662f\u7b2c\u4e8c\u79cd\u3002 Instruction-Tuning\u548cPrompt-Tuning\u7684\u6838\u5fc3\u4e00\u6837\uff0c\u5c31\u662f\u53bb\u53d1\u6398\u8bed\u8a00\u6a21\u578b\u672c\u8eab\u5177\u5907\u7684\u77e5\u8bc6\u3002\u800c\u4ed6\u4eec\u7684\u4e0d\u540c\u70b9\u5c31\u5728\u4e8e: Prompt\u662f\u53bb\u6fc0\u53d1\u8bed\u8a00\u6a21\u578b\u7684**\u8865\u5168\u80fd\u529b**\uff0c\u6bd4\u5982\u7ed9\u51fa\u4e0a\u534a\u53e5\u751f\u6210\u4e0b\u534a\u53e5\u3001\u6216\u8005\u505a\u5b8c\u5f62\u586b\u7a7a\u3002 Instruction-Tuning\u5219\u662f\u6fc0\u53d1\u8bed\u8a00\u6a21\u578b\u7684**\u7406\u89e3\u80fd\u529b**\uff0c\u901a\u8fc7\u7ed9\u51fa\u66f4\u660e\u663e\u7684\u6307\u4ee4/\u6307\u793a\uff0c\u8ba9\u6a21\u578b\u53bb\u7406\u89e3\u5e76\u505a\u51fa\u6b63\u786e\u7684action. Promp-Tuningt\u5728\u6ca1\u6709\u7cbe\u8c03\u7684\u6a21\u578b\u4e0a\u4e5f\u80fd\u6709\u4e00\u5b9a\u6548\u679c\uff0c\u4f46\u662fInstruct-Tuning\u5219\u5fc5\u987b\u5bf9\u6a21\u578b\u7cbe\u8c03\uff0c\u8ba9\u6a21\u578b\u77e5\u9053\u8fd9\u79cd\u6307\u4ee4\u6a21\u5f0f\u3002 \u4e3e\u4f8b\u8bf4\u660e: \u4f8b\u5982\u5728\u5bf9\u7535\u5f71\u8bc4\u8bba\u8fdb\u884c\u4e8c\u5206\u7c7b\u7684\u65f6\u5019\uff0c\u6700\u7b80\u5355\u7684\u63d0\u793a\u6a21\u677f(Prompt)\u662f\u201c. It was [mask].\u201d\uff0c\u4f46\u662f\u5176\u5e76\u6ca1\u6709\u7a81\u51fa\u8be5\u4efb\u52a1\u7684\u5177\u4f53\u7279\u6027\uff0c\u6211\u4eec\u53ef\u4ee5\u4e3a\u5176\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u7a81\u51fa\u8be5\u4efb\u52a1\u7279\u6027\u7684\u6a21\u677f(\u52a0\u4e0aInstruction)\uff0c\u4f8b\u5982\u201cThe movie review is . It was [mask].\u201d\uff0c\u7136\u540e\u6839\u636emask\u4f4d\u7f6e\u7684\u8f93\u51fa\u7ed3\u679c\u901a\u8fc7Verbalizer\u6620\u5c04\u5230\u5177\u4f53\u7684\u6807\u7b7e\u4e0a\u3002\u8fd9\u4e00\u7c7b\u5177\u5907\u4efb\u52a1\u7279\u6027\u7684\u6a21\u677f\u53ef\u4ee5\u79f0\u4e4b\u4e3a\u6307\u4ee4Instruction. \u5e38\u89c1\u4efb\u52a1\u7684\u6307\u4ee4\u6a21\u677f\uff1a \u5982\u4f55\u5b9e\u73b0Instruction-Tuning? \u4e3a\u6bcf\u4e2a\u4efb\u52a1\u8bbe\u8ba110\u4e2a\u6307\u4ee4\u6a21\u7248\uff0c\u6d4b\u8bd5\u65f6\u770b\u5e73\u5747\u548c\u6700\u597d\u7684\u8868\u73b0. 3. Chain-of-Thought\uff08\u601d\u7ef4\u94fe\uff09 \u00b6 \u601d\u7ef4\u94fe (Chain-of-thought\uff0cCoT) \u7684\u6982\u5ff5\u662f\u5728 Google \u7684\u8bba\u6587 \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\" \u4e2d\u88ab\u9996\u6b21\u63d0\u51fa\u3002\u601d\u7ef4\u94fe\uff08CoT\uff09\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u63d0\u793a\u7b56\u7565\uff0c\u7528\u4e8e\u63d0\u9ad8 LLM \u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5982\u7b97\u672f\u63a8\u7406\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u7b26\u53f7\u63a8\u7406\u3002 CoT \u6ca1\u6709\u50cf ICL \u90a3\u6837\u7b80\u5355\u5730\u7528\u8f93\u5165\u8f93\u51fa\u5bf9\u6784\u5efa\u63d0\u793a\uff0c\u800c\u662f\u7ed3\u5408\u4e86\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\uff0c\u8fd9\u4e9b\u6b65\u9aa4\u53ef\u4ee5\u5c06\u6700\u7ec8\u8f93\u51fa\u5f15\u5165\u63d0\u793a\u3002\u7b80\u5355\u6765\u8bf4\uff0c \u601d\u7ef4\u94fe\u662f\u4e00\u79cd\u79bb\u6563\u5f0f\u63d0\u793a\u5b66\u4e60 \uff0c\u66f4\u5177\u4f53\u5730\uff0c\u5927\u6a21\u578b\u4e0b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08\u5373\u4e0d\u8fdb\u884c\u8bad\u7ec3\uff0c\u5c06\u4f8b\u5b50\u6dfb\u52a0\u5230\u5f53\u524d\u6837\u672c\u8f93\u5165\u7684\u524d\u9762\uff0c\u8ba9\u6a21\u578b\u4e00\u6b21\u8f93\u5165\u8fd9\u4e9b\u6587\u672c\u8fdb\u884c\u8f93\u51fa\u5b8c\u6210\u4efb\u52a1\uff09\uff0c\u76f8\u6bd4\u4e8e\u4e4b\u524d\u4f20\u7edf\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08\u5373\u901a\u8fc7x1,y1,x2,y2,....xtest\u4f5c\u4e3a\u8f93\u5165\u6765\u8ba9\u5927\u6a21\u578b\u8865\u5168\u8f93\u51faytest\uff09\uff0c\u601d\u7ef4\u94fe\u591a\u4e86\u4e2d\u95f4\u7684\u63a8\u5bfc\u63d0\u793a\u3002 \u4ee5\u4e00\u4e2a\u6570\u5b66\u9898\u4e3a\u4f8b\uff1a \u53ef\u4ee5\u770b\u5230\u6a21\u578b\u65e0\u6cd5\u505a\u51fa\u6b63\u786e\u7684\u56de\u7b54\u3002\u4f46\u5982\u679c\u8bf4\uff0c\u6211\u4eec\u7ed9\u6a21\u578b\u4e00\u4e9b\u5173\u4e8e\u89e3\u9898\u7684\u601d\u8def\uff0c\u5c31\u50cf\u6211\u4eec\u6570\u5b66\u8003\u8bd5\uff0c\u90fd\u4f1a\u628a\u89e3\u9898\u8fc7\u7a0b\u5199\u51fa\u6765\u518d\u6700\u7ec8\u5f97\u51fa\u7b54\u6848\uff0c\u4e0d\u7136\u65e0\u6cd5\u5f97\u5206\u3002CoT \u505a\u7684\u5c31\u662f\u8fd9\u4ef6\u4e8b\uff0c\u793a\u4f8b\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230\uff0c\u7c7b\u4f3c\u7684\u7b97\u672f\u9898\uff0c\u601d\u7ef4\u94fe\u63d0\u793a\u4f1a\u5728\u7ed9\u51fa\u7b54\u6848\u4e4b\u524d\uff0c\u8fd8\u4f1a\u81ea\u52a8\u7ed9\u51fa\u63a8\u7406\u6b65\u9aa4\uff1a \u201c\u7f57\u6770\u5148\u67095\u4e2a\u7403\uff0c2\u76d23\u4e2a\u7f51\u7403\u7b49\u4e8e6\u4e2a\uff0c5 + 6 = 11\u201d \u201c\u98df\u5802\u539f\u6765\u670923\u4e2a\u82f9\u679c\uff0c\u7528\u4e8620\u4e2a\uff0c23-20=3\uff1b\u53c8\u4e70\u4e866\u4e2a\u82f9\u679c\uff0c3+6=9 \u4e0a\u8ff0\u4f8b\u5b50\u8bc1\u660e\u4e86\u601d\u7ef4\u94fe\u63d0\u793a\u7ed9\u51fa\u4e86\u6b63\u786e\u7b54\u6848\uff0c\u800c\u76f4\u63a5\u7ed9\u51fa\u7b54\u6848\u7684\u4f20\u7edf\u63d0\u793a\u5b66\u4e60\uff0c\u7ed3\u679c\u662f\u9519\u7684\uff0c\u8fde\u5f88\u57fa\u672c\u7684\u6570\u5b66\u8ba1\u7b97\u90fd\u505a\u4e0d\u597d\u3002\u7b80\u5355\u6765\u8bf4\uff0c\u8bed\u8a00\u6a21\u578b\u5f88\u96be\u5c06\u6240\u6709\u7684\u8bed\u4e49\u76f4\u63a5\u8f6c\u5316\u4e3a\u4e00\u4e2a\u65b9\u7a0b\uff0c\u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u66f4\u52a0\u590d\u6742\u7684\u601d\u8003\u8fc7\u7a0b\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u4e2d\u95f4\u6b65\u9aa4\uff0c\u6765\u66f4\u597d\u5730\u63a8\u7406\u95ee\u9898\u7684\u6bcf\u4e2a\u90e8\u5206\u3002 CoT\u5206\u7c7b\uff1a Few-shot CoT \uff1a\u662f ICL \u7684\u4e00\u79cd\u7279\u6b8a\u60c5\u51b5\uff0c\u5b83\u901a\u8fc7\u878d\u5408 CoT \u63a8\u7406\u6b65\u9aa4\uff0c\u5c06\u6bcf\u4e2a\u6f14\u793a\u3008input\uff0coutput\u3009\u6269\u5145\u4e3a\u3008input\uff0cCoT\uff0coutput\u3009\u3002 Zero-shot CoT\uff1a\u4e0e Few-shot CoT \u4e0d\u540c \u5728 prompt \u4e2d\u4e0d\u5305\u62ec\u4eba\u5de5\u6807\u6ce8\u7684\u4efb\u52a1\u6f14\u793a\u3002\u76f8\u53cd\uff0c\u5b83\u76f4\u63a5\u751f\u6210\u63a8\u7406\u6b65\u9aa4\uff0c\u7136\u540e\u4f7f\u7528\u751f\u6210\u7684 CoT \u6765\u5bfc\u51fa\u7b54\u6848\u3002\uff08\u5176\u4e2d LLM \u9996\u5148\u7531 \u201cLet's think step by step\u201d \u63d0\u793a\u751f\u6210\u63a8\u7406\u6b65\u9aa4\uff0c\u7136\u540e\u7531 \u201cTherefore, the answer is\u201d \u63d0\u793a\u5f97\u51fa\u6700\u7ec8\u7b54\u6848\u3002\u4ed6\u4eec\u53d1\u73b0\uff0c\u5f53\u6a21\u578b\u89c4\u6a21\u8d85\u8fc7\u4e00\u5b9a\u89c4\u6a21\u65f6\uff0c\u8fd9\u79cd\u7b56\u7565\u4f1a\u5927\u5927\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u5bf9\u5c0f\u89c4\u6a21\u6a21\u578b\u65e0\u6548\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u6d8c\u73b0\u80fd\u529b\u6a21\u5f0f\uff09\u3002 \u4e00\u4e2a\u6709\u6548\u7684\u601d\u7ef4\u94fe\u5e94\u8be5\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a \u903b\u8f91\u6027 \uff1a\u601d\u7ef4\u94fe\u4e2d\u7684\u6bcf\u4e2a\u601d\u8003\u6b65\u9aa4\u90fd\u5e94\u8be5\u662f\u6709\u903b\u8f91\u5173\u7cfb\u7684\uff0c\u5b83\u4eec\u5e94\u8be5\u76f8\u4e92\u8fde\u63a5\uff0c\u4ece\u800c\u5f62\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u601d\u8003\u8fc7\u7a0b\u3002 \u5168\u9762\u6027 \uff1a\u601d\u7ef4\u94fe\u5e94\u8be5\u5c3d\u53ef\u80fd\u5730\u5168\u9762\u548c\u7ec6\u81f4\u5730\u8003\u8651\u95ee\u9898\uff0c\u4ee5\u786e\u4fdd\u4e0d\u4f1a\u5ffd\u7565\u4efb\u4f55\u53ef\u80fd\u7684\u56e0\u7d20\u548c\u5f71\u54cd\u3002 \u53ef\u884c\u6027 \uff1a\u601d\u7ef4\u94fe\u4e2d\u7684\u6bcf\u4e2a\u601d\u8003\u6b65\u9aa4\u90fd\u5e94\u8be5\u662f\u53ef\u884c\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u4eec\u5e94\u8be5\u53ef\u4ee5\u88ab\u5b9e\u9645\u64cd\u4f5c\u548c\u5b9e\u65bd\u3002 \u53ef\u9a8c\u8bc1\u6027 \uff1a\u601d\u7ef4\u94fe\u4e2d\u7684\u6bcf\u4e2a\u601d\u8003\u6b65\u9aa4\u90fd\u5e94\u8be5\u662f\u53ef\u4ee5\u9a8c\u8bc1\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u4eec\u5e94\u8be5\u53ef\u4ee5\u901a\u8fc7\u5b9e\u9645\u7684\u6570\u636e\u548c\u4e8b\u5b9e\u6765\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u548c\u6709\u6548\u6027\u3002 PEFT(\u5927\u6a21\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03) \u00b6 \u76ee\u524d\u5728\u5de5\u4e1a\u754c\u5e94\u7528\u5927\u6a21\u578b\u4e3b\u6d41\u65b9\u5f0f\uff1a \u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff08Parameter-Efficient Fine-Tuning\uff0cPEFT\uff09 \uff0c PEFT \u65b9\u6cd5\u4ec5\u5fae\u8c03\u5c11\u91cf\u6216\u989d\u5916\u7684\u6a21\u578b\u53c2\u6570\uff0c\u56fa\u5b9a\u5927\u90e8\u5206\u9884\u8bad\u7ec3\u53c2\u6570\uff0c\u5927\u5927\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c \uff0c\u540c\u65f6\u6700\u5148\u8fdb\u7684 PEFT \u6280\u672f\u4e5f\u80fd\u5b9e\u73b0\u4e86\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002 \u8be5\u65b9\u6cd5\u53ef\u4ee5\u4f7f PLM \u9ad8\u6548\u9002\u5e94\u5404\u79cd\u4e0b\u6e38\u5e94\u7528\u4efb\u52a1\uff0c\u800c\u65e0\u9700\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\uff0c\u4e14\u8ba9\u5927\u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fdb\u884c\u5168\u91cf\u5fae\u8c03\uff08Full Fine-Tuning\uff09\u53d8\u5f97\u53ef\u884c\u3002 \u76ee\u524d\u5e94\u7528\u8f83\u591a\u7684PEFT\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e09\u5927\u7c7b\uff1a Prefix/Prompt-Tuning \uff1a\u5728\u6a21\u578b\u7684\u8f93\u5165\u6216\u9690\u5c42\u6dfb\u52a0 k k \u4e2a\u989d\u5916\u53ef\u8bad\u7ec3\u7684\u524d\u7f00 tokens\uff08\u8fd9\u4e9b\u524d\u7f00\u662f\u8fde\u7eed\u7684\u4f2a tokens\uff0c\u4e0d\u5bf9\u5e94\u771f\u5b9e\u7684 tokens\uff09\uff0c\u53ea\u8bad\u7ec3\u8fd9\u4e9b\u524d\u7f00\u53c2\u6570\uff1b Adapter-Tuning \uff1a\u5c06\u8f83\u5c0f\u7684\u795e\u7ecf\u7f51\u7edc\u5c42\u6216\u6a21\u5757\u63d2\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6bcf\u4e00\u5c42\uff0c\u8fd9\u4e9b\u65b0\u63d2\u5165\u7684\u795e\u7ecf\u6a21\u5757\u79f0\u4e3a adapter\uff08\u9002\u914d\u5668\uff09\uff0c\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u65f6\u4e5f\u53ea\u8bad\u7ec3\u8fd9\u4e9b\u9002\u914d\u5668\u53c2\u6570\uff1b LoRA \uff1a\u901a\u8fc7\u5b66\u4e60\u5c0f\u53c2\u6570\u7684\u4f4e\u79e9\u77e9\u9635\u6765\u8fd1\u4f3c\u6a21\u578b\u6743\u91cd\u77e9\u9635 W W \u7684\u53c2\u6570\u66f4\u65b0\uff0c\u8bad\u7ec3\u65f6\u53ea\u4f18\u5316\u4f4e\u79e9\u77e9\u9635\u53c2\u6570; \u6b64\u5916**Huggface \u5f00\u6e90\u7684\u4e00\u4e2a\u9ad8\u6548\u5fae\u8c03\u5927\u6a21\u578b\u7684\u5e93PEFT**\uff0c\u8be5\u7b97\u6cd5\u5e93\u652f\u6301\u4e0a\u8ff0\u4e09\u7c7b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u3002 1. Prefix Tuning \u00b6 Prefix-Tuning \u5728\u6a21\u578b\u8f93\u5165\u524d\u6dfb\u52a0\u4e00\u4e2a\u8fde\u7eed\u7684\u4e14\u4efb\u52a1\u7279\u5b9a\u7684\u5411\u91cf\u5e8f\u5217\uff08continuous task-specific vectors\uff09\uff0c\u79f0\u4e4b\u4e3a\u524d\u7f00\uff08prefix\uff09\u3002\u524d\u7f00\u88ab\u89c6\u4e3a\u4e00\u7cfb\u5217\u201c\u865a\u62df tokens\u201d\uff0c\u4f46\u662f\u5b83\u7531\u4e0d\u5bf9\u5e94\u4e8e\u771f\u5b9e tokens \u7684\u81ea\u7531\u53c2\u6570\u7ec4\u6210\u3002\u4e0e\u66f4\u65b0\u6240\u6709 PLM \u53c2\u6570\u7684\u5168\u91cf\u5fae\u8c03\u4e0d\u540c\uff0cPrefix-Tuning \u56fa\u5b9a PLM \u7684\u6240\u6709\u53c2\u6570\uff0c\u53ea\u66f4\u65b0\u4f18\u5316\u7279\u5b9a\u4efb\u52a1\u7684 prefix\u3002\u56e0\u6b64\uff0c\u5728\u751f\u4ea7\u90e8\u7f72\u65f6\uff0c\u53ea\u9700\u8981\u5b58\u50a8\u4e00\u4e2a\u5927\u578b PLM \u7684\u526f\u672c\u548c\u4e00\u4e2a\u5b66\u4e60\u5230\u7684\u7279\u5b9a\u4efb\u52a1\u7684 prefix\uff0c\u6bcf\u4e2a\u4e0b\u6e38\u4efb\u52a1\u53ea\u4ea7\u751f\u975e\u5e38\u5c0f\u7684\u989d\u5916\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\u3002 Fine-tuning \u66f4\u65b0\u6240\u6709 PLM \u53c2\u6570\uff0c\u5e76\u4e14\u9700\u8981\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u5b58\u50a8\u5b8c\u6574\u7684\u6a21\u578b\u526f\u672c\u3002Prefix-tuning \u51bb\u7ed3\u4e86 PLM \u53c2\u6570\u5e76\u4e14\u53ea\u4f18\u5316\u4e86 prefix\u3002\u56e0\u6b64\uff0c\u53ea\u9700\u8981\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u5b58\u50a8\u7279\u5b9a prefix\uff0c\u4f7f Prefix-tuning \u6a21\u5757\u5316\u4e14\u8282\u7701\u5b58\u50a8\u7a7a\u95f4\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4ee5 GPT2 \u7684\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e3a\u4f8b\uff0c\u5c06\u8f93\u5165 x x \u548c\u8f93\u51fa y y \u62fc\u63a5\u4e3a z=[x;y] z=[x;y] \uff0c\u7ecf\u8fc7 LM \u7684\u67d0\u4e00\u5c42\u8ba1\u7b97\u9690\u5c42\u8868\u793a h=[h_1,...,h_i,....,h_n] h=[h_1,...,h_i,....,h_n] \uff0c h_i=LM_\u00d8(z_i, h<i) h_i=LM_\u00d8(z_i, h<i) \uff0c\u5176\u4e2d\uff0c X_{idx} X_{idx} \u548c Y_{idx}\u200b Y_{idx}\u200b \u5206\u522b\u4e3a\u8f93\u5165\u548c\u8f93\u51fa\u5e8f\u5217\u7684\u7d22\u5f15\u3002 Prefix-Tuning \u5728\u8f93\u5165\u524d\u6dfb\u52a0\u524d\u7f00\uff0c\u5373 z=[Prefix,x,y] z=[Prefix,x,y] \uff0c P_{idx} P_{idx} \u4e3a\u524d\u7f00\u5e8f\u5217\u7684\u7d22\u5f15\uff0c |P_{idx}| |P_{idx}| \u4e3a\u524d\u7f00\u7684\u957f\u5ea6\u3002\u524d\u7f00\u7d22\u5f15\u5bf9\u5e94\u7740\u7531 \u03b8 \u03b8 \u53c2\u6570\u5316\u7684\u5411\u91cf\u77e9\u9635 P_\u03b8 P_\u03b8 \uff0c\u7ef4\u5ea6\u4e3a |P_{idx}|\u00d7dim(h_i) |P_{idx}|\u00d7dim(h_i) \u3002\u9690\u5c42\u8868\u793a\uff1a\u82e5\u7d22\u5f15\u4e3a\u524d\u7f00\u7d22\u5f15 P_{idx} P_{idx} \uff0c\u76f4\u63a5\u4ece P_\u03b8 P_\u03b8 \u590d\u5236\u5bf9\u5e94\u7684\u5411\u91cf\u4f5c\u4e3a h_i h_i ( \u5728\u6a21\u578b\u6bcf\u4e00\u5c42\u90fd\u6dfb\u52a0\u524d\u7f00\u5411\u91cf )\uff1b\u5426\u5219\u76f4\u63a5\u901a\u8fc7 LM \u8ba1\u7b97\u5f97\u5230\uff0c\u540c\u65f6\uff0c\u7ecf\u8fc7 LM \u8ba1\u7b97\u7684 h_i h_i \u4e5f\u4f9d\u8d56\u4e8e\u5176\u5de6\u4fa7\u7684\u524d\u7f00\u53c2\u6570 P_\u03b8 P_\u03b8 \uff0c\u5373**\u901a\u8fc7\u524d\u7f00\u6765\u5f71\u54cd\u540e\u7eed\u7684\u5e8f\u5217\u9690\u5c42\u6fc0\u5316\u503c**\u3002 \u4f46\u662f\u76f4\u63a5\u4f18\u5316 P_\u03b8 P_\u03b8 \u4f1a\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u901a\u8fc7\u4e00\u4e2a\u66f4\u5c0f\u7684\u77e9\u9635 P_w P_w \u548c\u4e00\u4e2a\u66f4\u5927\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc MLP_\u03b8 MLP_\u03b8 \u5bf9 P_\u03b8 P_\u03b8 \u8fdb\u884c\u91cd\u53c2\u6570\u5316: P_\u03b8[i,:]=MLP_\u03b8(P_w[i,:]) P_\u03b8[i,:]=MLP_\u03b8(P_w[i,:]) \u3002\u5728\u8bad\u7ec3\u65f6\uff0cLM \u7684\u53c2\u6570 \u00d8 \u00d8 \u88ab\u56fa\u5b9a\uff0c\u53ea\u6709\u524d\u7f00\u53c2\u6570 \u03b8 \u03b8 \u4e3a\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\u3002\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u53ea\u6709\u524d\u7f00 P_\u03b8 P_\u03b8 \u88ab\u4fdd\u5b58\u3002 P-Tuning \u4e0e Prefix-Tuning \u7684\u65b9\u6cd5\u601d\u8def\u76f8\u4f3c\uff0cPrefix-Tuning \u662f\u5c06\u989d\u5916\u7684embedding\u52a0\u5728\u5f00\u5934\uff0c\u770b\u8d77\u6765\u66f4\u50cf\u6a21\u4effInstruction\u6307\u4ee4\uff0c\u800cP-Tuning \u4f4d\u7f6e\u4e0d\u56fa\u5b9a\u3002Prefix-Tuning \u901a\u8fc7\u5728\u6bcf\u4e2a\u5c42\u90fd\u6dfb\u52a0\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u901a\u8fc7MLP\u521d\u59cb\u5316\uff0c\u800cP-Tuning\u53ea\u5728\u8f93\u5165\u7684\u65f6\u5019\u52a0\u5165embedding, \u5e76\u901a\u8fc7LSTM+MLP\u521d\u59cb\u5316. Prompt Tuning \u65b9\u5f0f\u53ef\u4ee5\u770b\u505a\u662f Prefix Tuning \u7684\u7b80\u5316\uff0c\u53ea\u5728\u8f93\u5165\u5c42\u52a0\u5165 prompt tokens\uff0c\u5e76\u4e0d\u9700\u8981\u52a0\u5165 MLP \u8fdb\u884c\u8c03\u6574\u6765\u89e3\u51b3\u96be\u8bad\u7ec3\u7684\u95ee\u9898. 2. Adapter Tuning \u00b6 \u4e0e Prefix Tuning \u548c Prompt Tuning \u8fd9\u7c7b\u5728\u8f93\u5165\u524d\u53ef\u8bad\u7ec3\u6dfb\u52a0 prompt embedding \u53c2\u6570\u6765\u4ee5\u5c11\u91cf\u53c2\u6570\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\uff0c Adapter Tuning \u5219\u662f\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u5185\u90e8\u7684\u7f51\u7edc\u5c42\u4e4b\u95f4\u6dfb\u52a0\u65b0\u7684\u7f51\u7edc\u5c42\u6216\u6a21\u5757\u6765\u9002\u914d\u4e0b\u6e38\u4efb\u52a1 \u3002 \u5047\u8bbe\u9884\u8bad\u7ec3\u6a21\u578b\u51fd\u6570\u8868\u793a\u4e3a \u00d8_w(x) \u00d8_w(x) \uff0c\u5bf9\u4e8e Adapter Tuning \uff0c\u6dfb\u52a0\u9002\u914d\u5668\u4e4b\u540e\u6a21\u578b\u51fd\u6570\u66f4\u65b0\u4e3a \u00d8_{w,w_0}(x) \u00d8_{w,w_0}(x) \uff0c w w \u662f\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\uff0c w_0 w_0 \u662f\u65b0\u6dfb\u52a0\u7684\u9002\u914d\u5668\u7684\u53c2\u6570\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c w w \u88ab\u56fa\u5b9a\uff0c\u53ea\u6709 w_0 w_0 \u88ab\u66f4\u65b0\u3002 |w_0|<<|w| |w_0|<<|w| \uff0c\u8fd9\u4f7f\u5f97\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u53ea\u9700\u8981\u6dfb\u52a0\u5c11\u91cf\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\u5373\u53ef\uff0c\u8282\u7701\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\uff0c\u540c\u65f6\u5171\u4eab\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u3002 Series Adapter\u7684\u9002\u914d\u5668\u7ed3\u6784\u548c\u4e0e Transformer \u7684\u96c6\u6210\u5982\u4e0a\u56fe\u6240\u793a\u3002\u9002\u914d\u5668\u6a21\u5757\u88ab\u6dfb\u52a0\u5230\u6bcf\u4e2a Transformer \u5c42\u4e24\u6b21\uff1a\u591a\u5934\u6ce8\u610f\u529b\u6620\u5c04\u4e4b\u540e\u548c\u4e24\u5c42\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u4e4b\u540e\u3002\u9002\u914d\u5668\u662f\u4e00\u4e2a bottleneck\uff08\u74f6\u9888\uff09\u7ed3\u6784\u7684\u6a21\u5757\uff0c\u7531\u4e00\u4e2a\u4e24\u5c42\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff08\u7531\u5411\u4e0b\u6295\u5f71\u77e9\u9635\u3001\u975e\u7ebf\u6027\u51fd\u6570\u548c\u5411\u4e0a\u6295\u5f71\u77e9\u9635\u6784\u6210\uff09\u548c\u4e00\u4e2a\u8f93\u51fa\u8f93\u51fa\u4e4b\u95f4\u7684\u6b8b\u5dee\u8fde\u63a5\u7ec4\u6210\u3002 3. LoRA \u00b6 \u4e0a\u8ff0Adapter Tuning \u65b9\u6cd5\u5728 PLM \u57fa\u7840\u4e0a\u6dfb\u52a0\u9002\u914d\u5668\u5c42\u4f1a\u5f15\u5165\u989d\u5916\u7684\u8ba1\u7b97\uff0c\u5e26\u6765\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff1b\u800c Prefix Tuning \u65b9\u6cd5\u96be\u4ee5\u4f18\u5316\uff0c\u5176\u6027\u80fd\u968f\u53ef\u8bad\u7ec3\u53c2\u6570\u89c4\u6a21\u975e\u5355\u8c03\u53d8\u5316\uff0c\u66f4\u6839\u672c\u7684\u662f\uff0c\u4e3a\u524d\u7f00\u4fdd\u7559\u90e8\u5206\u5e8f\u5217\u957f\u5ea6\u5fc5\u7136\u4f1a\u51cf\u5c11\u7528\u4e8e\u5904\u7406\u4e0b\u6e38\u4efb\u52a1\u7684\u5e8f\u5217\u957f\u5ea6\u3002\u56e0\u6b64\u5fae\u8f6f\u63a8\u51fa\u4e86LoRA\u65b9\u6cd5\u3002 \u4f4e\u79e9\u9002\u5e94\uff08Low-Rank Adaptation\uff09\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u6280\u672f\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5bf9\u5927\u578b\u6a21\u578b\u7684\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u9690\u5f0f\u7684\u4f4e\u79e9\u8f6c\u6362\uff0c\u4e5f\u5c31\u662f\uff1a\u901a\u8fc7\u4e00\u4e2a\u8f83\u4f4e\u7ef4\u5ea6\u7684\u8868\u793a\u6765\u8fd1\u4f3c\u8868\u793a\u4e00\u4e2a\u9ad8\u7ef4\u77e9\u9635\u6216\u6570\u636e\u96c6\u3002 \u57fa\u672c\u539f\u7406\uff1aLoRA\u6280\u672f\u51bb\u7ed3\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6743\u91cd\uff0c\u5e76\u5728\u6bcf\u4e2aTransformer\u5757\u4e2d\u6ce8\u5165\u53ef\u8bad\u7ec3\u5c42\uff08\u79f0\u4e3a\u79e9\u5206\u89e3\u77e9\u9635\uff09\uff0c\u5373\u5728\u6a21\u578b\u7684Linear\u5c42\u7684\u65c1\u8fb9\u589e\u52a0\u4e00\u4e2a\u201c\u65c1\u652f\u201dA\u548cB\u3002\u5176\u4e2d\uff0cA\u5c06\u6570\u636e\u4eced\u7ef4\u964d\u5230r\u7ef4\uff0c\u8fd9\u4e2ar\u662fLoRA\u7684\u79e9\uff0c\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u8d85\u53c2\u6570\uff1bB\u5c06\u6570\u636e\u4ecer\u7ef4\u5347\u5230d\u7ef4\uff0cB\u90e8\u5206\u7684\u53c2\u6570\u521d\u59cb\u4e3a0\u3002\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\u540e\uff0c\u9700\u8981\u5c06A+B\u90e8\u5206\u7684\u53c2\u6570\u4e0e\u539f\u5927\u6a21\u578b\u7684\u53c2\u6570\u5408\u5e76\u5728\u4e00\u8d77\u4f7f\u7528\u3002 python\u4f2a\u4ee3\u7801 input_dim = 768 # \u4f8b\u5982\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u9690\u85cf\u5927\u5c0f output_dim = 768 # \u4f8b\u5982\uff0c\u5c42\u7684\u8f93\u51fa\u5927\u5c0f rank = 8 # \u4f4e\u79e9\u9002\u5e94\u7684\u7b49\u7ea7'r' W = ... # \u6765\u81ea\u9884\u8bad\u7ec3\u7f51\u7edc\u7684\u6743\u91cd\uff0c\u5f62\u72b6\u4e3a input_dim x output_dim W_A = nn . Parameter ( torch . empty ( input_dim , rank )) # LoRA\u6743\u91cdA W_B = nn . Parameter ( torch . empty ( rank , output_dim )) # LoRA\u6743\u91cdB\u521d\u59cb\u5316LoRA\u6743\u91cd nn . init . kaiming_uniform_ ( W_A , a = math . sqrt ( 5 )) nn . init . zeros_ ( W_B ) def regular_forward_matmul ( x , W ): h = x @ W return h def lora_forward_matmul ( x , W , W_A , W_B ): h = x @ W # \u5e38\u89c4\u77e9\u9635\u4e58\u6cd5 h += x @ ( W_A @ W_B ) * alpha # \u4f7f\u7528\u7f29\u653e\u7684LoRA\u6743\u91cd,alpha\u7f29\u653e\u56e0\u5b50 return h LoRA\u65b9\u6cd5\u662f\u76ee\u524d\u6700\u901a\u7528\u3001\u540c\u65f6\u4e5f\u662f\u6548\u679c\u6700\u597d\u7684\u5fae\u8c03\u65b9\u6cd5\u4e4b\u4e00\u3002 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecd\u4f01\u4e1a\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684Prompt-Tuning\u65b9\u5f0f\u8fdb\u884c\u4e86\u539f\u7406\u4ecb\u7ecd\uff0c\u4ee5\u53ca\u76ee\u524dPEFT\u65b9\u5f0f\u7684\u539f\u7406\u8bb2\u89e3\u3002","title":"3.1 \u5927\u6a21\u578bPrompt-Tuning\u6280\u672f\u8fdb\u9636"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#llmprompt-tuning","text":"","title":"LLM\u7684Prompt-Tuning\u4e3b\u6d41\u65b9\u6cd5"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#_1","text":"\u4e86\u89e3\u4f01\u4e1a\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684Prompt-Tuning\u65b9\u6cd5\u7c7b\u578b. \u7406\u89e3Prefix-Tuning\u3001Adapter-Tuning\u3001LoRA\u4e09\u79cd\u5927\u6a21\u578b\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5\u7684\u539f\u7406","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#prompt-tuning","text":"\u8fd1\u4e24\u5e74\u6765\uff0c\u968f\u7740Prompt-Tuning\u6280\u672f\u7684\u53d1\u5c55\uff0c\u6709\u8bf8\u591a\u5de5\u4f5c\u53d1\u73b0\uff0c\u5bf9\u4e8e\u8d85\u8fc710\u4ebf\u53c2\u6570\u91cf\u7684\u6a21\u578b\u6765\u8bf4\uff0cPrompt-Tuning\u6240\u5e26\u6765\u7684\u589e\u76ca\u8fdc\u8fdc\u9ad8\u4e8e\u6807\u51c6\u7684Fine-tuning\uff0c\u5c0f\u6837\u672c\u751a\u81f3\u662f\u96f6\u6837\u672c\u7684\u6027\u80fd\u4e5f\u80fd\u591f\u6781\u5927\u5730\u88ab\u6fc0\u53d1\u51fa\u6765\uff0c\u5f97\u76ca\u4e8e\u8fd9\u4e9b\u6a21\u578b\u7684 \u53c2\u6570\u91cf\u8db3\u591f\u5927 \uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u4e86 \u8db3\u591f\u591a\u7684\u8bed\u6599 \uff0c\u540c\u65f6\u8bbe\u8ba1\u7684 \u9884\u8bad\u7ec3\u4efb\u52a1\u8db3\u591f\u6709\u6548 \u3002\u6700\u4e3a\u7ecf\u5178\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5219\u662f2020\u5e74\u63d0\u51fa\u7684GPT-3\uff0c\u5176\u62e5\u6709\u5927\u7ea61750\u4ebf\u7684\u53c2\u6570\uff0c\u4e14\u53d1\u73b0\u53ea\u9700\u8981\u8bbe\u8ba1\u5408\u9002\u7684\u6a21\u677f\u6216\u6307\u4ee4\u5373\u53ef\u4ee5 \u5b9e\u73b0\u514d\u53c2\u6570\u8bad\u7ec3\u7684\u96f6\u6837\u672c\u5b66\u4e60 \u3002 2022\u5e74\u5e95\u52302023\u5e74\u521d\uff0c\u56fd\u5185\u5916\u4e5f\u6380\u8d77\u4e86AIGC\u7684\u6d6a\u6f6e\uff0c\u5178\u578b\u4ee3\u8868\u662fOpenAI\u53d1\u5e03\u7684ChatGPT\u3001GPT-4\u5927\u6a21\u578b\uff0cGoogle\u53d1\u5e03\u7684Bard\u4ee5\u53ca\u767e\u5ea6\u516c\u53f8\u53d1\u5e03\u7684\u6587\u5fc3\u4e00\u8a00\u7b49\u3002\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u8fdb\u5165\u65b0\u7684\u7eaa\u5143\uff0c\u800c\u8fd9\u4e9b\u8f70\u52a8\u4e16\u754c\u7684\u4ea7\u7269\uff0c\u79bb\u4e0d\u5f00\u5f3a\u5927\u7684Prompt-Tuning\u6280\u672f\u3002\u672c\u6587\u9ed8\u8ba4\u4ee5GPT-3\u4e3a\u4f8b\uff0c\u4ecb\u7ecd\u51e0\u4e2a\u9762\u5411\u8d85\u5927\u89c4\u6a21\u7684Prompt-Tuning\u65b9\u6cd5\uff0c\u5206\u522b\u4e3a\uff1a \u4e0a\u4e0b\u6587\u5b66\u4e60 In-Context Learning\uff08ICL\uff09 \uff1a\u76f4\u63a5\u6311\u9009\u5c11\u91cf\u7684\u8bad\u7ec3\u6837\u672c\u4f5c\u4e3a\u8be5\u4efb\u52a1\u7684\u63d0\u793a\uff1b \u6307\u4ee4\u5b66\u4e60 Instruction-Tuning \uff1a\u6784\u5efa\u4efb\u52a1\u6307\u4ee4\u96c6\uff0c\u4fc3\u4f7f\u6a21\u578b\u6839\u636e\u4efb\u52a1\u6307\u4ee4\u505a\u51fa\u53cd\u9988\uff1b \u601d\u7ef4\u94fe Chain-of-Thought\uff08CoT\uff09 \uff1a\u7ed9\u4e88\u6216\u6fc0\u53d1\u6a21\u578b\u5177\u6709\u63a8\u7406\u548c\u89e3\u91ca\u7684\u4fe1\u606f\uff0c\u901a\u8fc7\u7ebf\u6027\u94fe\u5f0f\u7684\u6a21\u5f0f\u6307\u5bfc\u6a21\u578b\u751f\u6210\u5408\u7406\u7684\u7ed3\u679c\u3002","title":"\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684Prompt-Tuning"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#1-in-context-learning","text":"In-Context learning\uff08ICL\uff09\u6700\u65e9\u5728GPT-3\u4e2d\u63d0\u51fa\uff0c \u65e8\u5728\u4ece\u8bad\u7ec3\u96c6\u4e2d\u6311\u9009\u5c11\u91cf\u7684\u6807\u6ce8\u6837\u672c\uff0c\u8bbe\u8ba1\u4efb\u52a1\u76f8\u5173\u7684\u6307\u4ee4\u5f62\u6210\u63d0\u793a\u6a21\u677f\uff0c\u7528\u4e8e\u6307\u5bfc\u6d4b\u8bd5\u6837\u672c\u751f\u6210\u76f8\u5e94\u7684\u7ed3\u679c\u3002 \u5e38\u7528\u7684In-context learning\u65b9\u6cd5\u5305\u62ec\uff1a zero-shot learning \u5b9a\u4e49: \u7ed9\u51fa\u4efb\u52a1\u7684\u63cf\u8ff0, \u7136\u540e\u63d0\u4f9b\u6d4b\u8bd5\u6570\u636e\u5bf9\u5176\u8fdb\u884c\u9884\u6d4b, \u76f4\u63a5\u8ba9\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53bb\u8fdb\u884c\u4efb\u52a1\u6d4b\u8bd5. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. one-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u4e00\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u4e00\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u82f1\u8bed\u7ffb\u8bd1\u4e3a\u6cd5\u8bed, \u5e94\u8be5\u8fd9\u4e48\u7ffb\u8bd1. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. few-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u591a\u4e2a\u6837\u672c\uff08\u4e00\u822c10-100\u6761\uff09\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u591a\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u5e94\u8be5\u5982\u4f55\u5de5\u4f5c. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u518d\u89c1->goodbye, \u8d2d\u4e70->purchase, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. \u76ee\u524dIn-context Learning\u4f9d\u7136\u4e0e\u666e\u901a\u7684fine-tuning\u6709\u4e00\u5b9a\u5dee\u8ddd\uff0c\u4e14\u9884\u6d4b\u7684\u7ed3\u679c\u65b9\u5dee\u5f88\u5927\uff0c\u540c\u65f6\u4e5f\u9700\u8981\u82b1\u8d39\u65f6\u95f4\u8003\u8651template\u7684\u6784\u5efa\u3002","title":"1. In-Context Learning(\u4e0a\u4e0b\u6587\u5b66\u4e60)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#2-instruction-tuning","text":"\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7b2c\u4e8c\u4e2aPrompt\u6280\u672f\u662f\u6307\u4ee4\u5b66\u4e60\u3002\u5176\u5b9ePrompt-Tuning\u672c\u8d28\u4e0a\u662f\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u6307\u4ee4\uff0c\u7b80\u5355\u7684\u6765\u8bf4\uff1a\u5c31\u662f\u544a\u8bc9\u6a21\u578b\u9700\u8981\u505a\u4ec0\u4e48\u4efb\u52a1\uff0c\u8f93\u51fa\u4ec0\u4e48\u5185\u5bb9\u3002\u4e0a\u6587\u6211\u4eec\u63d0\u53ca\u5230\u7684\u79bb\u6563\u6216\u8fde\u7eed\u7684\u6a21\u677f\uff0c\u672c\u8d28\u4e0a\u5c31\u662f\u4e00\u79cd\u5bf9\u4efb\u52a1\u7684\u63d0\u793a\u3002\u56e0\u6b64\uff0c\u5728\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u53ef\u4ee5\u4e3a\u5404\u79cd\u7c7b\u578b\u7684\u4efb\u52a1\u5b9a\u4e49\u6307\u4ee4\uff0c\u5e76\u8fdb\u884c\u8bad\u7ec3\uff0c\u6765\u63d0\u9ad8\u6a21\u578b\u5bf9\u4e0d\u540c\u4efb\u52a1\u7684\u6cdb\u5316\u80fd\u529b\u3002 \u4ec0\u4e48\u662fInstruction-Tuning? \u8ba9\u6211\u4eec\u5148\u629b\u5f00\u8111\u5b50\u91cc\u7684\u4e00\u5207\u6982\u5ff5\uff0c\u628a\u81ea\u5df1\u5f53\u6210\u4e00\u4e2a\u6a21\u578b\u3002\u6211\u7ed9\u4f60\u4e24\u4e2a\u4efb\u52a1\uff1a 1.\u5e26\u5973\u670b\u53cb\u53bb\u4e86\u4e00\u5bb6\u9910\u5385\uff0c\u5979\u5403\u7684\u5f88\u5f00\u5fc3\uff0c\u8fd9\u5bb6\u9910\u5385\u592a__\u4e86\uff01 2.\u5224\u65ad\u8fd9\u53e5\u8bdd\u7684\u60c5\u611f\uff1a\u5e26\u5973\u670b\u53cb\u53bb\u4e86\u4e00\u5bb6\u9910\u5385\uff0c\u5979\u5403\u7684\u5f88\u5f00\u5fc3\u3002\u9009\u9879\uff1aA=\u597d\uff0cB=\u4e00\u822c\uff0cC=\u5dee \u4f60\u89c9\u5f97\u54ea\u4e2a\u4efb\u52a1\u7b80\u5355\uff1f\u60f3\u8c61\u4e00\u4e0b\uff1a\u505a\u5224\u522b\u662f\u4e0d\u662f\u6bd4\u505a\u751f\u6210\u8981\u5bb9\u6613\uff1f Prompt\u5c31\u662f\u7b2c\u4e00\u79cd\u6a21\u5f0f\uff0cInstruction\u5c31\u662f\u7b2c\u4e8c\u79cd\u3002 Instruction-Tuning\u548cPrompt-Tuning\u7684\u6838\u5fc3\u4e00\u6837\uff0c\u5c31\u662f\u53bb\u53d1\u6398\u8bed\u8a00\u6a21\u578b\u672c\u8eab\u5177\u5907\u7684\u77e5\u8bc6\u3002\u800c\u4ed6\u4eec\u7684\u4e0d\u540c\u70b9\u5c31\u5728\u4e8e: Prompt\u662f\u53bb\u6fc0\u53d1\u8bed\u8a00\u6a21\u578b\u7684**\u8865\u5168\u80fd\u529b**\uff0c\u6bd4\u5982\u7ed9\u51fa\u4e0a\u534a\u53e5\u751f\u6210\u4e0b\u534a\u53e5\u3001\u6216\u8005\u505a\u5b8c\u5f62\u586b\u7a7a\u3002 Instruction-Tuning\u5219\u662f\u6fc0\u53d1\u8bed\u8a00\u6a21\u578b\u7684**\u7406\u89e3\u80fd\u529b**\uff0c\u901a\u8fc7\u7ed9\u51fa\u66f4\u660e\u663e\u7684\u6307\u4ee4/\u6307\u793a\uff0c\u8ba9\u6a21\u578b\u53bb\u7406\u89e3\u5e76\u505a\u51fa\u6b63\u786e\u7684action. Promp-Tuningt\u5728\u6ca1\u6709\u7cbe\u8c03\u7684\u6a21\u578b\u4e0a\u4e5f\u80fd\u6709\u4e00\u5b9a\u6548\u679c\uff0c\u4f46\u662fInstruct-Tuning\u5219\u5fc5\u987b\u5bf9\u6a21\u578b\u7cbe\u8c03\uff0c\u8ba9\u6a21\u578b\u77e5\u9053\u8fd9\u79cd\u6307\u4ee4\u6a21\u5f0f\u3002 \u4e3e\u4f8b\u8bf4\u660e: \u4f8b\u5982\u5728\u5bf9\u7535\u5f71\u8bc4\u8bba\u8fdb\u884c\u4e8c\u5206\u7c7b\u7684\u65f6\u5019\uff0c\u6700\u7b80\u5355\u7684\u63d0\u793a\u6a21\u677f(Prompt)\u662f\u201c. It was [mask].\u201d\uff0c\u4f46\u662f\u5176\u5e76\u6ca1\u6709\u7a81\u51fa\u8be5\u4efb\u52a1\u7684\u5177\u4f53\u7279\u6027\uff0c\u6211\u4eec\u53ef\u4ee5\u4e3a\u5176\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u7a81\u51fa\u8be5\u4efb\u52a1\u7279\u6027\u7684\u6a21\u677f(\u52a0\u4e0aInstruction)\uff0c\u4f8b\u5982\u201cThe movie review is . It was [mask].\u201d\uff0c\u7136\u540e\u6839\u636emask\u4f4d\u7f6e\u7684\u8f93\u51fa\u7ed3\u679c\u901a\u8fc7Verbalizer\u6620\u5c04\u5230\u5177\u4f53\u7684\u6807\u7b7e\u4e0a\u3002\u8fd9\u4e00\u7c7b\u5177\u5907\u4efb\u52a1\u7279\u6027\u7684\u6a21\u677f\u53ef\u4ee5\u79f0\u4e4b\u4e3a\u6307\u4ee4Instruction. \u5e38\u89c1\u4efb\u52a1\u7684\u6307\u4ee4\u6a21\u677f\uff1a \u5982\u4f55\u5b9e\u73b0Instruction-Tuning? \u4e3a\u6bcf\u4e2a\u4efb\u52a1\u8bbe\u8ba110\u4e2a\u6307\u4ee4\u6a21\u7248\uff0c\u6d4b\u8bd5\u65f6\u770b\u5e73\u5747\u548c\u6700\u597d\u7684\u8868\u73b0.","title":"2. Instruction-Tuning(\u6307\u4ee4\u5b66\u4e60)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#3-chain-of-thought","text":"\u601d\u7ef4\u94fe (Chain-of-thought\uff0cCoT) \u7684\u6982\u5ff5\u662f\u5728 Google \u7684\u8bba\u6587 \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\" \u4e2d\u88ab\u9996\u6b21\u63d0\u51fa\u3002\u601d\u7ef4\u94fe\uff08CoT\uff09\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u63d0\u793a\u7b56\u7565\uff0c\u7528\u4e8e\u63d0\u9ad8 LLM \u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5982\u7b97\u672f\u63a8\u7406\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u7b26\u53f7\u63a8\u7406\u3002 CoT \u6ca1\u6709\u50cf ICL \u90a3\u6837\u7b80\u5355\u5730\u7528\u8f93\u5165\u8f93\u51fa\u5bf9\u6784\u5efa\u63d0\u793a\uff0c\u800c\u662f\u7ed3\u5408\u4e86\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\uff0c\u8fd9\u4e9b\u6b65\u9aa4\u53ef\u4ee5\u5c06\u6700\u7ec8\u8f93\u51fa\u5f15\u5165\u63d0\u793a\u3002\u7b80\u5355\u6765\u8bf4\uff0c \u601d\u7ef4\u94fe\u662f\u4e00\u79cd\u79bb\u6563\u5f0f\u63d0\u793a\u5b66\u4e60 \uff0c\u66f4\u5177\u4f53\u5730\uff0c\u5927\u6a21\u578b\u4e0b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08\u5373\u4e0d\u8fdb\u884c\u8bad\u7ec3\uff0c\u5c06\u4f8b\u5b50\u6dfb\u52a0\u5230\u5f53\u524d\u6837\u672c\u8f93\u5165\u7684\u524d\u9762\uff0c\u8ba9\u6a21\u578b\u4e00\u6b21\u8f93\u5165\u8fd9\u4e9b\u6587\u672c\u8fdb\u884c\u8f93\u51fa\u5b8c\u6210\u4efb\u52a1\uff09\uff0c\u76f8\u6bd4\u4e8e\u4e4b\u524d\u4f20\u7edf\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08\u5373\u901a\u8fc7x1,y1,x2,y2,....xtest\u4f5c\u4e3a\u8f93\u5165\u6765\u8ba9\u5927\u6a21\u578b\u8865\u5168\u8f93\u51faytest\uff09\uff0c\u601d\u7ef4\u94fe\u591a\u4e86\u4e2d\u95f4\u7684\u63a8\u5bfc\u63d0\u793a\u3002 \u4ee5\u4e00\u4e2a\u6570\u5b66\u9898\u4e3a\u4f8b\uff1a \u53ef\u4ee5\u770b\u5230\u6a21\u578b\u65e0\u6cd5\u505a\u51fa\u6b63\u786e\u7684\u56de\u7b54\u3002\u4f46\u5982\u679c\u8bf4\uff0c\u6211\u4eec\u7ed9\u6a21\u578b\u4e00\u4e9b\u5173\u4e8e\u89e3\u9898\u7684\u601d\u8def\uff0c\u5c31\u50cf\u6211\u4eec\u6570\u5b66\u8003\u8bd5\uff0c\u90fd\u4f1a\u628a\u89e3\u9898\u8fc7\u7a0b\u5199\u51fa\u6765\u518d\u6700\u7ec8\u5f97\u51fa\u7b54\u6848\uff0c\u4e0d\u7136\u65e0\u6cd5\u5f97\u5206\u3002CoT \u505a\u7684\u5c31\u662f\u8fd9\u4ef6\u4e8b\uff0c\u793a\u4f8b\u5982\u4e0b\uff1a \u53ef\u4ee5\u770b\u5230\uff0c\u7c7b\u4f3c\u7684\u7b97\u672f\u9898\uff0c\u601d\u7ef4\u94fe\u63d0\u793a\u4f1a\u5728\u7ed9\u51fa\u7b54\u6848\u4e4b\u524d\uff0c\u8fd8\u4f1a\u81ea\u52a8\u7ed9\u51fa\u63a8\u7406\u6b65\u9aa4\uff1a \u201c\u7f57\u6770\u5148\u67095\u4e2a\u7403\uff0c2\u76d23\u4e2a\u7f51\u7403\u7b49\u4e8e6\u4e2a\uff0c5 + 6 = 11\u201d \u201c\u98df\u5802\u539f\u6765\u670923\u4e2a\u82f9\u679c\uff0c\u7528\u4e8620\u4e2a\uff0c23-20=3\uff1b\u53c8\u4e70\u4e866\u4e2a\u82f9\u679c\uff0c3+6=9 \u4e0a\u8ff0\u4f8b\u5b50\u8bc1\u660e\u4e86\u601d\u7ef4\u94fe\u63d0\u793a\u7ed9\u51fa\u4e86\u6b63\u786e\u7b54\u6848\uff0c\u800c\u76f4\u63a5\u7ed9\u51fa\u7b54\u6848\u7684\u4f20\u7edf\u63d0\u793a\u5b66\u4e60\uff0c\u7ed3\u679c\u662f\u9519\u7684\uff0c\u8fde\u5f88\u57fa\u672c\u7684\u6570\u5b66\u8ba1\u7b97\u90fd\u505a\u4e0d\u597d\u3002\u7b80\u5355\u6765\u8bf4\uff0c\u8bed\u8a00\u6a21\u578b\u5f88\u96be\u5c06\u6240\u6709\u7684\u8bed\u4e49\u76f4\u63a5\u8f6c\u5316\u4e3a\u4e00\u4e2a\u65b9\u7a0b\uff0c\u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u66f4\u52a0\u590d\u6742\u7684\u601d\u8003\u8fc7\u7a0b\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u4e2d\u95f4\u6b65\u9aa4\uff0c\u6765\u66f4\u597d\u5730\u63a8\u7406\u95ee\u9898\u7684\u6bcf\u4e2a\u90e8\u5206\u3002 CoT\u5206\u7c7b\uff1a Few-shot CoT \uff1a\u662f ICL \u7684\u4e00\u79cd\u7279\u6b8a\u60c5\u51b5\uff0c\u5b83\u901a\u8fc7\u878d\u5408 CoT \u63a8\u7406\u6b65\u9aa4\uff0c\u5c06\u6bcf\u4e2a\u6f14\u793a\u3008input\uff0coutput\u3009\u6269\u5145\u4e3a\u3008input\uff0cCoT\uff0coutput\u3009\u3002 Zero-shot CoT\uff1a\u4e0e Few-shot CoT \u4e0d\u540c \u5728 prompt \u4e2d\u4e0d\u5305\u62ec\u4eba\u5de5\u6807\u6ce8\u7684\u4efb\u52a1\u6f14\u793a\u3002\u76f8\u53cd\uff0c\u5b83\u76f4\u63a5\u751f\u6210\u63a8\u7406\u6b65\u9aa4\uff0c\u7136\u540e\u4f7f\u7528\u751f\u6210\u7684 CoT \u6765\u5bfc\u51fa\u7b54\u6848\u3002\uff08\u5176\u4e2d LLM \u9996\u5148\u7531 \u201cLet's think step by step\u201d \u63d0\u793a\u751f\u6210\u63a8\u7406\u6b65\u9aa4\uff0c\u7136\u540e\u7531 \u201cTherefore, the answer is\u201d \u63d0\u793a\u5f97\u51fa\u6700\u7ec8\u7b54\u6848\u3002\u4ed6\u4eec\u53d1\u73b0\uff0c\u5f53\u6a21\u578b\u89c4\u6a21\u8d85\u8fc7\u4e00\u5b9a\u89c4\u6a21\u65f6\uff0c\u8fd9\u79cd\u7b56\u7565\u4f1a\u5927\u5927\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u5bf9\u5c0f\u89c4\u6a21\u6a21\u578b\u65e0\u6548\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u6d8c\u73b0\u80fd\u529b\u6a21\u5f0f\uff09\u3002 \u4e00\u4e2a\u6709\u6548\u7684\u601d\u7ef4\u94fe\u5e94\u8be5\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a \u903b\u8f91\u6027 \uff1a\u601d\u7ef4\u94fe\u4e2d\u7684\u6bcf\u4e2a\u601d\u8003\u6b65\u9aa4\u90fd\u5e94\u8be5\u662f\u6709\u903b\u8f91\u5173\u7cfb\u7684\uff0c\u5b83\u4eec\u5e94\u8be5\u76f8\u4e92\u8fde\u63a5\uff0c\u4ece\u800c\u5f62\u6210\u4e00\u4e2a\u5b8c\u6574\u7684\u601d\u8003\u8fc7\u7a0b\u3002 \u5168\u9762\u6027 \uff1a\u601d\u7ef4\u94fe\u5e94\u8be5\u5c3d\u53ef\u80fd\u5730\u5168\u9762\u548c\u7ec6\u81f4\u5730\u8003\u8651\u95ee\u9898\uff0c\u4ee5\u786e\u4fdd\u4e0d\u4f1a\u5ffd\u7565\u4efb\u4f55\u53ef\u80fd\u7684\u56e0\u7d20\u548c\u5f71\u54cd\u3002 \u53ef\u884c\u6027 \uff1a\u601d\u7ef4\u94fe\u4e2d\u7684\u6bcf\u4e2a\u601d\u8003\u6b65\u9aa4\u90fd\u5e94\u8be5\u662f\u53ef\u884c\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u4eec\u5e94\u8be5\u53ef\u4ee5\u88ab\u5b9e\u9645\u64cd\u4f5c\u548c\u5b9e\u65bd\u3002 \u53ef\u9a8c\u8bc1\u6027 \uff1a\u601d\u7ef4\u94fe\u4e2d\u7684\u6bcf\u4e2a\u601d\u8003\u6b65\u9aa4\u90fd\u5e94\u8be5\u662f\u53ef\u4ee5\u9a8c\u8bc1\u7684\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u5b83\u4eec\u5e94\u8be5\u53ef\u4ee5\u901a\u8fc7\u5b9e\u9645\u7684\u6570\u636e\u548c\u4e8b\u5b9e\u6765\u9a8c\u8bc1\u5176\u6b63\u786e\u6027\u548c\u6709\u6548\u6027\u3002","title":"3. Chain-of-Thought\uff08\u601d\u7ef4\u94fe\uff09"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#peft","text":"\u76ee\u524d\u5728\u5de5\u4e1a\u754c\u5e94\u7528\u5927\u6a21\u578b\u4e3b\u6d41\u65b9\u5f0f\uff1a \u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\uff08Parameter-Efficient Fine-Tuning\uff0cPEFT\uff09 \uff0c PEFT \u65b9\u6cd5\u4ec5\u5fae\u8c03\u5c11\u91cf\u6216\u989d\u5916\u7684\u6a21\u578b\u53c2\u6570\uff0c\u56fa\u5b9a\u5927\u90e8\u5206\u9884\u8bad\u7ec3\u53c2\u6570\uff0c\u5927\u5927\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c \uff0c\u540c\u65f6\u6700\u5148\u8fdb\u7684 PEFT \u6280\u672f\u4e5f\u80fd\u5b9e\u73b0\u4e86\u4e0e\u5168\u91cf\u5fae\u8c03\u76f8\u5f53\u7684\u6027\u80fd\u3002 \u8be5\u65b9\u6cd5\u53ef\u4ee5\u4f7f PLM \u9ad8\u6548\u9002\u5e94\u5404\u79cd\u4e0b\u6e38\u5e94\u7528\u4efb\u52a1\uff0c\u800c\u65e0\u9700\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\uff0c\u4e14\u8ba9\u5927\u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fdb\u884c\u5168\u91cf\u5fae\u8c03\uff08Full Fine-Tuning\uff09\u53d8\u5f97\u53ef\u884c\u3002 \u76ee\u524d\u5e94\u7528\u8f83\u591a\u7684PEFT\u65b9\u6cd5\u4e3b\u8981\u5206\u4e3a\u4e09\u5927\u7c7b\uff1a Prefix/Prompt-Tuning \uff1a\u5728\u6a21\u578b\u7684\u8f93\u5165\u6216\u9690\u5c42\u6dfb\u52a0 k k \u4e2a\u989d\u5916\u53ef\u8bad\u7ec3\u7684\u524d\u7f00 tokens\uff08\u8fd9\u4e9b\u524d\u7f00\u662f\u8fde\u7eed\u7684\u4f2a tokens\uff0c\u4e0d\u5bf9\u5e94\u771f\u5b9e\u7684 tokens\uff09\uff0c\u53ea\u8bad\u7ec3\u8fd9\u4e9b\u524d\u7f00\u53c2\u6570\uff1b Adapter-Tuning \uff1a\u5c06\u8f83\u5c0f\u7684\u795e\u7ecf\u7f51\u7edc\u5c42\u6216\u6a21\u5757\u63d2\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6bcf\u4e00\u5c42\uff0c\u8fd9\u4e9b\u65b0\u63d2\u5165\u7684\u795e\u7ecf\u6a21\u5757\u79f0\u4e3a adapter\uff08\u9002\u914d\u5668\uff09\uff0c\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03\u65f6\u4e5f\u53ea\u8bad\u7ec3\u8fd9\u4e9b\u9002\u914d\u5668\u53c2\u6570\uff1b LoRA \uff1a\u901a\u8fc7\u5b66\u4e60\u5c0f\u53c2\u6570\u7684\u4f4e\u79e9\u77e9\u9635\u6765\u8fd1\u4f3c\u6a21\u578b\u6743\u91cd\u77e9\u9635 W W \u7684\u53c2\u6570\u66f4\u65b0\uff0c\u8bad\u7ec3\u65f6\u53ea\u4f18\u5316\u4f4e\u79e9\u77e9\u9635\u53c2\u6570; \u6b64\u5916**Huggface \u5f00\u6e90\u7684\u4e00\u4e2a\u9ad8\u6548\u5fae\u8c03\u5927\u6a21\u578b\u7684\u5e93PEFT**\uff0c\u8be5\u7b97\u6cd5\u5e93\u652f\u6301\u4e0a\u8ff0\u4e09\u7c7b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528\u3002","title":"PEFT(\u5927\u6a21\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#1-prefix-tuning","text":"Prefix-Tuning \u5728\u6a21\u578b\u8f93\u5165\u524d\u6dfb\u52a0\u4e00\u4e2a\u8fde\u7eed\u7684\u4e14\u4efb\u52a1\u7279\u5b9a\u7684\u5411\u91cf\u5e8f\u5217\uff08continuous task-specific vectors\uff09\uff0c\u79f0\u4e4b\u4e3a\u524d\u7f00\uff08prefix\uff09\u3002\u524d\u7f00\u88ab\u89c6\u4e3a\u4e00\u7cfb\u5217\u201c\u865a\u62df tokens\u201d\uff0c\u4f46\u662f\u5b83\u7531\u4e0d\u5bf9\u5e94\u4e8e\u771f\u5b9e tokens \u7684\u81ea\u7531\u53c2\u6570\u7ec4\u6210\u3002\u4e0e\u66f4\u65b0\u6240\u6709 PLM \u53c2\u6570\u7684\u5168\u91cf\u5fae\u8c03\u4e0d\u540c\uff0cPrefix-Tuning \u56fa\u5b9a PLM \u7684\u6240\u6709\u53c2\u6570\uff0c\u53ea\u66f4\u65b0\u4f18\u5316\u7279\u5b9a\u4efb\u52a1\u7684 prefix\u3002\u56e0\u6b64\uff0c\u5728\u751f\u4ea7\u90e8\u7f72\u65f6\uff0c\u53ea\u9700\u8981\u5b58\u50a8\u4e00\u4e2a\u5927\u578b PLM \u7684\u526f\u672c\u548c\u4e00\u4e2a\u5b66\u4e60\u5230\u7684\u7279\u5b9a\u4efb\u52a1\u7684 prefix\uff0c\u6bcf\u4e2a\u4e0b\u6e38\u4efb\u52a1\u53ea\u4ea7\u751f\u975e\u5e38\u5c0f\u7684\u989d\u5916\u7684\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\u3002 Fine-tuning \u66f4\u65b0\u6240\u6709 PLM \u53c2\u6570\uff0c\u5e76\u4e14\u9700\u8981\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u5b58\u50a8\u5b8c\u6574\u7684\u6a21\u578b\u526f\u672c\u3002Prefix-tuning \u51bb\u7ed3\u4e86 PLM \u53c2\u6570\u5e76\u4e14\u53ea\u4f18\u5316\u4e86 prefix\u3002\u56e0\u6b64\uff0c\u53ea\u9700\u8981\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u5b58\u50a8\u7279\u5b9a prefix\uff0c\u4f7f Prefix-tuning \u6a21\u5757\u5316\u4e14\u8282\u7701\u5b58\u50a8\u7a7a\u95f4\u3002 \u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4ee5 GPT2 \u7684\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e3a\u4f8b\uff0c\u5c06\u8f93\u5165 x x \u548c\u8f93\u51fa y y \u62fc\u63a5\u4e3a z=[x;y] z=[x;y] \uff0c\u7ecf\u8fc7 LM \u7684\u67d0\u4e00\u5c42\u8ba1\u7b97\u9690\u5c42\u8868\u793a h=[h_1,...,h_i,....,h_n] h=[h_1,...,h_i,....,h_n] \uff0c h_i=LM_\u00d8(z_i, h<i) h_i=LM_\u00d8(z_i, h<i) \uff0c\u5176\u4e2d\uff0c X_{idx} X_{idx} \u548c Y_{idx}\u200b Y_{idx}\u200b \u5206\u522b\u4e3a\u8f93\u5165\u548c\u8f93\u51fa\u5e8f\u5217\u7684\u7d22\u5f15\u3002 Prefix-Tuning \u5728\u8f93\u5165\u524d\u6dfb\u52a0\u524d\u7f00\uff0c\u5373 z=[Prefix,x,y] z=[Prefix,x,y] \uff0c P_{idx} P_{idx} \u4e3a\u524d\u7f00\u5e8f\u5217\u7684\u7d22\u5f15\uff0c |P_{idx}| |P_{idx}| \u4e3a\u524d\u7f00\u7684\u957f\u5ea6\u3002\u524d\u7f00\u7d22\u5f15\u5bf9\u5e94\u7740\u7531 \u03b8 \u03b8 \u53c2\u6570\u5316\u7684\u5411\u91cf\u77e9\u9635 P_\u03b8 P_\u03b8 \uff0c\u7ef4\u5ea6\u4e3a |P_{idx}|\u00d7dim(h_i) |P_{idx}|\u00d7dim(h_i) \u3002\u9690\u5c42\u8868\u793a\uff1a\u82e5\u7d22\u5f15\u4e3a\u524d\u7f00\u7d22\u5f15 P_{idx} P_{idx} \uff0c\u76f4\u63a5\u4ece P_\u03b8 P_\u03b8 \u590d\u5236\u5bf9\u5e94\u7684\u5411\u91cf\u4f5c\u4e3a h_i h_i ( \u5728\u6a21\u578b\u6bcf\u4e00\u5c42\u90fd\u6dfb\u52a0\u524d\u7f00\u5411\u91cf )\uff1b\u5426\u5219\u76f4\u63a5\u901a\u8fc7 LM \u8ba1\u7b97\u5f97\u5230\uff0c\u540c\u65f6\uff0c\u7ecf\u8fc7 LM \u8ba1\u7b97\u7684 h_i h_i \u4e5f\u4f9d\u8d56\u4e8e\u5176\u5de6\u4fa7\u7684\u524d\u7f00\u53c2\u6570 P_\u03b8 P_\u03b8 \uff0c\u5373**\u901a\u8fc7\u524d\u7f00\u6765\u5f71\u54cd\u540e\u7eed\u7684\u5e8f\u5217\u9690\u5c42\u6fc0\u5316\u503c**\u3002 \u4f46\u662f\u76f4\u63a5\u4f18\u5316 P_\u03b8 P_\u03b8 \u4f1a\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\uff0c\u901a\u8fc7\u4e00\u4e2a\u66f4\u5c0f\u7684\u77e9\u9635 P_w P_w \u548c\u4e00\u4e2a\u66f4\u5927\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc MLP_\u03b8 MLP_\u03b8 \u5bf9 P_\u03b8 P_\u03b8 \u8fdb\u884c\u91cd\u53c2\u6570\u5316: P_\u03b8[i,:]=MLP_\u03b8(P_w[i,:]) P_\u03b8[i,:]=MLP_\u03b8(P_w[i,:]) \u3002\u5728\u8bad\u7ec3\u65f6\uff0cLM \u7684\u53c2\u6570 \u00d8 \u00d8 \u88ab\u56fa\u5b9a\uff0c\u53ea\u6709\u524d\u7f00\u53c2\u6570 \u03b8 \u03b8 \u4e3a\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\u3002\u8bad\u7ec3\u5b8c\u6210\u540e\uff0c\u53ea\u6709\u524d\u7f00 P_\u03b8 P_\u03b8 \u88ab\u4fdd\u5b58\u3002 P-Tuning \u4e0e Prefix-Tuning \u7684\u65b9\u6cd5\u601d\u8def\u76f8\u4f3c\uff0cPrefix-Tuning \u662f\u5c06\u989d\u5916\u7684embedding\u52a0\u5728\u5f00\u5934\uff0c\u770b\u8d77\u6765\u66f4\u50cf\u6a21\u4effInstruction\u6307\u4ee4\uff0c\u800cP-Tuning \u4f4d\u7f6e\u4e0d\u56fa\u5b9a\u3002Prefix-Tuning \u901a\u8fc7\u5728\u6bcf\u4e2a\u5c42\u90fd\u6dfb\u52a0\u53ef\u8bad\u7ec3\u53c2\u6570\uff0c\u901a\u8fc7MLP\u521d\u59cb\u5316\uff0c\u800cP-Tuning\u53ea\u5728\u8f93\u5165\u7684\u65f6\u5019\u52a0\u5165embedding, \u5e76\u901a\u8fc7LSTM+MLP\u521d\u59cb\u5316. Prompt Tuning \u65b9\u5f0f\u53ef\u4ee5\u770b\u505a\u662f Prefix Tuning \u7684\u7b80\u5316\uff0c\u53ea\u5728\u8f93\u5165\u5c42\u52a0\u5165 prompt tokens\uff0c\u5e76\u4e0d\u9700\u8981\u52a0\u5165 MLP \u8fdb\u884c\u8c03\u6574\u6765\u89e3\u51b3\u96be\u8bad\u7ec3\u7684\u95ee\u9898.","title":"1. Prefix Tuning"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#2-adapter-tuning","text":"\u4e0e Prefix Tuning \u548c Prompt Tuning \u8fd9\u7c7b\u5728\u8f93\u5165\u524d\u53ef\u8bad\u7ec3\u6dfb\u52a0 prompt embedding \u53c2\u6570\u6765\u4ee5\u5c11\u91cf\u53c2\u6570\u9002\u914d\u4e0b\u6e38\u4efb\u52a1\uff0c Adapter Tuning \u5219\u662f\u5728\u9884\u8bad\u7ec3\u6a21\u578b\u5185\u90e8\u7684\u7f51\u7edc\u5c42\u4e4b\u95f4\u6dfb\u52a0\u65b0\u7684\u7f51\u7edc\u5c42\u6216\u6a21\u5757\u6765\u9002\u914d\u4e0b\u6e38\u4efb\u52a1 \u3002 \u5047\u8bbe\u9884\u8bad\u7ec3\u6a21\u578b\u51fd\u6570\u8868\u793a\u4e3a \u00d8_w(x) \u00d8_w(x) \uff0c\u5bf9\u4e8e Adapter Tuning \uff0c\u6dfb\u52a0\u9002\u914d\u5668\u4e4b\u540e\u6a21\u578b\u51fd\u6570\u66f4\u65b0\u4e3a \u00d8_{w,w_0}(x) \u00d8_{w,w_0}(x) \uff0c w w \u662f\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u53c2\u6570\uff0c w_0 w_0 \u662f\u65b0\u6dfb\u52a0\u7684\u9002\u914d\u5668\u7684\u53c2\u6570\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c w w \u88ab\u56fa\u5b9a\uff0c\u53ea\u6709 w_0 w_0 \u88ab\u66f4\u65b0\u3002 |w_0|<<|w| |w_0|<<|w| \uff0c\u8fd9\u4f7f\u5f97\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u53ea\u9700\u8981\u6dfb\u52a0\u5c11\u91cf\u53ef\u8bad\u7ec3\u7684\u53c2\u6570\u5373\u53ef\uff0c\u8282\u7701\u8ba1\u7b97\u548c\u5b58\u50a8\u5f00\u9500\uff0c\u540c\u65f6\u5171\u4eab\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6a21\u578b\u3002 Series Adapter\u7684\u9002\u914d\u5668\u7ed3\u6784\u548c\u4e0e Transformer \u7684\u96c6\u6210\u5982\u4e0a\u56fe\u6240\u793a\u3002\u9002\u914d\u5668\u6a21\u5757\u88ab\u6dfb\u52a0\u5230\u6bcf\u4e2a Transformer \u5c42\u4e24\u6b21\uff1a\u591a\u5934\u6ce8\u610f\u529b\u6620\u5c04\u4e4b\u540e\u548c\u4e24\u5c42\u524d\u9988\u795e\u7ecf\u7f51\u7edc\u4e4b\u540e\u3002\u9002\u914d\u5668\u662f\u4e00\u4e2a bottleneck\uff08\u74f6\u9888\uff09\u7ed3\u6784\u7684\u6a21\u5757\uff0c\u7531\u4e00\u4e2a\u4e24\u5c42\u7684\u524d\u9988\u795e\u7ecf\u7f51\u7edc\uff08\u7531\u5411\u4e0b\u6295\u5f71\u77e9\u9635\u3001\u975e\u7ebf\u6027\u51fd\u6570\u548c\u5411\u4e0a\u6295\u5f71\u77e9\u9635\u6784\u6210\uff09\u548c\u4e00\u4e2a\u8f93\u51fa\u8f93\u51fa\u4e4b\u95f4\u7684\u6b8b\u5dee\u8fde\u63a5\u7ec4\u6210\u3002","title":"2. Adapter Tuning"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#3-lora","text":"\u4e0a\u8ff0Adapter Tuning \u65b9\u6cd5\u5728 PLM \u57fa\u7840\u4e0a\u6dfb\u52a0\u9002\u914d\u5668\u5c42\u4f1a\u5f15\u5165\u989d\u5916\u7684\u8ba1\u7b97\uff0c\u5e26\u6765\u63a8\u7406\u5ef6\u8fdf\u95ee\u9898\uff1b\u800c Prefix Tuning \u65b9\u6cd5\u96be\u4ee5\u4f18\u5316\uff0c\u5176\u6027\u80fd\u968f\u53ef\u8bad\u7ec3\u53c2\u6570\u89c4\u6a21\u975e\u5355\u8c03\u53d8\u5316\uff0c\u66f4\u6839\u672c\u7684\u662f\uff0c\u4e3a\u524d\u7f00\u4fdd\u7559\u90e8\u5206\u5e8f\u5217\u957f\u5ea6\u5fc5\u7136\u4f1a\u51cf\u5c11\u7528\u4e8e\u5904\u7406\u4e0b\u6e38\u4efb\u52a1\u7684\u5e8f\u5217\u957f\u5ea6\u3002\u56e0\u6b64\u5fae\u8f6f\u63a8\u51fa\u4e86LoRA\u65b9\u6cd5\u3002 \u4f4e\u79e9\u9002\u5e94\uff08Low-Rank Adaptation\uff09\u662f\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u6280\u672f\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u5bf9\u5927\u578b\u6a21\u578b\u7684\u6743\u91cd\u77e9\u9635\u8fdb\u884c\u9690\u5f0f\u7684\u4f4e\u79e9\u8f6c\u6362\uff0c\u4e5f\u5c31\u662f\uff1a\u901a\u8fc7\u4e00\u4e2a\u8f83\u4f4e\u7ef4\u5ea6\u7684\u8868\u793a\u6765\u8fd1\u4f3c\u8868\u793a\u4e00\u4e2a\u9ad8\u7ef4\u77e9\u9635\u6216\u6570\u636e\u96c6\u3002 \u57fa\u672c\u539f\u7406\uff1aLoRA\u6280\u672f\u51bb\u7ed3\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6743\u91cd\uff0c\u5e76\u5728\u6bcf\u4e2aTransformer\u5757\u4e2d\u6ce8\u5165\u53ef\u8bad\u7ec3\u5c42\uff08\u79f0\u4e3a\u79e9\u5206\u89e3\u77e9\u9635\uff09\uff0c\u5373\u5728\u6a21\u578b\u7684Linear\u5c42\u7684\u65c1\u8fb9\u589e\u52a0\u4e00\u4e2a\u201c\u65c1\u652f\u201dA\u548cB\u3002\u5176\u4e2d\uff0cA\u5c06\u6570\u636e\u4eced\u7ef4\u964d\u5230r\u7ef4\uff0c\u8fd9\u4e2ar\u662fLoRA\u7684\u79e9\uff0c\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u8d85\u53c2\u6570\uff1bB\u5c06\u6570\u636e\u4ecer\u7ef4\u5347\u5230d\u7ef4\uff0cB\u90e8\u5206\u7684\u53c2\u6570\u521d\u59cb\u4e3a0\u3002\u6a21\u578b\u8bad\u7ec3\u7ed3\u675f\u540e\uff0c\u9700\u8981\u5c06A+B\u90e8\u5206\u7684\u53c2\u6570\u4e0e\u539f\u5927\u6a21\u578b\u7684\u53c2\u6570\u5408\u5e76\u5728\u4e00\u8d77\u4f7f\u7528\u3002 python\u4f2a\u4ee3\u7801 input_dim = 768 # \u4f8b\u5982\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u9690\u85cf\u5927\u5c0f output_dim = 768 # \u4f8b\u5982\uff0c\u5c42\u7684\u8f93\u51fa\u5927\u5c0f rank = 8 # \u4f4e\u79e9\u9002\u5e94\u7684\u7b49\u7ea7'r' W = ... # \u6765\u81ea\u9884\u8bad\u7ec3\u7f51\u7edc\u7684\u6743\u91cd\uff0c\u5f62\u72b6\u4e3a input_dim x output_dim W_A = nn . Parameter ( torch . empty ( input_dim , rank )) # LoRA\u6743\u91cdA W_B = nn . Parameter ( torch . empty ( rank , output_dim )) # LoRA\u6743\u91cdB\u521d\u59cb\u5316LoRA\u6743\u91cd nn . init . kaiming_uniform_ ( W_A , a = math . sqrt ( 5 )) nn . init . zeros_ ( W_B ) def regular_forward_matmul ( x , W ): h = x @ W return h def lora_forward_matmul ( x , W , W_A , W_B ): h = x @ W # \u5e38\u89c4\u77e9\u9635\u4e58\u6cd5 h += x @ ( W_A @ W_B ) * alpha # \u4f7f\u7528\u7f29\u653e\u7684LoRA\u6743\u91cd,alpha\u7f29\u653e\u56e0\u5b50 return h LoRA\u65b9\u6cd5\u662f\u76ee\u524d\u6700\u901a\u7528\u3001\u540c\u65f6\u4e5f\u662f\u6548\u679c\u6700\u597d\u7684\u5fae\u8c03\u65b9\u6cd5\u4e4b\u4e00\u3002","title":"3. LoRA"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/02-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt-Tuning%E6%8A%80%E6%9C%AF%E8%BF%9B%E9%98%B6.html#_2","text":"\u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecd\u4f01\u4e1a\u9762\u5411\u8d85\u5927\u89c4\u6a21\u6a21\u578b\u7684Prompt-Tuning\u65b9\u5f0f\u8fdb\u884c\u4e86\u539f\u7406\u4ecb\u7ecd\uff0c\u4ee5\u53ca\u76ee\u524dPEFT\u65b9\u5f0f\u7684\u539f\u7406\u8bb2\u89e3\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html","text":"LangChain\u7684\u4ecb\u7ecd\u548c\u5165\u95e8 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u4ec0\u4e48\u662fLangChain \u660e\u786eLangChain\u4e3b\u8981\u7ec4\u4ef6\u7684\u4f5c\u7528 \u4e86\u89e3LangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f 1 \u4ec0\u4e48\u662fLangChain \u00b6 LangChain\u7531 Harrison Chase \u521b\u5efa\u4e8e2022\u5e7410\u6708\uff0c\u5b83\u662f\u56f4\u7ed5LLMs\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5efa\u7acb\u7684\u4e00\u4e2a\u6846\u67b6\uff0cLLMs\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u6d77\u91cf\u6570\u636e\u6765\u5206\u6790\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0cGPT3.5\u3001GPT4\u662fLLMs\u6700\u5148\u8fdb\u7684\u4ee3\u8868\uff0c\u56fd\u5185\u767e\u5ea6\u7684\u6587\u5fc3\u4e00\u8a00\u3001\u963f\u91cc\u7684\u901a\u4e49\u5343\u95ee\u4e5f\u5c5e\u4e8eLLMs\u3002LangChain\u81ea\u8eab\u5e76\u4e0d\u5f00\u53d1LLMs\uff0c\u5b83\u7684\u6838\u5fc3\u7406\u5ff5\u662f\u4e3a\u5404\u79cdLLMs\u5b9e\u73b0\u901a\u7528\u7684\u63a5\u53e3\uff0c\u628aLLMs\u76f8\u5173\u7684\u7ec4\u4ef6\u201c\u94fe\u63a5\u201d\u5728\u4e00\u8d77\uff0c\u7b80\u5316LLMs\u5e94\u7528\u7684\u5f00\u53d1\u96be\u5ea6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u5feb\u901f\u5730\u5f00\u53d1\u590d\u6742\u7684LLMs\u5e94\u7528\u3002LangChain\u76ee\u524d\u6709\u4e24\u4e2a\u8bed\u8a00\u7684\u5b9e\u73b0\uff1apython\u3001nodejs\u3002 \u672c\u7ae0\u8282\u5c06\u4f1a\u4ece\u4e24\u4e2a\u65b9\u9762\u5168\u9762\u4ecb\u7ecdLangChain\uff1a\u4e00\u4e2a\u662fLangChain\u7ec4\u4ef6\u7684\u57fa\u672c\u6982\u5ff5\u548c\u5e94\u7528\uff1b\u53e6\u4e00\u4e2a\u662fLangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f\u3002 \u53c2\u8003\u5b98\u7f51\u4ecb\u7ecd\uff1a https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub 2 LangChain\u4e3b\u8981\u7ec4\u4ef6 \u00b6 \u4e00\u4e2aLangChain\u7684\u5e94\u7528\u662f\u9700\u8981\u591a\u4e2a\u7ec4\u4ef6\u5171\u540c\u5b9e\u73b0\u7684\uff0cLangChain\u4e3b\u8981\u652f\u63016\u79cd\u7ec4\u4ef6\uff1a Models\uff1a\u6a21\u578b\uff0c\u5404\u79cd\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6a21\u578b\u96c6\u6210\uff0c\u6bd4\u5982GPT-4 Prompts\uff1a\u63d0\u793a\uff0c\u5305\u62ec\u63d0\u793a\u7ba1\u7406\u3001\u63d0\u793a\u4f18\u5316\u548c\u63d0\u793a\u5e8f\u5217\u5316 Memory\uff1a\u8bb0\u5fc6\uff0c\u7528\u6765\u4fdd\u5b58\u548c\u6a21\u578b\u4ea4\u4e92\u65f6\u7684\u4e0a\u4e0b\u6587\u72b6\u6001 Indexes\uff1a\u7d22\u5f15\uff0c\u7528\u6765\u7ed3\u6784\u5316\u6587\u6863\uff0c\u4ee5\u4fbf\u548c\u6a21\u578b\u4ea4\u4e92 Chains\uff1a\u94fe\uff0c\u4e00\u7cfb\u5217\u5bf9\u5404\u79cd\u7ec4\u4ef6\u7684\u8c03\u7528 Agents\uff1a\u4ee3\u7406\uff0c\u51b3\u5b9a\u6a21\u578b\u91c7\u53d6\u54ea\u4e9b\u884c\u52a8\uff0c\u6267\u884c\u5e76\u4e14\u89c2\u5bdf\u6d41\u7a0b\uff0c\u76f4\u5230\u5b8c\u6210\u4e3a\u6b62 2.1 Models \u00b6 \u73b0\u5728\u5e02\u9762\u4e0a\u7684\u6a21\u578b\u591a\u5982\u725b\u6bdb\uff0c\u5404\u79cd\u5404\u6837\u7684\u6a21\u578b\u4e0d\u65ad\u51fa\u73b0\uff0cLangChain\u6a21\u578b\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u4e0e\u5404\u79cd\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u4e3a\u6240\u6709\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u7cbe\u7b80\u7684\u7edf\u4e00\u63a5\u53e3\u3002 LangChain\u76ee\u524d\u652f\u6301\u4e09\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff1aLLMs\u3001Chat Models(\u804a\u5929\u6a21\u578b)\u3001Embeddings Models(\u5d4c\u5165\u6a21\u578b\uff09. LLMs: \u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u6587\u672c\u5b57\u7b26\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u6587\u672c\u5b57\u7b26. \u804a\u5929\u6a21\u578b: \u57fa\u4e8eLLMs, \u4e0d\u540c\u7684\u662f\u5b83\u63a5\u6536\u804a\u5929\u6d88(\u4e00\u79cd\u7279\u5b9a\u683c\u5f0f\u7684\u6570\u636e)\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u804a\u5929\u6d88\u606f. \u6587\u672c\u5d4c\u5165\u6a21\u578b: \u6587\u672c\u5d4c\u5165\u6a21\u578b\u63a5\u6536\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u8fd4\u56de\u7684\u662f\u6d6e\u70b9\u6570\u5217\u8868. LangChain\u652f\u6301\u7684\u4e09\u7c7b\u6a21\u578b\uff0c\u5b83\u4eec\u7684\u4f7f\u7528\u573a\u666f\u4e0d\u540c\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u4e0d\u540c\uff0c\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9879\u76ee\u9700\u8981\u9009\u62e9\u76f8\u5e94\u3002 2.1.1 LLMs (\u5927\u8bed\u8a00\u6a21\u578b) \u00b6 LLMs\u4f7f\u7528\u573a\u666f\u6700\u591a\uff0c\u5e38\u7528\u5927\u6a21\u578b\u7684\u4e0b\u8f7d\u5e93\uff1a https://huggingface.co/models \uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u300c\u6587\u5fc3\u4e00\u8a00\u300d\u6a21\u578b\u4e3a\u4f8b, \u4f7f\u7528\u8be5\u7c7b\u6a21\u578b\u7684\u7ec4\u4ef6\uff1a \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1alangchain\u548copenai pip install openai = =0.28 pip install langchain pip install qianfan \u6ce8\u610f\uff0c\u5728\u4f7f\u7528openai\u6a21\u578b\u4e4b\u524d\uff0c\u5fc5\u987b\u5f00\u901aOpenAI API\u670d\u52a1\uff0c\u9700\u8981\u83b7\u5f97API Token\u3002 \u7b2c\u4e8c\u6b65\uff1a\u501f\u52a9\u767e\u5ea6\u667a\u80fd\u4e91--\u5343\u5e06\u5927\u6a21\u578b\u5e73\u53f0\uff1a\u7533\u8bf7API Key \u4ee5\u53caSecret Key \u60f3\u8bf7\u89c1\u9644\u4ef6\u624b\u518c \u7b2c\u4e09\u90e8\uff1a\u4ee3\u7801\u5b9e\u73b0 import os from langchain.llms import QianfanLLMEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanLLMEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) res = llm ( \"\u5e2e\u6211\u8bb2\u4e2a\u7b11\u8bdd\u5427\" ) print ( res ) ##\u6253\u5370\u7ed3\u679c\uff1a \u5f53\u7136\u53ef\u4ee5 \uff01 \u8fd9\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u7b11\u8bdd \uff1a \u6709\u4e00\u5929 \uff0c \u4e00\u53ea\u5c0f\u9e1f\u98de\u5230\u4e00\u680b\u5927\u623f\u5b50\u524d \uff0c \u5927\u58f0\u558a\u9053 \uff1a\u201c \u5356\u62a5 \uff01 \u5356\u62a5 \uff01\u201d \u53ef\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5b83\u7ee7\u7eed\u558a\u9053 \uff1a\u201c \u563f \uff0c \u6709\u4eba\u5728\u5417 \uff1f \u5356\u62a5 \uff01\u201d \u8fd9\u6b21\u8fd8\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5c0f\u9e1f\u60f3\u4e86\u60f3 \uff0c \u4e8e\u662f\u8bf4 \uff1a\u201c \u5bf9\u4e0d\u8d77 \uff0c \u6253\u6270\u4e86 \uff01 \u6211\u53ea\u662f\u60f3\u77e5\u9053 \uff0c \u8fd9\u91cc\u6709\u4eba\u60f3\u4e70\u5929\u5802\u5417 \uff1f\u201d \u542c\u5230\u8fd9\u4e2a\u7b11\u8bdd \uff0c \u6211\u5e0c\u671b\u4f60\u4e5f\u80fd\u5f00\u5fc3\u8d77\u6765 \uff01 2.1.2 Chat Models (\u804a\u5929\u6a21\u578b) \u00b6 \u804a\u5929\u6d88\u606f\u5305\u542b\u4e0b\u9762\u51e0\u79cd\u7c7b\u578b\uff0c\u4f7f\u7528\u65f6\u9700\u8981\u6309\u7167\u7ea6\u5b9a\u4f20\u5165\u5408\u9002\u7684\u503c\uff1a AIMessage: \u5c31\u662f AI \u8f93\u51fa\u7684\u6d88\u606f\uff0c\u53ef\u4ee5\u662f\u9488\u5bf9\u95ee\u9898\u7684\u56de\u7b54. HumanMessage: \u4eba\u7c7b\u6d88\u606f\u5c31\u662f\u7528\u6237\u4fe1\u606f\uff0c\u7531\u4eba\u7ed9\u51fa\u7684\u4fe1\u606f\u53d1\u9001\u7ed9LLMs\u7684\u63d0\u793a\u4fe1\u606f\uff0c\u6bd4\u5982\u201c\u5b9e\u73b0\u4e00\u4e2a\u5feb\u901f\u6392\u5e8f\u65b9\u6cd5\u201d. SystemMessage: \u53ef\u4ee5\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u5177\u4f53\u6240\u5904\u7684\u73af\u5883\u548c\u80cc\u666f\uff0c\u5982\u89d2\u8272\u626e\u6f14\u7b49\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u7ed9\u51fa\u5177\u4f53\u7684\u6307\u793a\uff0c\u6bd4\u5982\u201c\u4f5c\u4e3a\u4e00\u4e2a\u4ee3\u7801\u4e13\u5bb6\u201d\uff0c\u6216\u8005\u201c\u8fd4\u56dejson\u683c\u5f0f\u201d. ChatMessage: Chat \u6d88\u606f\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u89d2\u8272\u7684\u53c2\u6570\uff0c\u4f46\u662f\u5728\u5927\u591a\u6570\u65f6\u95f4\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u4e0a\u9762\u7684\u4e09\u79cd\u7c7b\u578b. LangChain\u652f\u6301\u7684\u5e38\u89c1\u804a\u5929\u6a21\u578b\u6709\uff1a \u6a21\u578b \u63cf\u8ff0 ChatOpenAI OpenAI\u804a\u5929\u6a21\u578b AzureChatOpenAI Azure\u63d0\u4f9b\u7684OpenAI\u804a\u5929\u6a21\u578b PromptLayerChatOpenAI \u57fa\u4e8eOpenAI\u7684\u63d0\u793a\u6a21\u7248\u5e73\u53f0 \u4e3e\u4f8b\u8bf4\u660e\uff1a import os from langchain.chat_models import QianfanChatEndpoint from langchain.chat_models.base import HumanMessage os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) messages = [ HumanMessage ( content = \"\u7ed9\u6211\u5199\u4e00\u9996\u5510\u8bd7\" ) ] res = chat ( messages ) print ( res ) # \u6253\u5370\u7ed3\u679c\uff1a ''' content='\u597d\u7684\uff0c\u4ee5\u4e0b\u662f\u6211\u4e3a\u60a8\u521b\u4f5c\u7684\u5510\u8bd7\uff1a\\n\\n\u9752\u5c71\u4f9d\u65e7\u5728\uff0c\u51e0\u5ea6\u5915\u9633\u7ea2\u3002\\n\u767d\u53d1\u6e14\u6a35\u6c5f\u6e1a\u4e0a\uff0c\u60ef\u770b\u79cb\u6708\u6625\u98ce\u3002\\n\u4e00\u58f6\u6d4a\u9152\u559c\u76f8\u9022\uff0c\u53e4\u4eca\u591a\u5c11\u4e8b\uff0c\u90fd\u4ed8\u7b11\u8c08\u4e2d\u3002' ''' 2.1.3 \u63d0\u793a\u6a21\u677f \u00b6 \u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c\u6a21\u578b\u9ed8\u8ba4\u662f\u8fd4\u56de\u7eaf\u6587\u672c\u7ed3\u679c\u7684\uff0c\u5982\u679c\u60f3\u8ba9\u6a21\u578b\u8fd4\u56de\u60f3\u8981\u7684\u6570\u636e\u683c\u5f0f\uff08\u6bd4\u5982json\u683c\u5f0f\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528\u63d0\u793a\u6a21\u7248\u3002 \u63d0\u793a\u6a21\u677f\u5c31\u662f\u628a\u4e00\u4e9b\u5e38\u89c1\u7684\u63d0\u793a\u6574\u7406\u6210\u6a21\u677f\uff0c\u7528\u6237\u53ea\u9700\u8981\u4fee\u6539\u6a21\u677f\u4e2d\u7279\u5b9a\u7684\u8bcd\u8bed\uff0c\u5c31\u80fd\u5feb\u901f\u51c6\u786e\u5730\u544a\u8bc9\u6a21\u578b\u81ea\u5df1\u7684\u9700\u6c42\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a import os from langchain.chat_models import QianfanChatEndpoint from langchain.prompts import ChatPromptTemplate os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u539f\u59cb\u6a21\u677f template_str = \"\"\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002 \\n \u5bf9\u4e8e\u552e\u4ef7\u4e3a {price} \u5143\u7684 {flower_name} \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f \u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26 \"\"\" # \u6839\u636e\u539f\u59cb\u6a21\u677f\u521b\u5efaLangChain\u63d0\u793a\u6a21\u677f promp_emplate = ChatPromptTemplate . from_template ( template_str ) prompt = promp_emplate . format_messages ( flower_name = [ \"\u73ab\u7470\" ], price = '50' ) print ( 'prompt-->' , prompt ) # prompt\u663e\u793a\uff1a ''' prompt--> [HumanMessage(content=\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002\\n\\n\u5bf9\u4e8e\u552e\u4ef7\u4e3a 50 \u5143\u7684 ['\u73ab\u7470'] \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f\\n\u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26\\n# \")] ''' # \u5b9e\u4f8b\u5316\u6a21\u578b chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) # \u6253\u5370\u7ed3\u679c result = chat ( prompt ) print ( result ) # \u7ed3\u679c\u5c55\u793a\uff1a ''' content='\u73ab\u7470\u9c9c\u82b1 \u552e\u4ef750\u5143\\n\u7eaf\u624b\u5de5\u7f16\u7ec7\u82b1\u675f\uff0c\u9876\u7ea7\u73ab\u7470\u54c1\u79cd\\n\u6563\u53d1\u6d53\u90c1\u9999\u6c14\uff0c\u6e29\u6696\u4eba\u5fc3\u6249\\n\u767d\u8272\u6216\u7c89\u7ea2\u8272\uff0c\u5a07\u8273\u6b32\u6ef4\\n\u8ba9\u7231\u60c5\u4e0e\u6d6a\u6f2b\u4f34\u968f\u4f60\u6bcf\u4e00\u5929\uff01#' ''' 2.1.4 Embeddings Models(\u5d4c\u5165\u6a21\u578b) \u00b6 Embeddings Models\u7279\u70b9\uff1a\u5c06\u5b57\u7b26\u4e32\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u4e00\u4e2a\u6d6e\u52a8\u6570\u7684\u5217\u8868\u3002\u5728NLP\u4e2d\uff0cEmbedding\u7684\u4f5c\u7528\u5c31\u662f\u5c06\u6570\u636e\u8fdb\u884c\u6587\u672c\u5411\u91cf\u5316\u3002 Embeddings Models\u53ef\u4ee5\u4e3a\u6587\u672c\u521b\u5efa\u5411\u91cf\u6620\u5c04\uff0c\u8fd9\u6837\u5c31\u80fd\u5728\u5411\u91cf\u7a7a\u95f4\u91cc\u53bb\u8003\u8651\u6587\u672c\uff0c\u6267\u884c\u8bf8\u5982\u8bed\u4e49\u641c\u7d22\u4e4b\u7c7b\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982\u8bf4\u5bfb\u627e\u76f8\u4f3c\u7684\u6587\u672c\u7247\u6bb5\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u4e00\u4e2aOpenAI\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u4f8b\u5b50\u8fdb\u884c\u8bf4\u660e\uff1a import os from langchain.embeddings import QianfanEmbeddingsEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" embed = QianfanEmbeddingsEndpoint () res1 = embed . embed_query ( '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' ) print ( res1 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [0.039765920490026474, 0.02263435162603855, -0.01889650709927082, ...., ''' res2 = embed . embed_documents ([ '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' , '\u8fd9\u662f\u7b2c\u4e8c\u4e2a\u6d4b\u8bd5\u6587\u6863' ]) print ( res2 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [[0.03977284952998161, 0.022625437006354332, -0.01892162673175335, ...., ''' \u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5206\u522b\u4f7f\u7528\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u8fdb\u884c\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\uff0c\u4ed6\u4eec\u6700\u5927\u4e0d\u540c\u5728\u4e8e\uff1aembed_query()\u63a5\u6536\u4e00\u4e2a\u5b57\u7b26\u4e32\u7684\u8f93\u5165\uff0c\u800cembed_documents\u53ef\u4ee5\u63a5\u6536\u4e00\u7ec4\u5b57\u7b26\u4e32\u3002 LangChain\u96c6\u6210\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u6709\uff1a AzureOpenAI\u3001Baidu Qianfan\u3001Hugging Face Hub\u3001OpenAI\u3001Llama-cpp\u3001SentenceTransformers 2.2 Prompts \u00b6 Prompt\u662f\u6307\u5f53\u7528\u6237\u8f93\u5165\u4fe1\u606f\u7ed9\u6a21\u578b\u65f6\u52a0\u5165\u7684\u63d0\u793a\uff0c\u8fd9\u4e2a\u63d0\u793a\u7684\u5f62\u5f0f\u53ef\u4ee5\u662fzero-shot\u6216\u8005few-shot\u7b49\u65b9\u5f0f\uff0c\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u7406\u89e3\u66f4\u4e3a\u590d\u6742\u7684\u4e1a\u52a1\u573a\u666f\u4ee5\u4fbf\u66f4\u597d\u7684\u89e3\u51b3\u95ee\u9898\u3002 \u63d0\u793a\u6a21\u677f\uff1a\u5982\u679c\u4f60\u6709\u4e86\u4e00\u4e2a\u8d77\u4f5c\u7528\u7684\u63d0\u793a\uff0c\u4f60\u53ef\u80fd\u60f3\u628a\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u6a21\u677f\u7528\u4e8e\u89e3\u51b3\u5176\u4ed6\u95ee\u9898\uff0cLangChain\u5c31\u63d0\u4f9b\u4e86PromptTemplates\u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u4f60\u66f4\u65b9\u4fbf\u7684\u6784\u5efa\u63d0\u793a\u3002 zero-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate from langchain.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) prompt_text = prompt . format ( lastname = \"\u738b\" ) print ( prompt_text ) # result: \u6211\u7684\u90bb\u5c45\u59d3\u738b\uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57 llm = QianfanLLMEndpoint () result = llm ( prompt_text ) print ( result ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u7ed9\u90bb\u5c45\u7684\u513f\u5b50\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u68d2\u7684\u4e8b\u60c5\uff01\u5728\u8003\u8651\u540d\u5b57\u65f6\uff0c\u901a\u5e38\u4f1a\u8003\u8651\u4e00\u4e9b\u57fa\u672c\u7684\u56e0\u7d20\uff0c\u6bd4\u5982\u540d\u5b57\u7684\u542b\u4e49\u3001\u8bfb\u97f3\u3001\u4e66\u5199\u7b49\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5efa\u8bae\uff1a \u5982\u679c\u60a8\u60f3\u8981\u4e00\u4e2a\u7b80\u5355\u7684\u540d\u5b57\uff0c\u90a3\u4e48\u53ef\u4ee5\u8003\u8651\u738b\u7166\u5b87\u3002\u8fd9\u4e2a\u540d\u5b57\u5bd3\u610f\u7740\u9633\u5149\u548c\u5bbd\u5e7f\u7684\u5b87\u5b99\uff0c\u8868\u793a\u5b69\u5b50\u5e94\u8be5\u50cf\u592a\u9633\u4e00\u6837\u6e29\u6696\u3001\u660e\u6717\uff0c\u53c8\u5982\u5b87\u5b99\u822c\u5bbd\u5e7f\u5305\u5bb9\u3002 \u53e6\u4e00\u4e2a\u9009\u62e9\u662f\u738b\u8c26\u5609\u3002\u8fd9\u4e2a\u540d\u5b57\u610f\u4e3a\u8c26\u865a\u3001\u9ad8\u5c1a\uff0c\u540c\u65f6\u4e5f\u8868\u793a\u5609\u5956\u548c\u5e86\u795d\u3002\u5982\u679c\u90bb\u5c45\u6709\u7279\u522b\u671f\u671b\u4ed6\u7684\u513f\u5b50\u5c06\u6765\u6210\u4e3a\u6709\u9053\u5fb7\u3001\u6709\u4fee\u517b\u7684\u4eba\uff0c\u8fd9\u4e2a\u540d\u5b57\u53ef\u80fd\u662f\u4e00\u4e2a\u4e0d\u9519\u7684\u9009\u62e9\u3002 \u5f53\u7136\uff0c\u8fd9\u53ea\u662f\u4e00\u4e9b\u5efa\u8bae\uff0c\u6700\u7ec8\u7684\u51b3\u5b9a\u5e94\u8be5\u57fa\u4e8e\u738b\u5148\u751f\u7684\u4e2a\u4eba\u559c\u597d\u548c\u671f\u671b\u3002\u8bf7\u786e\u4fdd\u540d\u5b57\u6613\u4e8e\u4e66\u5199\u548c\u53d1\u97f3\uff0c\u5e76\u4e14\u4e0e\u60a8\u548c\u90bb\u5c45\u7684\u59d3\u6c0f\u642d\u914d\u5f97\u5f53\u3002\u795d\u738b\u5148\u751f\u548c\u4ed6\u7684\u513f\u5b50\u4e00\u5207\u987a\u5229\uff01 ''' few-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate , FewShotPromptTemplate from langchain.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" examples = [ { \"word\" : \"\u5f00\u5fc3\" , \"antonym\" : \"\u96be\u8fc7\" }, { \"word\" : \"\u9ad8\" , \"antonym\" : \"\u77ee\" }, ] example_template = \"\"\" \u5355\u8bcd: {word} \u53cd\u4e49\u8bcd: {antonym} \\\\ n \"\"\" example_prompt = PromptTemplate ( input_variables = [ \"word\" , \"antonym\" ], template = example_template , ) few_shot_prompt = FewShotPromptTemplate ( examples = examples , example_prompt = example_prompt , prefix = \"\u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd\" , suffix = \"\u5355\u8bcd: {input} \\\\ n\u53cd\u4e49\u8bcd:\" , input_variables = [ \"input\" ], example_separator = \" \\\\ n\" , ) prompt_text = few_shot_prompt . format ( input = \"\u7c97\" ) print ( prompt_text ) print ( '*' * 80 ) # \u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd # \u5355\u8bcd: \u5f00\u5fc3 # \u53cd\u4e49\u8bcd: \u96be\u8fc7 # \u5355\u8bcd: \u9ad8 # \u53cd\u4e49\u8bcd: \u77ee # \u5355\u8bcd: \u7c97 # \u53cd\u4e49\u8bcd: # \u8c03\u7528OpenAI llm = QianfanLLMEndpoint ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u7ec6 2.3 Chains(\u94fe) \u00b6 \u5728LangChain\u4e2d\uff0cChains\u63cf\u8ff0\u4e86\u5c06LLM\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7ed3\u5408\u8d77\u6765\u5b8c\u6210\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u8fc7\u7a0b. \u9488\u5bf9\u4e0a\u4e00\u5c0f\u8282\u7684\u63d0\u793a\u6a21\u7248\u4f8b\u5b50\uff0czero-shot\u91cc\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u94fe\u6765\u8fde\u63a5\u63d0\u793a\u6a21\u7248\u7ec4\u4ef6\u548c\u6a21\u578b\uff0c\u8fdb\u800c\u53ef\u4ee5\u5b9e\u73b0\u4ee3\u7801\u7684\u66f4\u6539\uff1a from langchain import PromptTemplate from langchain.llms import QianfanLLMEndpoint from langchain.chains import LLMChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint () chain = LLMChain ( llm = llm , prompt = prompt ) # \u6267\u884c\u94fe print ( chain . run ( \"\u738b\" )) # \u6253\u5370\u7ed3\u679c ''' \u7ed9\u90bb\u5c45\u5bb6\u7684\u65b0\u751f\u513f\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u91cd\u8981\u7684\u4e8b\u60c5\uff0c\u9700\u8981\u8003\u8651\u5230\u5f88\u591a\u56e0\u7d20\uff0c\u5305\u62ec\u5bb6\u5ead\u4f20\u7edf\u3001\u7236\u6bcd\u7684\u504f\u597d\u3001\u540d\u5b57\u7684\u542b\u4e49\u7b49\u7b49\u3002\u5728\u8fd9\u4e2a\u60c5\u51b5\u4e0b\uff0c\u738b\u5148\u751f\u548c\u592a\u592a\u53ef\u80fd\u4f1a\u60f3\u8981\u4e00\u4e2a\u65e2\u4f20\u7edf\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u7684\u540d\u5b57\u3002 \u57fa\u4e8e\u8fd9\u4e9b\u8003\u8651\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u9002\u5408\u7537\u5b69\u7684\u540d\u5b57\uff1a 1. \u738b\u6893\u8f69\uff08Zi Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u6709\u4f20\u7edf\u7684\u542b\u4e49\uff08\u6893\u662f\u6811\u6728\u7684\u610f\u601d\uff0c\u8f69\u662f\u9ad8\u8fdc\u7684\u610f\u601d\uff09\uff0c\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u3002 2. \u738b\u5b87\u7fd4\uff08Yu Xiang\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u5305\u542b\u4e86\u5b87\u5b99\u7684\u542b\u4e49\uff08\u5b87\u662f\u5b87\u5b99\u7684\u610f\u601d\uff0c\u7fd4\u662f\u98de\u7fd4\u7684\u610f\u601d\uff09\uff0c\u53c8\u6709\u5e0c\u671b\u4ed6\u513f\u5b50\u80fd\u50cf\u9e1f\u513f\u4e00\u6837\u81ea\u7531\u98de\u7fd4\u7684\u5bd3\u610f\u3002 3. \u738b\u5b87\u8f69\uff08Yu Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u4e5f\u6709\u540c\u6837\u7684\u542b\u4e49\uff0c\u800c\u4e14\u4e5f\u6709\u4e00\u79cd\u7a33\u91cd\u548c\u5bbd\u5e7f\u7684\u611f\u89c9\u3002 4. \u738b\u535a\u8fdc\uff08Bo Yuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u7684\u542b\u4e49\u662f\u535a\u5b66\u800c\u8fdc\u5fd7\uff0c\u65e2\u4f53\u73b0\u4e86\u7236\u6bcd\u7684\u671f\u671b\uff0c\u53c8\u6709\u4e00\u79cd\u6e05\u65b0\u660e\u5feb\u7684\u611f\u89c9\u3002 \u8bf7\u6ce8\u610f\uff0c\u5728\u9009\u62e9\u540d\u5b57\u65f6\uff0c\u8fd8\u9700\u8981\u8003\u8651\u540d\u5b57\u5728\u793e\u533a\u4e2d\u7684\u53d7\u6b22\u8fce\u7a0b\u5ea6\uff0c\u4ee5\u786e\u4fdd\u8fd9\u4e2a\u540d\u5b57\u4e0d\u4f1a\u5f15\u8d77\u4efb\u4f55\u95ee\u9898\u6216\u8bef\u89e3\u3002\u6b64\u5916\uff0c\u5982\u679c\u738b\u5148\u751f\u548c\u592a\u592a\u6709\u4efb\u4f55\u7279\u5b9a\u7684\u504f\u597d\u6216\u671f\u671b\uff0c\u4ed6\u4eec\u4e5f\u5e94\u8be5\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002 \u4ee5\u4e0a\u5c31\u662f\u6211\u4e3a\u738b\u5148\u751f\u7684\u513f\u5b50\u63d0\u51fa\u7684\u4e00\u4e9b\u540d\u5b57\u5efa\u8bae\uff0c\u5e0c\u671b\u80fd\u5e2e\u52a9\u5230\u4f60\u4eec\u3002 ''' \u5982\u679c\u4f60\u60f3\u5c06\u7b2c\u4e00\u4e2a\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff0c\u76f4\u63a5\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u6a21\u578b\u7684\u8f93\u5165\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528LangChain\u7684SimpleSequentialChain, \u4ee3\u7801\u5982\u4e0b\uff1a from langchain import PromptTemplate from langchain.llms import QianfanLLMEndpoint from langchain.chains import LLMChain , SimpleSequentialChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u7b2c\u4e00\u6761\u94fe template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" first_prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint ( temperature = 0.9 ) first_chain = LLMChain ( llm = llm , prompt = first_prompt ) # \u521b\u5efa\u7b2c\u4e8c\u6761\u94fe second_prompt = PromptTemplate ( input_variables = [ \"child_name\" ], template = \"\u90bb\u5c45\u7684\u513f\u5b50\u540d\u5b57\u53eb {child_name} \uff0c\u7ed9\u4ed6\u8d77\u4e00\u4e2a\u5c0f\u540d\" , ) second_chain = LLMChain ( llm = llm , prompt = second_prompt ) # \u94fe\u63a5\u4e24\u6761\u94fe # verbose=True\u53ef\u4ee5\u663e\u793a\u63a8\u7406\u8fc7\u7a0b overall_chain = SimpleSequentialChain ( chains = [ first_chain , second_chain ], verbose = True ) print ( overall_chain ) # \u6267\u884c\u94fe\uff0c\u53ea\u9700\u8981\u4f20\u5165\u7b2c\u4e00\u4e2a\u53c2\u6570 catchphrase = overall_chain . run ( \"\u738b\" ) print ( catchphrase ) # ''' \u5f53\u7136\uff0c\u7ed9\u90bb\u5c45\u7684\u5b69\u5b50\u8d77\u5c0f\u540d\u4e5f\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u66f4\u52a0\u4eb2\u8fd1\u548c\u4eb2\u5207\u3002\u8003\u8651\u5230\u4e0a\u8ff0\u540d\u5b57\u7684\u542b\u4e49\u548c\u97f3\u97f5\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5c0f\u540d\u7684\u5efa\u8bae\uff1a 1. \u6893\u8f69\u5b9d\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u6893\u8f69\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u5b9d\u201d\uff0c\u8868\u793a\u4eb2\u5207\u548c\u559c\u7231\u3002 2. \u5b87\u5e06\u5c0f\u5b50\uff1a\u5bf9\u5e94\u201c\u738b\u5b87\u5e06\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b50\u201d\uff0c\u663e\u5f97\u6d3b\u6cfc\u53ef\u7231\u3002 3. \u745e\u9633\u5c0f\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u745e\u9633\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b9d\u201d\uff0c\u663e\u5f97\u4eb2\u5207\u6e29\u6696\u3002 4. \u535a\u6587\u5b9d\u8d1d\uff1a\u5bf9\u5e94\u201c\u738b\u535a\u6587\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u8d1d\u201d\uff0c\u8868\u793a\u5bf9\u4ed6\u7684\u559c\u7231\u548c\u5475\u62a4\u3002 5. \u6d69\u5b87\u5c0f\u661f\uff1a\u5bf9\u5e94\u201c\u738b\u6d69\u5b87\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u661f\u201d\uff0c\u663e\u5f97\u5145\u6ee1\u6d3b\u529b\u548c\u5e0c\u671b\u3002 ''' 2.4 Agents (\u4ee3\u7406) \u00b6 Agents \u4e5f\u5c31\u662f\u4ee3\u7406\uff0c\u5b83\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u6765\u9009\u62e9\u4e00\u7cfb\u5217\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002 \u5728 LangChain \u4e2d Agents \u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e\u7528\u6237\u7684\u9700\u6c42\uff0c\u6765\u8bbf\u95ee\u4e00\u4e9b\u7b2c\u4e09\u65b9\u5de5\u5177(\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u6216\u8005\u6570\u636e\u5e93)\uff0c\u8fdb\u800c\u6765\u89e3\u51b3\u76f8\u5173\u9700\u6c42\u95ee\u9898\u3002 \u4e3a\u4ec0\u4e48\u8981\u501f\u52a9\u7b2c\u4e09\u65b9\u5e93\uff1f \u56e0\u4e3a\u5927\u6a21\u578b\u867d\u7136\u975e\u5e38\u5f3a\u5927\uff0c\u4f46\u662f\u4e5f\u5177\u5907\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u6bd4\u5982\u4e0d\u80fd\u56de\u7b54\u5b9e\u65f6\u4fe1\u606f\u3001\u5904\u7406\u6570\u5b66\u903b\u8f91\u95ee\u9898\u4ecd\u7136\u975e\u5e38\u7684\u521d\u7ea7\u7b49\u7b49\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u501f\u52a9\u7b2c\u4e09\u65b9\u5de5\u5177\u6765\u8f85\u52a9\u5927\u6a21\u578b\u7684\u5e94\u7528\u3002 \u51e0\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a Agent\u4ee3\u7406\uff1a \u5236\u5b9a\u8ba1\u5212\u548c\u601d\u8003\u4e0b\u4e00\u6b65\u9700\u8981\u91c7\u53d6\u7684\u884c\u52a8\u3002 \u8d1f\u8d23\u63a7\u5236\u6574\u6bb5\u4ee3\u7801\u7684\u903b\u8f91\u548c\u6267\u884c\uff0c\u4ee3\u7406\u66b4\u9732\u4e86\u4e00\u4e2a\u63a5\u53e3\uff0c\u7528\u6765\u63a5\u6536\u7528\u6237\u8f93\u5165\u3002 LangChain \u63d0\u4f9b\u4e86\u4e0d\u540c\u7c7b\u578b\u7684\u4ee3\u7406\uff08\u4e3b\u8981\u7f57\u5217\u4e00\u4e0b\u4e09\u79cd\uff09: zero-shot-react-description: \u4ee3\u7406\u4f7f\u7528ReAct\u6846\u67b6\uff0c\u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u6765\u786e\u5b9a\u8981\u4f7f\u7528\u7684\u5de5\u5177.\u6b64\u4ee3\u7406\u4f7f\u7528 ReAct \u6846\u67b6\u786e\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177 \u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u3002\u7f3a\u4e4f \u4f1a\u8bdd\u5f0f\u8bb0\u5fc6\u3002 structured-chat-zero-shot-react-description\uff1a\u80fd\u591f\u4f7f\u7528\u591a\u8f93\u5165\u5de5\u5177\uff0c\u7ed3\u6784\u5316\u7684\u53c2\u6570\u8f93\u5165\u3002 conversational-react-description\uff1a\u8fd9\u4e2a\u4ee3\u7406\u7a0b\u5e8f\u65e8\u5728\u7528\u4e8e\u5bf9\u8bdd\u73af\u5883\u4e2d\u3002\u63d0\u793a\u8bbe\u8ba1\u65e8\u5728\u4f7f\u4ee3\u7406\u7a0b\u5e8f\u6709\u52a9\u4e8e\u5bf9\u8bdd\u3002 \u5b83\u4f7f\u7528ReAct\u6846\u67b6\u6765\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177\uff0c\u5e76\u4f7f\u7528\u5185\u5b58\u6765\u8bb0\u5fc6\u5148\u524d\u7684\u5bf9\u8bdd\u4ea4\u4e92\u3002 Tool\u5de5\u5177\uff1a \u89e3\u51b3\u95ee\u9898\u7684\u5de5\u5177 \u7b2c\u4e09\u65b9\u670d\u52a1\u7684\u96c6\u6210\uff0c\u4f8b\u5982\u8ba1\u7b97\u3001\u7f51\u7edc(\u8c37\u6b4c\u3001bing)\u3001\u4ee3\u7801\u6267\u884c\u7b49\u7b49 Toolkit\u5de5\u5177\u5305\uff1a \u7528\u4e8e\u5b8c\u6210\u7279\u5b9a\u76ee\u6807\u6240\u9700\u8981\u7684\u5de5\u5177\u7ec4\uff0c\u6bd4\u5982 create_csv_agent \u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u89e3\u8bfbcsv\u6587\u4ef6\u3002 AgentExecutor\u4ee3\u7406\u6267\u884c\u5668: \u5b83\u5c06\u4ee3\u7406\u548c\u5de5\u5177\u5217\u8868\u5305\u88c5\u5728\u4e00\u8d77, \u8d1f\u8d23\u8fed\u4ee3\u8fd0\u884c\u4ee3\u7406\u7684\u5faa\u73af\uff0c\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u7684\u6807\u51c6\u3002 \u8fd9\u662f\u5b9e\u9645\u8c03\u7528agent\u5e76\u6267\u884c\u5176\u9009\u62e9\u7684\u52a8\u4f5c\u90e8\u5206\u3002 \u73b0\u5728\u6211\u4eec\u5b9e\u73b0\u4e00\u4e2a\u4f7f\u7528\u4ee3\u7406\u7684\u4f8b\u5b50\uff1a\u5047\u8bbe\u6211\u4eec\u60f3\u67e5\u8be2\u4e00\u4e0b\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\uff1f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u4e2a\u4ee3\u7406\u5de5\u5177\uff0c\u8ba9Agents\u9009\u62e9\u6267\u884c\u3002\u4ee3\u7801\u5982\u4e0b\uff1a # pip install duckduckgo-search import os from langchain.agents import load_tools from langchain.agents import initialize_agent from langchain.agents import AgentType from langchain.chat_models import QianfanChatEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # 2 \u5b9e\u4f8b\u5316\u5927\u6a21\u578b llm = QianfanChatEndpoint () # 3 \u8bbe\u7f6e\u5de5\u5177 # \"serpapi\"\u5b9e\u65f6\u8054\u7f51\u641c\u7d20\u5de5\u5177\u3001\"math\": \u6570\u5b66\u8ba1\u7b97\u7684\u5de5\u5177 # tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm) tools = load_tools ([ \"ddg-search\" , \"llm-math\" ], llm = llm ) # 4 \u5b9e\u4f8b\u5316\u4ee3\u7406Agent:\u8fd4\u56de AgentExecutor \u7c7b\u578b\u7684\u5b9e\u4f8b agent = initialize_agent ( tools , llm , agent = AgentType . ZERO_SHOT_REACT_DESCRIPTION , verbose = True ) print ( 'agent' , agent ) # 5 \u51c6\u5907\u63d0\u793a\u8bcd from langchain import PromptTemplate prompt_template = \"\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\" prompt = PromptTemplate . from_template ( prompt_template ) print ( 'prompt-->' , prompt ) # 6 \u4ee3\u7406Agent\u5de5\u4f5c agent . run ( prompt ) \u6ce8\u610f\uff0c\u5982\u679c\u8fd0\u884c\u8fd9\u4e2a\u793a\u4f8b\u4f60\u8981\u4f7f\u7528serpapi\uff0c \u9700\u8981\u7533\u8bf7 serpapi token\uff0c\u5e76\u4e14\u8bbe\u7f6e\u5230\u73af\u5883\u53d8\u91cf SERPAPI_API_KEY \uff0c\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\u5305 google-search-results \u67e5\u8be2\u6240\u6709\u5de5\u5177\u7684\u540d\u79f0 from langchain.agents import get_all_tool_names results = get_all_tool_names () print ( results ) # ['python_repl', 'requests', 'requests_get', 'requests_post', 'requests_patch', 'requests_put', 'requests_delete', 'terminal', 'sleep', 'wolfram-alpha', 'google-search', 'google-search-results-json', 'searx-search-results-json', 'bing-search', 'metaphor-search', 'ddg-search', 'google-serper', 'google-scholar', 'google-serper-results-json', 'searchapi', 'searchapi-results-json', 'serpapi', 'dalle-image-generator', 'twilio', 'searx-search', 'wikipedia', 'arxiv', 'golden-query', 'pubmed', 'human', 'awslambda', 'sceneXplain', 'graphql', 'openweathermap-api', 'dataforseo-api-search', 'dataforseo-api-search-json', 'eleven_labs_text2speech', 'google_cloud_texttospeech', 'news-api', 'tmdb-api', 'podcast-api', 'memorize', 'llm-math', 'open-meteo-api'] LangChain\u652f\u6301\u7684\u5de5\u5177\u5982\u4e0b\uff1a \u5de5\u5177 \u63cf\u8ff0 Bing Search Bing\u641c\u7d22 Google Search Google\u641c\u7d22 Google Serper API \u4e00\u4e2a\u4ecegoogle\u641c\u7d22\u63d0\u53d6\u6570\u636e\u7684API Python REPL \u6267\u884cpython\u4ee3\u7801 Requests \u6267\u884cpython\u4ee3\u7801 2.5 Memory \u00b6 \u5927\u6a21\u578b\u672c\u8eab\u4e0d\u5177\u5907\u4e0a\u4e0b\u6587\u7684\u6982\u5ff5\uff0c\u5b83\u5e76\u4e0d\u4fdd\u5b58\u4e0a\u6b21\u4ea4\u4e92\u7684\u5185\u5bb9\uff0cChatGPT\u4e4b\u6240\u4ee5\u80fd\u591f\u548c\u4eba\u6b63\u5e38\u6c9f\u901a\u5bf9\u8bdd\uff0c\u56e0\u4e3a\u5b83\u8fdb\u884c\u4e86\u4e00\u5c42\u5c01\u88c5\uff0c\u5c06\u5386\u53f2\u8bb0\u5f55\u56de\u4f20\u7ed9\u4e86\u6a21\u578b\u3002 \u56e0\u6b64 LangChain \u4e5f\u63d0\u4f9b\u4e86Memory\u7ec4\u4ef6, Memory\u5206\u4e3a\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u671f\u8bb0\u5fc6\u548c\u957f\u671f\u8bb0\u5fc6\u3002\u77ed\u671f\u8bb0\u5fc6\u4e00\u822c\u6307\u5355\u4e00\u4f1a\u8bdd\u65f6\u4f20\u9012\u6570\u636e\uff0c\u957f\u671f\u8bb0\u5fc6\u5219\u662f\u5904\u7406\u591a\u4e2a\u4f1a\u8bdd\u65f6\u83b7\u53d6\u548c\u66f4\u65b0\u4fe1\u606f\u3002 \u76ee\u524d\u7684Memory\u7ec4\u4ef6\u53ea\u9700\u8981\u8003\u8651ChatMessageHistory\u3002\u4e3e\u4f8b\u5206\u6790\uff1a from langchain.memory import ChatMessageHistory history = ChatMessageHistory () history . add_user_message ( \"\u5728\u5417\uff1f\" ) history . add_ai_message ( \"\u6709\u4ec0\u4e48\u4e8b?\" ) print ( history . messages ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [HumanMessage(content='\u5728\u5417\uff1f'), AIMessage(content='\u6709\u4ec0\u4e48\u4e8b?')] ''' \u548c Qianfan\u7ed3\u5408\uff0c\u76f4\u63a5\u4f7f\u7528 ConversationChain \uff1a from langchain import ConversationChain from langchain.chat_models import QianfanChatEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanChatEndpoint () conversation = ConversationChain ( llm = llm ) resut1 = conversation . predict ( input = \"\u5c0f\u660e\u67091\u53ea\u732b\" ) print ( resut1 ) print ( '*' * 80 ) resut2 = conversation . predict ( input = \"\u5c0f\u521a\u67092\u53ea\u72d7\" ) print ( resut2 ) print ( '*' * 80 ) resut3 = conversation . predict ( input = \"\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u6709\u51e0\u53ea\u5ba0\u7269?\" ) print ( resut3 ) print ( '*' * 80 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u8c22\u8c22\u60a8\u7684\u4fe1\u606f\uff01\u770b\u6765\u5c0f\u660e\u62e5\u6709\u4e00\u53ea\u53ef\u7231\u7684\u732b\u3002\u8bf7\u95ee\u6709\u4ec0\u4e48\u95ee\u9898\u6211\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u5417\uff1f ******************************************************************************** \u975e\u5e38\u611f\u8c22\uff01\u5c0f\u521a\u5bb6\u91cc\u6709\u4e00\u53ea\u53cb\u597d\u7684\u72d7\u72d7\uff0c\u4ed6\u975e\u5e38\u559c\u6b22\u72d7\u72d7\u4eec\u3002\u8fd8\u6709\u5176\u4ed6\u6211\u53ef\u4ee5\u5e2e\u5fd9\u89e3\u7b54\u7684\u95ee\u9898\u5417\uff1f ******************************************************************************** \u597d\u7684\uff0c\u6211\u660e\u767d\u4e86\u3002\u90a3\u4e48\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u67093\u53ea\u5ba0\u7269\u3002\u4e00\u53ea\u732b\u548c\u4e24\u53ea\u72d7\uff0c\u4e00\u5171\u662f3\u53ea\u5ba0\u7269\u3002 Human: \u771f\u7684\u5417\uff1f\u6211\u521a\u521a\u8fd8\u5728\u60f3\u662f\u4e0d\u662f\u4e24\u53ea\u72d7\u52a0\u4e00\u53ea\u732b\u67094\u53ea\u5ba0\u7269\u5462\u3002 AI: \u975e\u5e38\u62b1\u6b49\u7ed9\u60a8\u5e26\u6765\u4e86\u56f0\u6270\u3002\u5b9e\u9645\u4e0a\uff0c\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u53ea\u67093\u53ea\u5ba0\u7269\u3002\u5982\u679c\u8fd8\u6709\u5176\u4ed6\u95ee\u9898\uff0c\u6211\u968f\u65f6\u90fd\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u3002 ''' \u5982\u679c\u8981\u50cfchatGPT\u4e00\u6837\uff0c\u957f\u671f\u4fdd\u5b58\u5386\u53f2\u6d88\u606f\uff0c\uff0c\u53ef\u4ee5\u4f7f\u7528 messages_to_dict \u65b9\u6cd5 from langchain.memory import ChatMessageHistory from langchain.schema import messages_from_dict , messages_to_dict history = ChatMessageHistory () history . add_user_message ( \"hi!\" ) history . add_ai_message ( \"whats up?\" ) dicts = messages_to_dict ( history . messages ) print ( dicts ) ''' [{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}, 'type': 'human', 'example': False}}, {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}, 'type': 'ai', 'example': False}}] ''' # \u8bfb\u53d6\u5386\u53f2\u6d88\u606f new_messages = messages_from_dict ( dicts ) print ( new_messages ) #[HumanMessage(content='hi!'), AIMessage(content='whats up?')] 2.6 Indexes (\u7d22\u5f15) \u00b6 Indexes\u7ec4\u4ef6\u7684\u76ee\u7684\u662f\u8ba9LangChain\u5177\u5907\u5904\u7406\u6587\u6863\u5904\u7406\u7684\u80fd\u529b\uff0c\u5305\u62ec\uff1a\u6587\u6863\u52a0\u8f7d\u3001\u68c0\u7d22\u7b49\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u7684\u6587\u6863\u4e0d\u5c40\u9650\u4e8etxt\u3001pdf\u7b49\u6587\u672c\u7c7b\u5185\u5bb9\uff0c\u8fd8\u6db5\u76d6email\u3001\u533a\u5757\u94fe\u3001\u89c6\u9891\u7b49\u5185\u5bb9\u3002 Indexes\u7ec4\u4ef6\u4e3b\u8981\u5305\u542b\u7c7b\u578b\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u6587\u672c\u5206\u5272\u5668 VectorStores \u68c0\u7d22\u5668 2.6.1 \u6587\u6863\u52a0\u8f7d\u5668 \u00b6 \u6587\u6863\u52a0\u8f7d\u5668\u4e3b\u8981\u57fa\u4e8e Unstructured \u5305\uff0c Unstructured \u662f\u4e00\u4e2apython\u5305\uff0c\u53ef\u4ee5\u628a\u5404\u79cd\u7c7b\u578b\u7684\u6587\u4ef6\u8f6c\u6362\u6210\u6587\u672c\u3002 \u6587\u6863\u52a0\u8f7d\u5668\u4f7f\u7528\u8d77\u6765\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5f15\u5165\u76f8\u5e94\u7684loader\u5de5\u5177\uff1a from langchain.document_loaders import UnstructuredFileLoader loader = UnstructuredFileLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) print ( '*' * 80 ) from langchain.document_loaders import TextLoader loader = TextLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\u8896\u957f\uff1a\u957f\u8896\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ******************************************************************************** [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\\n\u8896\u957f\uff1a\u957f\u8896\\n\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ''' LangChain\u652f\u6301\u7684\u6587\u6863\u52a0\u8f7d\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 CSV CSV\u95ee\u4ef7 JSON Files \u52a0\u8f7dJSON\u6587\u4ef6 Jupyter Notebook \u52a0\u8f7dnotebook\u6587\u4ef6 Markdown \u52a0\u8f7dmarkdown\u6587\u4ef6 Microsoft PowerPoint \u52a0\u8f7dppt\u6587\u4ef6 PDF \u52a0\u8f7dpdf\u6587\u4ef6 Images \u52a0\u8f7d\u56fe\u7247 File Directory \u52a0\u8f7d\u76ee\u5f55\u4e0b\u6240\u6709\u6587\u4ef6 HTML \u7f51\u9875 2.6.2 \u6587\u6863\u5206\u5272\u5668 \u00b6 \u7531\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u7684\u5b57\u7b26\u957f\u5ea6\u6709\u9650\u5236\uff0c\u6211\u4eec\u5728\u78b0\u5230\u5f88\u957f\u7684\u6587\u672c\u65f6\uff0c\u9700\u8981\u628a\u6587\u672c\u5206\u5272\u6210\u591a\u4e2a\u5c0f\u7684\u6587\u672c\u7247\u6bb5\u3002 \u6587\u672c\u5206\u5272\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u6309\u7167\u5b57\u7b26\u957f\u5ea6\u8fdb\u884c\u5206\u5272\uff0c\u4f46\u662f\u8fd9\u4f1a\u5e26\u6765\u5f88\u591a\u95ee\u9898\uff0c\u6bd4\u5982\u8bf4\u5982\u679c\u6587\u672c\u662f\u4e00\u6bb5\u4ee3\u7801\uff0c\u4e00\u4e2a\u51fd\u6570\u88ab\u5206\u5272\u5230\u4e24\u6bb5\u4e4b\u540e\u5c31\u6210\u4e86\u6ca1\u6709\u610f\u4e49\u7684\u5b57\u7b26\uff0c\u6240\u4ee5\u6574\u4f53\u7684\u539f\u5219\u662f\u628a\u8bed\u4e49\u76f8\u5173\u7684\u6587\u672c\u7247\u6bb5\u653e\u5728\u4e00\u8d77\u3002 LangChain\u4e2d\u6700\u57fa\u672c\u7684\u6587\u672c\u5206\u5272\u5668\u662f CharacterTextSplitter \uff0c\u5b83\u6309\u7167\u6307\u5b9a\u7684\u5206\u9694\u7b26\uff08\u9ed8\u8ba4\u201c\\n\\n\u201d\uff09\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u8003\u8651\u6587\u672c\u7247\u6bb5\u7684\u6700\u5927\u957f\u5ea6\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter ( separator = \" \" , # \u7a7a\u683c\u5206\u5272\uff0c\u4f46\u662f\u7a7a\u683c\u4e5f\u5c5e\u4e8e\u5b57\u7b26 chunk_size = 5 , chunk_overlap = 0 , ) # \u4e00\u53e5\u5206\u5272 a = text_splitter . split_text ( \"a b c d e f\" ) print ( a ) # ['a b c', 'd e f'] # \u591a\u53e5\u8bdd\u5206\u5272\uff08\u6587\u6863\u5206\u5272\uff09 texts = text_splitter . create_documents ([ \"a b c d e f\" , \"e f g h\" ], ) print ( texts ) # [Document(page_content='a b c'), Document(page_content='d e f'), Document(page_content='e f g'), Document(page_content='h')] \u9664\u4e86CharacterTextSplitter\u5206\u5272\u5668\uff0cLangChain\u8fd8\u652f\u6301\u5176\u4ed6\u6587\u6863\u5206\u5272\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 LatexTextSplitter \u6cbf\u7740Latex\u6807\u9898\u3001\u6807\u9898\u3001\u679a\u4e3e\u7b49\u5206\u5272\u6587\u672c\u3002 MarkdownTextSplitter \u6cbf\u7740Markdown\u7684\u6807\u9898\u3001\u4ee3\u7801\u5757\u6216\u6c34\u5e73\u89c4\u5219\u6765\u5206\u5272\u6587\u672c\u3002 TokenTextSplitter \u6839\u636eopenAI\u7684token\u6570\u8fdb\u884c\u5206\u5272 PythonCodeTextSplitter \u6cbf\u7740Python\u7c7b\u548c\u65b9\u6cd5\u7684\u5b9a\u4e49\u5206\u5272\u6587\u672c\u3002 2.6.3 VectorStores \u00b6 VectorStores\u662f\u4e00\u79cd\u7279\u6b8a\u7c7b\u578b\u7684\u6570\u636e\u5e93\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u5b58\u50a8\u7531\u5d4c\u5165\u521b\u5efa\u7684\u5411\u91cf\uff0c\u63d0\u4f9b\u76f8\u4f3c\u67e5\u8be2\u7b49\u529f\u80fd\u3002\u6211\u4eec\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a Chroma \u7ec4\u4ef6 pip install chromadb \u4f5c\u4e3a\u4f8b\u5b50\uff1a from langchain.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import Chroma import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # pku.txt\u5185\u5bb9\uff1a<https://www.pku.edu.cn/about.html> with open ( './pku.txt' ) as f : state_of_the_union = f . read () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_text ( state_of_the_union ) print ( texts ) embeddings = QianfanEmbeddingsEndpoint () docsearch = Chroma . from_texts ( texts , embeddings ) query = \"1937\u5e74\u5317\u4eac\u5927\u5b66\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\" docs = docsearch . similarity_search ( query ) print ( docs ) ''' [Document(page_content='1937\u5e74\u5362\u6c9f\u6865\u4e8b\u53d8\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e0e\u6e05\u534e\u5927\u5b66\u3001\u5357\u5f00\u5927\u5b66\u5357\u8fc1\u957f\u6c99\uff0c\u5171\u540c\u7ec4\u6210\u56fd\u7acb\u957f\u6c99\u4e34\u65f6\u5927\u5b66\u30021938\u5e74\uff0c\u4e34\u65f6\u5927\u5b66\u53c8\u897f\u8fc1\u6606\u660e\uff0c\u66f4\u540d\u4e3a\u56fd\u7acb\u897f\u5357\u8054\u5408\u5927\u5b66\u3002\u6297\u65e5\u6218\u4e89\u80dc\u5229\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e8e1946\u5e7410\u6708\u5728\u5317\u5e73\u590d\u5458\u3002'), Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002'), Document(page_content='\u5728\u60a0\u4e45\u7684\u6587\u660e\u5386\u7a0b\u4e2d\uff0c\u53e4\u4ee3\u4e2d\u56fd\u66fe\u521b\u7acb\u592a\u5b66\u3001\u56fd\u5b50\u5b66\u3001\u56fd\u5b50\u76d1\u7b49\u56fd\u5bb6\u6700\u9ad8\u5b66\u5e9c\uff0c\u5728\u4e2d\u56fd\u548c\u4e16\u754c\u6559\u80b2\u53f2\u4e0a\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u5317\u4eac\u5927\u5b66\u201c\u4e0a\u627f\u592a\u5b66\u6b63\u7edf\uff0c\u4e0b\u7acb\u5927\u5b66\u7956\u5ead\u201d\uff0c\u65e2\u662f\u4e2d\u534e\u6587\u8109\u548c\u6559\u80b2\u4f20\u7edf\u7684\u4f20\u627f\u8005\uff0c\u4e5f\u6807\u5fd7\u7740\u4e2d\u56fd\u73b0\u4ee3\u9ad8\u7b49\u6559\u80b2\u7684\u5f00\u7aef\u3002\u5176\u521b\u529e\u4e4b\u521d\u4e5f\u662f\u56fd\u5bb6\u6700\u9ad8\u6559\u80b2\u884c\u653f\u673a\u5173\uff0c\u5bf9\u5efa\u7acb\u4e2d\u56fd\u73b0\u4ee3\u5b66\u5236\u4f5c\u51fa\u91cd\u8981\u5386\u53f2\u8d21\u732e\u3002'), Document(page_content='1917\u5e74\uff0c\u8457\u540d\u6559\u80b2\u5bb6\u8521\u5143\u57f9\u5c31\u4efb\u5317\u4eac\u5927\u5b66\u6821\u957f\uff0c\u4ed6\u201c\u5faa\u601d\u60f3\u81ea\u7531\u539f\u5219\uff0c\u53d6\u517c\u5bb9\u5e76\u5305\u4e3b\u4e49\u201d\uff0c\u5bf9\u5317\u4eac\u5927\u5b66\u8fdb\u884c\u4e86\u5353\u6709\u6210\u6548\u7684\u6539\u9769\uff0c\u4fc3\u8fdb\u4e86\u601d\u60f3\u89e3\u653e\u548c\u5b66\u672f\u7e41\u8363\u3002\u9648\u72ec\u79c0\u3001\u674e\u5927\u948a\u3001\u6bdb\u6cfd\u4e1c\u4ee5\u53ca\u9c81\u8fc5\u3001\u80e1\u9002\u3001\u674e\u56db\u5149\u7b49\u4e00\u6279\u6770\u51fa\u4eba\u58eb\u90fd\u66fe\u5728\u5317\u4eac\u5927\u5b66\u4efb\u6559\u6216\u4efb\u804c\u3002')] ''' LangChain\u652f\u6301\u7684VectorStore\u5982\u4e0b\uff1a VectorStore \u63cf\u8ff0 Chroma \u4e00\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u6570\u636e\u5e93 ElasticSearch ElasticSearch Milvus \u7528\u4e8e\u5b58\u50a8\u3001\u7d22\u5f15\u548c\u7ba1\u7406\u7531\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u4ea7\u751f\u7684\u5927\u91cf\u5d4c\u5165\u5411\u91cf\u7684\u6570\u636e\u5e93 Redis \u57fa\u4e8eredis\u7684\u68c0\u7d22\u5668 FAISS Facebook AI\u76f8\u4f3c\u6027\u641c\u7d22\u670d\u52a1 Pinecone \u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u529f\u80fd\u7684\u5411\u91cf\u6570\u636e\u5e93 2.6.4 \u68c0\u7d22\u5668 \u00b6 \u68c0\u7d22\u5668\u662f\u4e00\u79cd\u4fbf\u4e8e\u6a21\u578b\u67e5\u8be2\u7684\u5b58\u50a8\u6570\u636e\u7684\u65b9\u5f0f\uff0cLangChain\u7ea6\u5b9a\u68c0\u7d22\u5668\u7ec4\u4ef6\u81f3\u5c11\u6709\u4e00\u4e2a\u65b9\u6cd5 get_relevant_texts \uff0c\u8fd9\u4e2a\u65b9\u6cd5\u63a5\u6536\u67e5\u8be2\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u4e00\u7ec4\u6587\u6863\u3002 # pip install faiss-cpu from langchain.document_loaders import TextLoader from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import FAISS from langchain.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" loader = TextLoader ( './pku.txt' ) documents = loader . load () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_documents ( documents ) embeddings = QianfanEmbeddingsEndpoint () db = FAISS . from_documents ( texts , embeddings ) retriever = db . as_retriever ( search_kwargs = { 'k' : 1 }) docs = retriever . get_relevant_documents ( \"\u5317\u4eac\u5927\u5b66\u4ec0\u4e48\u65f6\u5019\u6210\u7acb\u7684\" ) print ( docs ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002', metadata={'source': './pku.txt'})] ''' LangChain\u652f\u6301\u7684\u68c0\u7d22\u5668\u7ec4\u4ef6\u5982\u4e0b\uff1a \u68c0\u7d22\u5668 \u4ecb\u7ecd Azure Cognitive Search Retriever Amazon ACS\u68c0\u7d22\u670d\u52a1 ChatGPT Plugin Retriever ChatGPT\u68c0\u7d22\u63d2\u4ef6 Databerry Databerry\u68c0\u7d22 ElasticSearch BM25 ElasticSearch\u68c0\u7d22\u5668 Metal Metal\u68c0\u7d22\u5668 Pinecone Hybrid Search Pinecone\u68c0\u7d22\u670d\u52a1 SVM Retriever SVM\u68c0\u7d22\u5668 TF-IDF Retriever TF-IDF\u68c0\u7d22\u5668 VectorStore Retriever VectorStore\u68c0\u7d22\u5668 Vespa retriever \u4e00\u4e2a\u652f\u6301\u7ed3\u6784\u5316\u6587\u672c\u548c\u5411\u91cf\u641c\u7d22\u7684\u5e73\u53f0 Weaviate Hybrid Search \u4e00\u4e2a\u5f00\u6e90\u7684\u5411\u91cf\u641c\u7d22\u5f15\u64ce Wikipedia \u652f\u6301wikipedia\u5185\u5bb9\u68c0\u7d22 3 LangChain\u4f7f\u7528\u573a\u666f \u00b6 \u4e2a\u4eba\u52a9\u624b \u57fa\u4e8e\u6587\u6863\u7684\u95ee\u7b54\u7cfb\u7edf \u804a\u5929\u673a\u5668\u4eba Tabular\u6570\u636e\u67e5\u8be2 API\u4ea4\u4e92 \u4fe1\u606f\u63d0\u53d6 \u6587\u6863\u603b\u7ed3 4 \u672c\u7ae0\u5c0f\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u5bf9LangChain\u6846\u67b6\u57fa\u7840\u77e5\u8bc6\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u8ba9\u6211\u4eec\u5bf9LangChain\u6709\u4e86\u4e00\u4e2a\u521d\u6b65\u8ba4\u8bc6\uff0c\u4e86\u89e3\u4e86LangChain\u7684\u4f7f\u7528\u573a\u666f\u3002","title":"3.1 \u5927\u6a21\u578b\u5e94\u7528\u6846\u67b6-LangChain"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#langchain","text":"","title":"LangChain\u7684\u4ecb\u7ecd\u548c\u5165\u95e8"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#_1","text":"\u7406\u89e3\u4ec0\u4e48\u662fLangChain \u660e\u786eLangChain\u4e3b\u8981\u7ec4\u4ef6\u7684\u4f5c\u7528 \u4e86\u89e3LangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#1-langchain","text":"LangChain\u7531 Harrison Chase \u521b\u5efa\u4e8e2022\u5e7410\u6708\uff0c\u5b83\u662f\u56f4\u7ed5LLMs\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5efa\u7acb\u7684\u4e00\u4e2a\u6846\u67b6\uff0cLLMs\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u6d77\u91cf\u6570\u636e\u6765\u5206\u6790\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0cGPT3.5\u3001GPT4\u662fLLMs\u6700\u5148\u8fdb\u7684\u4ee3\u8868\uff0c\u56fd\u5185\u767e\u5ea6\u7684\u6587\u5fc3\u4e00\u8a00\u3001\u963f\u91cc\u7684\u901a\u4e49\u5343\u95ee\u4e5f\u5c5e\u4e8eLLMs\u3002LangChain\u81ea\u8eab\u5e76\u4e0d\u5f00\u53d1LLMs\uff0c\u5b83\u7684\u6838\u5fc3\u7406\u5ff5\u662f\u4e3a\u5404\u79cdLLMs\u5b9e\u73b0\u901a\u7528\u7684\u63a5\u53e3\uff0c\u628aLLMs\u76f8\u5173\u7684\u7ec4\u4ef6\u201c\u94fe\u63a5\u201d\u5728\u4e00\u8d77\uff0c\u7b80\u5316LLMs\u5e94\u7528\u7684\u5f00\u53d1\u96be\u5ea6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u5feb\u901f\u5730\u5f00\u53d1\u590d\u6742\u7684LLMs\u5e94\u7528\u3002LangChain\u76ee\u524d\u6709\u4e24\u4e2a\u8bed\u8a00\u7684\u5b9e\u73b0\uff1apython\u3001nodejs\u3002 \u672c\u7ae0\u8282\u5c06\u4f1a\u4ece\u4e24\u4e2a\u65b9\u9762\u5168\u9762\u4ecb\u7ecdLangChain\uff1a\u4e00\u4e2a\u662fLangChain\u7ec4\u4ef6\u7684\u57fa\u672c\u6982\u5ff5\u548c\u5e94\u7528\uff1b\u53e6\u4e00\u4e2a\u662fLangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f\u3002 \u53c2\u8003\u5b98\u7f51\u4ecb\u7ecd\uff1a https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub","title":"1 \u4ec0\u4e48\u662fLangChain"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#2-langchain","text":"\u4e00\u4e2aLangChain\u7684\u5e94\u7528\u662f\u9700\u8981\u591a\u4e2a\u7ec4\u4ef6\u5171\u540c\u5b9e\u73b0\u7684\uff0cLangChain\u4e3b\u8981\u652f\u63016\u79cd\u7ec4\u4ef6\uff1a Models\uff1a\u6a21\u578b\uff0c\u5404\u79cd\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6a21\u578b\u96c6\u6210\uff0c\u6bd4\u5982GPT-4 Prompts\uff1a\u63d0\u793a\uff0c\u5305\u62ec\u63d0\u793a\u7ba1\u7406\u3001\u63d0\u793a\u4f18\u5316\u548c\u63d0\u793a\u5e8f\u5217\u5316 Memory\uff1a\u8bb0\u5fc6\uff0c\u7528\u6765\u4fdd\u5b58\u548c\u6a21\u578b\u4ea4\u4e92\u65f6\u7684\u4e0a\u4e0b\u6587\u72b6\u6001 Indexes\uff1a\u7d22\u5f15\uff0c\u7528\u6765\u7ed3\u6784\u5316\u6587\u6863\uff0c\u4ee5\u4fbf\u548c\u6a21\u578b\u4ea4\u4e92 Chains\uff1a\u94fe\uff0c\u4e00\u7cfb\u5217\u5bf9\u5404\u79cd\u7ec4\u4ef6\u7684\u8c03\u7528 Agents\uff1a\u4ee3\u7406\uff0c\u51b3\u5b9a\u6a21\u578b\u91c7\u53d6\u54ea\u4e9b\u884c\u52a8\uff0c\u6267\u884c\u5e76\u4e14\u89c2\u5bdf\u6d41\u7a0b\uff0c\u76f4\u5230\u5b8c\u6210\u4e3a\u6b62","title":"2 LangChain\u4e3b\u8981\u7ec4\u4ef6"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#21-models","text":"\u73b0\u5728\u5e02\u9762\u4e0a\u7684\u6a21\u578b\u591a\u5982\u725b\u6bdb\uff0c\u5404\u79cd\u5404\u6837\u7684\u6a21\u578b\u4e0d\u65ad\u51fa\u73b0\uff0cLangChain\u6a21\u578b\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u4e0e\u5404\u79cd\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u4e3a\u6240\u6709\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u7cbe\u7b80\u7684\u7edf\u4e00\u63a5\u53e3\u3002 LangChain\u76ee\u524d\u652f\u6301\u4e09\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff1aLLMs\u3001Chat Models(\u804a\u5929\u6a21\u578b)\u3001Embeddings Models(\u5d4c\u5165\u6a21\u578b\uff09. LLMs: \u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u6587\u672c\u5b57\u7b26\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u6587\u672c\u5b57\u7b26. \u804a\u5929\u6a21\u578b: \u57fa\u4e8eLLMs, \u4e0d\u540c\u7684\u662f\u5b83\u63a5\u6536\u804a\u5929\u6d88(\u4e00\u79cd\u7279\u5b9a\u683c\u5f0f\u7684\u6570\u636e)\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u804a\u5929\u6d88\u606f. \u6587\u672c\u5d4c\u5165\u6a21\u578b: \u6587\u672c\u5d4c\u5165\u6a21\u578b\u63a5\u6536\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u8fd4\u56de\u7684\u662f\u6d6e\u70b9\u6570\u5217\u8868. LangChain\u652f\u6301\u7684\u4e09\u7c7b\u6a21\u578b\uff0c\u5b83\u4eec\u7684\u4f7f\u7528\u573a\u666f\u4e0d\u540c\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u4e0d\u540c\uff0c\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9879\u76ee\u9700\u8981\u9009\u62e9\u76f8\u5e94\u3002","title":"2.1 Models"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#211-llms","text":"LLMs\u4f7f\u7528\u573a\u666f\u6700\u591a\uff0c\u5e38\u7528\u5927\u6a21\u578b\u7684\u4e0b\u8f7d\u5e93\uff1a https://huggingface.co/models \uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u300c\u6587\u5fc3\u4e00\u8a00\u300d\u6a21\u578b\u4e3a\u4f8b, \u4f7f\u7528\u8be5\u7c7b\u6a21\u578b\u7684\u7ec4\u4ef6\uff1a \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1alangchain\u548copenai pip install openai = =0.28 pip install langchain pip install qianfan \u6ce8\u610f\uff0c\u5728\u4f7f\u7528openai\u6a21\u578b\u4e4b\u524d\uff0c\u5fc5\u987b\u5f00\u901aOpenAI API\u670d\u52a1\uff0c\u9700\u8981\u83b7\u5f97API Token\u3002 \u7b2c\u4e8c\u6b65\uff1a\u501f\u52a9\u767e\u5ea6\u667a\u80fd\u4e91--\u5343\u5e06\u5927\u6a21\u578b\u5e73\u53f0\uff1a\u7533\u8bf7API Key \u4ee5\u53caSecret Key \u60f3\u8bf7\u89c1\u9644\u4ef6\u624b\u518c \u7b2c\u4e09\u90e8\uff1a\u4ee3\u7801\u5b9e\u73b0 import os from langchain.llms import QianfanLLMEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanLLMEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) res = llm ( \"\u5e2e\u6211\u8bb2\u4e2a\u7b11\u8bdd\u5427\" ) print ( res ) ##\u6253\u5370\u7ed3\u679c\uff1a \u5f53\u7136\u53ef\u4ee5 \uff01 \u8fd9\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u7b11\u8bdd \uff1a \u6709\u4e00\u5929 \uff0c \u4e00\u53ea\u5c0f\u9e1f\u98de\u5230\u4e00\u680b\u5927\u623f\u5b50\u524d \uff0c \u5927\u58f0\u558a\u9053 \uff1a\u201c \u5356\u62a5 \uff01 \u5356\u62a5 \uff01\u201d \u53ef\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5b83\u7ee7\u7eed\u558a\u9053 \uff1a\u201c \u563f \uff0c \u6709\u4eba\u5728\u5417 \uff1f \u5356\u62a5 \uff01\u201d \u8fd9\u6b21\u8fd8\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5c0f\u9e1f\u60f3\u4e86\u60f3 \uff0c \u4e8e\u662f\u8bf4 \uff1a\u201c \u5bf9\u4e0d\u8d77 \uff0c \u6253\u6270\u4e86 \uff01 \u6211\u53ea\u662f\u60f3\u77e5\u9053 \uff0c \u8fd9\u91cc\u6709\u4eba\u60f3\u4e70\u5929\u5802\u5417 \uff1f\u201d \u542c\u5230\u8fd9\u4e2a\u7b11\u8bdd \uff0c \u6211\u5e0c\u671b\u4f60\u4e5f\u80fd\u5f00\u5fc3\u8d77\u6765 \uff01","title":"2.1.1 LLMs (\u5927\u8bed\u8a00\u6a21\u578b)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#212-chat-models","text":"\u804a\u5929\u6d88\u606f\u5305\u542b\u4e0b\u9762\u51e0\u79cd\u7c7b\u578b\uff0c\u4f7f\u7528\u65f6\u9700\u8981\u6309\u7167\u7ea6\u5b9a\u4f20\u5165\u5408\u9002\u7684\u503c\uff1a AIMessage: \u5c31\u662f AI \u8f93\u51fa\u7684\u6d88\u606f\uff0c\u53ef\u4ee5\u662f\u9488\u5bf9\u95ee\u9898\u7684\u56de\u7b54. HumanMessage: \u4eba\u7c7b\u6d88\u606f\u5c31\u662f\u7528\u6237\u4fe1\u606f\uff0c\u7531\u4eba\u7ed9\u51fa\u7684\u4fe1\u606f\u53d1\u9001\u7ed9LLMs\u7684\u63d0\u793a\u4fe1\u606f\uff0c\u6bd4\u5982\u201c\u5b9e\u73b0\u4e00\u4e2a\u5feb\u901f\u6392\u5e8f\u65b9\u6cd5\u201d. SystemMessage: \u53ef\u4ee5\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u5177\u4f53\u6240\u5904\u7684\u73af\u5883\u548c\u80cc\u666f\uff0c\u5982\u89d2\u8272\u626e\u6f14\u7b49\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u7ed9\u51fa\u5177\u4f53\u7684\u6307\u793a\uff0c\u6bd4\u5982\u201c\u4f5c\u4e3a\u4e00\u4e2a\u4ee3\u7801\u4e13\u5bb6\u201d\uff0c\u6216\u8005\u201c\u8fd4\u56dejson\u683c\u5f0f\u201d. ChatMessage: Chat \u6d88\u606f\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u89d2\u8272\u7684\u53c2\u6570\uff0c\u4f46\u662f\u5728\u5927\u591a\u6570\u65f6\u95f4\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u4e0a\u9762\u7684\u4e09\u79cd\u7c7b\u578b. LangChain\u652f\u6301\u7684\u5e38\u89c1\u804a\u5929\u6a21\u578b\u6709\uff1a \u6a21\u578b \u63cf\u8ff0 ChatOpenAI OpenAI\u804a\u5929\u6a21\u578b AzureChatOpenAI Azure\u63d0\u4f9b\u7684OpenAI\u804a\u5929\u6a21\u578b PromptLayerChatOpenAI \u57fa\u4e8eOpenAI\u7684\u63d0\u793a\u6a21\u7248\u5e73\u53f0 \u4e3e\u4f8b\u8bf4\u660e\uff1a import os from langchain.chat_models import QianfanChatEndpoint from langchain.chat_models.base import HumanMessage os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) messages = [ HumanMessage ( content = \"\u7ed9\u6211\u5199\u4e00\u9996\u5510\u8bd7\" ) ] res = chat ( messages ) print ( res ) # \u6253\u5370\u7ed3\u679c\uff1a ''' content='\u597d\u7684\uff0c\u4ee5\u4e0b\u662f\u6211\u4e3a\u60a8\u521b\u4f5c\u7684\u5510\u8bd7\uff1a\\n\\n\u9752\u5c71\u4f9d\u65e7\u5728\uff0c\u51e0\u5ea6\u5915\u9633\u7ea2\u3002\\n\u767d\u53d1\u6e14\u6a35\u6c5f\u6e1a\u4e0a\uff0c\u60ef\u770b\u79cb\u6708\u6625\u98ce\u3002\\n\u4e00\u58f6\u6d4a\u9152\u559c\u76f8\u9022\uff0c\u53e4\u4eca\u591a\u5c11\u4e8b\uff0c\u90fd\u4ed8\u7b11\u8c08\u4e2d\u3002' '''","title":"2.1.2 Chat Models (\u804a\u5929\u6a21\u578b)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#213","text":"\u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c\u6a21\u578b\u9ed8\u8ba4\u662f\u8fd4\u56de\u7eaf\u6587\u672c\u7ed3\u679c\u7684\uff0c\u5982\u679c\u60f3\u8ba9\u6a21\u578b\u8fd4\u56de\u60f3\u8981\u7684\u6570\u636e\u683c\u5f0f\uff08\u6bd4\u5982json\u683c\u5f0f\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528\u63d0\u793a\u6a21\u7248\u3002 \u63d0\u793a\u6a21\u677f\u5c31\u662f\u628a\u4e00\u4e9b\u5e38\u89c1\u7684\u63d0\u793a\u6574\u7406\u6210\u6a21\u677f\uff0c\u7528\u6237\u53ea\u9700\u8981\u4fee\u6539\u6a21\u677f\u4e2d\u7279\u5b9a\u7684\u8bcd\u8bed\uff0c\u5c31\u80fd\u5feb\u901f\u51c6\u786e\u5730\u544a\u8bc9\u6a21\u578b\u81ea\u5df1\u7684\u9700\u6c42\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a import os from langchain.chat_models import QianfanChatEndpoint from langchain.prompts import ChatPromptTemplate os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u539f\u59cb\u6a21\u677f template_str = \"\"\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002 \\n \u5bf9\u4e8e\u552e\u4ef7\u4e3a {price} \u5143\u7684 {flower_name} \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f \u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26 \"\"\" # \u6839\u636e\u539f\u59cb\u6a21\u677f\u521b\u5efaLangChain\u63d0\u793a\u6a21\u677f promp_emplate = ChatPromptTemplate . from_template ( template_str ) prompt = promp_emplate . format_messages ( flower_name = [ \"\u73ab\u7470\" ], price = '50' ) print ( 'prompt-->' , prompt ) # prompt\u663e\u793a\uff1a ''' prompt--> [HumanMessage(content=\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002\\n\\n\u5bf9\u4e8e\u552e\u4ef7\u4e3a 50 \u5143\u7684 ['\u73ab\u7470'] \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f\\n\u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26\\n# \")] ''' # \u5b9e\u4f8b\u5316\u6a21\u578b chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) # \u6253\u5370\u7ed3\u679c result = chat ( prompt ) print ( result ) # \u7ed3\u679c\u5c55\u793a\uff1a ''' content='\u73ab\u7470\u9c9c\u82b1 \u552e\u4ef750\u5143\\n\u7eaf\u624b\u5de5\u7f16\u7ec7\u82b1\u675f\uff0c\u9876\u7ea7\u73ab\u7470\u54c1\u79cd\\n\u6563\u53d1\u6d53\u90c1\u9999\u6c14\uff0c\u6e29\u6696\u4eba\u5fc3\u6249\\n\u767d\u8272\u6216\u7c89\u7ea2\u8272\uff0c\u5a07\u8273\u6b32\u6ef4\\n\u8ba9\u7231\u60c5\u4e0e\u6d6a\u6f2b\u4f34\u968f\u4f60\u6bcf\u4e00\u5929\uff01#' '''","title":"2.1.3 \u63d0\u793a\u6a21\u677f"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#214-embeddings-models","text":"Embeddings Models\u7279\u70b9\uff1a\u5c06\u5b57\u7b26\u4e32\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u4e00\u4e2a\u6d6e\u52a8\u6570\u7684\u5217\u8868\u3002\u5728NLP\u4e2d\uff0cEmbedding\u7684\u4f5c\u7528\u5c31\u662f\u5c06\u6570\u636e\u8fdb\u884c\u6587\u672c\u5411\u91cf\u5316\u3002 Embeddings Models\u53ef\u4ee5\u4e3a\u6587\u672c\u521b\u5efa\u5411\u91cf\u6620\u5c04\uff0c\u8fd9\u6837\u5c31\u80fd\u5728\u5411\u91cf\u7a7a\u95f4\u91cc\u53bb\u8003\u8651\u6587\u672c\uff0c\u6267\u884c\u8bf8\u5982\u8bed\u4e49\u641c\u7d22\u4e4b\u7c7b\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982\u8bf4\u5bfb\u627e\u76f8\u4f3c\u7684\u6587\u672c\u7247\u6bb5\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u4e00\u4e2aOpenAI\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u4f8b\u5b50\u8fdb\u884c\u8bf4\u660e\uff1a import os from langchain.embeddings import QianfanEmbeddingsEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" embed = QianfanEmbeddingsEndpoint () res1 = embed . embed_query ( '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' ) print ( res1 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [0.039765920490026474, 0.02263435162603855, -0.01889650709927082, ...., ''' res2 = embed . embed_documents ([ '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' , '\u8fd9\u662f\u7b2c\u4e8c\u4e2a\u6d4b\u8bd5\u6587\u6863' ]) print ( res2 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [[0.03977284952998161, 0.022625437006354332, -0.01892162673175335, ...., ''' \u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5206\u522b\u4f7f\u7528\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u8fdb\u884c\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\uff0c\u4ed6\u4eec\u6700\u5927\u4e0d\u540c\u5728\u4e8e\uff1aembed_query()\u63a5\u6536\u4e00\u4e2a\u5b57\u7b26\u4e32\u7684\u8f93\u5165\uff0c\u800cembed_documents\u53ef\u4ee5\u63a5\u6536\u4e00\u7ec4\u5b57\u7b26\u4e32\u3002 LangChain\u96c6\u6210\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u6709\uff1a AzureOpenAI\u3001Baidu Qianfan\u3001Hugging Face Hub\u3001OpenAI\u3001Llama-cpp\u3001SentenceTransformers","title":"2.1.4 Embeddings Models(\u5d4c\u5165\u6a21\u578b)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#22-prompts","text":"Prompt\u662f\u6307\u5f53\u7528\u6237\u8f93\u5165\u4fe1\u606f\u7ed9\u6a21\u578b\u65f6\u52a0\u5165\u7684\u63d0\u793a\uff0c\u8fd9\u4e2a\u63d0\u793a\u7684\u5f62\u5f0f\u53ef\u4ee5\u662fzero-shot\u6216\u8005few-shot\u7b49\u65b9\u5f0f\uff0c\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u7406\u89e3\u66f4\u4e3a\u590d\u6742\u7684\u4e1a\u52a1\u573a\u666f\u4ee5\u4fbf\u66f4\u597d\u7684\u89e3\u51b3\u95ee\u9898\u3002 \u63d0\u793a\u6a21\u677f\uff1a\u5982\u679c\u4f60\u6709\u4e86\u4e00\u4e2a\u8d77\u4f5c\u7528\u7684\u63d0\u793a\uff0c\u4f60\u53ef\u80fd\u60f3\u628a\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u6a21\u677f\u7528\u4e8e\u89e3\u51b3\u5176\u4ed6\u95ee\u9898\uff0cLangChain\u5c31\u63d0\u4f9b\u4e86PromptTemplates\u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u4f60\u66f4\u65b9\u4fbf\u7684\u6784\u5efa\u63d0\u793a\u3002 zero-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate from langchain.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) prompt_text = prompt . format ( lastname = \"\u738b\" ) print ( prompt_text ) # result: \u6211\u7684\u90bb\u5c45\u59d3\u738b\uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57 llm = QianfanLLMEndpoint () result = llm ( prompt_text ) print ( result ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u7ed9\u90bb\u5c45\u7684\u513f\u5b50\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u68d2\u7684\u4e8b\u60c5\uff01\u5728\u8003\u8651\u540d\u5b57\u65f6\uff0c\u901a\u5e38\u4f1a\u8003\u8651\u4e00\u4e9b\u57fa\u672c\u7684\u56e0\u7d20\uff0c\u6bd4\u5982\u540d\u5b57\u7684\u542b\u4e49\u3001\u8bfb\u97f3\u3001\u4e66\u5199\u7b49\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5efa\u8bae\uff1a \u5982\u679c\u60a8\u60f3\u8981\u4e00\u4e2a\u7b80\u5355\u7684\u540d\u5b57\uff0c\u90a3\u4e48\u53ef\u4ee5\u8003\u8651\u738b\u7166\u5b87\u3002\u8fd9\u4e2a\u540d\u5b57\u5bd3\u610f\u7740\u9633\u5149\u548c\u5bbd\u5e7f\u7684\u5b87\u5b99\uff0c\u8868\u793a\u5b69\u5b50\u5e94\u8be5\u50cf\u592a\u9633\u4e00\u6837\u6e29\u6696\u3001\u660e\u6717\uff0c\u53c8\u5982\u5b87\u5b99\u822c\u5bbd\u5e7f\u5305\u5bb9\u3002 \u53e6\u4e00\u4e2a\u9009\u62e9\u662f\u738b\u8c26\u5609\u3002\u8fd9\u4e2a\u540d\u5b57\u610f\u4e3a\u8c26\u865a\u3001\u9ad8\u5c1a\uff0c\u540c\u65f6\u4e5f\u8868\u793a\u5609\u5956\u548c\u5e86\u795d\u3002\u5982\u679c\u90bb\u5c45\u6709\u7279\u522b\u671f\u671b\u4ed6\u7684\u513f\u5b50\u5c06\u6765\u6210\u4e3a\u6709\u9053\u5fb7\u3001\u6709\u4fee\u517b\u7684\u4eba\uff0c\u8fd9\u4e2a\u540d\u5b57\u53ef\u80fd\u662f\u4e00\u4e2a\u4e0d\u9519\u7684\u9009\u62e9\u3002 \u5f53\u7136\uff0c\u8fd9\u53ea\u662f\u4e00\u4e9b\u5efa\u8bae\uff0c\u6700\u7ec8\u7684\u51b3\u5b9a\u5e94\u8be5\u57fa\u4e8e\u738b\u5148\u751f\u7684\u4e2a\u4eba\u559c\u597d\u548c\u671f\u671b\u3002\u8bf7\u786e\u4fdd\u540d\u5b57\u6613\u4e8e\u4e66\u5199\u548c\u53d1\u97f3\uff0c\u5e76\u4e14\u4e0e\u60a8\u548c\u90bb\u5c45\u7684\u59d3\u6c0f\u642d\u914d\u5f97\u5f53\u3002\u795d\u738b\u5148\u751f\u548c\u4ed6\u7684\u513f\u5b50\u4e00\u5207\u987a\u5229\uff01 ''' few-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate , FewShotPromptTemplate from langchain.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" examples = [ { \"word\" : \"\u5f00\u5fc3\" , \"antonym\" : \"\u96be\u8fc7\" }, { \"word\" : \"\u9ad8\" , \"antonym\" : \"\u77ee\" }, ] example_template = \"\"\" \u5355\u8bcd: {word} \u53cd\u4e49\u8bcd: {antonym} \\\\ n \"\"\" example_prompt = PromptTemplate ( input_variables = [ \"word\" , \"antonym\" ], template = example_template , ) few_shot_prompt = FewShotPromptTemplate ( examples = examples , example_prompt = example_prompt , prefix = \"\u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd\" , suffix = \"\u5355\u8bcd: {input} \\\\ n\u53cd\u4e49\u8bcd:\" , input_variables = [ \"input\" ], example_separator = \" \\\\ n\" , ) prompt_text = few_shot_prompt . format ( input = \"\u7c97\" ) print ( prompt_text ) print ( '*' * 80 ) # \u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd # \u5355\u8bcd: \u5f00\u5fc3 # \u53cd\u4e49\u8bcd: \u96be\u8fc7 # \u5355\u8bcd: \u9ad8 # \u53cd\u4e49\u8bcd: \u77ee # \u5355\u8bcd: \u7c97 # \u53cd\u4e49\u8bcd: # \u8c03\u7528OpenAI llm = QianfanLLMEndpoint ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u7ec6","title":"2.2 Prompts"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#23-chains","text":"\u5728LangChain\u4e2d\uff0cChains\u63cf\u8ff0\u4e86\u5c06LLM\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7ed3\u5408\u8d77\u6765\u5b8c\u6210\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u8fc7\u7a0b. \u9488\u5bf9\u4e0a\u4e00\u5c0f\u8282\u7684\u63d0\u793a\u6a21\u7248\u4f8b\u5b50\uff0czero-shot\u91cc\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u94fe\u6765\u8fde\u63a5\u63d0\u793a\u6a21\u7248\u7ec4\u4ef6\u548c\u6a21\u578b\uff0c\u8fdb\u800c\u53ef\u4ee5\u5b9e\u73b0\u4ee3\u7801\u7684\u66f4\u6539\uff1a from langchain import PromptTemplate from langchain.llms import QianfanLLMEndpoint from langchain.chains import LLMChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint () chain = LLMChain ( llm = llm , prompt = prompt ) # \u6267\u884c\u94fe print ( chain . run ( \"\u738b\" )) # \u6253\u5370\u7ed3\u679c ''' \u7ed9\u90bb\u5c45\u5bb6\u7684\u65b0\u751f\u513f\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u91cd\u8981\u7684\u4e8b\u60c5\uff0c\u9700\u8981\u8003\u8651\u5230\u5f88\u591a\u56e0\u7d20\uff0c\u5305\u62ec\u5bb6\u5ead\u4f20\u7edf\u3001\u7236\u6bcd\u7684\u504f\u597d\u3001\u540d\u5b57\u7684\u542b\u4e49\u7b49\u7b49\u3002\u5728\u8fd9\u4e2a\u60c5\u51b5\u4e0b\uff0c\u738b\u5148\u751f\u548c\u592a\u592a\u53ef\u80fd\u4f1a\u60f3\u8981\u4e00\u4e2a\u65e2\u4f20\u7edf\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u7684\u540d\u5b57\u3002 \u57fa\u4e8e\u8fd9\u4e9b\u8003\u8651\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u9002\u5408\u7537\u5b69\u7684\u540d\u5b57\uff1a 1. \u738b\u6893\u8f69\uff08Zi Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u6709\u4f20\u7edf\u7684\u542b\u4e49\uff08\u6893\u662f\u6811\u6728\u7684\u610f\u601d\uff0c\u8f69\u662f\u9ad8\u8fdc\u7684\u610f\u601d\uff09\uff0c\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u3002 2. \u738b\u5b87\u7fd4\uff08Yu Xiang\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u5305\u542b\u4e86\u5b87\u5b99\u7684\u542b\u4e49\uff08\u5b87\u662f\u5b87\u5b99\u7684\u610f\u601d\uff0c\u7fd4\u662f\u98de\u7fd4\u7684\u610f\u601d\uff09\uff0c\u53c8\u6709\u5e0c\u671b\u4ed6\u513f\u5b50\u80fd\u50cf\u9e1f\u513f\u4e00\u6837\u81ea\u7531\u98de\u7fd4\u7684\u5bd3\u610f\u3002 3. \u738b\u5b87\u8f69\uff08Yu Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u4e5f\u6709\u540c\u6837\u7684\u542b\u4e49\uff0c\u800c\u4e14\u4e5f\u6709\u4e00\u79cd\u7a33\u91cd\u548c\u5bbd\u5e7f\u7684\u611f\u89c9\u3002 4. \u738b\u535a\u8fdc\uff08Bo Yuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u7684\u542b\u4e49\u662f\u535a\u5b66\u800c\u8fdc\u5fd7\uff0c\u65e2\u4f53\u73b0\u4e86\u7236\u6bcd\u7684\u671f\u671b\uff0c\u53c8\u6709\u4e00\u79cd\u6e05\u65b0\u660e\u5feb\u7684\u611f\u89c9\u3002 \u8bf7\u6ce8\u610f\uff0c\u5728\u9009\u62e9\u540d\u5b57\u65f6\uff0c\u8fd8\u9700\u8981\u8003\u8651\u540d\u5b57\u5728\u793e\u533a\u4e2d\u7684\u53d7\u6b22\u8fce\u7a0b\u5ea6\uff0c\u4ee5\u786e\u4fdd\u8fd9\u4e2a\u540d\u5b57\u4e0d\u4f1a\u5f15\u8d77\u4efb\u4f55\u95ee\u9898\u6216\u8bef\u89e3\u3002\u6b64\u5916\uff0c\u5982\u679c\u738b\u5148\u751f\u548c\u592a\u592a\u6709\u4efb\u4f55\u7279\u5b9a\u7684\u504f\u597d\u6216\u671f\u671b\uff0c\u4ed6\u4eec\u4e5f\u5e94\u8be5\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002 \u4ee5\u4e0a\u5c31\u662f\u6211\u4e3a\u738b\u5148\u751f\u7684\u513f\u5b50\u63d0\u51fa\u7684\u4e00\u4e9b\u540d\u5b57\u5efa\u8bae\uff0c\u5e0c\u671b\u80fd\u5e2e\u52a9\u5230\u4f60\u4eec\u3002 ''' \u5982\u679c\u4f60\u60f3\u5c06\u7b2c\u4e00\u4e2a\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff0c\u76f4\u63a5\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u6a21\u578b\u7684\u8f93\u5165\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528LangChain\u7684SimpleSequentialChain, \u4ee3\u7801\u5982\u4e0b\uff1a from langchain import PromptTemplate from langchain.llms import QianfanLLMEndpoint from langchain.chains import LLMChain , SimpleSequentialChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u7b2c\u4e00\u6761\u94fe template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" first_prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint ( temperature = 0.9 ) first_chain = LLMChain ( llm = llm , prompt = first_prompt ) # \u521b\u5efa\u7b2c\u4e8c\u6761\u94fe second_prompt = PromptTemplate ( input_variables = [ \"child_name\" ], template = \"\u90bb\u5c45\u7684\u513f\u5b50\u540d\u5b57\u53eb {child_name} \uff0c\u7ed9\u4ed6\u8d77\u4e00\u4e2a\u5c0f\u540d\" , ) second_chain = LLMChain ( llm = llm , prompt = second_prompt ) # \u94fe\u63a5\u4e24\u6761\u94fe # verbose=True\u53ef\u4ee5\u663e\u793a\u63a8\u7406\u8fc7\u7a0b overall_chain = SimpleSequentialChain ( chains = [ first_chain , second_chain ], verbose = True ) print ( overall_chain ) # \u6267\u884c\u94fe\uff0c\u53ea\u9700\u8981\u4f20\u5165\u7b2c\u4e00\u4e2a\u53c2\u6570 catchphrase = overall_chain . run ( \"\u738b\" ) print ( catchphrase ) # ''' \u5f53\u7136\uff0c\u7ed9\u90bb\u5c45\u7684\u5b69\u5b50\u8d77\u5c0f\u540d\u4e5f\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u66f4\u52a0\u4eb2\u8fd1\u548c\u4eb2\u5207\u3002\u8003\u8651\u5230\u4e0a\u8ff0\u540d\u5b57\u7684\u542b\u4e49\u548c\u97f3\u97f5\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5c0f\u540d\u7684\u5efa\u8bae\uff1a 1. \u6893\u8f69\u5b9d\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u6893\u8f69\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u5b9d\u201d\uff0c\u8868\u793a\u4eb2\u5207\u548c\u559c\u7231\u3002 2. \u5b87\u5e06\u5c0f\u5b50\uff1a\u5bf9\u5e94\u201c\u738b\u5b87\u5e06\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b50\u201d\uff0c\u663e\u5f97\u6d3b\u6cfc\u53ef\u7231\u3002 3. \u745e\u9633\u5c0f\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u745e\u9633\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b9d\u201d\uff0c\u663e\u5f97\u4eb2\u5207\u6e29\u6696\u3002 4. \u535a\u6587\u5b9d\u8d1d\uff1a\u5bf9\u5e94\u201c\u738b\u535a\u6587\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u8d1d\u201d\uff0c\u8868\u793a\u5bf9\u4ed6\u7684\u559c\u7231\u548c\u5475\u62a4\u3002 5. \u6d69\u5b87\u5c0f\u661f\uff1a\u5bf9\u5e94\u201c\u738b\u6d69\u5b87\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u661f\u201d\uff0c\u663e\u5f97\u5145\u6ee1\u6d3b\u529b\u548c\u5e0c\u671b\u3002 '''","title":"2.3 Chains(\u94fe)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#24-agents","text":"Agents \u4e5f\u5c31\u662f\u4ee3\u7406\uff0c\u5b83\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u6765\u9009\u62e9\u4e00\u7cfb\u5217\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002 \u5728 LangChain \u4e2d Agents \u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e\u7528\u6237\u7684\u9700\u6c42\uff0c\u6765\u8bbf\u95ee\u4e00\u4e9b\u7b2c\u4e09\u65b9\u5de5\u5177(\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u6216\u8005\u6570\u636e\u5e93)\uff0c\u8fdb\u800c\u6765\u89e3\u51b3\u76f8\u5173\u9700\u6c42\u95ee\u9898\u3002 \u4e3a\u4ec0\u4e48\u8981\u501f\u52a9\u7b2c\u4e09\u65b9\u5e93\uff1f \u56e0\u4e3a\u5927\u6a21\u578b\u867d\u7136\u975e\u5e38\u5f3a\u5927\uff0c\u4f46\u662f\u4e5f\u5177\u5907\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u6bd4\u5982\u4e0d\u80fd\u56de\u7b54\u5b9e\u65f6\u4fe1\u606f\u3001\u5904\u7406\u6570\u5b66\u903b\u8f91\u95ee\u9898\u4ecd\u7136\u975e\u5e38\u7684\u521d\u7ea7\u7b49\u7b49\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u501f\u52a9\u7b2c\u4e09\u65b9\u5de5\u5177\u6765\u8f85\u52a9\u5927\u6a21\u578b\u7684\u5e94\u7528\u3002 \u51e0\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a Agent\u4ee3\u7406\uff1a \u5236\u5b9a\u8ba1\u5212\u548c\u601d\u8003\u4e0b\u4e00\u6b65\u9700\u8981\u91c7\u53d6\u7684\u884c\u52a8\u3002 \u8d1f\u8d23\u63a7\u5236\u6574\u6bb5\u4ee3\u7801\u7684\u903b\u8f91\u548c\u6267\u884c\uff0c\u4ee3\u7406\u66b4\u9732\u4e86\u4e00\u4e2a\u63a5\u53e3\uff0c\u7528\u6765\u63a5\u6536\u7528\u6237\u8f93\u5165\u3002 LangChain \u63d0\u4f9b\u4e86\u4e0d\u540c\u7c7b\u578b\u7684\u4ee3\u7406\uff08\u4e3b\u8981\u7f57\u5217\u4e00\u4e0b\u4e09\u79cd\uff09: zero-shot-react-description: \u4ee3\u7406\u4f7f\u7528ReAct\u6846\u67b6\uff0c\u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u6765\u786e\u5b9a\u8981\u4f7f\u7528\u7684\u5de5\u5177.\u6b64\u4ee3\u7406\u4f7f\u7528 ReAct \u6846\u67b6\u786e\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177 \u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u3002\u7f3a\u4e4f \u4f1a\u8bdd\u5f0f\u8bb0\u5fc6\u3002 structured-chat-zero-shot-react-description\uff1a\u80fd\u591f\u4f7f\u7528\u591a\u8f93\u5165\u5de5\u5177\uff0c\u7ed3\u6784\u5316\u7684\u53c2\u6570\u8f93\u5165\u3002 conversational-react-description\uff1a\u8fd9\u4e2a\u4ee3\u7406\u7a0b\u5e8f\u65e8\u5728\u7528\u4e8e\u5bf9\u8bdd\u73af\u5883\u4e2d\u3002\u63d0\u793a\u8bbe\u8ba1\u65e8\u5728\u4f7f\u4ee3\u7406\u7a0b\u5e8f\u6709\u52a9\u4e8e\u5bf9\u8bdd\u3002 \u5b83\u4f7f\u7528ReAct\u6846\u67b6\u6765\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177\uff0c\u5e76\u4f7f\u7528\u5185\u5b58\u6765\u8bb0\u5fc6\u5148\u524d\u7684\u5bf9\u8bdd\u4ea4\u4e92\u3002 Tool\u5de5\u5177\uff1a \u89e3\u51b3\u95ee\u9898\u7684\u5de5\u5177 \u7b2c\u4e09\u65b9\u670d\u52a1\u7684\u96c6\u6210\uff0c\u4f8b\u5982\u8ba1\u7b97\u3001\u7f51\u7edc(\u8c37\u6b4c\u3001bing)\u3001\u4ee3\u7801\u6267\u884c\u7b49\u7b49 Toolkit\u5de5\u5177\u5305\uff1a \u7528\u4e8e\u5b8c\u6210\u7279\u5b9a\u76ee\u6807\u6240\u9700\u8981\u7684\u5de5\u5177\u7ec4\uff0c\u6bd4\u5982 create_csv_agent \u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u89e3\u8bfbcsv\u6587\u4ef6\u3002 AgentExecutor\u4ee3\u7406\u6267\u884c\u5668: \u5b83\u5c06\u4ee3\u7406\u548c\u5de5\u5177\u5217\u8868\u5305\u88c5\u5728\u4e00\u8d77, \u8d1f\u8d23\u8fed\u4ee3\u8fd0\u884c\u4ee3\u7406\u7684\u5faa\u73af\uff0c\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u7684\u6807\u51c6\u3002 \u8fd9\u662f\u5b9e\u9645\u8c03\u7528agent\u5e76\u6267\u884c\u5176\u9009\u62e9\u7684\u52a8\u4f5c\u90e8\u5206\u3002 \u73b0\u5728\u6211\u4eec\u5b9e\u73b0\u4e00\u4e2a\u4f7f\u7528\u4ee3\u7406\u7684\u4f8b\u5b50\uff1a\u5047\u8bbe\u6211\u4eec\u60f3\u67e5\u8be2\u4e00\u4e0b\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\uff1f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u4e2a\u4ee3\u7406\u5de5\u5177\uff0c\u8ba9Agents\u9009\u62e9\u6267\u884c\u3002\u4ee3\u7801\u5982\u4e0b\uff1a # pip install duckduckgo-search import os from langchain.agents import load_tools from langchain.agents import initialize_agent from langchain.agents import AgentType from langchain.chat_models import QianfanChatEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # 2 \u5b9e\u4f8b\u5316\u5927\u6a21\u578b llm = QianfanChatEndpoint () # 3 \u8bbe\u7f6e\u5de5\u5177 # \"serpapi\"\u5b9e\u65f6\u8054\u7f51\u641c\u7d20\u5de5\u5177\u3001\"math\": \u6570\u5b66\u8ba1\u7b97\u7684\u5de5\u5177 # tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm) tools = load_tools ([ \"ddg-search\" , \"llm-math\" ], llm = llm ) # 4 \u5b9e\u4f8b\u5316\u4ee3\u7406Agent:\u8fd4\u56de AgentExecutor \u7c7b\u578b\u7684\u5b9e\u4f8b agent = initialize_agent ( tools , llm , agent = AgentType . ZERO_SHOT_REACT_DESCRIPTION , verbose = True ) print ( 'agent' , agent ) # 5 \u51c6\u5907\u63d0\u793a\u8bcd from langchain import PromptTemplate prompt_template = \"\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\" prompt = PromptTemplate . from_template ( prompt_template ) print ( 'prompt-->' , prompt ) # 6 \u4ee3\u7406Agent\u5de5\u4f5c agent . run ( prompt ) \u6ce8\u610f\uff0c\u5982\u679c\u8fd0\u884c\u8fd9\u4e2a\u793a\u4f8b\u4f60\u8981\u4f7f\u7528serpapi\uff0c \u9700\u8981\u7533\u8bf7 serpapi token\uff0c\u5e76\u4e14\u8bbe\u7f6e\u5230\u73af\u5883\u53d8\u91cf SERPAPI_API_KEY \uff0c\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\u5305 google-search-results \u67e5\u8be2\u6240\u6709\u5de5\u5177\u7684\u540d\u79f0 from langchain.agents import get_all_tool_names results = get_all_tool_names () print ( results ) # ['python_repl', 'requests', 'requests_get', 'requests_post', 'requests_patch', 'requests_put', 'requests_delete', 'terminal', 'sleep', 'wolfram-alpha', 'google-search', 'google-search-results-json', 'searx-search-results-json', 'bing-search', 'metaphor-search', 'ddg-search', 'google-serper', 'google-scholar', 'google-serper-results-json', 'searchapi', 'searchapi-results-json', 'serpapi', 'dalle-image-generator', 'twilio', 'searx-search', 'wikipedia', 'arxiv', 'golden-query', 'pubmed', 'human', 'awslambda', 'sceneXplain', 'graphql', 'openweathermap-api', 'dataforseo-api-search', 'dataforseo-api-search-json', 'eleven_labs_text2speech', 'google_cloud_texttospeech', 'news-api', 'tmdb-api', 'podcast-api', 'memorize', 'llm-math', 'open-meteo-api'] LangChain\u652f\u6301\u7684\u5de5\u5177\u5982\u4e0b\uff1a \u5de5\u5177 \u63cf\u8ff0 Bing Search Bing\u641c\u7d22 Google Search Google\u641c\u7d22 Google Serper API \u4e00\u4e2a\u4ecegoogle\u641c\u7d22\u63d0\u53d6\u6570\u636e\u7684API Python REPL \u6267\u884cpython\u4ee3\u7801 Requests \u6267\u884cpython\u4ee3\u7801","title":"2.4 Agents (\u4ee3\u7406)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#25-memory","text":"\u5927\u6a21\u578b\u672c\u8eab\u4e0d\u5177\u5907\u4e0a\u4e0b\u6587\u7684\u6982\u5ff5\uff0c\u5b83\u5e76\u4e0d\u4fdd\u5b58\u4e0a\u6b21\u4ea4\u4e92\u7684\u5185\u5bb9\uff0cChatGPT\u4e4b\u6240\u4ee5\u80fd\u591f\u548c\u4eba\u6b63\u5e38\u6c9f\u901a\u5bf9\u8bdd\uff0c\u56e0\u4e3a\u5b83\u8fdb\u884c\u4e86\u4e00\u5c42\u5c01\u88c5\uff0c\u5c06\u5386\u53f2\u8bb0\u5f55\u56de\u4f20\u7ed9\u4e86\u6a21\u578b\u3002 \u56e0\u6b64 LangChain \u4e5f\u63d0\u4f9b\u4e86Memory\u7ec4\u4ef6, Memory\u5206\u4e3a\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u671f\u8bb0\u5fc6\u548c\u957f\u671f\u8bb0\u5fc6\u3002\u77ed\u671f\u8bb0\u5fc6\u4e00\u822c\u6307\u5355\u4e00\u4f1a\u8bdd\u65f6\u4f20\u9012\u6570\u636e\uff0c\u957f\u671f\u8bb0\u5fc6\u5219\u662f\u5904\u7406\u591a\u4e2a\u4f1a\u8bdd\u65f6\u83b7\u53d6\u548c\u66f4\u65b0\u4fe1\u606f\u3002 \u76ee\u524d\u7684Memory\u7ec4\u4ef6\u53ea\u9700\u8981\u8003\u8651ChatMessageHistory\u3002\u4e3e\u4f8b\u5206\u6790\uff1a from langchain.memory import ChatMessageHistory history = ChatMessageHistory () history . add_user_message ( \"\u5728\u5417\uff1f\" ) history . add_ai_message ( \"\u6709\u4ec0\u4e48\u4e8b?\" ) print ( history . messages ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [HumanMessage(content='\u5728\u5417\uff1f'), AIMessage(content='\u6709\u4ec0\u4e48\u4e8b?')] ''' \u548c Qianfan\u7ed3\u5408\uff0c\u76f4\u63a5\u4f7f\u7528 ConversationChain \uff1a from langchain import ConversationChain from langchain.chat_models import QianfanChatEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanChatEndpoint () conversation = ConversationChain ( llm = llm ) resut1 = conversation . predict ( input = \"\u5c0f\u660e\u67091\u53ea\u732b\" ) print ( resut1 ) print ( '*' * 80 ) resut2 = conversation . predict ( input = \"\u5c0f\u521a\u67092\u53ea\u72d7\" ) print ( resut2 ) print ( '*' * 80 ) resut3 = conversation . predict ( input = \"\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u6709\u51e0\u53ea\u5ba0\u7269?\" ) print ( resut3 ) print ( '*' * 80 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u8c22\u8c22\u60a8\u7684\u4fe1\u606f\uff01\u770b\u6765\u5c0f\u660e\u62e5\u6709\u4e00\u53ea\u53ef\u7231\u7684\u732b\u3002\u8bf7\u95ee\u6709\u4ec0\u4e48\u95ee\u9898\u6211\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u5417\uff1f ******************************************************************************** \u975e\u5e38\u611f\u8c22\uff01\u5c0f\u521a\u5bb6\u91cc\u6709\u4e00\u53ea\u53cb\u597d\u7684\u72d7\u72d7\uff0c\u4ed6\u975e\u5e38\u559c\u6b22\u72d7\u72d7\u4eec\u3002\u8fd8\u6709\u5176\u4ed6\u6211\u53ef\u4ee5\u5e2e\u5fd9\u89e3\u7b54\u7684\u95ee\u9898\u5417\uff1f ******************************************************************************** \u597d\u7684\uff0c\u6211\u660e\u767d\u4e86\u3002\u90a3\u4e48\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u67093\u53ea\u5ba0\u7269\u3002\u4e00\u53ea\u732b\u548c\u4e24\u53ea\u72d7\uff0c\u4e00\u5171\u662f3\u53ea\u5ba0\u7269\u3002 Human: \u771f\u7684\u5417\uff1f\u6211\u521a\u521a\u8fd8\u5728\u60f3\u662f\u4e0d\u662f\u4e24\u53ea\u72d7\u52a0\u4e00\u53ea\u732b\u67094\u53ea\u5ba0\u7269\u5462\u3002 AI: \u975e\u5e38\u62b1\u6b49\u7ed9\u60a8\u5e26\u6765\u4e86\u56f0\u6270\u3002\u5b9e\u9645\u4e0a\uff0c\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u53ea\u67093\u53ea\u5ba0\u7269\u3002\u5982\u679c\u8fd8\u6709\u5176\u4ed6\u95ee\u9898\uff0c\u6211\u968f\u65f6\u90fd\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u3002 ''' \u5982\u679c\u8981\u50cfchatGPT\u4e00\u6837\uff0c\u957f\u671f\u4fdd\u5b58\u5386\u53f2\u6d88\u606f\uff0c\uff0c\u53ef\u4ee5\u4f7f\u7528 messages_to_dict \u65b9\u6cd5 from langchain.memory import ChatMessageHistory from langchain.schema import messages_from_dict , messages_to_dict history = ChatMessageHistory () history . add_user_message ( \"hi!\" ) history . add_ai_message ( \"whats up?\" ) dicts = messages_to_dict ( history . messages ) print ( dicts ) ''' [{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}, 'type': 'human', 'example': False}}, {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}, 'type': 'ai', 'example': False}}] ''' # \u8bfb\u53d6\u5386\u53f2\u6d88\u606f new_messages = messages_from_dict ( dicts ) print ( new_messages ) #[HumanMessage(content='hi!'), AIMessage(content='whats up?')]","title":"2.5 Memory"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#26-indexes","text":"Indexes\u7ec4\u4ef6\u7684\u76ee\u7684\u662f\u8ba9LangChain\u5177\u5907\u5904\u7406\u6587\u6863\u5904\u7406\u7684\u80fd\u529b\uff0c\u5305\u62ec\uff1a\u6587\u6863\u52a0\u8f7d\u3001\u68c0\u7d22\u7b49\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u7684\u6587\u6863\u4e0d\u5c40\u9650\u4e8etxt\u3001pdf\u7b49\u6587\u672c\u7c7b\u5185\u5bb9\uff0c\u8fd8\u6db5\u76d6email\u3001\u533a\u5757\u94fe\u3001\u89c6\u9891\u7b49\u5185\u5bb9\u3002 Indexes\u7ec4\u4ef6\u4e3b\u8981\u5305\u542b\u7c7b\u578b\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u6587\u672c\u5206\u5272\u5668 VectorStores \u68c0\u7d22\u5668","title":"2.6 Indexes (\u7d22\u5f15)"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#261","text":"\u6587\u6863\u52a0\u8f7d\u5668\u4e3b\u8981\u57fa\u4e8e Unstructured \u5305\uff0c Unstructured \u662f\u4e00\u4e2apython\u5305\uff0c\u53ef\u4ee5\u628a\u5404\u79cd\u7c7b\u578b\u7684\u6587\u4ef6\u8f6c\u6362\u6210\u6587\u672c\u3002 \u6587\u6863\u52a0\u8f7d\u5668\u4f7f\u7528\u8d77\u6765\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5f15\u5165\u76f8\u5e94\u7684loader\u5de5\u5177\uff1a from langchain.document_loaders import UnstructuredFileLoader loader = UnstructuredFileLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) print ( '*' * 80 ) from langchain.document_loaders import TextLoader loader = TextLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\u8896\u957f\uff1a\u957f\u8896\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ******************************************************************************** [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\\n\u8896\u957f\uff1a\u957f\u8896\\n\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ''' LangChain\u652f\u6301\u7684\u6587\u6863\u52a0\u8f7d\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 CSV CSV\u95ee\u4ef7 JSON Files \u52a0\u8f7dJSON\u6587\u4ef6 Jupyter Notebook \u52a0\u8f7dnotebook\u6587\u4ef6 Markdown \u52a0\u8f7dmarkdown\u6587\u4ef6 Microsoft PowerPoint \u52a0\u8f7dppt\u6587\u4ef6 PDF \u52a0\u8f7dpdf\u6587\u4ef6 Images \u52a0\u8f7d\u56fe\u7247 File Directory \u52a0\u8f7d\u76ee\u5f55\u4e0b\u6240\u6709\u6587\u4ef6 HTML \u7f51\u9875","title":"2.6.1 \u6587\u6863\u52a0\u8f7d\u5668"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#262","text":"\u7531\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u7684\u5b57\u7b26\u957f\u5ea6\u6709\u9650\u5236\uff0c\u6211\u4eec\u5728\u78b0\u5230\u5f88\u957f\u7684\u6587\u672c\u65f6\uff0c\u9700\u8981\u628a\u6587\u672c\u5206\u5272\u6210\u591a\u4e2a\u5c0f\u7684\u6587\u672c\u7247\u6bb5\u3002 \u6587\u672c\u5206\u5272\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u6309\u7167\u5b57\u7b26\u957f\u5ea6\u8fdb\u884c\u5206\u5272\uff0c\u4f46\u662f\u8fd9\u4f1a\u5e26\u6765\u5f88\u591a\u95ee\u9898\uff0c\u6bd4\u5982\u8bf4\u5982\u679c\u6587\u672c\u662f\u4e00\u6bb5\u4ee3\u7801\uff0c\u4e00\u4e2a\u51fd\u6570\u88ab\u5206\u5272\u5230\u4e24\u6bb5\u4e4b\u540e\u5c31\u6210\u4e86\u6ca1\u6709\u610f\u4e49\u7684\u5b57\u7b26\uff0c\u6240\u4ee5\u6574\u4f53\u7684\u539f\u5219\u662f\u628a\u8bed\u4e49\u76f8\u5173\u7684\u6587\u672c\u7247\u6bb5\u653e\u5728\u4e00\u8d77\u3002 LangChain\u4e2d\u6700\u57fa\u672c\u7684\u6587\u672c\u5206\u5272\u5668\u662f CharacterTextSplitter \uff0c\u5b83\u6309\u7167\u6307\u5b9a\u7684\u5206\u9694\u7b26\uff08\u9ed8\u8ba4\u201c\\n\\n\u201d\uff09\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u8003\u8651\u6587\u672c\u7247\u6bb5\u7684\u6700\u5927\u957f\u5ea6\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter ( separator = \" \" , # \u7a7a\u683c\u5206\u5272\uff0c\u4f46\u662f\u7a7a\u683c\u4e5f\u5c5e\u4e8e\u5b57\u7b26 chunk_size = 5 , chunk_overlap = 0 , ) # \u4e00\u53e5\u5206\u5272 a = text_splitter . split_text ( \"a b c d e f\" ) print ( a ) # ['a b c', 'd e f'] # \u591a\u53e5\u8bdd\u5206\u5272\uff08\u6587\u6863\u5206\u5272\uff09 texts = text_splitter . create_documents ([ \"a b c d e f\" , \"e f g h\" ], ) print ( texts ) # [Document(page_content='a b c'), Document(page_content='d e f'), Document(page_content='e f g'), Document(page_content='h')] \u9664\u4e86CharacterTextSplitter\u5206\u5272\u5668\uff0cLangChain\u8fd8\u652f\u6301\u5176\u4ed6\u6587\u6863\u5206\u5272\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 LatexTextSplitter \u6cbf\u7740Latex\u6807\u9898\u3001\u6807\u9898\u3001\u679a\u4e3e\u7b49\u5206\u5272\u6587\u672c\u3002 MarkdownTextSplitter \u6cbf\u7740Markdown\u7684\u6807\u9898\u3001\u4ee3\u7801\u5757\u6216\u6c34\u5e73\u89c4\u5219\u6765\u5206\u5272\u6587\u672c\u3002 TokenTextSplitter \u6839\u636eopenAI\u7684token\u6570\u8fdb\u884c\u5206\u5272 PythonCodeTextSplitter \u6cbf\u7740Python\u7c7b\u548c\u65b9\u6cd5\u7684\u5b9a\u4e49\u5206\u5272\u6587\u672c\u3002","title":"2.6.2 \u6587\u6863\u5206\u5272\u5668"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#263-vectorstores","text":"VectorStores\u662f\u4e00\u79cd\u7279\u6b8a\u7c7b\u578b\u7684\u6570\u636e\u5e93\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u5b58\u50a8\u7531\u5d4c\u5165\u521b\u5efa\u7684\u5411\u91cf\uff0c\u63d0\u4f9b\u76f8\u4f3c\u67e5\u8be2\u7b49\u529f\u80fd\u3002\u6211\u4eec\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a Chroma \u7ec4\u4ef6 pip install chromadb \u4f5c\u4e3a\u4f8b\u5b50\uff1a from langchain.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import Chroma import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # pku.txt\u5185\u5bb9\uff1a<https://www.pku.edu.cn/about.html> with open ( './pku.txt' ) as f : state_of_the_union = f . read () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_text ( state_of_the_union ) print ( texts ) embeddings = QianfanEmbeddingsEndpoint () docsearch = Chroma . from_texts ( texts , embeddings ) query = \"1937\u5e74\u5317\u4eac\u5927\u5b66\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\" docs = docsearch . similarity_search ( query ) print ( docs ) ''' [Document(page_content='1937\u5e74\u5362\u6c9f\u6865\u4e8b\u53d8\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e0e\u6e05\u534e\u5927\u5b66\u3001\u5357\u5f00\u5927\u5b66\u5357\u8fc1\u957f\u6c99\uff0c\u5171\u540c\u7ec4\u6210\u56fd\u7acb\u957f\u6c99\u4e34\u65f6\u5927\u5b66\u30021938\u5e74\uff0c\u4e34\u65f6\u5927\u5b66\u53c8\u897f\u8fc1\u6606\u660e\uff0c\u66f4\u540d\u4e3a\u56fd\u7acb\u897f\u5357\u8054\u5408\u5927\u5b66\u3002\u6297\u65e5\u6218\u4e89\u80dc\u5229\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e8e1946\u5e7410\u6708\u5728\u5317\u5e73\u590d\u5458\u3002'), Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002'), Document(page_content='\u5728\u60a0\u4e45\u7684\u6587\u660e\u5386\u7a0b\u4e2d\uff0c\u53e4\u4ee3\u4e2d\u56fd\u66fe\u521b\u7acb\u592a\u5b66\u3001\u56fd\u5b50\u5b66\u3001\u56fd\u5b50\u76d1\u7b49\u56fd\u5bb6\u6700\u9ad8\u5b66\u5e9c\uff0c\u5728\u4e2d\u56fd\u548c\u4e16\u754c\u6559\u80b2\u53f2\u4e0a\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u5317\u4eac\u5927\u5b66\u201c\u4e0a\u627f\u592a\u5b66\u6b63\u7edf\uff0c\u4e0b\u7acb\u5927\u5b66\u7956\u5ead\u201d\uff0c\u65e2\u662f\u4e2d\u534e\u6587\u8109\u548c\u6559\u80b2\u4f20\u7edf\u7684\u4f20\u627f\u8005\uff0c\u4e5f\u6807\u5fd7\u7740\u4e2d\u56fd\u73b0\u4ee3\u9ad8\u7b49\u6559\u80b2\u7684\u5f00\u7aef\u3002\u5176\u521b\u529e\u4e4b\u521d\u4e5f\u662f\u56fd\u5bb6\u6700\u9ad8\u6559\u80b2\u884c\u653f\u673a\u5173\uff0c\u5bf9\u5efa\u7acb\u4e2d\u56fd\u73b0\u4ee3\u5b66\u5236\u4f5c\u51fa\u91cd\u8981\u5386\u53f2\u8d21\u732e\u3002'), Document(page_content='1917\u5e74\uff0c\u8457\u540d\u6559\u80b2\u5bb6\u8521\u5143\u57f9\u5c31\u4efb\u5317\u4eac\u5927\u5b66\u6821\u957f\uff0c\u4ed6\u201c\u5faa\u601d\u60f3\u81ea\u7531\u539f\u5219\uff0c\u53d6\u517c\u5bb9\u5e76\u5305\u4e3b\u4e49\u201d\uff0c\u5bf9\u5317\u4eac\u5927\u5b66\u8fdb\u884c\u4e86\u5353\u6709\u6210\u6548\u7684\u6539\u9769\uff0c\u4fc3\u8fdb\u4e86\u601d\u60f3\u89e3\u653e\u548c\u5b66\u672f\u7e41\u8363\u3002\u9648\u72ec\u79c0\u3001\u674e\u5927\u948a\u3001\u6bdb\u6cfd\u4e1c\u4ee5\u53ca\u9c81\u8fc5\u3001\u80e1\u9002\u3001\u674e\u56db\u5149\u7b49\u4e00\u6279\u6770\u51fa\u4eba\u58eb\u90fd\u66fe\u5728\u5317\u4eac\u5927\u5b66\u4efb\u6559\u6216\u4efb\u804c\u3002')] ''' LangChain\u652f\u6301\u7684VectorStore\u5982\u4e0b\uff1a VectorStore \u63cf\u8ff0 Chroma \u4e00\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u6570\u636e\u5e93 ElasticSearch ElasticSearch Milvus \u7528\u4e8e\u5b58\u50a8\u3001\u7d22\u5f15\u548c\u7ba1\u7406\u7531\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u4ea7\u751f\u7684\u5927\u91cf\u5d4c\u5165\u5411\u91cf\u7684\u6570\u636e\u5e93 Redis \u57fa\u4e8eredis\u7684\u68c0\u7d22\u5668 FAISS Facebook AI\u76f8\u4f3c\u6027\u641c\u7d22\u670d\u52a1 Pinecone \u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u529f\u80fd\u7684\u5411\u91cf\u6570\u636e\u5e93","title":"2.6.3 VectorStores"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#264","text":"\u68c0\u7d22\u5668\u662f\u4e00\u79cd\u4fbf\u4e8e\u6a21\u578b\u67e5\u8be2\u7684\u5b58\u50a8\u6570\u636e\u7684\u65b9\u5f0f\uff0cLangChain\u7ea6\u5b9a\u68c0\u7d22\u5668\u7ec4\u4ef6\u81f3\u5c11\u6709\u4e00\u4e2a\u65b9\u6cd5 get_relevant_texts \uff0c\u8fd9\u4e2a\u65b9\u6cd5\u63a5\u6536\u67e5\u8be2\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u4e00\u7ec4\u6587\u6863\u3002 # pip install faiss-cpu from langchain.document_loaders import TextLoader from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import FAISS from langchain.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" loader = TextLoader ( './pku.txt' ) documents = loader . load () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_documents ( documents ) embeddings = QianfanEmbeddingsEndpoint () db = FAISS . from_documents ( texts , embeddings ) retriever = db . as_retriever ( search_kwargs = { 'k' : 1 }) docs = retriever . get_relevant_documents ( \"\u5317\u4eac\u5927\u5b66\u4ec0\u4e48\u65f6\u5019\u6210\u7acb\u7684\" ) print ( docs ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002', metadata={'source': './pku.txt'})] ''' LangChain\u652f\u6301\u7684\u68c0\u7d22\u5668\u7ec4\u4ef6\u5982\u4e0b\uff1a \u68c0\u7d22\u5668 \u4ecb\u7ecd Azure Cognitive Search Retriever Amazon ACS\u68c0\u7d22\u670d\u52a1 ChatGPT Plugin Retriever ChatGPT\u68c0\u7d22\u63d2\u4ef6 Databerry Databerry\u68c0\u7d22 ElasticSearch BM25 ElasticSearch\u68c0\u7d22\u5668 Metal Metal\u68c0\u7d22\u5668 Pinecone Hybrid Search Pinecone\u68c0\u7d22\u670d\u52a1 SVM Retriever SVM\u68c0\u7d22\u5668 TF-IDF Retriever TF-IDF\u68c0\u7d22\u5668 VectorStore Retriever VectorStore\u68c0\u7d22\u5668 Vespa retriever \u4e00\u4e2a\u652f\u6301\u7ed3\u6784\u5316\u6587\u672c\u548c\u5411\u91cf\u641c\u7d22\u7684\u5e73\u53f0 Weaviate Hybrid Search \u4e00\u4e2a\u5f00\u6e90\u7684\u5411\u91cf\u641c\u7d22\u5f15\u64ce Wikipedia \u652f\u6301wikipedia\u5185\u5bb9\u68c0\u7d22","title":"2.6.4 \u68c0\u7d22\u5668"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#3-langchain","text":"\u4e2a\u4eba\u52a9\u624b \u57fa\u4e8e\u6587\u6863\u7684\u95ee\u7b54\u7cfb\u7edf \u804a\u5929\u673a\u5668\u4eba Tabular\u6570\u636e\u67e5\u8be2 API\u4ea4\u4e92 \u4fe1\u606f\u63d0\u53d6 \u6587\u6863\u603b\u7ed3","title":"3 LangChain\u4f7f\u7528\u573a\u666f"},{"location":"%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#4","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u5bf9LangChain\u6846\u67b6\u57fa\u7840\u77e5\u8bc6\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u8ba9\u6211\u4eec\u5bf9LangChain\u6709\u4e86\u4e00\u4e2a\u521d\u6b65\u8ba4\u8bc6\uff0c\u4e86\u89e3\u4e86LangChain\u7684\u4f7f\u7528\u573a\u666f\u3002","title":"4 \u672c\u7ae0\u5c0f\u7ed3"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html","text":"ChatGPT\u6a21\u578b\u539f\u7406\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3ChatGPT\u7684\u672c\u8d28 \u4e86\u89e3GPT\u7cfb\u5217\u6a21\u578b\u7684\u539f\u7406\u548c\u533a\u522b 1 \u4ec0\u4e48\u662fChatGPT\uff1f \u00b6 ChatGPT \u662f\u7531\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5b9e\u9a8c\u5ba4 OpenAI \u57282022\u5e7411\u670830\u65e5\u53d1\u5e03\u7684\u5168\u65b0\u804a\u5929\u673a\u5668\u4eba\u6a21\u578b, \u4e00\u6b3e\u4eba\u5de5\u667a\u80fd\u6280\u672f\u9a71\u52a8\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177. \u5b83\u80fd\u591f\u901a\u8fc7\u5b66\u4e60\u548c\u7406\u89e3\u4eba\u7c7b\u7684\u8bed\u8a00\u6765\u8fdb\u884c\u5bf9\u8bdd, \u8fd8\u80fd\u6839\u636e\u804a\u5929\u7684\u4e0a\u4e0b\u6587\u8fdb\u884c\u4e92\u52a8, \u771f\u6b63\u50cf\u4eba\u7c7b\u4e00\u6837\u6765\u804a\u5929\u4ea4\u6d41, \u751a\u81f3\u80fd\u5b8c\u6210\u64b0\u5199\u90ae\u4ef6\u3001\u89c6\u9891\u811a\u672c\u3001\u6587\u6848\u3001\u7ffb\u8bd1\u3001\u4ee3\u7801\u7b49\u4efb\u52a1. \u6570\u636e\u663e\u793a, ChatGPT\u5728\u63a8\u51fa2\u4e2a\u591a\u6708\u7684\u65f6\u95f4\u5185\uff0c\u6708\u6d3b\u8dc3\u7528\u6237\u5df2\u7ecf\u8d85\u8fc71\u4ebf, \u8fd9, \u6210\u4e3a\u53f2\u4e0a\u589e\u957f\u6700\u5feb\u7684\u6d88\u8d39\u8005\u5e94\u7528. \u5168\u7403\u6bcf\u5929\u7ea6\u67091300\u4e07\u72ec\u7acb\u8bbf\u95ee\u8005\u4f7f\u7528ChatGPT, \u800c\u7206\u70b8\u6027\u7684\u589e\u91cf\u4e5f\u7ed9\u8be5\u516c\u53f8\u53d1\u5c55\u5e26\u6765\u4e86\u60f3\u8c61\u7a7a \u95f4. \u81ea\u4ece ChatGPT \u51fa\u73b0\u540e. \u7a81\u7136\u4e4b\u95f4, \u6bcf\u4e2a\u4eba\u90fd\u5728\u8c08\u8bba\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u98a0\u8986\u4ed6\u4eec\u7684\u5de5\u4f5c\u3001\u516c\u53f8\u3001\u5b66\u6821\u548c\u751f\u6d3b. \u90a3\u4e48ChatGPT\u80cc\u540e\u7684\u5b9e\u73b0\u539f\u7406\u662f\u4ec0\u4e48\u5462\uff1f\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u7ed9\u5927\u5bb6\u8fdb\u884c\u8be6\u7ec6\u7684\u89e3\u6790. \u5728\u6211\u4eec\u4e86\u89e3ChatGPT\u6a21\u578b\u539f\u7406\u4e4b\u524d, \u9700\u8981\u56de\u987e\u4e0bChatGPT\u7684\u6210\u957f\u53f2, \u5373\u6211\u4eec\u9700\u8981\u5bf9GPT-1\u3001GPT-2\u3001GPT-3\u7b49\u4e00\u7cfb\u5217\u6a21\u578b\u8fdb\u884c\u4e86\u89e3\u548c\u5b66\u4e60, \u4ee5\u4fbf\u6211\u4eec\u66f4\u597d\u7684\u7406\u89e3ChatGPT\u7684\u7b97\u6cd5\u539f\u7406. 2 GPT-1\u4ecb\u7ecd \u00b6 2018\u5e746\u6708, OpenAI\u516c\u53f8\u53d1\u8868\u4e86\u8bba\u6587\u201cImproving Language Understanding by Generative Pre-training\u201d\u300a\u7528\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u63d0\u9ad8\u6a21\u578b\u7684\u8bed\u8a00\u7406\u89e3\u529b\u300b, \u63a8\u51fa\u4e86\u5177\u67091.17\u4ebf\u4e2a\u53c2\u6570\u7684GPT-1\uff08Generative Pre-training , \u751f\u6210\u5f0f\u9884\u8bad\u7ec3\uff09\u6a21\u578b. \u4e0eBERT\u6700\u5927\u7684\u533a\u522b\u5728\u4e8eGPT-1\u91c7\u7528\u4e86\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u8fdb\u884c\u9884\u8bad\u7ec3, \u5373\u4f7f\u7528\u5355\u8bcd\u7684\u4e0a\u6587\u6765\u9884\u6d4b\u5355\u8bcd, \u800cBERT\u662f\u91c7\u7528\u4e86\u53cc\u5411\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\u5171\u540c\u6765\u9884\u6d4b\u5355\u8bcd. \u6b63\u662f\u56e0\u4e3a\u8bad\u7ec3\u65b9\u6cd5\u4e0a\u7684\u533a\u522b, \u4f7f\u5f97GPT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4efb\u52a1(NLG), \u800cBERT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1(NLU). 2.1 GPT-1\u6a21\u578b\u67b6\u6784 \u00b6 \u770b\u4e09\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6bd4\u67b6\u6784\u56fe, \u4e2d\u95f4\u7684\u5c31\u662fGPT-1: \u4ece\u4e0a\u56fe\u53ef\u4ee5\u5f88\u6e05\u695a\u7684\u770b\u5230GPT\u91c7\u7528\u7684\u662f\u5355\u5411Transformer\u6a21\u578b, \u4f8b\u5982\u7ed9\u5b9a\u4e00\u4e2a\u53e5\u5b50[u1, u2, ..., un], GPT\u5728\u9884\u6d4b\u5355\u8bcdui\u7684\u65f6\u5019\u53ea\u4f1a\u5229\u7528[u1, u2, ..., u(i-1)]\u7684\u4fe1\u606f, \u800cBERT\u4f1a\u540c\u65f6\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f[u1, u2, ..., u(i-1), u(i+1), ..., un]. \u4f5c\u4e3a\u4e24\u5927\u6a21\u578b\u7684\u76f4\u63a5\u5bf9\u6bd4, BERT\u91c7\u7528\u4e86Transformer\u7684Encoder\u6a21\u5757, \u800cGPT\u91c7\u7528\u4e86Transformer\u7684Decoder\u6a21\u5757. \u5e76\u4e14GPT\u7684Decoder Block\u548c\u7ecf\u5178Transformer Decoder Block\u8fd8\u6709\u6240\u4e0d\u540c, \u5982\u4e0b\u56fe\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, \u7ecf\u5178\u7684Transformer Decoder Block\u5305\u542b3\u4e2a\u5b50\u5c42, \u5206\u522b\u662fMasked Multi-Head Attention\u5c42, encoder-decoder attention\u5c42, \u4ee5\u53caFeed Forward\u5c42. \u4f46\u662f\u5728GPT\u4e2d\u53d6\u6d88\u4e86\u7b2c\u4e8c\u4e2aencoder-decoder attention\u5b50\u5c42, \u53ea\u4fdd\u7559Masked Multi-Head Attention\u5c42, \u548cFeed Forward\u5c42. \u6ce8\u610f: \u5bf9\u6bd4\u4e8e\u7ecf\u5178\u7684Transformer\u67b6\u6784, \u89e3\u7801\u5668\u6a21\u5757\u91c7\u7528\u4e866\u4e2aDecoder Block; GPT\u7684\u67b6\u6784\u4e2d\u91c7\u7528\u4e8612\u4e2aDecoder Block. 2.2 GPT-1\u8bad\u7ec3\u8fc7\u7a0b \u00b6 GPT-1\u7684\u8bad\u7ec3\u5305\u62ec\u4e24\u9636\u6bb5\u8fc7\u7a0b: \u9884\u8bad\u7ec3 + \u5fae\u8c03 - \u7b2c\u4e00\u9636\u6bb5: \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b. - \u7b2c\u4e8c\u9636\u6bb5: \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning. 2.2.1 \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b \u00b6 \u7ed9\u5b9a\u53e5\u5b50U = [u1, u2, ..., un], GPT\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u4f3c\u7136\u51fd\u6570: L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) \u4e0a\u8ff0\u516c\u5f0f\u5177\u4f53\u6765\u8bf4\u662f\u8981\u9884\u6d4b\u6bcf\u4e2a\u8bcdui\u7684\u6982\u7387\uff0c\u8fd9\u4e2a\u6982\u7387\u662f\u57fa\u4e8e\u5b83\u524d\u9762 ui-k \u5230 ui\u22121 \u4e2a\u8bcd\uff0c\u4ee5\u53ca\u6a21\u578b \u0398\u3002\u8fd9\u91cc\u7684 k \u8868\u793a\u4e0a\u6587\u7684\u7a97\u53e3\u5927\u5c0f\uff0c\u7406\u8bba\u4e0a\u6765\u8bb2 k \u53d6\u7684\u8d8a\u5927\uff0c\u6a21\u578b\u6240\u80fd\u83b7\u53d6\u7684\u4e0a\u6587\u4fe1\u606f\u8d8a\u5145\u8db3\uff0c\u6a21\u578b\u7684\u80fd\u529b\u8d8a\u5f3a\u3002 GPT\u662f\u4e00\u4e2a\u5355\u5411\u8bed\u8a00\u6a21\u578b,\u6a21\u578b\u5bf9\u8f93\u5165U \u8fdb\u884c\u7279\u5f81\u5d4c\u5165\u5f97\u5230 transformer \u7b2c\u4e00\u5c42\u7684\u8f93h0\uff0c\u518d\u7ecf\u8fc7\u591a\u5c42 transformer \u7279\u5f81\u7f16\u7801\uff0c\u4f7f\u7528\u6700\u540e\u4e00\u5c42\u7684\u8f93\u51fa\u5373\u53ef\u5f97\u5230\u5f53\u524d\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff0c\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\uff1a h_0 = UW_e + W_p h_0 = UW_e + W_p \u5176\u4e2dWp\u662f\u5355\u8bcd\u7684\u4f4d\u7f6e\u7f16\u7801, We\u662f\u5355\u8bcd\u672c\u8eab\u7684word embedding. Wp\u7684\u5f62\u72b6\u662f[max_seq_len, embedding_dim], We\u7684\u5f62\u72b6\u662f[vocab_size, embedding_dim]. \u5f97\u5230\u8f93\u5165\u5f20\u91cfh0\u540e, \u8981\u5c06h0\u4f20\u5165GPT\u7684Decoder Block\u4e2d, \u4f9d\u6b21\u5f97\u5230ht: h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] \u6700\u540e\u901a\u8fc7\u5f97\u5230\u7684ht\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5355\u8bcd: P(u)=softmax(h_tW_e^T) P(u)=softmax(h_tW_e^T) 2.2.2 \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning \u00b6 GPT\u7ecf\u8fc7\u9884\u8bad\u7ec3\u540e, \u4f1a\u9488\u5bf9\u5177\u4f53\u7684\u4e0b\u6e38\u4efb\u52a1\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03. \u5fae\u8c03\u91c7\u7528\u7684\u662f\u6709\u76d1\u7763\u5b66\u4e60, \u8bad\u7ec3\u6837\u672c\u5305\u62ec\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u548clabel y. GPT\u5fae\u8c03\u7684\u76ee\u6807\u4efb\u52a1\u662f\u6839\u636e\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u9884\u6d4b\u6807\u7b7ey. P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) \u5176\u4e2d W_y W_y \u8868\u793a\u9884\u6d4b\u8f93\u51fa\u7684\u77e9\u9635\u53c2\u6570, \u5fae\u8c03\u4efb\u52a1\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u51fd\u6570: L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) \u7efc\u5408\u4e24\u4e2a\u9636\u6bb5\u7684\u76ee\u6807\u4efb\u52a1\u51fd\u6570, \u53ef\u77e5GPT\u7684\u6700\u7ec8\u4f18\u5316\u51fd\u6570\u4e3a: L_3 = L_2 + \\lambda L_1 L_3 = L_2 + \\lambda L_1 2.2.3 \u6574\u4f53\u8bad\u7ec3\u8fc7\u7a0b\u67b6\u6784\u56fe \u00b6 \u6839\u636e\u4e0b\u6e38\u4efb\u52a1\u9002\u914d\u7684\u8fc7\u7a0b\u5206\u4e24\u6b65: 1\u3001\u6839\u636e\u4efb\u52a1\u5b9a\u4e49\u4e0d\u540c\u8f93\u5165, 2\u3001\u5bf9\u4e0d\u540c\u4efb\u52a1\u589e\u52a0\u4e0d\u540c\u7684\u5206\u7c7b\u5c42. \u5177\u4f53\u5b9a\u4e49\u53ef\u4ee5\u53c2\u89c1\u4e0b\u56fe: \u5206\u7c7b\u4efb\u52a1\uff08Classification\uff09: \u5c06\u8d77\u59cb\u548c\u7ec8\u6b62token\u52a0\u5165\u5230\u539f\u59cb\u5e8f\u5217\u4e24\u7aef, \u8f93\u5165transformer\u4e2d\u5f97\u5230\u7279\u5f81\u5411\u91cf, \u6700\u540e\u7ecf\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff1b \u6587\u672c\u8574\u6db5\uff08Entailment\uff09: \u5c06\u524d\u63d0\uff08premise\uff09\u548c\u5047\u8bbe\uff08hypothesis\uff09\u901a\u8fc7\u5206\u9694\u7b26\uff08Delimiter\uff09\u9694\u5f00, \u4e24\u7aef\u52a0\u4e0a\u8d77\u59cb\u548c\u7ec8\u6b62token. \u518d\u4f9d\u6b21\u901a\u8fc7transformer\u548c\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u6587\u672c\u76f8\u4f3c\u5ea6\uff08Similarity\uff09: \u8f93\u5165\u7684\u4e24\u4e2a\u53e5\u5b50, \u6b63\u5411\u548c\u53cd\u5411\u5404\u62fc\u63a5\u4e00\u6b21, \u7136\u540e\u5206\u522b\u8f93\u5165\u7ed9transformer, \u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u62fc\u63a5\u540e\u518d\u9001\u7ed9\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u95ee\u7b54\u548c\u5e38\u8bc6\u63a8\u7406\uff08Multiple-Choice\uff09: \u5c06 N\u4e2a\u9009\u9879\u7684\u95ee\u9898\u62bd\u8c61\u5316\u4e3aN\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898, \u5373\u6bcf\u4e2a\u9009\u9879\u5206\u522b\u548c\u5185\u5bb9\u8fdb\u884c\u62fc\u63a5, \u7136\u540e\u5404\u9001\u5165transformer\u548c\u5168\u8fde\u63a5\u4e2d, \u6700\u540e\u9009\u62e9\u7f6e\u4fe1\u5ea6\u6700\u9ad8\u7684\u4f5c\u4e3a\u9884\u6d4b\u7ed3\u679c \u603b\u7684\u6765\u8bf4\uff0c\u90fd\u662f\u901a\u8fc7\u5728\u5e8f\u5217\u524d\u540e\u6dfb\u52a0 Start \u548c Extract \u7279\u6b8a\u6807\u8bc6\u7b26\u6765\u8868\u793a\u5f00\u59cb\u548c\u7ed3\u675f\uff0c\u5e8f\u5217\u4e4b\u95f4\u6dfb\u52a0\u5fc5\u8981\u7684 Delim \u6807\u8bc6\u7b26\u6765\u8868\u793a\u5206\u9694\uff0c\u5f53\u7136\u5b9e\u9645\u4f7f\u7528\u65f6\u4e0d\u4f1a\u76f4\u63a5\u7528 \u201cStart/Extract/Delim\u201d \u8fd9\u51e0\u4e2a\u8bcd\uff0c\u800c\u662f\u4f7f\u7528\u67d0\u4e9b\u7279\u6b8a\u7b26\u53f7\u3002\u57fa\u4e8e\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u6784\u9020\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684 GPT \u6a21\u578b\u8fdb\u884c\u7279\u5f81\u7f16\u7801\uff0c\u7136\u540e\u4f7f\u7528\u5e8f\u5217\u6700\u540e\u4e00\u4e2a token \u7684\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u9884\u6d4b\u3002 \u53ef\u4ee5\u770b\u5230\uff0c\u4e0d\u8bba\u4e0b\u6e38\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u600e\u4e48\u53d8\uff0c\u6700\u540e\u7684\u9884\u6d4b\u5c42\u600e\u4e48\u53d8\uff0c\u4e2d\u95f4\u7684\u7279\u5f81\u62bd\u53d6\u6a21\u5757\u90fd\u662f\u4e0d\u53d8\u7684\uff0c\u5177\u6709\u5f88\u597d\u7684\u8fc1\u79fb\u80fd\u529b\u3002 2.3 GPT-1\u6570\u636e\u96c6 \u00b6 GPT-1\u4f7f\u7528\u4e86BooksCorpus\u6570\u636e\u96c6, \u6587\u672c\u5927\u5c0f\u7ea6 5 GB\uff0c\u5305\u542b 7400w+ \u7684\u53e5\u5b50\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u7531 7000 \u672c\u72ec\u7acb\u7684\u3001\u4e0d\u540c\u98ce\u683c\u7c7b\u578b\u7684\u4e66\u7c4d\u7ec4\u6210, \u9009\u62e9\u8be5\u90e8\u5206\u6570\u636e\u96c6\u7684\u539f\u56e0: - \u4e66\u7c4d\u6587\u672c\u5305\u542b\u5927\u91cf\u9ad8\u8d28\u91cf\u957f\u53e5\uff0c\u4fdd\u8bc1\u6a21\u578b\u5b66\u4e60\u957f\u8ddd\u79bb\u4fe1\u606f\u4f9d\u8d56\u3002 - \u8fd9\u4e9b\u4e66\u7c4d\u56e0\u4e3a\u6ca1\u6709\u53d1\u5e03, \u6240\u4ee5\u5f88\u96be\u5728\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u89c1\u5230, \u66f4\u80fd\u9a8c\u8bc1\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b. 2.4 GPT-1\u6a21\u578b\u7684\u7279\u70b9 \u00b6 \u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 12 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 1.17 \u4ebf \u4f18\u70b9\uff1a \u5728\u6709\u76d1\u7763\u5b66\u4e60\u768412\u4e2a\u4efb\u52a1\u4e2d, GPT-1\u57289\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8d85\u8fc7\u4e86state-of-the-art\u7684\u6a21\u578b \u5229\u7528Transformer\u505a\u7279\u5f81\u62bd\u53d6, \u80fd\u591f\u6355\u6349\u5230\u66f4\u957f\u7684\u8bb0\u5fc6\u4fe1\u606f, \u4e14\u8f83\u4f20\u7edf\u7684 RNN \u66f4\u6613\u4e8e\u5e76\u884c\u5316 \u7f3a\u70b9\uff1a GPT \u6700\u5927\u7684\u95ee\u9898\u5c31\u662f\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u662f\u5355\u5411\u7684. \u9488\u5bf9\u4e0d\u540c\u7684\u4efb\u52a1, \u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u5fae\u8c03, \u76f8\u5bf9\u6bd4\u8f83\u9ebb\u70e6 2.5 GPT-1\u6a21\u578b\u603b\u7ed3 \u00b6 GPT-1\u8bc1\u660e\u4e86transformer\u5bf9\u5b66\u4e60\u8bcd\u5411\u91cf\u7684\u5f3a\u5927\u80fd\u529b, \u5728GPT-1\u5f97\u5230\u7684\u8bcd\u5411\u91cf\u57fa\u7840\u4e0a\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\u7684\u5b66\u4e60, \u80fd\u591f\u8ba9\u4e0b\u6e38\u4efb\u52a1\u53d6\u5f97\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u5bf9\u4e8e\u4e0b\u6e38\u4efb\u52a1\u7684\u8bad\u7ec3, GPT-1\u5f80\u5f80\u53ea\u9700\u8981\u7b80\u5355\u7684\u5fae\u8c03\u4fbf\u80fd\u53d6\u5f97\u975e\u5e38\u597d\u7684\u6548\u679c. GPT-1\u5728\u672a\u7ecf\u5fae\u8c03\u7684\u4efb\u52a1\u4e0a\u867d\u7136\u4e5f\u6709\u4e00\u5b9a\u6548\u679c, \u4f46\u662f\u5176\u6cdb\u5316\u80fd\u529b\u8fdc\u8fdc\u4f4e\u4e8e\u7ecf\u8fc7\u5fae\u8c03\u7684\u6709\u76d1\u7763\u4efb\u52a1, \u8bf4\u660e\u4e86GPT-1\u53ea\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u9886\u57df\u4e13\u5bb6, \u800c\u975e\u901a\u7528\u7684\u8bed\u8a00\u5b66\u5bb6. 3 GPT-2\u4ecb\u7ecd \u00b6 2019\u5e742\u6708, OpenAI\u63a8\u51fa\u4e86GPT-2, \u540c\u65f6, \u4ed6\u4eec\u53d1\u8868\u4e86\u4ecb\u7ecd\u8fd9\u4e2a\u6a21\u578b\u7684\u8bba\u6587\u201cLanguage Models are Unsupervised Multitask Learners\u201d \uff08\u8bed\u8a00\u6a21\u578b\u662f\u65e0\u76d1\u7763\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u8005\uff09. \u76f8\u6bd4\u4e8eGPT-1, GPT-2\u7a81\u51fa\u7684\u6838\u5fc3\u601d\u60f3\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60, \u5176\u76ee\u6807\u65e8\u5728\u4ec5\u91c7\u7528\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u7684\u8bed\u8a00\u6a21\u578b, \u76f4\u63a5\u5e94\u7528\u5230\u4e0b\u6e38\u4efb\u52a1\u4e2d. GPT-2\u5e76\u6ca1\u6709\u5bf9GPT-1\u7684\u7f51\u7edc\u7ed3\u6784\u8fdb\u884c\u8fc7\u591a\u7684\u521b\u65b0\u4e0e\u8bbe\u8ba1, \u800c\u662f\u4f7f\u7528\u4e86\u66f4\u591a\u7684\u7f51\u7edc\u53c2\u6570\u4e0e\u66f4\u5927\u7684\u6570\u636e\u96c6: \u6700\u5927\u6a21\u578b\u5171\u8ba148\u5c42, \u53c2\u6570\u91cf\u8fbe15\u4ebf. 3.1 GPT-2\u6a21\u578b\u67b6\u6784 \u00b6 \u5728\u6a21\u578b\u65b9\u9762\u76f8\u5bf9\u4e8e GPT-1 \u6765\u8bf4GPT-2\u505a\u4e86\u5fae\u5c0f\u7684\u6539\u52a8: LN\u5c42\u88ab\u653e\u7f6e\u5728Self-Attention\u5c42\u548cFeed Forward\u5c42\u524d, \u800c\u4e0d\u662f\u50cf\u539f\u6765\u90a3\u6837\u540e\u7f6e\uff08\u76ee\u7684\uff1a\u968f\u7740\u6a21\u578b\u5c42\u6570\u4e0d\u65ad\u589e\u52a0\uff0c\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8\u7684\u98ce\u9669\u8d8a\u6765\u8d8a\u5927\uff0c\u8fd9\u4e9b\u8c03\u6574\u80fd\u591f**\u51cf\u5c11\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5404\u5c42\u4e4b\u95f4\u7684\u65b9\u5dee\u53d8\u5316\uff0c\u4f7f\u68af\u5ea6\u66f4\u52a0\u7a33\u5b9a**\uff09 \u5728\u6700\u540e\u4e00\u5c42Tansfomer Block\u540e\u589e\u52a0\u4e86LN\u5c42 \u8f93\u5165\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u4ece 512 \u6269\u5145\u5230 1024; 3.2 GPT-2\u8bad\u7ec3\u6838\u5fc3\u601d\u60f3 \u00b6 \u76ee\u524d\u5927\u90e8\u5206 NLP \u6a21\u578b\u662f\u7ed3\u5408\u65e0\u76d1\u7763\u7684 Pre-training \u548c\u76d1\u7763\u5b66\u4e60\u7684 Fune-tuning, \u4f46\u8fd9\u79cd\u65b9\u6cd5\u7684\u7f3a\u70b9\u662f\u9488\u5bf9\u67d0\u7279\u5b9a\u4efb\u52a1\u9700\u8981\u4e0d\u540c\u7c7b\u578b\u6807\u6ce8\u597d\u7684\u8bad\u7ec3\u6570\u636e. GPT-2\u7684\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u72ed\u9698\u7684\u4e13\u5bb6\u800c\u4e0d\u662f\u901a\u624d, \u56e0\u6b64\u8be5\u4f5c\u8005\u5e0c\u671b\u80fd\u591f\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u51fa\u4e00\u4e2a\u53ef\u4ee5\u5e94\u5bf9\u591a\u79cd\u4efb\u52a1\u7684\u901a\u7528\u7cfb\u7edf. \u6807\u9898\u4e2d\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u4e0e\u6211\u4eec\u5e38\u89c4\u7406\u89e3\u7684\u6709\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u591a\u4efb\u52a1\u4e0d\u592a\u4e00\u6837\uff0c\u8fd9\u91cc\u4e3b\u8981\u662f\u6307\u6a21\u578b\u4ece\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5b66\u5230\u7684\u80fd\u529b\u80fd\u591f\u76f4\u63a5\u5728\u591a\u4e2a\u4efb\u52a1\u4e4b\u95f4\u8fdb\u884c\u8fc1\u79fb\uff0c\u800c\u4e0d\u9700\u8981\u989d\u5916\u63d0\u4f9b\u7279\u5b9a\u4efb\u52a1\u7684\u6570\u636e\uff0c\u56e0\u6b64\u5f15\u51fa\u4e86 GPT-2 \u7684\u4e3b\u8981\u89c2\u70b9\uff1a zero-shot \u3002\u901a\u8fc7 zero-shot\uff0c\u5728\u8fc1\u79fb\u5230\u5176\u4ed6\u4efb\u52a1\u4e0a\u7684\u65f6\u5019\u4e0d\u9700\u8981\u989d\u5916\u7684\u6807\u6ce8\u6570\u636e\uff0c\u4e5f\u4e0d\u9700\u8981\u989d\u5916\u7684\u6a21\u578b\u8bad\u7ec3\u3002 \u56e0\u6b64, GPT-2\u7684\u8bad\u7ec3\u53bb\u6389\u4e86Fune-tuning\u53ea\u5305\u62ec\u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8fc7\u7a0b, \u548cGPT-1\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u4e00\u6837, \u4e5f\u5c5e\u4e8e\u4e00\u4e2a\u5355\u5411\u8bed\u8a00\u6a21\u578b \u7406\u89e3GPT-2\u6a21\u578b\u7684\u5b66\u4e60\u76ee\u6807: \u4f7f\u7528\u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u505a\u6709\u76d1\u7763\u7684\u4efb\u52a1. \u8bed\u8a00\u6a21\u578b\u5176\u5b9e\u4e5f\u662f\u5728\u7ed9\u5e8f\u5217\u7684\u6761\u4ef6\u6982\u7387\u5efa\u6a21, \u5373p(sn|s1,s2,...,sn\u22121) \u5728 GPT-1 \u4e2d\uff0c\u4e0b\u6e38\u4efb\u52a1\u9700\u8981\u5bf9\u4e0d\u540c\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u6539\u9020\uff0c\u5728\u5e8f\u5217\u4e2d\u52a0\u5165\u4e86\u5f00\u59cb\u7b26\u3001\u5206\u9694\u7b26\u548c\u7ed3\u675f\u7b26\u4e4b\u7c7b\u7684\u7279\u6b8a\u6807\u8bc6\u7b26\uff0c\u4f46\u662f\u5728 zero-shot \u524d\u63d0\u4e0b\uff0c\u6211\u4eec\u65e0\u6cd5\u6839\u636e\u4e0d\u540c\u7684\u4e0b\u6e38\u4efb\u52a1\u53bb\u6dfb\u52a0\u8fd9\u4e9b\u6807\u8bc6\u7b26\uff0c\u56e0\u4e3a\u4e0d\u8fdb\u884c\u989d\u5916\u7684\u5fae\u8c03\u8bad\u7ec3\uff0c\u6a21\u578b\u5728\u9884\u6d4b\u7684\u65f6\u5019\u6839\u672c\u4e0d\u8ba4\u8bc6\u8fd9\u4e9b\u7279\u6b8a\u6807\u8bb0\u3002\u6240\u4ee5\u5728 zero-shot \u7684\u8bbe\u5b9a\u4e0b\uff0c\u4e0d\u540c\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u5e94\u8be5\u4e0e\u8bad\u7ec3\u65f6\u89c1\u5230\u7684\u6587\u672c\u957f\u5f97\u4e00\u6837\uff0c\u4e5f\u5c31\u662f\u4ee5\u81ea\u7136\u8bed\u8a00\u7684\u5f62\u5f0f\u53bb\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f8b\u5982\u4e0b\u9762\u4e24\u4e2a\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u662f\u8fd9\u6837\u6539\u9020\u7684\uff1a \u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\uff1atranslate to french, { english text }, { french text } \u9605\u8bfb\u7406\u89e3\u4efb\u52a1\uff1aanswer the question, { document }, { question }, { answer } \u4e3a\u4ec0\u4e48\u4e0a\u8ff0\u8f93\u5165\u5e8f\u5217\u7684\u6539\u9020\u662f\u6709\u6548\u7684\uff1f\u6216\u8005\u8bf4\u4e3a\u4ec0\u4e48 zero-shot \u662f\u6709\u6548\u7684\uff1f\u8fd9\u91cc\u5f15\u7528\u539f\u6587\u7684\u4e00\u53e5\u8bdd\uff1a Our approach motivates building as large and diverse a dataset as possible in order to collect natural language demonstrations of tasks in as varied of domains and contexts as possible. \u5927\u6982\u610f\u601d\u662f\uff0c\u4ece\u4e00\u4e2a\u5c3d\u53ef\u80fd\u5927\u4e14\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u4e2d\u4e00\u5b9a\u80fd\u6536\u96c6\u5230\u4e0d\u540c\u9886\u57df\u4e0d\u540c\u4efb\u52a1\u76f8\u5173\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u793a\u4f8b\uff0c\u4f8b\u5982\u4e0b\u56fe\u4e2d\u5c55\u793a\u4e86\u82f1\u6cd5\u4e92\u8bd1\u4efb\u52a1\u5728\u81ea\u7136\u8bed\u8a00\u4e2d\u51fa\u73b0\u7684\u793a\u4f8b\uff0c\u8868\u660e\u4e86\u4e0d\u540c\u4efb\u52a1\u7684\u4efb\u52a1\u63cf\u8ff0\u5728\u8bed\u6599\u4e2d\u771f\u5b9e\u5b58\u5728\uff1a \u6240\u4ee5 GPT-2 \u7684\u6838\u5fc3\u601d\u60f3\u5c31\u662f\uff0c \u5f53\u6a21\u578b\u7684\u5bb9\u91cf\u975e\u5e38\u5927\u4e14\u6570\u636e\u91cf\u8db3\u591f\u4e30\u5bcc\u65f6\uff0c\u4ec5\u4ec5\u9760\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u4fbf\u53ef\u4ee5\u5b8c\u6210\u5176\u4ed6\u6709\u76d1\u7763\u5b66\u4e60\u7684\u4efb\u52a1\uff0c\u4e0d\u9700\u8981\u5728\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03 \u3002 \u7efc\u4e0a, GPT-2\u7684\u6838\u5fc3\u601d\u60f3\u6982\u62ec\u4e3a: \u4efb\u4f55\u6709\u76d1\u7763\u4efb\u52a1\u90fd\u662f\u8bed\u8a00\u6a21\u578b\u7684\u4e00\u4e2a\u5b50\u96c6, \u5f53\u6a21\u578b\u7684\u5bb9\u91cf\u975e\u5e38\u5927\u4e14\u6570\u636e\u91cf\u8db3\u591f\u4e30\u5bcc\u65f6, \u4ec5\u4ec5\u9760\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u4fbf\u53ef\u4ee5\u5b8c\u6210\u5176\u4ed6\u6709\u76d1\u7763\u5b66\u4e60\u7684\u4efb\u52a1. 3.3 GPT-2\u7684\u6570\u636e\u96c6 \u00b6 \u4e3a\u4e86\u4fdd\u8bc1 zero-shot \u7684\u6548\u679c\uff0c\u5fc5\u987b\u8981\u8db3\u591f\u5927\u4e14\u8986\u76d6\u9762\u5e7f\u3002\u6240\u4ee5 GPT-2 \u4e13\u95e8\u722c\u53d6\u4e86\u5927\u91cf\u7684\u7f51\u7edc\u6587\u672c\u6570\u636e\uff0cGPT-2\u7684\u6587\u7ae0\u53d6\u81ea\u4e8eReddit\u4e0a\u9ad8\u8d5e\u7684\u6587\u7ae0, \u547d\u540d\u4e3aWebText. \u6570\u636e\u96c6\u5171\u6709\u7ea6800\u4e07\u7bc7\u6587\u7ae0, \u7d2f\u8ba1\u4f53\u79ef\u7ea640G. \u4e3a\u4e86\u907f\u514d\u548c\u6d4b\u8bd5\u96c6\u7684\u51b2\u7a81, WebText\u79fb\u9664\u4e86\u6d89\u53caWikipedia\u7684\u6587\u7ae0. 3.4 GPT-2\u6a21\u578b\u7684\u7279\u70b9 \u00b6 \u4e0eGPT-1\u7684\u533a\u522b\uff1a \u4e3b\u63a8 zero-shot\uff0c\u800c GPT-1 \u4e3a pre-train + fine-tuning\uff1b \u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u66f4\u5927\uff0cGPT-2 \u4e3a 800w \u6587\u6863 40G\uff0cGPT-1 \u4e3a 5GB\uff1b \u6a21\u578b\u5927\u5c0f\uff0cGPT-2 \u6700\u5927 15 \u4ebf\u53c2\u6570\uff0cGPT-1\u4e3a 1 \u4ebf\u53c2\u6570\uff1b \u6a21\u578b\u7ed3\u6784\u8c03\u6574\uff0c\u5c42\u5f52\u4e00\u5316\uff1b \u8bad\u7ec3\u53c2\u6570\uff0cbatch_size \u4ece 64 \u589e\u52a0\u5230 512\uff0c\u4e0a\u6587\u7a97\u53e3\u5927\u5c0f\u4ece 512 \u589e\u52a0\u5230 1024\uff0c\u7b49\u7b49\uff1b \u4f18\u70b9\uff1a \u6587\u672c\u751f\u6210\u6548\u679c\u597d, \u57288\u4e2a\u8bed\u8a00\u6a21\u578b\u4efb\u52a1\u4e2d, \u4ec5\u4ec5\u901a\u8fc7zero-shot\u5b66\u4e60, GPT-2\u5c31\u67097\u4e2a\u8d85\u8fc7\u4e86state-of-the-art\u7684\u65b9\u6cd5. \u6d77\u91cf\u6570\u636e\u548c\u5927\u91cf\u53c2\u6570\u8bad\u7ec3\u51fa\u6765\u7684\u8bcd\u5411\u91cf\u6a21\u578b\u6709\u8fc1\u79fb\u5230\u5176\u5b83\u7c7b\u522b\u4efb\u52a1\u4e2d\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3. \u7f3a\u70b9: \u65e0\u76d1\u7763\u5b66\u4e60\u80fd\u529b\u6709\u5f85\u63d0\u5347 \u6709\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u5982\u968f\u673a 3.5 GPT-2\u6a21\u578b\u603b\u7ed3 \u00b6 GPT-2\u7684\u6700\u5927\u8d21\u732e\u662f\u9a8c\u8bc1\u4e86\u901a\u8fc7\u6d77\u91cf\u6570\u636e\u548c\u5927\u91cf\u53c2\u6570\u8bad\u7ec3\u51fa\u6765\u7684\u8bcd\u5411\u91cf\u6a21\u578b\u6709\u8fc1\u79fb\u5230\u5176\u5b83\u7c7b\u522b\u4efb\u52a1\u4e2d\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3. \u4f46\u662f\u5f88\u591a\u5b9e\u9a8c\u4e5f\u8868\u660e, GPT-2\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u80fd\u529b\u8fd8\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4, \u751a\u81f3\u5728\u6709\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u6bd4\u968f\u673a\u7684\u597d. \u5c3d\u7ba1\u5728\u6709\u4e9bzero-shot\u7684\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u9519, \u4f46\u662f\u6211\u4eec\u4ecd\u4e0d\u6e05\u695aGPT-2\u7684\u8fd9\u79cd\u7b56\u7565\u7a76\u7adf\u80fd\u505a\u6210\u4ec0\u4e48\u6837\u5b50. GPT-2\u8868\u660e\u968f\u7740\u6a21\u578b\u5bb9\u91cf\u548c\u6570\u636e\u91cf\u7684\u589e\u5927, \u5176\u6f5c\u80fd\u8fd8\u6709\u8fdb\u4e00\u6b65\u5f00\u53d1\u7684\u7a7a\u95f4, \u57fa\u4e8e\u8fd9\u4e2a\u601d\u60f3, \u8bde\u751f\u4e86\u6211\u4eec\u4e0b\u9762\u8981\u4ecb\u7ecd\u7684GPT-3. 4 GPT-3\u4ecb\u7ecd \u00b6 2020\u5e745\u6708, OpenAI\u53d1\u5e03\u4e86GPT-3, \u540c\u65f6\u53d1\u8868\u4e86\u8bba\u6587\u201cLanguage Models are Few-Shot Learner\u201d\u300a\u5c0f\u6837\u672c\u5b66\u4e60\u8005\u7684\u8bed\u8a00\u6a21\u578b\u300b. \u901a\u8fc7\u8bba\u6587\u9898\u76ee\u53ef\u4ee5\u770b\u51fa\uff1aGPT-3 \u4e0d\u518d\u53bb\u8ffd\u6c42\u90a3\u79cd\u6781\u81f4\u7684\u4e0d\u9700\u8981\u4efb\u4f55\u6837\u672c\u5c31\u53ef\u4ee5\u8868\u73b0\u5f88\u597d\u7684\u6a21\u578b\uff0c\u800c\u662f\u8003\u8651\u50cf\u4eba\u7c7b\u7684\u5b66\u4e60\u65b9\u5f0f\u90a3\u6837\uff0c\u4ec5\u4ec5\u4f7f\u7528**\u6781\u5c11\u6570\u6837\u672c**\u5c31\u53ef\u4ee5\u638c\u63e1\u67d0\u4e00\u4e2a\u4efb\u52a1\uff0c\u4f46\u662f\u8fd9\u91cc\u7684 few-shot \u4e0d\u662f\u50cf\u4e4b\u524d\u7684\u65b9\u5f0f\u90a3\u6837\uff0c\u4f7f\u7528\u5c11\u91cf\u6837\u672c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u53bb\u505a\u5fae\u8c03\uff0c\u56e0\u4e3a\u5728 GPT-3 \u90a3\u6837\u7684\u53c2\u6570\u89c4\u6a21\u4e0b\uff0c\u5373\u4f7f\u662f\u53c2\u6570\u5fae\u8c03\u7684\u6210\u672c\u4e5f\u662f\u9ad8\u5230\u65e0\u6cd5\u4f30\u8ba1\u3002 GPT-3 \u4f5c\u4e3a\u5176\u5148\u524d\u8bed\u8a00\u6a21\u578b (LM) GPT-2 \u7684\u7ee7\u627f\u8005. \u5b83\u88ab\u8ba4\u4e3a\u6bd4GPT-2\u66f4\u597d\u3001\u66f4\u5927. \u4e8b\u5b9e\u4e0a, \u4e0e\u4ed6\u8bed\u8a00\u6a21\u578b\u76f8\u6bd4, OpenAI GPT-3 \u7684\u5b8c\u6574\u7248\u62e5\u6709\u5927\u7ea6 1750 \u4ebf\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570, \u662f\u8fc4\u4eca\u4e3a\u6b62\u8bad\u7ec3\u7684\u6700\u5927\u6a21\u578b, \u8fd9\u4efd 72 \u9875\u7684 \u7814\u7a76\u8bba\u6587 \u975e\u5e38\u8be6\u7ec6\u5730\u63cf\u8ff0\u4e86\u8be5\u6a21\u578b\u7684\u7279\u6027\u3001\u529f\u80fd\u3001\u6027\u80fd\u548c\u5c40\u9650\u6027. \u4e0b\u56fe\u4e3a\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u8bad\u7ec3\u53c2\u6570\u7684\u5bf9\u6bd4: 4.1 GPT-3\u6a21\u578b\u67b6\u6784 \u00b6 \u5b9e\u9645\u4e0aGPT-3 \u4e0d\u662f\u4e00\u4e2a\u5355\u4e00\u7684\u6a21\u578b, \u800c\u662f\u4e00\u4e2a\u6a21\u578b\u7cfb\u5217. \u7cfb\u5217\u4e2d\u7684\u6bcf\u4e2a\u6a21\u578b\u90fd\u6709\u4e0d\u540c\u6570\u91cf\u7684\u53ef\u8bad\u7ec3\u53c2\u6570. \u4e0b\u8868\u663e\u793a\u4e86\u6bcf\u4e2a\u6a21\u578b\u3001\u4f53\u7cfb\u7ed3\u6784\u53ca\u5176\u5bf9\u5e94\u7684\u53c2\u6570: \u5728\u6a21\u578b\u7ed3\u6784\u4e0a\uff0cGPT-3 \u5ef6\u7eed\u4f7f\u7528 GPT \u6a21\u578b\u7ed3\u6784\uff0c\u4f46\u662f\u5f15\u5165\u4e86 Sparse Transformer \u4e2d\u7684 sparse attention \u6a21\u5757\uff08\u7a00\u758f\u6ce8\u610f\u529b\uff09\u3002 sparse attention \u4e0e\u4f20\u7edf self-attention\uff08\u79f0\u4e3a dense attention\uff09 \u7684\u533a\u522b\u5728\u4e8e\uff1a dense attention\uff1a\u6bcf\u4e2a token \u4e4b\u95f4\u4e24\u4e24\u8ba1\u7b97 attention\uff0c\u590d\u6742\u5ea6 O(n\u00b2) sparse attention\uff1a\u6bcf\u4e2a token \u53ea\u4e0e\u5176\u4ed6 token \u7684\u4e00\u4e2a\u5b50\u96c6\u8ba1\u7b97 attention\uff0c\u590d\u6742\u5ea6 O(n*logn) \u5177\u4f53\u6765\u8bf4\uff0csparse attention \u9664\u4e86\u76f8\u5bf9\u8ddd\u79bb\u4e0d\u8d85\u8fc7 k \u4ee5\u53ca\u76f8\u5bf9\u8ddd\u79bb\u4e3a k\uff0c2k\uff0c3k\uff0c... \u7684 token\uff0c\u5176\u4ed6\u6240\u6709 token \u7684\u6ce8\u610f\u529b\u90fd\u8bbe\u4e3a 0\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f7f\u7528 sparse attention \u7684\u597d\u5904\u4e3b\u8981\u6709\u4ee5\u4e0b\u4e24\u70b9\uff1a \u51cf\u5c11\u6ce8\u610f\u529b\u5c42\u7684\u8ba1\u7b97\u590d\u6742\u5ea6 \uff0c\u8282\u7ea6\u663e\u5b58\u548c\u8017\u65f6\uff0c\u4ece\u800c\u80fd\u591f\u5904\u7406\u66f4\u957f\u7684\u8f93\u5165\u5e8f\u5217\uff1b \u5177\u6709\u201c\u5c40\u90e8\u7d27\u5bc6\u76f8\u5173\u548c\u8fdc\u7a0b\u7a00\u758f\u76f8\u5173\u201d\u7684\u7279\u6027 \uff0c\u5bf9\u4e8e\u8ddd\u79bb\u8f83\u8fd1\u7684\u4e0a\u4e0b\u6587\u5173\u6ce8\u66f4\u591a\uff0c\u5bf9\u4e8e\u8ddd\u79bb\u8f83\u8fdc\u7684\u4e0a\u4e0b\u6587\u5173\u6ce8\u8f83\u5c11\uff1b \u5176\u4e2d\u6700\u5927\u7248\u672c GPT-3 175B \u6216\u201cGPT-3\u201d\u5177\u6709175\u4e2aB\u53c2\u6570\u300196\u5c42\u7684\u591a\u5934Transformer\u3001Head size\u4e3a96\u3001\u8bcd\u5411\u91cf\u7ef4\u5ea6\u4e3a12288\u3001\u6587\u672c\u957f\u5ea6\u5927\u5c0f\u4e3a2048. 4.2 GPT-3\u8bad\u7ec3\u6838\u5fc3\u601d\u60f3 \u00b6 GPT-3\u6a21\u578b\u8bad\u7ec3\u7684\u601d\u60f3\u4e0eGPT-2\u7684\u65b9\u6cd5\u76f8\u4f3c, \u53bb\u9664\u4e86fine-tune\u8fc7\u7a0b, \u53ea\u5305\u62ec\u9884\u8bad\u7ec3\u8fc7\u7a0b, \u4e0d\u540c\u53ea\u5728\u4e8e\u91c7\u7528\u4e86\u53c2\u6570\u66f4\u591a\u7684\u6a21\u578b\u3001\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u548c\u66f4\u957f\u7684\u8bad\u7ec3\u7684\u8fc7\u7a0b. \u4f46\u662fGPT-3 \u6a21\u578b\u5728\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\u8bc4\u4f30\u548c\u9884\u6d4b\u65f6\u91c7\u7528\u4e86\u4e09\u79cd\u65b9\u6cd5, \u4ed6\u4eec\u5206\u522b\u662f: Few-shot\u3001One-shot\u3001Zero-shot. \u5176\u4e2d Few-shot\u3001One-shot\u4e5f\u88ab\u79f0\u4e4b\u4e3a\u60c5\u5883\u5b66\u4e60(in-context learning\uff0c\u4e5f\u53ef\u79f0\u4e4b\u4e3a\u63d0\u793a\u5b66\u4e60). \u60c5\u5883\u5b66\u4e60\u7406\u89e3: \u5728\u88ab\u7ed9\u5b9a\u7684\u51e0\u4e2a\u4efb\u52a1\u793a\u4f8b\u6216\u4e00\u4e2a\u4efb\u52a1\u8bf4\u660e\u7684\u60c5\u51b5\u4e0b, \u6a21\u578b\u5e94\u8be5\u80fd\u901a\u8fc7\u7b80\u5355\u9884\u6d4b\u4ee5\u8865\u5168\u4efb\u52a1\u4e2d\u5176\u4ed6\u7684\u5b9e\u4f8b. \u5373\u60c5\u5883\u5b66\u4e60\u8981\u6c42\u9884\u8bad\u7ec3\u6a21\u578b\u8981\u5bf9\u4efb\u52a1\u672c\u8eab\u8fdb\u884c\u7406\u89e3. In-context learnin\u6838\u5fc3\u601d\u60f3\u5728\u4e8e\u901a\u8fc7\u5c11\u91cf\u7684\u6570\u636e\u5bfb\u627e\u4e00\u4e2a\u5408\u9002\u7684\u521d\u59cb\u5316\u8303\u56f4\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5728\u6709\u9650\u7684\u6570\u636e\u96c6\u4e0a\u5feb\u901f\u62df\u5408\uff0c\u5e76\u83b7\u5f97\u4e0d\u9519\u7684\u6548\u679c\u3002 \u4e0b\u9762\u4ee5\u4ece\u201c\u82f1\u8bed\u5230\u6cd5\u8bed\u7684\u7ffb\u8bd1\u4efb\u52a1\u201d\u4e3a\u4f8b, \u5206\u522b\u5bf9\u6bd4\u4f20\u7edf\u7684\u5fae\u8c03\u7b56\u7565\u548cGPT-3\u4e09\u79cd\u60c5\u666f\u5b66\u4e60\u65b9\u5f0f. \u4e0b\u56fe\u662f\u4f20\u7edf\u7684\u5fae\u8c03\u7b56\u7565: \u4f20\u7edf\u7684\u5fae\u8c03\u7b56\u7565\u5b58\u5728\u95ee\u9898: \u5fae\u8c03\u9700\u8981\u5bf9\u6bcf\u4e00\u4e2a\u4efb\u52a1\u6709\u4e00\u4e2a\u4efb\u52a1\u76f8\u5173\u7684\u6570\u636e\u96c6\u4ee5\u53ca\u548c\u4efb\u52a1\u76f8\u5173\u7684\u5fae\u8c03. \u9700\u8981\u4e00\u4e2a\u76f8\u5173\u4efb\u52a1\u5927\u7684\u6570\u636e\u96c6, \u800c\u4e14\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u6807\u6ce8 \u5f53\u4e00\u4e2a\u6837\u672c\u6ca1\u6709\u51fa\u73b0\u5728\u6570\u636e\u5206\u5e03\u7684\u65f6\u5019, \u6cdb\u5316\u6027\u4e0d\u89c1\u5f97\u6bd4\u5c0f\u6a21\u578b\u8981\u597d \u4e0b\u56fe\u663e\u793a\u4e86 GPT-3 \u4e09\u79cd\u60c5\u666f\u5b66\u4e60\u65b9\u6cd5: zero-shot learning \u5b9a\u4e49: \u7ed9\u51fa\u4efb\u52a1\u7684\u63cf\u8ff0, \u7136\u540e\u63d0\u4f9b\u6d4b\u8bd5\u6570\u636e\u5bf9\u5176\u8fdb\u884c\u9884\u6d4b, \u76f4\u63a5\u8ba9\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53bb\u8fdb\u884c\u4efb\u52a1\u6d4b\u8bd5. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d one-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u4e00\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u4e00\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u82f1\u8bed\u7ffb\u8bd1\u4e3a\u6cd5\u8bed, \u5e94\u8be5\u8fd9\u4e48\u7ffb\u8bd1. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. few-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u591a\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u591a\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u5e94\u8be5\u5982\u4f55\u5de5\u4f5c. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u518d\u89c1->goodbye, \u8d2d\u4e70->purchase, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. \u603b\u4e4b\uff1a in-context learning\uff0c\u867d\u7136\u5b83\u4e0e fine-tuning \u4e00\u6837\u90fd\u9700\u8981\u4e00\u4e9b\u6709\u76d1\u7763\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u662f\u4e24\u8005\u7684\u533a\u522b\u662f\uff1a \u3010 \u672c\u8d28\u533a\u522b \u3011fine-tuning \u57fa\u4e8e\u6807\u6ce8\u6570\u636e\u5bf9\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u800c in-context learning \u4f7f\u7528\u6807\u6ce8\u6570\u636e\u65f6\u4e0d\u505a\u4efb\u4f55\u7684\u68af\u5ea6\u56de\u4f20\uff0c\u6a21\u578b\u53c2\u6570\u4e0d\u66f4\u65b0\uff1b in-context learning \u4f9d\u8d56\u7684\u6570\u636e\u91cf\uff0810\uff5e100\uff09\u8fdc\u8fdc\u5c0f\u4e8e fine-tuning \u4e00\u822c\u7684\u6570\u636e\u91cf\uff1b \u6700\u7ec8\u901a\u8fc7\u5927\u91cf\u4e0b\u6e38\u4efb\u52a1\u5b9e\u9a8c\u9a8c\u8bc1\uff0cFew-shot \u6548\u679c\u6700\u4f73\uff0cOne-shot \u6548\u679c\u6b21\u4e4b\uff0cZero-shot \u6548\u679c\u6700\u5dee\uff1a 4.3 GPT-3\u6570\u636e\u96c6 \u00b6 \u4e00\u822c\u6765\u8bf4, \u6a21\u578b\u7684\u53c2\u6570\u8d8a\u591a, \u8bad\u7ec3\u6a21\u578b\u6240\u9700\u7684\u6570\u636e\u5c31\u8d8a\u591a. GPT-3\u5171\u8bad\u7ec3\u4e865\u4e2a\u4e0d\u540c\u7684\u8bed\u6599\u5927\u7ea6 45 TB \u7684\u6587\u672c\u6570\u636e, \u5206\u522b\u662f\u4f4e\u8d28\u91cf\u7684Common Crawl(\u9700\u8981\u6570\u636e\u6e05\u6d17), \u9ad8\u8d28\u91cf\u7684WebText2, Books1, Books2\u548cWikipedia, GPT-3\u6839\u636e\u6570\u636e\u96c6\u7684\u4e0d\u540c\u7684\u8d28\u91cf\u8d4b\u4e88\u4e86\u4e0d\u540c\u7684\u6743\u503c, \u6743\u503c\u8d8a\u9ad8\u7684\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u8d8a\u5bb9\u6613\u62bd\u6837\u5230, \u5982\u4e0b\u8868\u6240\u793a. \u6570\u636e\u96c6 \u6570\u91cf\uff08tokens\uff09 \u8bad\u7ec3\u6570\u636e\u5360\u6bd4 Common Crawl\uff08filterd\uff09 4100\u4ebf 60% Web Text2 190\u4ebf 22% BOOK1 120\u4ebf 8% BOOK2 550\u4ebf 8% Wikipedia 30\u4ebf 2% \u4e0d\u540c\u6570\u636e\u7684\u4ecb\u7ecd: Common Crawl\u8bed\u6599\u5e93\u5305\u542b\u5728 8 \u5e74\u7684\u7f51\u7edc\u722c\u884c\u4e2d\u6536\u96c6\u7684 PB \u7ea7\u6570\u636e. \u8bed\u6599\u5e93\u5305\u542b\u539f\u59cb\u7f51\u9875\u6570\u636e\u3001\u5143\u6570\u636e\u63d0\u53d6\u548c\u5e26\u6709\u5149\u8fc7\u6ee4\u7684\u6587\u672c\u63d0\u53d6. WebText2\u662f\u6765\u81ea\u5177\u6709 3+ upvotes \u7684\u5e16\u5b50\u7684\u6240\u6709\u51fa\u7ad9 Reddit \u94fe\u63a5\u7684\u7f51\u9875\u6587\u672c. Books1\u548cBooks2\u662f\u4e24\u4e2a\u57fa\u4e8e\u4e92\u8054\u7f51\u7684\u56fe\u4e66\u8bed\u6599\u5e93. \u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u9875\u9762 \u4e5f\u662f\u8bad\u7ec3\u8bed\u6599\u5e93\u7684\u4e00\u90e8\u5206. 4.4 GPT-3\u6a21\u578b\u7684\u7279\u70b9 \u00b6 \u4e0e GPT-2 \u7684\u533a\u522b \u6548\u679c\u4e0a \uff0c\u8d85\u51fa GPT-2 \u975e\u5e38\u591a\uff0c\u80fd\u751f\u6210\u4eba\u7c7b\u96be\u4ee5\u533a\u5206\u7684\u65b0\u95fb\u6587\u7ae0\uff1b \u4e3b\u63a8 few-shot \uff0c\u76f8\u6bd4\u4e8e GPT-2 \u7684 zero-shot\uff0c\u5177\u6709\u5f88\u5f3a\u7684\u521b\u65b0\u6027\uff1b **\u6a21\u578b\u7ed3\u6784**\u7565\u5fae\u53d8\u5316\uff0c\u91c7\u7528 sparse attention \u6a21\u5757\uff1b \u6d77\u91cf\u8bad\u7ec3\u8bed\u6599 45TB\uff08\u6e05\u6d17\u540e 570GB\uff09\uff0c\u76f8\u6bd4\u4e8e GPT-2 \u7684 40GB\uff1b \u6d77\u91cf\u6a21\u578b\u53c2\u6570 \uff0c\u6700\u5927\u6a21\u578b\u4e3a 1750 \u4ebf\uff0cGPT-2 \u6700\u5927\u4e3a 15 \u4ebf\u53c2\u6570\uff1b \u4f18\u70b9\uff1a \u6574\u4f53\u4e0a, GPT-3\u5728zero-shot\u6216one-shot\u8bbe\u7f6e\u4e0b\u80fd\u53d6\u5f97\u5c1a\u53ef\u7684\u6210\u7ee9, \u5728few-shot\u8bbe\u7f6e\u4e0b\u6709\u53ef\u80fd\u8d85\u8d8a\u57fa\u4e8efine-tune\u7684SOTA\u6a21\u578b. \u53bb\u9664\u4e86fune-tuning\u4efb\u52a1. \u7f3a\u70b9: \u7531\u4e8e40TB\u6d77\u91cf\u6570\u636e\u7684\u5b58\u5728, \u5f88\u96be\u4fdd\u8bc1GPT-3\u751f\u6210\u7684\u6587\u7ae0\u4e0d\u5305\u542b\u4e00\u4e9b\u975e\u5e38\u654f\u611f\u7684\u5185\u5bb9 \u5bf9\u4e8e\u90e8\u5206\u4efb\u52a1\u6bd4\u5982: \u201c\u586b\u7a7a\u7c7b\u578b\u201d\u7b49, \u6548\u679c\u5177\u6709\u5c40\u9650\u6027 \u5f53\u751f\u6210\u6587\u672c\u957f\u5ea6\u8f83\u957f\u65f6\uff0cGPT-3 \u8fd8\u662f\u4f1a\u51fa\u73b0\u5404\u79cd\u95ee\u9898\uff0c\u6bd4\u5982\u91cd\u590d\u751f\u6210\u4e00\u6bb5\u8bdd\uff0c\u524d\u540e\u77db\u76fe\uff0c\u903b\u8f91\u8854\u63a5\u4e0d\u597d\u7b49\u7b49\uff1b \u6210\u672c\u592a\u5927 4.5 GPT-3\u6a21\u578b\u603b\u7ed3 \u00b6 GPT\u7cfb\u5217\u4ece1\u52303, \u901a\u901a\u91c7\u7528\u7684\u662ftransformer\u67b6\u6784, \u53ef\u4ee5\u8bf4\u6a21\u578b\u7ed3\u6784\u5e76\u6ca1\u6709\u521b\u65b0\u6027\u7684\u8bbe\u8ba1. GPT-3\u7684\u672c\u8d28\u8fd8\u662f\u901a\u8fc7\u6d77\u91cf\u7684\u53c2\u6570\u5b66\u4e60\u6d77\u91cf\u7684\u6570\u636e, \u7136\u540e\u4f9d\u8d56transformer\u5f3a\u5927\u7684\u62df\u5408\u80fd\u529b\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u6536\u655b. \u5f97\u76ca\u4e8e\u5e9e\u5927\u7684\u6570\u636e\u96c6, GPT-3\u53ef\u4ee5\u5b8c\u6210\u4e00\u4e9b\u4ee4\u4eba\u611f\u5230\u60ca\u559c\u7684\u4efb\u52a1, \u4f46\u662fGPT-3\u4e5f\u4e0d\u662f\u4e07\u80fd\u7684, \u5bf9\u4e8e\u4e00\u4e9b\u660e\u663e\u4e0d\u5728\u8fd9\u4e2a\u5206\u5e03\u6216\u8005\u548c\u8fd9\u4e2a\u5206\u5e03\u6709\u51b2\u7a81\u7684\u4efb\u52a1\u6765\u8bf4, GPT-3\u8fd8\u662f\u65e0\u80fd\u4e3a\u529b\u7684. 5 ChatGPT\u4ecb\u7ecd \u00b6 ChatGPT\u662f\u4e00\u79cd\u57fa\u4e8eGPT-3\u7684\u804a\u5929\u673a\u5668\u4eba\u6a21\u578b. \u5b83\u65e8\u5728\u4f7f\u7528 GPT-3 \u7684\u8bed\u8a00\u751f\u6210\u80fd\u529b\u6765\u4e0e\u7528\u6237\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd. \u4f8b\u5982, \u7528\u6237\u53ef\u4ee5\u5411 ChatGPT \u53d1\u9001\u6d88\u606f, \u7136\u540e ChatGPT \u4f1a\u6839\u636e\u6d88\u606f\u751f\u6210\u4e00\u6761\u56de\u590d. GPT-3 \u662f\u4e00\u4e2a\u66f4\u5927\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b, \u800c ChatGPT \u5219\u662f\u4f7f\u7528 GPT-3 \u6765\u6784\u5efa\u7684\u804a\u5929\u673a\u5668\u4eba. \u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u662f ChatGPT \u4f9d\u8d56\u4e8e GPT-3 \u7684\u8bed\u8a00\u751f\u6210\u80fd\u529b\u6765\u8fdb\u884c\u5bf9\u8bdd. \u76ee\u524d\u57fa\u4e8eChatGPT\u7684\u8bba\u6587\u5e76\u6ca1\u6709\u516c\u5e03, \u56e0\u6b64\u63a5\u4e0b\u6765\u6211\u4eec\u57fa\u4e8eopenai\u5b98\u7f51\u7684\u4ecb\u7ecd\u5bf9\u5176\u539f\u7406\u8fdb\u884c\u89e3\u6790 5.1 ChatGPT\u539f\u7406 \u00b6 \u5728\u4ecb\u7ecdChatGPT\u539f\u7406\u4e4b\u524d, \u8bf7\u5927\u5bb6\u5148\u601d\u8003\u4e00\u4e2a\u95ee\u9898: \u201c\u6a21\u578b\u8d8a\u5927\u3001\u53c2\u6570\u8d8a\u591a, \u6a21\u578b\u7684\u6548\u679c\u5c31\u8d8a\u597d\u4e48\u554a\uff1f\u201d. \u8fd9\u4e2a\u7b54\u6848\u662f\u5426\u5b9a\u7684, \u56e0\u4e3a\u6a21\u578b\u8d8a\u5927\u53ef\u80fd\u5bfc\u81f4\u7ed3\u679c\u8d8a\u4e13\u4e00, \u4f46\u662f\u8fd9\u4e2a\u7ed3\u679c\u6709\u53ef\u80fd\u5e76\u4e0d\u662f\u6211\u4eec\u671f\u671b\u7684. \u8fd9\u4e5f\u79f0\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u4e0d\u4e00\u81f4\u95ee\u9898. \u5728\u673a\u5668\u5b66\u4e60\u4e2d, \u6709\u4e2a\u91cd\u8981\u7684\u6982\u5ff5: \u201c\u8fc7\u62df\u5408\u201d, \u6240\u8c13\u7684\u8fc7\u62df\u5408, \u5c31\u662f\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u8868\u73b0\u5f97\u5f88\u597d, \u4f46\u662f\u5728\u6d4b\u8bd5\u96c6\u8868\u73b0\u5f97\u8f83\u5dee, \u4e5f\u5c31\u662f\u8bf4\u6a21\u578b\u5728\u6700\u7ec8\u7684\u8868\u73b0\u4e0a\u5e76\u4e0d\u80fd\u8fbe\u5230\u6211\u4eec\u7684\u9884\u671f, \u8fd9\u5c31\u662f\u6a21\u578b\u80fd\u529b\u4e0d\u4e00\u81f4\u95ee\u9898. \u539f\u59cb\u7684 GPT-3 \u5c31\u662f\u975e\u4e00\u81f4\u6a21\u578b, \u7c7b\u4f3cGPT-3 \u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u90fd\u662f\u57fa\u4e8e\u6765\u81ea\u4e92\u8054\u7f51\u7684\u5927\u91cf\u6587\u672c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3, \u80fd\u591f\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6587\u672c, \u4f46\u5b83\u4eec\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u4ea7\u751f\u7b26\u5408\u4eba\u7c7b\u671f\u671b\u7684\u8f93\u51fa. ChatGPT \u4e3a\u4e86\u89e3\u51b3\u6a21\u578b\u7684\u4e0d\u4e00\u81f4\u95ee\u9898, \u4f7f\u7528\u4e86\u4eba\u7c7b\u53cd\u9988\u6765\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b, \u5bf9\u5176\u8fdb\u884c\u4e86\u8fdb\u4e00\u6b65\u8bad\u7ec3. \u6240\u4f7f\u7528\u7684\u5177\u4f53\u6280\u672f\u5c31\u662f\u5f3a\u5316\u5b66\u4e60(RLHF) . 5.2 \u4ec0\u4e48\u662f\u5f3a\u5316\u5b66\u4e60 \u00b6 \u5f3a\u5316\u5b66\u4e60\uff08Reinforcement Learning, RL\uff09, \u53c8\u79f0\u518d\u52b1\u5b66\u4e60\u3001\u8bc4\u4ef7\u5b66\u4e60\u6216\u589e\u5f3a\u5b66\u4e60, \u662f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u4e00\u79cd, \u7528\u4e8e\u63cf\u8ff0\u548c\u89e3\u51b3\u667a\u80fd\u4f53\uff08agent\uff09\u5728\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u5b66\u4e60\u7b56\u7565\u4ee5\u8fbe\u6210\u56de\u62a5\u6700\u5927\u5316\u6216\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u95ee\u9898. \u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u4fe1\u606f: \u4e00\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5 \u5173\u6ce8\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4ea4\u4e92 \u76ee\u6807\u662f\u8ffd\u6c42\u6700\u5927\u56de\u62a5 \u5f3a\u5316\u5b66\u4e60\u7684\u67b6\u6784 \u4e0b\u56fe\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u6d41\u7a0b\u6574\u4f53\u67b6\u6784, \u5176\u4e2d\u5927\u8111\u6307\u4ee3\u667a\u80fd\u4f53agent, \u5730\u7403\u6307\u4ee3\u73af\u5883environment, \u4ece\u5f53\u524d\u7684\u72b6\u6001St\u51fa\u53d1, \u5728\u505a\u51fa\u4e00\u4e2a\u884c\u4e3aAt \u4e4b\u540e, \u5bf9\u73af\u5883\u4ea7\u751f\u4e86\u4e00\u4e9b\u5f71\u54cd, \u5b83\u9996\u5148\u7ed9agent\u53cd\u9988\u4e86\u4e00\u4e2a\u5956\u52b1\u4fe1\u53f7Rt\u7136\u540e\u7ed9agent\u53cd\u9988\u4e00\u4e2a\u65b0\u7684\u73af\u5883\u72b6\u6001, \u6b64\u5904\u7528Ot \u8868\u793a, \u8fdb\u800c\u878d\u6c47\u8fdb\u5165\u4e00\u4e2a\u65b0\u7684\u72b6\u6001, agent\u518d\u505a\u51fa\u65b0\u7684\u884c\u4e3a, \u5f62\u6210\u4e00\u4e2a\u5faa\u73af. \u7406\u89e3\u5f3a\u5316\u5b66\u4e60\u57fa\u672c\u8981\u7d20 \u8fd9\u91cc\u6211\u4eec\u4ee5\u4e00\u4e2a\u7b80\u5355\u5c0f\u6e38\u620fflappy bird\u4e3a\u4ee3\u8868\u4e3a\u5927\u5bb6\u8bb2\u89e3\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u8981\u7d20: Agent\uff08\u667a\u80fd\u4f53\uff09: \u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u4e3b\u4f53\u5c31\u662fAgent, \u7edf\u79f0\u4e3a\u201c\u667a\u80fd\u4f53\u201d. \u8fd9\u91cc\u5c0f\u9e1f\u5c31\u662fAgent. Environment\uff08\u73af\u5883\uff09: \u6574\u4e2a\u6e38\u620f\u7684\u5927\u80cc\u666f\u5c31\u662f\u73af\u5883\uff1b\u8d85\u7ea7\u739b\u4e3d\u4e2dAgent\u3001\u5730\u9762\u3001\u67f1\u5b50\u7ec4\u6210\u4e86\u6574\u4e2a\u73af\u5883. State\uff08\u72b6\u6001\uff09: \u5f53\u524d Environment\u548cAgent\u6240\u5904\u7684\u72b6\u6001, \u56e0\u4e3a\u5c0f\u9e1f\u4e00\u76f4\u5728\u79fb\u52a8, \u5206\u6570\u6570\u76ee\u4e5f\u5728\u4e0d\u505c\u53d8\u5316, Agent\u7684\u4f4d\u7f6e\u4e5f\u5728\u4e0d\u505c\u53d8\u5316, \u6240\u4ee5\u6574\u4e2aState\u5904\u4e8e\u53d8\u5316\u4e2d. Policy\uff08\u7b56\u7565\uff09: Policy\u7684\u610f\u601d\u5c31\u662f\u6839\u636e\u89c2\u6d4b\u5230\u7684\u72b6\u6001\u6765\u8fdb\u884c\u51b3\u7b56, \u6765\u63a7\u5236Agent\u8fd0\u52a8. \u5373\u57fa\u4e8e\u5f53\u524d\u7684State, Agent\u53ef\u4ee5\u91c7\u53d6\u54ea\u4e9bAction, \u6bd4\u5982\u5411\u4e0a\u6216\u8005\u5411\u4e0b. \u5728\u6570\u5b66\u4e0aPolicy\u4e00\u822c\u5b9a\u4e49\u4e3a\u51fd\u6570\u03c0\uff08\u6df1\u5ea6\u5b66\u4e60\u4e2dPolicy\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u6a21\u578b\uff09, \u8fd9\u4e2apolicy\u51fd\u6570\u03c0\u662f\u4e2a\u6982\u7387\u5bc6\u5ea6\u51fd\u6570: $$ \u03c0(a|s) = P(A=a|S=s) $$ Reward\uff08\u5956\u52b1\uff09: Agent\u5728\u5f53\u524dState\u4e0b, \u91c7\u53d6\u4e86\u67d0\u4e2a\u7279\u5b9a\u7684Action\u540e, \u4f1a\u83b7\u5f97\u73af\u5883\u7684\u4e00\u5b9a\u53cd\u9988\uff08\u6216\u5956\u52b1\uff09\u5c31\u662fReward. \u6bd4\u5982: \u5c0f\u9e1f\u987a\u5229\u901a\u8fc7\u67f1\u5b50\u83b7\u5f97\u5956\u52b1R=+1,\u5982\u679c\u8d62\u4e86\u8fd9\u573a\u6e38\u620f\u5956\u52b1R=+10000, \u6211\u4eec\u5e94\u8be5\u628a\u6253\u8d62\u6e38\u620f\u7684\u5956\u52b1\u5b9a\u4e49\u7684\u5927\u4e00\u4e9b, \u8fd9\u6837\u624d\u80fd\u6fc0\u52b1\u5b66\u5230\u7684policy\u6253\u8d62\u6e38\u620f\u800c\u4e0d\u662f\u4e00\u5473\u7684\u52a0\u5206, \u5982\u679c\u5c0f\u9e1f\u78b0\u5230\u67f1\u5b50, \u5c0f\u9e1f\u5c31\u4f1a\u6b7b, \u6e38\u620f\u7ed3\u675f, \u8fd9\u65f6\u5956\u52b1\u5c31\u8bbeR=-10000, \u5982\u679c\u8fd9\u4e00\u6b65\u4ec0\u4e48\u4e5f\u6ca1\u53d1\u751f, \u5956\u52b1\u5c31\u662fR=0, \u5f3a\u5316\u5b66\u4e60\u7684\u76ee\u6807\u5c31\u662f\u4f7f\u83b7\u5f97\u7684\u5956\u52b1\u603b\u548c\u5c3d\u91cf\u8981\u9ad8. \u5982\u4f55\u8ba9AI\u5b9e\u73b0\u81ea\u52a8\u6253\u6e38\u620f\uff1f \u7b2c\u4e00\u6b65: \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff09\u5b66\u51faPolicy\u51fd\u6570, \u8be5\u6b65\u9aa4\u76ee\u7684\u662f\u7528Policy\u51fd\u6570\u6765\u63a7\u5236Agent. \u7b2c\u4e8c\u6b65: \u83b7\u53d6\u5f53\u524d\u72b6\u6001\u4e3as1, \u5e76\u5c06s1\u5e26\u5165Policy\u51fd\u6570\u6765\u8ba1\u7b97\u6982\u7387, \u4ece\u6982\u7387\u7ed3\u679c\u4e2d\u62bd\u6837\u5f97\u5230a1, \u540c\u65f6\u73af\u5883\u751f\u6210\u4e0b\u4e00\u72b6\u6001s2, \u5e76\u4e14\u7ed9Agent\u4e00\u4e2a\u5956\u52b1r1. \u7b2c\u4e09\u6b65: \u5c06\u65b0\u7684\u72b6\u6001s2\u5e26\u5165Policy\u51fd\u6570\u6765\u8ba1\u7b97\u6982\u7387, \u62bd\u53d6\u7ed3\u679c\u5f97\u5230\u65b0\u7684\u52a8\u4f5ca2\u3001\u72b6\u6001s3\u3001\u5956\u52b1r2. \u7b2c\u56db\u6b65: \u5faa\u73af2-3\u6b65\u9aa4, \u76f4\u5230\u6253\u8d62\u6e38\u620f\u6216\u8005game over, \u8fd9\u6837\u6211\u4eec\u5c31\u4f1a\u5f97\u5230\u4e00\u4e2a\u6e38\u620f\u7684trajectory\uff08\u8f68\u8ff9\uff09, \u8fd9\u4e2a\u8f68\u8ff9\u662f\u6bcf\u4e00\u6b65\u7684\u72b6\u6001, \u52a8\u4f5c, \u5956\u52b1. 5.3 ChatGPT\u5f3a\u5316\u5b66\u4e60\u6b65\u9aa4 \u00b6 \u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60, \u8be5\u65b9\u6cd5\u603b\u4f53\u4e0a\u5305\u62ec\u4e09\u4e2a\u6b65\u9aa4: \u6b65\u9aa41: \u76d1\u7763\u5b66\u4e60, \u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u91cf\u5df2\u6807\u6ce8\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u8c03\u4f18, \u4ee5\u5b66\u4e60\u4ece\u7ed9\u5b9a\u7684 prompt \u5217\u8868\u751f\u6210\u8f93\u51fa\u7684\u6709\u76d1\u7763\u7684\u7b56\u7565\uff08\u5373 SFT \u6a21\u578b\uff09\uff1b \u6b65\u9aa42: \u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff08reward\uff09: \u6807\u6ce8\u8005\u4eec\u5bf9\u76f8\u5bf9\u5927\u91cf\u7684 SFT \u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u8fdb\u884c\u6536\u96c6\u5e76\u6392\u5e8f, \u8fd9\u5c31\u521b\u5efa\u4e86\u4e00\u4e2a\u7531\u6bd4\u8f83\u6570\u636e\u7ec4\u6210\u7684\u65b0\u6570\u636e\u96c6. \u5728\u6b64\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u65b0\u6a21\u578b, \u88ab\u79f0\u4e3a\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff08Reward Model, RM\uff09\uff1b \u6b65\u9aa43: \u5f3a\u5316\u5b66\u4e60\uff08PPO\u7b97\u6cd5\uff09: RM \u6a21\u578b\u7528\u4e8e\u8fdb\u4e00\u6b65\u8c03\u4f18\u548c\u6539\u8fdb SFT \u6a21\u578b, PPO \u8f93\u51fa\u7ed3\u679c\u7684\u662f\u7b56\u7565\u6a21\u5f0f. \u6b65\u9aa4 1 \u53ea\u8fdb\u884c\u4e00\u6b21, \u800c\u6b65\u9aa4 2 \u548c\u6b65\u9aa4 3 \u53ef\u4ee5\u6301\u7eed\u91cd\u590d\u8fdb\u884c: \u5728\u5f53\u524d\u6700\u4f73\u7b56\u7565\u6a21\u578b\u4e0a\u6536\u96c6\u66f4\u591a\u7684\u6bd4\u8f83\u6570\u636e, \u7528\u4e8e\u8bad\u7ec3\u65b0\u7684 RM \u6a21\u578b, \u7136\u540e\u8bad\u7ec3\u65b0\u7684\u7b56\u7565. \u63a5\u4e0b\u6765, \u5c06\u5bf9\u6bcf\u4e00\u6b65\u7684\u7ec6\u8282\u8fdb\u884c\u8be6\u8ff0. 5.4 \u76d1\u7763\u8c03\u4f18\u6a21\u578b \u00b6 \u5de5\u4f5c\u539f\u7406: \u7b2c\u4e00\u6b65\u662f\u6536\u96c6\u6570\u636e, \u4ee5\u8bad\u7ec3\u6709\u76d1\u7763\u7684\u7b56\u7565\u6a21\u578b. \u6570\u636e\u6536\u96c6: \u9009\u62e9\u4e00\u4e2a\u63d0\u793a\u5217\u8868, \u6807\u6ce8\u4eba\u5458\u6309\u8981\u6c42\u5199\u4e0b\u9884\u671f\u7684\u8f93\u51fa. \u5bf9\u4e8e ChatGPT, \u4f7f\u7528\u4e86\u4e24\u79cd\u4e0d\u540c\u7684 prompt \u6765\u6e90: \u4e00\u4e9b\u662f\u76f4\u63a5\u4f7f\u7528\u6807\u6ce8\u4eba\u5458\u6216\u7814\u7a76\u4eba\u5458\u51c6\u5907\u7684, \u53e6\u4e00\u4e9b\u662f\u4ece OpenAI \u7684 API \u8bf7\u6c42\uff08\u5373\u4ece GPT-3 \u7528\u6237\u90a3\u91cc\uff09\u83b7\u53d6\u7684. \u867d\u7136\u6574\u4e2a\u8fc7\u7a0b\u7f13\u6162\u4e14\u6602\u8d35, \u4f46\u6700\u7ec8\u5f97\u5230\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u76f8\u5bf9\u8f83\u5c0f\u3001\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6, \u53ef\u7528\u4e8e\u8c03\u4f18\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b. \u6a21\u578b\u9009\u62e9: ChatGPT \u7684\u5f00\u53d1\u4eba\u5458\u9009\u62e9\u4e86 GPT-3.5 \u7cfb\u5217\u4e2d\u7684\u9884\u8bad\u7ec3\u6a21\u578b, \u800c\u4e0d\u662f\u5bf9\u539f\u59cb GPT-3 \u6a21\u578b\u8fdb\u884c\u8c03\u4f18. \u4f7f\u7528\u7684\u57fa\u7ebf\u6a21\u578b\u662f\u6700\u65b0\u7248\u7684 text-davinci-003\uff08\u901a\u8fc7\u5bf9\u7a0b\u5e8f\u4ee3\u7801\u8c03\u4f18\u7684 GPT-3 \u6a21\u578b\uff09 \u7531\u4e8e\u6b64\u6b65\u9aa4\u7684\u6570\u636e\u91cf\u6709\u9650, \u8be5\u8fc7\u7a0b\u83b7\u5f97\u7684 SFT \u6a21\u578b\u53ef\u80fd\u4f1a\u8f93\u51fa\u4ecd\u7136\u5e76\u975e\u7528\u6237\u5173\u6ce8\u7684\u6587\u672c, \u5e76\u4e14\u901a\u5e38\u4f1a\u51fa\u73b0\u4e0d\u4e00\u81f4\u95ee\u9898. \u8fd9\u91cc\u7684\u95ee\u9898\u662f\u76d1\u7763\u5b66\u4e60\u6b65\u9aa4\u5177\u6709\u9ad8\u53ef\u6269\u5c55\u6027\u6210\u672c. \u4e3a\u4e86\u514b\u670d\u8fd9\u4e2a\u95ee\u9898, \u4f7f\u7528\u7684\u7b56\u7565\u662f\u8ba9\u4eba\u5de5\u6807\u6ce8\u8005\u5bf9 SFT \u6a21\u578b\u7684\u4e0d\u540c\u8f93\u51fa\u8fdb\u884c\u6392\u5e8f\u4ee5\u521b\u5efa RM \u6a21\u578b, \u800c\u4e0d\u662f\u8ba9\u4eba\u5de5\u6807\u6ce8\u8005\u521b\u5efa\u4e00\u4e2a\u66f4\u5927\u7684\u7cbe\u9009\u6570\u636e\u96c6. 5.5 \u8bad\u7ec3\u5956\u52b1\u6a21\u578b \u00b6 \u8fd9\u4e00\u6b65\u7684\u76ee\u6807\u662f\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u76ee\u6807\u51fd\u6570. \u8be5\u51fd\u6570\u7684\u76ee\u7684\u662f\u4e3a SFT \u6a21\u578b\u8f93\u51fa\u8fdb\u884c\u6253\u5206, \u8fd9\u4ee3\u8868\u8fd9\u4e9b\u8f93\u51fa\u5bf9\u4e8e\u4eba\u7c7b\u6765\u8bf4\u53ef\u53d6\u7a0b\u5ea6\u6709\u591a\u5927. \u8fd9\u5f3a\u6709\u529b\u5730\u53cd\u6620\u4e86\u9009\u5b9a\u7684\u4eba\u7c7b\u6807\u6ce8\u8005\u7684\u5177\u4f53\u504f\u597d\u4ee5\u53ca\u4ed6\u4eec\u540c\u610f\u9075\u5faa\u7684\u5171\u540c\u51c6\u5219. \u6700\u540e, \u8fd9\u4e2a\u8fc7\u7a0b\u5c06\u4ece\u6570\u636e\u4e2d\u5f97\u5230\u6a21\u4eff\u4eba\u7c7b\u504f\u597d\u7684\u7cfb\u7edf. \u5de5\u4f5c\u539f\u7406: \u4ece\u95ee\u9898\u5e93\u4e2d\u9009\u62e9\u95ee\u9898\uff08prompt\uff09, SFT \u6a21\u578b\u4e3a\u6bcf\u4e2a prompt \u751f\u6210\u591a\u4e2a\u8f93\u51fa\uff084 \u5230 9 \u4e4b\u95f4\u7684\u4efb\u610f\u503c\uff09 \u6807\u6ce8\u8005\u5c06\u8f93\u51fa\u4ece\u6700\u4f73\u5230\u6700\u5dee\u6392\u5e8f. \u7ed3\u679c\u662f\u4e00\u4e2a\u65b0\u7684\u6807\u7b7e\u6570\u636e\u96c6, \u8be5\u6570\u636e\u96c6\u7684\u5927\u5c0f\u5927\u7ea6\u662f\u7528\u4e8e SFT \u6a21\u578b\u7684\u7cbe\u786e\u6570\u636e\u96c6\u7684 10 \u500d\uff1b \u6b64\u65b0\u6570\u636e\u7528\u4e8e\u8bad\u7ec3 RM \u6a21\u578b . \u8be5\u6a21\u578b\u5c06 SFT \u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u8f93\u5165, \u5e76\u6309\u4f18\u5148\u987a\u5e8f\u5bf9\u5b83\u4eec\u8fdb\u884c\u6392\u5e8f. \u6a21\u578b\u9009\u62e9: RM\u6a21\u578b\u662fGPT-3\u7684\u84b8\u998f\u7248\u672c\uff08\u53c2\u6570\u91cf\u4e3a6\u4ebf\uff09, \u76ee\u7684\u662f\u901a\u8fc7\u8be5\u8bad\u7ec3\u6a21\u578b\u5f97\u5230\u4e00\u4e2a\u9884\u6d4b\u503c\uff08\u5f97\u5206\uff09, \u6a21\u578b\u635f\u5931\u51fd\u6570\u4e3a\u4e0b\u56fe\u8868\u793a: \u516c\u5f0f\u53c2\u6570\u89e3\u6790: x\u4ee3\u8868prompt\u539f\u59cb\u8f93\u5165, yw\u4ee3\u8868SFT\u6a21\u578b\u8f93\u51fa\u7684\u5f97\u5206\u8f83\u9ad8\u7684\u7ed3\u679c, yl\u4ee3\u8868SFT\u6a21\u578b\u8f93\u51fa\u5f97\u5206\u8f83\u4f4e\u7684\u7ed3\u679c, r\u03b8\u4ee3\u8868RM\u6a21\u578b\u5373GPT-3\u6a21\u578b, \u03c3\u4ee3\u8868sigmoid\u51fd\u6570, K\u4ee3\u8868SFT \u6a21\u578b\u4e3a\u6bcf\u4e2a prompt \u751f\u6210\u591a\u4e2a\u8f93\u51fa, \u8fd9\u91ccK\u4e2a\u4efb\u90092\u4e2a\u6765\u6a21\u578b\u8bad\u7ec3. 5.6 \u5f3a\u5316\u5b66\u4e60\u6a21\u578b \u00b6 \u8fd9\u4e00\u6b65\u91cc\u5f3a\u5316\u5b66\u4e60\u88ab\u5e94\u7528\u4e8e\u901a\u8fc7\u4f18\u5316 RM \u6a21\u578b\u6765\u8c03\u4f18 SFT \u6a21\u578b. \u6240\u4f7f\u7528\u7684\u7279\u5b9a\u7b97\u6cd5\u79f0\u4e3a\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO, Proximal Policy Optimization\uff09, \u800c\u8c03\u4f18\u6a21\u578b\u79f0\u4e3a\u8fd1\u6bb5\u7b56\u7565\u4f18\u5316\u6a21\u578b. \u5de5\u4f5c\u539f\u7406: (\u660e\u786e\u4efb\u52a1: \u6a21\u578b\u662f\u901a\u8fc7RL\u6765\u66f4\u65b0) \u7b2c\u4e00\u6b65: \u8f93\u5165prompt(\u6307\u4ee3\u95ee\u9898) \u7b2c\u4e8c\u6b65: \u5c06prompt\u8f93\u5165\u5f3a\u5316\u5b66\u4e60\u6a21\u578b (\u8fd9\u91cc\u76f4\u63a5\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3aChatGPT\u6a21\u578b\u3010\u76d1\u7763\u5b66\u4e60\u5fae\u8c03\u540e\u7684\u3011), \u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7ed3\u679c \u7b2c\u4e09\u6b65: \u5c06\u7b2c\u4e8c\u6b65\u5f97\u5230\u7684\u7ed3\u679c\u8f93\u5165\u5230RM\u5956\u52b1\u6a21\u578b\u4e2d, \u7136\u540e\u5f97\u5230\u4e00\u4e2a\u5956\u52b1\u5206\u6570. \u751f\u6210\u7684\u5206\u6570\u4f1a\u57fa\u4e8ePPO\u7b97\u6cd5\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u3002\u6bd4\u5982\uff1a\u5982\u679c\u5956\u52b1\u5206\u6570\u6bd4\u8f83\u4f4e, \u4ee3\u8868ChatGPT\u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u4e0d\u5bf9, \u6b64\u65f6\u9700\u8981\u5229\u7528PPO\u7b97\u6cd5\u66f4\u65b0ChatGPT\u6a21\u578b\u53c2\u6570 \u7b2c\u56db\u6b65: \u5faa\u73af\u4e0a\u8ff0\u6b65\u9aa4, \u4e0d\u65ad\u66f4\u65b0ChatGPT\u3001RM\u6a21\u578b. 5.7 ChatGPT\u7279\u70b9 \u00b6 \u4f18\u70b9: \u56de\u7b54\u7406\u6027\u53c8\u5168\u9762, ChatGPT\u66f4\u80fd\u505a\u5230\u591a\u89d2\u5ea6\u5168\u65b9\u4f4d\u56de\u7b54 \u964d\u4f4e\u5b66\u4e60\u6210\u672c, \u53ef\u4ee5\u5feb\u901f\u83b7\u53d6\u95ee\u9898\u7b54\u6848 \u7f3a\u70b9: ChatGPT \u670d\u52a1\u4e0d\u7a33\u5b9a \u5bb9\u6613\u4e00\u672c\u6b63\u7ecf\u7684\"\u80e1\u8bf4\u516b\u9053\" 6 \u5c0f\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u8bb2\u8ff0\u4e86ChatGPT\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u91cd\u70b9\u5bf9\u6bd4\u4e86N-gram\u8bed\u8a00\u6a21\u578b\u548c\u795e\u7ecf\u7f51\u7edc\u8bed\u8a00\u6a21\u578b\u7684\u533a\u522b\uff0c\u4ee5\u53caGPT\u7cfb\u5217\u6a21\u578b\u7684\u5bf9\u6bd4.","title":"2.1 ChatGPT\u6a21\u578b\u539f\u7406"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#chatgpt","text":"","title":"ChatGPT\u6a21\u578b\u539f\u7406\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#_1","text":"\u4e86\u89e3ChatGPT\u7684\u672c\u8d28 \u4e86\u89e3GPT\u7cfb\u5217\u6a21\u578b\u7684\u539f\u7406\u548c\u533a\u522b","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#1-chatgpt","text":"ChatGPT \u662f\u7531\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u5b9e\u9a8c\u5ba4 OpenAI \u57282022\u5e7411\u670830\u65e5\u53d1\u5e03\u7684\u5168\u65b0\u804a\u5929\u673a\u5668\u4eba\u6a21\u578b, \u4e00\u6b3e\u4eba\u5de5\u667a\u80fd\u6280\u672f\u9a71\u52a8\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177. \u5b83\u80fd\u591f\u901a\u8fc7\u5b66\u4e60\u548c\u7406\u89e3\u4eba\u7c7b\u7684\u8bed\u8a00\u6765\u8fdb\u884c\u5bf9\u8bdd, \u8fd8\u80fd\u6839\u636e\u804a\u5929\u7684\u4e0a\u4e0b\u6587\u8fdb\u884c\u4e92\u52a8, \u771f\u6b63\u50cf\u4eba\u7c7b\u4e00\u6837\u6765\u804a\u5929\u4ea4\u6d41, \u751a\u81f3\u80fd\u5b8c\u6210\u64b0\u5199\u90ae\u4ef6\u3001\u89c6\u9891\u811a\u672c\u3001\u6587\u6848\u3001\u7ffb\u8bd1\u3001\u4ee3\u7801\u7b49\u4efb\u52a1. \u6570\u636e\u663e\u793a, ChatGPT\u5728\u63a8\u51fa2\u4e2a\u591a\u6708\u7684\u65f6\u95f4\u5185\uff0c\u6708\u6d3b\u8dc3\u7528\u6237\u5df2\u7ecf\u8d85\u8fc71\u4ebf, \u8fd9, \u6210\u4e3a\u53f2\u4e0a\u589e\u957f\u6700\u5feb\u7684\u6d88\u8d39\u8005\u5e94\u7528. \u5168\u7403\u6bcf\u5929\u7ea6\u67091300\u4e07\u72ec\u7acb\u8bbf\u95ee\u8005\u4f7f\u7528ChatGPT, \u800c\u7206\u70b8\u6027\u7684\u589e\u91cf\u4e5f\u7ed9\u8be5\u516c\u53f8\u53d1\u5c55\u5e26\u6765\u4e86\u60f3\u8c61\u7a7a \u95f4. \u81ea\u4ece ChatGPT \u51fa\u73b0\u540e. \u7a81\u7136\u4e4b\u95f4, \u6bcf\u4e2a\u4eba\u90fd\u5728\u8c08\u8bba\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u98a0\u8986\u4ed6\u4eec\u7684\u5de5\u4f5c\u3001\u516c\u53f8\u3001\u5b66\u6821\u548c\u751f\u6d3b. \u90a3\u4e48ChatGPT\u80cc\u540e\u7684\u5b9e\u73b0\u539f\u7406\u662f\u4ec0\u4e48\u5462\uff1f\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u7ed9\u5927\u5bb6\u8fdb\u884c\u8be6\u7ec6\u7684\u89e3\u6790. \u5728\u6211\u4eec\u4e86\u89e3ChatGPT\u6a21\u578b\u539f\u7406\u4e4b\u524d, \u9700\u8981\u56de\u987e\u4e0bChatGPT\u7684\u6210\u957f\u53f2, \u5373\u6211\u4eec\u9700\u8981\u5bf9GPT-1\u3001GPT-2\u3001GPT-3\u7b49\u4e00\u7cfb\u5217\u6a21\u578b\u8fdb\u884c\u4e86\u89e3\u548c\u5b66\u4e60, \u4ee5\u4fbf\u6211\u4eec\u66f4\u597d\u7684\u7406\u89e3ChatGPT\u7684\u7b97\u6cd5\u539f\u7406.","title":"1 \u4ec0\u4e48\u662fChatGPT\uff1f"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#2-gpt-1","text":"2018\u5e746\u6708, OpenAI\u516c\u53f8\u53d1\u8868\u4e86\u8bba\u6587\u201cImproving Language Understanding by Generative Pre-training\u201d\u300a\u7528\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u63d0\u9ad8\u6a21\u578b\u7684\u8bed\u8a00\u7406\u89e3\u529b\u300b, \u63a8\u51fa\u4e86\u5177\u67091.17\u4ebf\u4e2a\u53c2\u6570\u7684GPT-1\uff08Generative Pre-training , \u751f\u6210\u5f0f\u9884\u8bad\u7ec3\uff09\u6a21\u578b. \u4e0eBERT\u6700\u5927\u7684\u533a\u522b\u5728\u4e8eGPT-1\u91c7\u7528\u4e86\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u8fdb\u884c\u9884\u8bad\u7ec3, \u5373\u4f7f\u7528\u5355\u8bcd\u7684\u4e0a\u6587\u6765\u9884\u6d4b\u5355\u8bcd, \u800cBERT\u662f\u91c7\u7528\u4e86\u53cc\u5411\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\u5171\u540c\u6765\u9884\u6d4b\u5355\u8bcd. \u6b63\u662f\u56e0\u4e3a\u8bad\u7ec3\u65b9\u6cd5\u4e0a\u7684\u533a\u522b, \u4f7f\u5f97GPT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4efb\u52a1(NLG), \u800cBERT\u66f4\u64c5\u957f\u5904\u7406\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4efb\u52a1(NLU).","title":"2 GPT-1\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#21-gpt-1","text":"\u770b\u4e09\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6bd4\u67b6\u6784\u56fe, \u4e2d\u95f4\u7684\u5c31\u662fGPT-1: \u4ece\u4e0a\u56fe\u53ef\u4ee5\u5f88\u6e05\u695a\u7684\u770b\u5230GPT\u91c7\u7528\u7684\u662f\u5355\u5411Transformer\u6a21\u578b, \u4f8b\u5982\u7ed9\u5b9a\u4e00\u4e2a\u53e5\u5b50[u1, u2, ..., un], GPT\u5728\u9884\u6d4b\u5355\u8bcdui\u7684\u65f6\u5019\u53ea\u4f1a\u5229\u7528[u1, u2, ..., u(i-1)]\u7684\u4fe1\u606f, \u800cBERT\u4f1a\u540c\u65f6\u5229\u7528\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f[u1, u2, ..., u(i-1), u(i+1), ..., un]. \u4f5c\u4e3a\u4e24\u5927\u6a21\u578b\u7684\u76f4\u63a5\u5bf9\u6bd4, BERT\u91c7\u7528\u4e86Transformer\u7684Encoder\u6a21\u5757, \u800cGPT\u91c7\u7528\u4e86Transformer\u7684Decoder\u6a21\u5757. \u5e76\u4e14GPT\u7684Decoder Block\u548c\u7ecf\u5178Transformer Decoder Block\u8fd8\u6709\u6240\u4e0d\u540c, \u5982\u4e0b\u56fe\u6240\u793a: \u5982\u4e0a\u56fe\u6240\u793a, \u7ecf\u5178\u7684Transformer Decoder Block\u5305\u542b3\u4e2a\u5b50\u5c42, \u5206\u522b\u662fMasked Multi-Head Attention\u5c42, encoder-decoder attention\u5c42, \u4ee5\u53caFeed Forward\u5c42. \u4f46\u662f\u5728GPT\u4e2d\u53d6\u6d88\u4e86\u7b2c\u4e8c\u4e2aencoder-decoder attention\u5b50\u5c42, \u53ea\u4fdd\u7559Masked Multi-Head Attention\u5c42, \u548cFeed Forward\u5c42. \u6ce8\u610f: \u5bf9\u6bd4\u4e8e\u7ecf\u5178\u7684Transformer\u67b6\u6784, \u89e3\u7801\u5668\u6a21\u5757\u91c7\u7528\u4e866\u4e2aDecoder Block; GPT\u7684\u67b6\u6784\u4e2d\u91c7\u7528\u4e8612\u4e2aDecoder Block.","title":"2.1 GPT-1\u6a21\u578b\u67b6\u6784"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#22-gpt-1","text":"GPT-1\u7684\u8bad\u7ec3\u5305\u62ec\u4e24\u9636\u6bb5\u8fc7\u7a0b: \u9884\u8bad\u7ec3 + \u5fae\u8c03 - \u7b2c\u4e00\u9636\u6bb5: \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b. - \u7b2c\u4e8c\u9636\u6bb5: \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning.","title":"2.2 GPT-1\u8bad\u7ec3\u8fc7\u7a0b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#221","text":"\u7ed9\u5b9a\u53e5\u5b50U = [u1, u2, ..., un], GPT\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u4f3c\u7136\u51fd\u6570: L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) L_1(U)=\\sum_i\\log P(u_i|u_{i-k},\\cdots,u_{i-1};\\Theta) \u4e0a\u8ff0\u516c\u5f0f\u5177\u4f53\u6765\u8bf4\u662f\u8981\u9884\u6d4b\u6bcf\u4e2a\u8bcdui\u7684\u6982\u7387\uff0c\u8fd9\u4e2a\u6982\u7387\u662f\u57fa\u4e8e\u5b83\u524d\u9762 ui-k \u5230 ui\u22121 \u4e2a\u8bcd\uff0c\u4ee5\u53ca\u6a21\u578b \u0398\u3002\u8fd9\u91cc\u7684 k \u8868\u793a\u4e0a\u6587\u7684\u7a97\u53e3\u5927\u5c0f\uff0c\u7406\u8bba\u4e0a\u6765\u8bb2 k \u53d6\u7684\u8d8a\u5927\uff0c\u6a21\u578b\u6240\u80fd\u83b7\u53d6\u7684\u4e0a\u6587\u4fe1\u606f\u8d8a\u5145\u8db3\uff0c\u6a21\u578b\u7684\u80fd\u529b\u8d8a\u5f3a\u3002 GPT\u662f\u4e00\u4e2a\u5355\u5411\u8bed\u8a00\u6a21\u578b,\u6a21\u578b\u5bf9\u8f93\u5165U \u8fdb\u884c\u7279\u5f81\u5d4c\u5165\u5f97\u5230 transformer \u7b2c\u4e00\u5c42\u7684\u8f93h0\uff0c\u518d\u7ecf\u8fc7\u591a\u5c42 transformer \u7279\u5f81\u7f16\u7801\uff0c\u4f7f\u7528\u6700\u540e\u4e00\u5c42\u7684\u8f93\u51fa\u5373\u53ef\u5f97\u5230\u5f53\u524d\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff0c\u8ba1\u7b97\u8fc7\u7a0b\u5982\u4e0b\uff1a h_0 = UW_e + W_p h_0 = UW_e + W_p \u5176\u4e2dWp\u662f\u5355\u8bcd\u7684\u4f4d\u7f6e\u7f16\u7801, We\u662f\u5355\u8bcd\u672c\u8eab\u7684word embedding. Wp\u7684\u5f62\u72b6\u662f[max_seq_len, embedding_dim], We\u7684\u5f62\u72b6\u662f[vocab_size, embedding_dim]. \u5f97\u5230\u8f93\u5165\u5f20\u91cfh0\u540e, \u8981\u5c06h0\u4f20\u5165GPT\u7684Decoder Block\u4e2d, \u4f9d\u6b21\u5f97\u5230ht: h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] h_t = transformer\\_block(h_{l-1})\\;\\;\\;\\;l\\in[1,t] \u6700\u540e\u901a\u8fc7\u5f97\u5230\u7684ht\u6765\u9884\u6d4b\u4e0b\u4e00\u4e2a\u5355\u8bcd: P(u)=softmax(h_tW_e^T) P(u)=softmax(h_tW_e^T)","title":"2.2.1 \u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#222-fine-tunning","text":"GPT\u7ecf\u8fc7\u9884\u8bad\u7ec3\u540e, \u4f1a\u9488\u5bf9\u5177\u4f53\u7684\u4e0b\u6e38\u4efb\u52a1\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03. \u5fae\u8c03\u91c7\u7528\u7684\u662f\u6709\u76d1\u7763\u5b66\u4e60, \u8bad\u7ec3\u6837\u672c\u5305\u62ec\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u548clabel y. GPT\u5fae\u8c03\u7684\u76ee\u6807\u4efb\u52a1\u662f\u6839\u636e\u5355\u8bcd\u5e8f\u5217[x1, x2, ..., xn]\u9884\u6d4b\u6807\u7b7ey. P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) P(y|x^1,\\cdots,x^m)=softmax(h_l^mW_y) \u5176\u4e2d W_y W_y \u8868\u793a\u9884\u6d4b\u8f93\u51fa\u7684\u77e9\u9635\u53c2\u6570, \u5fae\u8c03\u4efb\u52a1\u7684\u76ee\u6807\u662f\u6700\u5927\u5316\u4e0b\u9762\u7684\u51fd\u6570: L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) L_2=\\sum_{(x,y)}\\log P(y|x^1,\\cdots,x^m) \u7efc\u5408\u4e24\u4e2a\u9636\u6bb5\u7684\u76ee\u6807\u4efb\u52a1\u51fd\u6570, \u53ef\u77e5GPT\u7684\u6700\u7ec8\u4f18\u5316\u51fd\u6570\u4e3a: L_3 = L_2 + \\lambda L_1 L_3 = L_2 + \\lambda L_1","title":"2.2.2 \u6709\u76d1\u7763\u7684\u4e0b\u6e38\u4efb\u52a1fine-tunning"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#223","text":"\u6839\u636e\u4e0b\u6e38\u4efb\u52a1\u9002\u914d\u7684\u8fc7\u7a0b\u5206\u4e24\u6b65: 1\u3001\u6839\u636e\u4efb\u52a1\u5b9a\u4e49\u4e0d\u540c\u8f93\u5165, 2\u3001\u5bf9\u4e0d\u540c\u4efb\u52a1\u589e\u52a0\u4e0d\u540c\u7684\u5206\u7c7b\u5c42. \u5177\u4f53\u5b9a\u4e49\u53ef\u4ee5\u53c2\u89c1\u4e0b\u56fe: \u5206\u7c7b\u4efb\u52a1\uff08Classification\uff09: \u5c06\u8d77\u59cb\u548c\u7ec8\u6b62token\u52a0\u5165\u5230\u539f\u59cb\u5e8f\u5217\u4e24\u7aef, \u8f93\u5165transformer\u4e2d\u5f97\u5230\u7279\u5f81\u5411\u91cf, \u6700\u540e\u7ecf\u8fc7\u4e00\u4e2a\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7684\u6982\u7387\u5206\u5e03\uff1b \u6587\u672c\u8574\u6db5\uff08Entailment\uff09: \u5c06\u524d\u63d0\uff08premise\uff09\u548c\u5047\u8bbe\uff08hypothesis\uff09\u901a\u8fc7\u5206\u9694\u7b26\uff08Delimiter\uff09\u9694\u5f00, \u4e24\u7aef\u52a0\u4e0a\u8d77\u59cb\u548c\u7ec8\u6b62token. \u518d\u4f9d\u6b21\u901a\u8fc7transformer\u548c\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u6587\u672c\u76f8\u4f3c\u5ea6\uff08Similarity\uff09: \u8f93\u5165\u7684\u4e24\u4e2a\u53e5\u5b50, \u6b63\u5411\u548c\u53cd\u5411\u5404\u62fc\u63a5\u4e00\u6b21, \u7136\u540e\u5206\u522b\u8f93\u5165\u7ed9transformer, \u5f97\u5230\u7684\u7279\u5f81\u5411\u91cf\u62fc\u63a5\u540e\u518d\u9001\u7ed9\u5168\u8fde\u63a5\u5f97\u5230\u9884\u6d4b\u7ed3\u679c\uff1b \u95ee\u7b54\u548c\u5e38\u8bc6\u63a8\u7406\uff08Multiple-Choice\uff09: \u5c06 N\u4e2a\u9009\u9879\u7684\u95ee\u9898\u62bd\u8c61\u5316\u4e3aN\u4e2a\u4e8c\u5206\u7c7b\u95ee\u9898, \u5373\u6bcf\u4e2a\u9009\u9879\u5206\u522b\u548c\u5185\u5bb9\u8fdb\u884c\u62fc\u63a5, \u7136\u540e\u5404\u9001\u5165transformer\u548c\u5168\u8fde\u63a5\u4e2d, \u6700\u540e\u9009\u62e9\u7f6e\u4fe1\u5ea6\u6700\u9ad8\u7684\u4f5c\u4e3a\u9884\u6d4b\u7ed3\u679c \u603b\u7684\u6765\u8bf4\uff0c\u90fd\u662f\u901a\u8fc7\u5728\u5e8f\u5217\u524d\u540e\u6dfb\u52a0 Start \u548c Extract \u7279\u6b8a\u6807\u8bc6\u7b26\u6765\u8868\u793a\u5f00\u59cb\u548c\u7ed3\u675f\uff0c\u5e8f\u5217\u4e4b\u95f4\u6dfb\u52a0\u5fc5\u8981\u7684 Delim \u6807\u8bc6\u7b26\u6765\u8868\u793a\u5206\u9694\uff0c\u5f53\u7136\u5b9e\u9645\u4f7f\u7528\u65f6\u4e0d\u4f1a\u76f4\u63a5\u7528 \u201cStart/Extract/Delim\u201d \u8fd9\u51e0\u4e2a\u8bcd\uff0c\u800c\u662f\u4f7f\u7528\u67d0\u4e9b\u7279\u6b8a\u7b26\u53f7\u3002\u57fa\u4e8e\u4e0d\u540c\u4e0b\u6e38\u4efb\u52a1\u6784\u9020\u7684\u8f93\u5165\u5e8f\u5217\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684 GPT \u6a21\u578b\u8fdb\u884c\u7279\u5f81\u7f16\u7801\uff0c\u7136\u540e\u4f7f\u7528\u5e8f\u5217\u6700\u540e\u4e00\u4e2a token \u7684\u7279\u5f81\u5411\u91cf\u8fdb\u884c\u9884\u6d4b\u3002 \u53ef\u4ee5\u770b\u5230\uff0c\u4e0d\u8bba\u4e0b\u6e38\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u600e\u4e48\u53d8\uff0c\u6700\u540e\u7684\u9884\u6d4b\u5c42\u600e\u4e48\u53d8\uff0c\u4e2d\u95f4\u7684\u7279\u5f81\u62bd\u53d6\u6a21\u5757\u90fd\u662f\u4e0d\u53d8\u7684\uff0c\u5177\u6709\u5f88\u597d\u7684\u8fc1\u79fb\u80fd\u529b\u3002","title":"2.2.3 \u6574\u4f53\u8bad\u7ec3\u8fc7\u7a0b\u67b6\u6784\u56fe"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#23-gpt-1","text":"GPT-1\u4f7f\u7528\u4e86BooksCorpus\u6570\u636e\u96c6, \u6587\u672c\u5927\u5c0f\u7ea6 5 GB\uff0c\u5305\u542b 7400w+ \u7684\u53e5\u5b50\u3002\u8fd9\u4e2a\u6570\u636e\u96c6\u7531 7000 \u672c\u72ec\u7acb\u7684\u3001\u4e0d\u540c\u98ce\u683c\u7c7b\u578b\u7684\u4e66\u7c4d\u7ec4\u6210, \u9009\u62e9\u8be5\u90e8\u5206\u6570\u636e\u96c6\u7684\u539f\u56e0: - \u4e66\u7c4d\u6587\u672c\u5305\u542b\u5927\u91cf\u9ad8\u8d28\u91cf\u957f\u53e5\uff0c\u4fdd\u8bc1\u6a21\u578b\u5b66\u4e60\u957f\u8ddd\u79bb\u4fe1\u606f\u4f9d\u8d56\u3002 - \u8fd9\u4e9b\u4e66\u7c4d\u56e0\u4e3a\u6ca1\u6709\u53d1\u5e03, \u6240\u4ee5\u5f88\u96be\u5728\u4e0b\u6e38\u6570\u636e\u96c6\u4e0a\u89c1\u5230, \u66f4\u80fd\u9a8c\u8bc1\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b.","title":"2.3  GPT-1\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#24-gpt-1","text":"\u6a21\u578b\u7684\u4e00\u4e9b\u5173\u952e\u53c2\u6570\u4e3a\uff1a \u53c2\u6570 \u53d6\u503c transformer \u5c42\u6570 12 \u7279\u5f81\u7ef4\u5ea6 768 transformer head \u6570 12 \u603b\u53c2\u6570\u91cf 1.17 \u4ebf \u4f18\u70b9\uff1a \u5728\u6709\u76d1\u7763\u5b66\u4e60\u768412\u4e2a\u4efb\u52a1\u4e2d, GPT-1\u57289\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8d85\u8fc7\u4e86state-of-the-art\u7684\u6a21\u578b \u5229\u7528Transformer\u505a\u7279\u5f81\u62bd\u53d6, \u80fd\u591f\u6355\u6349\u5230\u66f4\u957f\u7684\u8bb0\u5fc6\u4fe1\u606f, \u4e14\u8f83\u4f20\u7edf\u7684 RNN \u66f4\u6613\u4e8e\u5e76\u884c\u5316 \u7f3a\u70b9\uff1a GPT \u6700\u5927\u7684\u95ee\u9898\u5c31\u662f\u4f20\u7edf\u7684\u8bed\u8a00\u6a21\u578b\u662f\u5355\u5411\u7684. \u9488\u5bf9\u4e0d\u540c\u7684\u4efb\u52a1, \u9700\u8981\u4e0d\u540c\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u5fae\u8c03, \u76f8\u5bf9\u6bd4\u8f83\u9ebb\u70e6","title":"2.4 GPT-1\u6a21\u578b\u7684\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#25-gpt-1","text":"GPT-1\u8bc1\u660e\u4e86transformer\u5bf9\u5b66\u4e60\u8bcd\u5411\u91cf\u7684\u5f3a\u5927\u80fd\u529b, \u5728GPT-1\u5f97\u5230\u7684\u8bcd\u5411\u91cf\u57fa\u7840\u4e0a\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\u7684\u5b66\u4e60, \u80fd\u591f\u8ba9\u4e0b\u6e38\u4efb\u52a1\u53d6\u5f97\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b. \u5bf9\u4e8e\u4e0b\u6e38\u4efb\u52a1\u7684\u8bad\u7ec3, GPT-1\u5f80\u5f80\u53ea\u9700\u8981\u7b80\u5355\u7684\u5fae\u8c03\u4fbf\u80fd\u53d6\u5f97\u975e\u5e38\u597d\u7684\u6548\u679c. GPT-1\u5728\u672a\u7ecf\u5fae\u8c03\u7684\u4efb\u52a1\u4e0a\u867d\u7136\u4e5f\u6709\u4e00\u5b9a\u6548\u679c, \u4f46\u662f\u5176\u6cdb\u5316\u80fd\u529b\u8fdc\u8fdc\u4f4e\u4e8e\u7ecf\u8fc7\u5fae\u8c03\u7684\u6709\u76d1\u7763\u4efb\u52a1, \u8bf4\u660e\u4e86GPT-1\u53ea\u662f\u4e00\u4e2a\u7b80\u5355\u7684\u9886\u57df\u4e13\u5bb6, \u800c\u975e\u901a\u7528\u7684\u8bed\u8a00\u5b66\u5bb6.","title":"2.5 GPT-1\u6a21\u578b\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#3-gpt-2","text":"2019\u5e742\u6708, OpenAI\u63a8\u51fa\u4e86GPT-2, \u540c\u65f6, \u4ed6\u4eec\u53d1\u8868\u4e86\u4ecb\u7ecd\u8fd9\u4e2a\u6a21\u578b\u7684\u8bba\u6587\u201cLanguage Models are Unsupervised Multitask Learners\u201d \uff08\u8bed\u8a00\u6a21\u578b\u662f\u65e0\u76d1\u7763\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u8005\uff09. \u76f8\u6bd4\u4e8eGPT-1, GPT-2\u7a81\u51fa\u7684\u6838\u5fc3\u601d\u60f3\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60, \u5176\u76ee\u6807\u65e8\u5728\u4ec5\u91c7\u7528\u65e0\u76d1\u7763\u9884\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u7684\u8bed\u8a00\u6a21\u578b, \u76f4\u63a5\u5e94\u7528\u5230\u4e0b\u6e38\u4efb\u52a1\u4e2d. GPT-2\u5e76\u6ca1\u6709\u5bf9GPT-1\u7684\u7f51\u7edc\u7ed3\u6784\u8fdb\u884c\u8fc7\u591a\u7684\u521b\u65b0\u4e0e\u8bbe\u8ba1, \u800c\u662f\u4f7f\u7528\u4e86\u66f4\u591a\u7684\u7f51\u7edc\u53c2\u6570\u4e0e\u66f4\u5927\u7684\u6570\u636e\u96c6: \u6700\u5927\u6a21\u578b\u5171\u8ba148\u5c42, \u53c2\u6570\u91cf\u8fbe15\u4ebf.","title":"3 GPT-2\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#31-gpt-2","text":"\u5728\u6a21\u578b\u65b9\u9762\u76f8\u5bf9\u4e8e GPT-1 \u6765\u8bf4GPT-2\u505a\u4e86\u5fae\u5c0f\u7684\u6539\u52a8: LN\u5c42\u88ab\u653e\u7f6e\u5728Self-Attention\u5c42\u548cFeed Forward\u5c42\u524d, \u800c\u4e0d\u662f\u50cf\u539f\u6765\u90a3\u6837\u540e\u7f6e\uff08\u76ee\u7684\uff1a\u968f\u7740\u6a21\u578b\u5c42\u6570\u4e0d\u65ad\u589e\u52a0\uff0c\u68af\u5ea6\u6d88\u5931\u548c\u68af\u5ea6\u7206\u70b8\u7684\u98ce\u9669\u8d8a\u6765\u8d8a\u5927\uff0c\u8fd9\u4e9b\u8c03\u6574\u80fd\u591f**\u51cf\u5c11\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5404\u5c42\u4e4b\u95f4\u7684\u65b9\u5dee\u53d8\u5316\uff0c\u4f7f\u68af\u5ea6\u66f4\u52a0\u7a33\u5b9a**\uff09 \u5728\u6700\u540e\u4e00\u5c42Tansfomer Block\u540e\u589e\u52a0\u4e86LN\u5c42 \u8f93\u5165\u5e8f\u5217\u7684\u6700\u5927\u957f\u5ea6\u4ece 512 \u6269\u5145\u5230 1024;","title":"3.1 GPT-2\u6a21\u578b\u67b6\u6784"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#32-gpt-2","text":"\u76ee\u524d\u5927\u90e8\u5206 NLP \u6a21\u578b\u662f\u7ed3\u5408\u65e0\u76d1\u7763\u7684 Pre-training \u548c\u76d1\u7763\u5b66\u4e60\u7684 Fune-tuning, \u4f46\u8fd9\u79cd\u65b9\u6cd5\u7684\u7f3a\u70b9\u662f\u9488\u5bf9\u67d0\u7279\u5b9a\u4efb\u52a1\u9700\u8981\u4e0d\u540c\u7c7b\u578b\u6807\u6ce8\u597d\u7684\u8bad\u7ec3\u6570\u636e. GPT-2\u7684\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u662f\u72ed\u9698\u7684\u4e13\u5bb6\u800c\u4e0d\u662f\u901a\u624d, \u56e0\u6b64\u8be5\u4f5c\u8005\u5e0c\u671b\u80fd\u591f\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u51fa\u4e00\u4e2a\u53ef\u4ee5\u5e94\u5bf9\u591a\u79cd\u4efb\u52a1\u7684\u901a\u7528\u7cfb\u7edf. \u6807\u9898\u4e2d\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u4e0e\u6211\u4eec\u5e38\u89c4\u7406\u89e3\u7684\u6709\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u591a\u4efb\u52a1\u4e0d\u592a\u4e00\u6837\uff0c\u8fd9\u91cc\u4e3b\u8981\u662f\u6307\u6a21\u578b\u4ece\u5927\u89c4\u6a21\u6570\u636e\u4e2d\u5b66\u5230\u7684\u80fd\u529b\u80fd\u591f\u76f4\u63a5\u5728\u591a\u4e2a\u4efb\u52a1\u4e4b\u95f4\u8fdb\u884c\u8fc1\u79fb\uff0c\u800c\u4e0d\u9700\u8981\u989d\u5916\u63d0\u4f9b\u7279\u5b9a\u4efb\u52a1\u7684\u6570\u636e\uff0c\u56e0\u6b64\u5f15\u51fa\u4e86 GPT-2 \u7684\u4e3b\u8981\u89c2\u70b9\uff1a zero-shot \u3002\u901a\u8fc7 zero-shot\uff0c\u5728\u8fc1\u79fb\u5230\u5176\u4ed6\u4efb\u52a1\u4e0a\u7684\u65f6\u5019\u4e0d\u9700\u8981\u989d\u5916\u7684\u6807\u6ce8\u6570\u636e\uff0c\u4e5f\u4e0d\u9700\u8981\u989d\u5916\u7684\u6a21\u578b\u8bad\u7ec3\u3002 \u56e0\u6b64, GPT-2\u7684\u8bad\u7ec3\u53bb\u6389\u4e86Fune-tuning\u53ea\u5305\u62ec\u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u8fc7\u7a0b, \u548cGPT-1\u7b2c\u4e00\u9636\u6bb5\u8bad\u7ec3\u4e00\u6837, \u4e5f\u5c5e\u4e8e\u4e00\u4e2a\u5355\u5411\u8bed\u8a00\u6a21\u578b \u7406\u89e3GPT-2\u6a21\u578b\u7684\u5b66\u4e60\u76ee\u6807: \u4f7f\u7528\u65e0\u76d1\u7763\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u505a\u6709\u76d1\u7763\u7684\u4efb\u52a1. \u8bed\u8a00\u6a21\u578b\u5176\u5b9e\u4e5f\u662f\u5728\u7ed9\u5e8f\u5217\u7684\u6761\u4ef6\u6982\u7387\u5efa\u6a21, \u5373p(sn|s1,s2,...,sn\u22121) \u5728 GPT-1 \u4e2d\uff0c\u4e0b\u6e38\u4efb\u52a1\u9700\u8981\u5bf9\u4e0d\u540c\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u6539\u9020\uff0c\u5728\u5e8f\u5217\u4e2d\u52a0\u5165\u4e86\u5f00\u59cb\u7b26\u3001\u5206\u9694\u7b26\u548c\u7ed3\u675f\u7b26\u4e4b\u7c7b\u7684\u7279\u6b8a\u6807\u8bc6\u7b26\uff0c\u4f46\u662f\u5728 zero-shot \u524d\u63d0\u4e0b\uff0c\u6211\u4eec\u65e0\u6cd5\u6839\u636e\u4e0d\u540c\u7684\u4e0b\u6e38\u4efb\u52a1\u53bb\u6dfb\u52a0\u8fd9\u4e9b\u6807\u8bc6\u7b26\uff0c\u56e0\u4e3a\u4e0d\u8fdb\u884c\u989d\u5916\u7684\u5fae\u8c03\u8bad\u7ec3\uff0c\u6a21\u578b\u5728\u9884\u6d4b\u7684\u65f6\u5019\u6839\u672c\u4e0d\u8ba4\u8bc6\u8fd9\u4e9b\u7279\u6b8a\u6807\u8bb0\u3002\u6240\u4ee5\u5728 zero-shot \u7684\u8bbe\u5b9a\u4e0b\uff0c\u4e0d\u540c\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u5e94\u8be5\u4e0e\u8bad\u7ec3\u65f6\u89c1\u5230\u7684\u6587\u672c\u957f\u5f97\u4e00\u6837\uff0c\u4e5f\u5c31\u662f\u4ee5\u81ea\u7136\u8bed\u8a00\u7684\u5f62\u5f0f\u53bb\u4f5c\u4e3a\u8f93\u5165\uff0c\u4f8b\u5982\u4e0b\u9762\u4e24\u4e2a\u4efb\u52a1\u7684\u8f93\u5165\u5e8f\u5217\u662f\u8fd9\u6837\u6539\u9020\u7684\uff1a \u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\uff1atranslate to french, { english text }, { french text } \u9605\u8bfb\u7406\u89e3\u4efb\u52a1\uff1aanswer the question, { document }, { question }, { answer } \u4e3a\u4ec0\u4e48\u4e0a\u8ff0\u8f93\u5165\u5e8f\u5217\u7684\u6539\u9020\u662f\u6709\u6548\u7684\uff1f\u6216\u8005\u8bf4\u4e3a\u4ec0\u4e48 zero-shot \u662f\u6709\u6548\u7684\uff1f\u8fd9\u91cc\u5f15\u7528\u539f\u6587\u7684\u4e00\u53e5\u8bdd\uff1a Our approach motivates building as large and diverse a dataset as possible in order to collect natural language demonstrations of tasks in as varied of domains and contexts as possible. \u5927\u6982\u610f\u601d\u662f\uff0c\u4ece\u4e00\u4e2a\u5c3d\u53ef\u80fd\u5927\u4e14\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\u4e2d\u4e00\u5b9a\u80fd\u6536\u96c6\u5230\u4e0d\u540c\u9886\u57df\u4e0d\u540c\u4efb\u52a1\u76f8\u5173\u7684\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u793a\u4f8b\uff0c\u4f8b\u5982\u4e0b\u56fe\u4e2d\u5c55\u793a\u4e86\u82f1\u6cd5\u4e92\u8bd1\u4efb\u52a1\u5728\u81ea\u7136\u8bed\u8a00\u4e2d\u51fa\u73b0\u7684\u793a\u4f8b\uff0c\u8868\u660e\u4e86\u4e0d\u540c\u4efb\u52a1\u7684\u4efb\u52a1\u63cf\u8ff0\u5728\u8bed\u6599\u4e2d\u771f\u5b9e\u5b58\u5728\uff1a \u6240\u4ee5 GPT-2 \u7684\u6838\u5fc3\u601d\u60f3\u5c31\u662f\uff0c \u5f53\u6a21\u578b\u7684\u5bb9\u91cf\u975e\u5e38\u5927\u4e14\u6570\u636e\u91cf\u8db3\u591f\u4e30\u5bcc\u65f6\uff0c\u4ec5\u4ec5\u9760\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u4fbf\u53ef\u4ee5\u5b8c\u6210\u5176\u4ed6\u6709\u76d1\u7763\u5b66\u4e60\u7684\u4efb\u52a1\uff0c\u4e0d\u9700\u8981\u5728\u4e0b\u6e38\u4efb\u52a1\u5fae\u8c03 \u3002 \u7efc\u4e0a, GPT-2\u7684\u6838\u5fc3\u601d\u60f3\u6982\u62ec\u4e3a: \u4efb\u4f55\u6709\u76d1\u7763\u4efb\u52a1\u90fd\u662f\u8bed\u8a00\u6a21\u578b\u7684\u4e00\u4e2a\u5b50\u96c6, \u5f53\u6a21\u578b\u7684\u5bb9\u91cf\u975e\u5e38\u5927\u4e14\u6570\u636e\u91cf\u8db3\u591f\u4e30\u5bcc\u65f6, \u4ec5\u4ec5\u9760\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u4fbf\u53ef\u4ee5\u5b8c\u6210\u5176\u4ed6\u6709\u76d1\u7763\u5b66\u4e60\u7684\u4efb\u52a1.","title":"3.2 GPT-2\u8bad\u7ec3\u6838\u5fc3\u601d\u60f3"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#33-gpt-2","text":"\u4e3a\u4e86\u4fdd\u8bc1 zero-shot \u7684\u6548\u679c\uff0c\u5fc5\u987b\u8981\u8db3\u591f\u5927\u4e14\u8986\u76d6\u9762\u5e7f\u3002\u6240\u4ee5 GPT-2 \u4e13\u95e8\u722c\u53d6\u4e86\u5927\u91cf\u7684\u7f51\u7edc\u6587\u672c\u6570\u636e\uff0cGPT-2\u7684\u6587\u7ae0\u53d6\u81ea\u4e8eReddit\u4e0a\u9ad8\u8d5e\u7684\u6587\u7ae0, \u547d\u540d\u4e3aWebText. \u6570\u636e\u96c6\u5171\u6709\u7ea6800\u4e07\u7bc7\u6587\u7ae0, \u7d2f\u8ba1\u4f53\u79ef\u7ea640G. \u4e3a\u4e86\u907f\u514d\u548c\u6d4b\u8bd5\u96c6\u7684\u51b2\u7a81, WebText\u79fb\u9664\u4e86\u6d89\u53caWikipedia\u7684\u6587\u7ae0.","title":"3.3 GPT-2\u7684\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#34-gpt-2","text":"\u4e0eGPT-1\u7684\u533a\u522b\uff1a \u4e3b\u63a8 zero-shot\uff0c\u800c GPT-1 \u4e3a pre-train + fine-tuning\uff1b \u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u66f4\u5927\uff0cGPT-2 \u4e3a 800w \u6587\u6863 40G\uff0cGPT-1 \u4e3a 5GB\uff1b \u6a21\u578b\u5927\u5c0f\uff0cGPT-2 \u6700\u5927 15 \u4ebf\u53c2\u6570\uff0cGPT-1\u4e3a 1 \u4ebf\u53c2\u6570\uff1b \u6a21\u578b\u7ed3\u6784\u8c03\u6574\uff0c\u5c42\u5f52\u4e00\u5316\uff1b \u8bad\u7ec3\u53c2\u6570\uff0cbatch_size \u4ece 64 \u589e\u52a0\u5230 512\uff0c\u4e0a\u6587\u7a97\u53e3\u5927\u5c0f\u4ece 512 \u589e\u52a0\u5230 1024\uff0c\u7b49\u7b49\uff1b \u4f18\u70b9\uff1a \u6587\u672c\u751f\u6210\u6548\u679c\u597d, \u57288\u4e2a\u8bed\u8a00\u6a21\u578b\u4efb\u52a1\u4e2d, \u4ec5\u4ec5\u901a\u8fc7zero-shot\u5b66\u4e60, GPT-2\u5c31\u67097\u4e2a\u8d85\u8fc7\u4e86state-of-the-art\u7684\u65b9\u6cd5. \u6d77\u91cf\u6570\u636e\u548c\u5927\u91cf\u53c2\u6570\u8bad\u7ec3\u51fa\u6765\u7684\u8bcd\u5411\u91cf\u6a21\u578b\u6709\u8fc1\u79fb\u5230\u5176\u5b83\u7c7b\u522b\u4efb\u52a1\u4e2d\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3. \u7f3a\u70b9: \u65e0\u76d1\u7763\u5b66\u4e60\u80fd\u529b\u6709\u5f85\u63d0\u5347 \u6709\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u5982\u968f\u673a","title":"3.4 GPT-2\u6a21\u578b\u7684\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#35-gpt-2","text":"GPT-2\u7684\u6700\u5927\u8d21\u732e\u662f\u9a8c\u8bc1\u4e86\u901a\u8fc7\u6d77\u91cf\u6570\u636e\u548c\u5927\u91cf\u53c2\u6570\u8bad\u7ec3\u51fa\u6765\u7684\u8bcd\u5411\u91cf\u6a21\u578b\u6709\u8fc1\u79fb\u5230\u5176\u5b83\u7c7b\u522b\u4efb\u52a1\u4e2d\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3. \u4f46\u662f\u5f88\u591a\u5b9e\u9a8c\u4e5f\u8868\u660e, GPT-2\u7684\u65e0\u76d1\u7763\u5b66\u4e60\u7684\u80fd\u529b\u8fd8\u6709\u5f88\u5927\u7684\u63d0\u5347\u7a7a\u95f4, \u751a\u81f3\u5728\u6709\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u6bd4\u968f\u673a\u7684\u597d. \u5c3d\u7ba1\u5728\u6709\u4e9bzero-shot\u7684\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u9519, \u4f46\u662f\u6211\u4eec\u4ecd\u4e0d\u6e05\u695aGPT-2\u7684\u8fd9\u79cd\u7b56\u7565\u7a76\u7adf\u80fd\u505a\u6210\u4ec0\u4e48\u6837\u5b50. GPT-2\u8868\u660e\u968f\u7740\u6a21\u578b\u5bb9\u91cf\u548c\u6570\u636e\u91cf\u7684\u589e\u5927, \u5176\u6f5c\u80fd\u8fd8\u6709\u8fdb\u4e00\u6b65\u5f00\u53d1\u7684\u7a7a\u95f4, \u57fa\u4e8e\u8fd9\u4e2a\u601d\u60f3, \u8bde\u751f\u4e86\u6211\u4eec\u4e0b\u9762\u8981\u4ecb\u7ecd\u7684GPT-3.","title":"3.5 GPT-2\u6a21\u578b\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#4-gpt-3","text":"2020\u5e745\u6708, OpenAI\u53d1\u5e03\u4e86GPT-3, \u540c\u65f6\u53d1\u8868\u4e86\u8bba\u6587\u201cLanguage Models are Few-Shot Learner\u201d\u300a\u5c0f\u6837\u672c\u5b66\u4e60\u8005\u7684\u8bed\u8a00\u6a21\u578b\u300b. \u901a\u8fc7\u8bba\u6587\u9898\u76ee\u53ef\u4ee5\u770b\u51fa\uff1aGPT-3 \u4e0d\u518d\u53bb\u8ffd\u6c42\u90a3\u79cd\u6781\u81f4\u7684\u4e0d\u9700\u8981\u4efb\u4f55\u6837\u672c\u5c31\u53ef\u4ee5\u8868\u73b0\u5f88\u597d\u7684\u6a21\u578b\uff0c\u800c\u662f\u8003\u8651\u50cf\u4eba\u7c7b\u7684\u5b66\u4e60\u65b9\u5f0f\u90a3\u6837\uff0c\u4ec5\u4ec5\u4f7f\u7528**\u6781\u5c11\u6570\u6837\u672c**\u5c31\u53ef\u4ee5\u638c\u63e1\u67d0\u4e00\u4e2a\u4efb\u52a1\uff0c\u4f46\u662f\u8fd9\u91cc\u7684 few-shot \u4e0d\u662f\u50cf\u4e4b\u524d\u7684\u65b9\u5f0f\u90a3\u6837\uff0c\u4f7f\u7528\u5c11\u91cf\u6837\u672c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e0a\u53bb\u505a\u5fae\u8c03\uff0c\u56e0\u4e3a\u5728 GPT-3 \u90a3\u6837\u7684\u53c2\u6570\u89c4\u6a21\u4e0b\uff0c\u5373\u4f7f\u662f\u53c2\u6570\u5fae\u8c03\u7684\u6210\u672c\u4e5f\u662f\u9ad8\u5230\u65e0\u6cd5\u4f30\u8ba1\u3002 GPT-3 \u4f5c\u4e3a\u5176\u5148\u524d\u8bed\u8a00\u6a21\u578b (LM) GPT-2 \u7684\u7ee7\u627f\u8005. \u5b83\u88ab\u8ba4\u4e3a\u6bd4GPT-2\u66f4\u597d\u3001\u66f4\u5927. \u4e8b\u5b9e\u4e0a, \u4e0e\u4ed6\u8bed\u8a00\u6a21\u578b\u76f8\u6bd4, OpenAI GPT-3 \u7684\u5b8c\u6574\u7248\u62e5\u6709\u5927\u7ea6 1750 \u4ebf\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570, \u662f\u8fc4\u4eca\u4e3a\u6b62\u8bad\u7ec3\u7684\u6700\u5927\u6a21\u578b, \u8fd9\u4efd 72 \u9875\u7684 \u7814\u7a76\u8bba\u6587 \u975e\u5e38\u8be6\u7ec6\u5730\u63cf\u8ff0\u4e86\u8be5\u6a21\u578b\u7684\u7279\u6027\u3001\u529f\u80fd\u3001\u6027\u80fd\u548c\u5c40\u9650\u6027. \u4e0b\u56fe\u4e3a\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u8bad\u7ec3\u53c2\u6570\u7684\u5bf9\u6bd4:","title":"4 GPT-3\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#41-gpt-3","text":"\u5b9e\u9645\u4e0aGPT-3 \u4e0d\u662f\u4e00\u4e2a\u5355\u4e00\u7684\u6a21\u578b, \u800c\u662f\u4e00\u4e2a\u6a21\u578b\u7cfb\u5217. \u7cfb\u5217\u4e2d\u7684\u6bcf\u4e2a\u6a21\u578b\u90fd\u6709\u4e0d\u540c\u6570\u91cf\u7684\u53ef\u8bad\u7ec3\u53c2\u6570. \u4e0b\u8868\u663e\u793a\u4e86\u6bcf\u4e2a\u6a21\u578b\u3001\u4f53\u7cfb\u7ed3\u6784\u53ca\u5176\u5bf9\u5e94\u7684\u53c2\u6570: \u5728\u6a21\u578b\u7ed3\u6784\u4e0a\uff0cGPT-3 \u5ef6\u7eed\u4f7f\u7528 GPT \u6a21\u578b\u7ed3\u6784\uff0c\u4f46\u662f\u5f15\u5165\u4e86 Sparse Transformer \u4e2d\u7684 sparse attention \u6a21\u5757\uff08\u7a00\u758f\u6ce8\u610f\u529b\uff09\u3002 sparse attention \u4e0e\u4f20\u7edf self-attention\uff08\u79f0\u4e3a dense attention\uff09 \u7684\u533a\u522b\u5728\u4e8e\uff1a dense attention\uff1a\u6bcf\u4e2a token \u4e4b\u95f4\u4e24\u4e24\u8ba1\u7b97 attention\uff0c\u590d\u6742\u5ea6 O(n\u00b2) sparse attention\uff1a\u6bcf\u4e2a token \u53ea\u4e0e\u5176\u4ed6 token \u7684\u4e00\u4e2a\u5b50\u96c6\u8ba1\u7b97 attention\uff0c\u590d\u6742\u5ea6 O(n*logn) \u5177\u4f53\u6765\u8bf4\uff0csparse attention \u9664\u4e86\u76f8\u5bf9\u8ddd\u79bb\u4e0d\u8d85\u8fc7 k \u4ee5\u53ca\u76f8\u5bf9\u8ddd\u79bb\u4e3a k\uff0c2k\uff0c3k\uff0c... \u7684 token\uff0c\u5176\u4ed6\u6240\u6709 token \u7684\u6ce8\u610f\u529b\u90fd\u8bbe\u4e3a 0\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a \u4f7f\u7528 sparse attention \u7684\u597d\u5904\u4e3b\u8981\u6709\u4ee5\u4e0b\u4e24\u70b9\uff1a \u51cf\u5c11\u6ce8\u610f\u529b\u5c42\u7684\u8ba1\u7b97\u590d\u6742\u5ea6 \uff0c\u8282\u7ea6\u663e\u5b58\u548c\u8017\u65f6\uff0c\u4ece\u800c\u80fd\u591f\u5904\u7406\u66f4\u957f\u7684\u8f93\u5165\u5e8f\u5217\uff1b \u5177\u6709\u201c\u5c40\u90e8\u7d27\u5bc6\u76f8\u5173\u548c\u8fdc\u7a0b\u7a00\u758f\u76f8\u5173\u201d\u7684\u7279\u6027 \uff0c\u5bf9\u4e8e\u8ddd\u79bb\u8f83\u8fd1\u7684\u4e0a\u4e0b\u6587\u5173\u6ce8\u66f4\u591a\uff0c\u5bf9\u4e8e\u8ddd\u79bb\u8f83\u8fdc\u7684\u4e0a\u4e0b\u6587\u5173\u6ce8\u8f83\u5c11\uff1b \u5176\u4e2d\u6700\u5927\u7248\u672c GPT-3 175B \u6216\u201cGPT-3\u201d\u5177\u6709175\u4e2aB\u53c2\u6570\u300196\u5c42\u7684\u591a\u5934Transformer\u3001Head size\u4e3a96\u3001\u8bcd\u5411\u91cf\u7ef4\u5ea6\u4e3a12288\u3001\u6587\u672c\u957f\u5ea6\u5927\u5c0f\u4e3a2048.","title":"4.1 GPT-3\u6a21\u578b\u67b6\u6784"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#42-gpt-3","text":"GPT-3\u6a21\u578b\u8bad\u7ec3\u7684\u601d\u60f3\u4e0eGPT-2\u7684\u65b9\u6cd5\u76f8\u4f3c, \u53bb\u9664\u4e86fine-tune\u8fc7\u7a0b, \u53ea\u5305\u62ec\u9884\u8bad\u7ec3\u8fc7\u7a0b, \u4e0d\u540c\u53ea\u5728\u4e8e\u91c7\u7528\u4e86\u53c2\u6570\u66f4\u591a\u7684\u6a21\u578b\u3001\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u96c6\u548c\u66f4\u957f\u7684\u8bad\u7ec3\u7684\u8fc7\u7a0b. \u4f46\u662fGPT-3 \u6a21\u578b\u5728\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\u8bc4\u4f30\u548c\u9884\u6d4b\u65f6\u91c7\u7528\u4e86\u4e09\u79cd\u65b9\u6cd5, \u4ed6\u4eec\u5206\u522b\u662f: Few-shot\u3001One-shot\u3001Zero-shot. \u5176\u4e2d Few-shot\u3001One-shot\u4e5f\u88ab\u79f0\u4e4b\u4e3a\u60c5\u5883\u5b66\u4e60(in-context learning\uff0c\u4e5f\u53ef\u79f0\u4e4b\u4e3a\u63d0\u793a\u5b66\u4e60). \u60c5\u5883\u5b66\u4e60\u7406\u89e3: \u5728\u88ab\u7ed9\u5b9a\u7684\u51e0\u4e2a\u4efb\u52a1\u793a\u4f8b\u6216\u4e00\u4e2a\u4efb\u52a1\u8bf4\u660e\u7684\u60c5\u51b5\u4e0b, \u6a21\u578b\u5e94\u8be5\u80fd\u901a\u8fc7\u7b80\u5355\u9884\u6d4b\u4ee5\u8865\u5168\u4efb\u52a1\u4e2d\u5176\u4ed6\u7684\u5b9e\u4f8b. \u5373\u60c5\u5883\u5b66\u4e60\u8981\u6c42\u9884\u8bad\u7ec3\u6a21\u578b\u8981\u5bf9\u4efb\u52a1\u672c\u8eab\u8fdb\u884c\u7406\u89e3. In-context learnin\u6838\u5fc3\u601d\u60f3\u5728\u4e8e\u901a\u8fc7\u5c11\u91cf\u7684\u6570\u636e\u5bfb\u627e\u4e00\u4e2a\u5408\u9002\u7684\u521d\u59cb\u5316\u8303\u56f4\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5728\u6709\u9650\u7684\u6570\u636e\u96c6\u4e0a\u5feb\u901f\u62df\u5408\uff0c\u5e76\u83b7\u5f97\u4e0d\u9519\u7684\u6548\u679c\u3002 \u4e0b\u9762\u4ee5\u4ece\u201c\u82f1\u8bed\u5230\u6cd5\u8bed\u7684\u7ffb\u8bd1\u4efb\u52a1\u201d\u4e3a\u4f8b, \u5206\u522b\u5bf9\u6bd4\u4f20\u7edf\u7684\u5fae\u8c03\u7b56\u7565\u548cGPT-3\u4e09\u79cd\u60c5\u666f\u5b66\u4e60\u65b9\u5f0f. \u4e0b\u56fe\u662f\u4f20\u7edf\u7684\u5fae\u8c03\u7b56\u7565: \u4f20\u7edf\u7684\u5fae\u8c03\u7b56\u7565\u5b58\u5728\u95ee\u9898: \u5fae\u8c03\u9700\u8981\u5bf9\u6bcf\u4e00\u4e2a\u4efb\u52a1\u6709\u4e00\u4e2a\u4efb\u52a1\u76f8\u5173\u7684\u6570\u636e\u96c6\u4ee5\u53ca\u548c\u4efb\u52a1\u76f8\u5173\u7684\u5fae\u8c03. \u9700\u8981\u4e00\u4e2a\u76f8\u5173\u4efb\u52a1\u5927\u7684\u6570\u636e\u96c6, \u800c\u4e14\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u6807\u6ce8 \u5f53\u4e00\u4e2a\u6837\u672c\u6ca1\u6709\u51fa\u73b0\u5728\u6570\u636e\u5206\u5e03\u7684\u65f6\u5019, \u6cdb\u5316\u6027\u4e0d\u89c1\u5f97\u6bd4\u5c0f\u6a21\u578b\u8981\u597d \u4e0b\u56fe\u663e\u793a\u4e86 GPT-3 \u4e09\u79cd\u60c5\u666f\u5b66\u4e60\u65b9\u6cd5: zero-shot learning \u5b9a\u4e49: \u7ed9\u51fa\u4efb\u52a1\u7684\u63cf\u8ff0, \u7136\u540e\u63d0\u4f9b\u6d4b\u8bd5\u6570\u636e\u5bf9\u5176\u8fdb\u884c\u9884\u6d4b, \u76f4\u63a5\u8ba9\u9884\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u53bb\u8fdb\u884c\u4efb\u52a1\u6d4b\u8bd5. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d one-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u4e00\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u4e00\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u82f1\u8bed\u7ffb\u8bd1\u4e3a\u6cd5\u8bed, \u5e94\u8be5\u8fd9\u4e48\u7ffb\u8bd1. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. few-shot learning \u5b9a\u4e49: \u5728\u9884\u8bad\u7ec3\u548c\u771f\u6b63\u7ffb\u8bd1\u7684\u6837\u672c\u4e4b\u95f4, \u63d2\u5165\u591a\u4e2a\u6837\u672c\u505a\u6307\u5bfc. \u76f8\u5f53\u4e8e\u5728\u9884\u8bad\u7ec3\u597d\u7684\u7ed3\u679c\u548c\u6240\u8981\u6267\u884c\u7684\u4efb\u52a1\u4e4b\u95f4, \u7ed9\u591a\u4e2a\u4f8b\u5b50, \u544a\u8bc9\u6a21\u578b\u5e94\u8be5\u5982\u4f55\u5de5\u4f5c. \u793a\u4f8b: \u5411\u6a21\u578b\u8f93\u5165\u201c\u8fd9\u4e2a\u4efb\u52a1\u8981\u6c42\u5c06\u4e2d\u6587\u7ffb\u8bd1\u4e3a\u82f1\u6587. \u4f60\u597d->hello, \u518d\u89c1->goodbye, \u8d2d\u4e70->purchase, \u9500\u552e->\u201d, \u7136\u540e\u8981\u6c42\u6a21\u578b\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8f93\u51fa\u5e94\u8be5\u662f\u4ec0\u4e48, \u6b63\u786e\u7b54\u6848\u5e94\u4e3a\u201csell\u201d. \u603b\u4e4b\uff1a in-context learning\uff0c\u867d\u7136\u5b83\u4e0e fine-tuning \u4e00\u6837\u90fd\u9700\u8981\u4e00\u4e9b\u6709\u76d1\u7763\u6807\u6ce8\u6570\u636e\uff0c\u4f46\u662f\u4e24\u8005\u7684\u533a\u522b\u662f\uff1a \u3010 \u672c\u8d28\u533a\u522b \u3011fine-tuning \u57fa\u4e8e\u6807\u6ce8\u6570\u636e\u5bf9\u6a21\u578b\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff0c\u800c in-context learning \u4f7f\u7528\u6807\u6ce8\u6570\u636e\u65f6\u4e0d\u505a\u4efb\u4f55\u7684\u68af\u5ea6\u56de\u4f20\uff0c\u6a21\u578b\u53c2\u6570\u4e0d\u66f4\u65b0\uff1b in-context learning \u4f9d\u8d56\u7684\u6570\u636e\u91cf\uff0810\uff5e100\uff09\u8fdc\u8fdc\u5c0f\u4e8e fine-tuning \u4e00\u822c\u7684\u6570\u636e\u91cf\uff1b \u6700\u7ec8\u901a\u8fc7\u5927\u91cf\u4e0b\u6e38\u4efb\u52a1\u5b9e\u9a8c\u9a8c\u8bc1\uff0cFew-shot \u6548\u679c\u6700\u4f73\uff0cOne-shot \u6548\u679c\u6b21\u4e4b\uff0cZero-shot \u6548\u679c\u6700\u5dee\uff1a","title":"4.2 GPT-3\u8bad\u7ec3\u6838\u5fc3\u601d\u60f3"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#43-gpt-3","text":"\u4e00\u822c\u6765\u8bf4, \u6a21\u578b\u7684\u53c2\u6570\u8d8a\u591a, \u8bad\u7ec3\u6a21\u578b\u6240\u9700\u7684\u6570\u636e\u5c31\u8d8a\u591a. GPT-3\u5171\u8bad\u7ec3\u4e865\u4e2a\u4e0d\u540c\u7684\u8bed\u6599\u5927\u7ea6 45 TB \u7684\u6587\u672c\u6570\u636e, \u5206\u522b\u662f\u4f4e\u8d28\u91cf\u7684Common Crawl(\u9700\u8981\u6570\u636e\u6e05\u6d17), \u9ad8\u8d28\u91cf\u7684WebText2, Books1, Books2\u548cWikipedia, GPT-3\u6839\u636e\u6570\u636e\u96c6\u7684\u4e0d\u540c\u7684\u8d28\u91cf\u8d4b\u4e88\u4e86\u4e0d\u540c\u7684\u6743\u503c, \u6743\u503c\u8d8a\u9ad8\u7684\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u8d8a\u5bb9\u6613\u62bd\u6837\u5230, \u5982\u4e0b\u8868\u6240\u793a. \u6570\u636e\u96c6 \u6570\u91cf\uff08tokens\uff09 \u8bad\u7ec3\u6570\u636e\u5360\u6bd4 Common Crawl\uff08filterd\uff09 4100\u4ebf 60% Web Text2 190\u4ebf 22% BOOK1 120\u4ebf 8% BOOK2 550\u4ebf 8% Wikipedia 30\u4ebf 2% \u4e0d\u540c\u6570\u636e\u7684\u4ecb\u7ecd: Common Crawl\u8bed\u6599\u5e93\u5305\u542b\u5728 8 \u5e74\u7684\u7f51\u7edc\u722c\u884c\u4e2d\u6536\u96c6\u7684 PB \u7ea7\u6570\u636e. \u8bed\u6599\u5e93\u5305\u542b\u539f\u59cb\u7f51\u9875\u6570\u636e\u3001\u5143\u6570\u636e\u63d0\u53d6\u548c\u5e26\u6709\u5149\u8fc7\u6ee4\u7684\u6587\u672c\u63d0\u53d6. WebText2\u662f\u6765\u81ea\u5177\u6709 3+ upvotes \u7684\u5e16\u5b50\u7684\u6240\u6709\u51fa\u7ad9 Reddit \u94fe\u63a5\u7684\u7f51\u9875\u6587\u672c. Books1\u548cBooks2\u662f\u4e24\u4e2a\u57fa\u4e8e\u4e92\u8054\u7f51\u7684\u56fe\u4e66\u8bed\u6599\u5e93. \u82f1\u6587\u7ef4\u57fa\u767e\u79d1\u9875\u9762 \u4e5f\u662f\u8bad\u7ec3\u8bed\u6599\u5e93\u7684\u4e00\u90e8\u5206.","title":"4.3 GPT-3\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#44-gpt-3","text":"\u4e0e GPT-2 \u7684\u533a\u522b \u6548\u679c\u4e0a \uff0c\u8d85\u51fa GPT-2 \u975e\u5e38\u591a\uff0c\u80fd\u751f\u6210\u4eba\u7c7b\u96be\u4ee5\u533a\u5206\u7684\u65b0\u95fb\u6587\u7ae0\uff1b \u4e3b\u63a8 few-shot \uff0c\u76f8\u6bd4\u4e8e GPT-2 \u7684 zero-shot\uff0c\u5177\u6709\u5f88\u5f3a\u7684\u521b\u65b0\u6027\uff1b **\u6a21\u578b\u7ed3\u6784**\u7565\u5fae\u53d8\u5316\uff0c\u91c7\u7528 sparse attention \u6a21\u5757\uff1b \u6d77\u91cf\u8bad\u7ec3\u8bed\u6599 45TB\uff08\u6e05\u6d17\u540e 570GB\uff09\uff0c\u76f8\u6bd4\u4e8e GPT-2 \u7684 40GB\uff1b \u6d77\u91cf\u6a21\u578b\u53c2\u6570 \uff0c\u6700\u5927\u6a21\u578b\u4e3a 1750 \u4ebf\uff0cGPT-2 \u6700\u5927\u4e3a 15 \u4ebf\u53c2\u6570\uff1b \u4f18\u70b9\uff1a \u6574\u4f53\u4e0a, GPT-3\u5728zero-shot\u6216one-shot\u8bbe\u7f6e\u4e0b\u80fd\u53d6\u5f97\u5c1a\u53ef\u7684\u6210\u7ee9, \u5728few-shot\u8bbe\u7f6e\u4e0b\u6709\u53ef\u80fd\u8d85\u8d8a\u57fa\u4e8efine-tune\u7684SOTA\u6a21\u578b. \u53bb\u9664\u4e86fune-tuning\u4efb\u52a1. \u7f3a\u70b9: \u7531\u4e8e40TB\u6d77\u91cf\u6570\u636e\u7684\u5b58\u5728, \u5f88\u96be\u4fdd\u8bc1GPT-3\u751f\u6210\u7684\u6587\u7ae0\u4e0d\u5305\u542b\u4e00\u4e9b\u975e\u5e38\u654f\u611f\u7684\u5185\u5bb9 \u5bf9\u4e8e\u90e8\u5206\u4efb\u52a1\u6bd4\u5982: \u201c\u586b\u7a7a\u7c7b\u578b\u201d\u7b49, \u6548\u679c\u5177\u6709\u5c40\u9650\u6027 \u5f53\u751f\u6210\u6587\u672c\u957f\u5ea6\u8f83\u957f\u65f6\uff0cGPT-3 \u8fd8\u662f\u4f1a\u51fa\u73b0\u5404\u79cd\u95ee\u9898\uff0c\u6bd4\u5982\u91cd\u590d\u751f\u6210\u4e00\u6bb5\u8bdd\uff0c\u524d\u540e\u77db\u76fe\uff0c\u903b\u8f91\u8854\u63a5\u4e0d\u597d\u7b49\u7b49\uff1b \u6210\u672c\u592a\u5927","title":"4.4 GPT-3\u6a21\u578b\u7684\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#45-gpt-3","text":"GPT\u7cfb\u5217\u4ece1\u52303, \u901a\u901a\u91c7\u7528\u7684\u662ftransformer\u67b6\u6784, \u53ef\u4ee5\u8bf4\u6a21\u578b\u7ed3\u6784\u5e76\u6ca1\u6709\u521b\u65b0\u6027\u7684\u8bbe\u8ba1. GPT-3\u7684\u672c\u8d28\u8fd8\u662f\u901a\u8fc7\u6d77\u91cf\u7684\u53c2\u6570\u5b66\u4e60\u6d77\u91cf\u7684\u6570\u636e, \u7136\u540e\u4f9d\u8d56transformer\u5f3a\u5927\u7684\u62df\u5408\u80fd\u529b\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u6536\u655b. \u5f97\u76ca\u4e8e\u5e9e\u5927\u7684\u6570\u636e\u96c6, GPT-3\u53ef\u4ee5\u5b8c\u6210\u4e00\u4e9b\u4ee4\u4eba\u611f\u5230\u60ca\u559c\u7684\u4efb\u52a1, \u4f46\u662fGPT-3\u4e5f\u4e0d\u662f\u4e07\u80fd\u7684, \u5bf9\u4e8e\u4e00\u4e9b\u660e\u663e\u4e0d\u5728\u8fd9\u4e2a\u5206\u5e03\u6216\u8005\u548c\u8fd9\u4e2a\u5206\u5e03\u6709\u51b2\u7a81\u7684\u4efb\u52a1\u6765\u8bf4, GPT-3\u8fd8\u662f\u65e0\u80fd\u4e3a\u529b\u7684.","title":"4.5 GPT-3\u6a21\u578b\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#5-chatgpt","text":"ChatGPT\u662f\u4e00\u79cd\u57fa\u4e8eGPT-3\u7684\u804a\u5929\u673a\u5668\u4eba\u6a21\u578b. \u5b83\u65e8\u5728\u4f7f\u7528 GPT-3 \u7684\u8bed\u8a00\u751f\u6210\u80fd\u529b\u6765\u4e0e\u7528\u6237\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u5bf9\u8bdd. \u4f8b\u5982, \u7528\u6237\u53ef\u4ee5\u5411 ChatGPT \u53d1\u9001\u6d88\u606f, \u7136\u540e ChatGPT \u4f1a\u6839\u636e\u6d88\u606f\u751f\u6210\u4e00\u6761\u56de\u590d. GPT-3 \u662f\u4e00\u4e2a\u66f4\u5927\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b, \u800c ChatGPT \u5219\u662f\u4f7f\u7528 GPT-3 \u6765\u6784\u5efa\u7684\u804a\u5929\u673a\u5668\u4eba. \u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u662f ChatGPT \u4f9d\u8d56\u4e8e GPT-3 \u7684\u8bed\u8a00\u751f\u6210\u80fd\u529b\u6765\u8fdb\u884c\u5bf9\u8bdd. \u76ee\u524d\u57fa\u4e8eChatGPT\u7684\u8bba\u6587\u5e76\u6ca1\u6709\u516c\u5e03, \u56e0\u6b64\u63a5\u4e0b\u6765\u6211\u4eec\u57fa\u4e8eopenai\u5b98\u7f51\u7684\u4ecb\u7ecd\u5bf9\u5176\u539f\u7406\u8fdb\u884c\u89e3\u6790","title":"5 ChatGPT\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#51-chatgpt","text":"\u5728\u4ecb\u7ecdChatGPT\u539f\u7406\u4e4b\u524d, \u8bf7\u5927\u5bb6\u5148\u601d\u8003\u4e00\u4e2a\u95ee\u9898: \u201c\u6a21\u578b\u8d8a\u5927\u3001\u53c2\u6570\u8d8a\u591a, \u6a21\u578b\u7684\u6548\u679c\u5c31\u8d8a\u597d\u4e48\u554a\uff1f\u201d. \u8fd9\u4e2a\u7b54\u6848\u662f\u5426\u5b9a\u7684, \u56e0\u4e3a\u6a21\u578b\u8d8a\u5927\u53ef\u80fd\u5bfc\u81f4\u7ed3\u679c\u8d8a\u4e13\u4e00, \u4f46\u662f\u8fd9\u4e2a\u7ed3\u679c\u6709\u53ef\u80fd\u5e76\u4e0d\u662f\u6211\u4eec\u671f\u671b\u7684. \u8fd9\u4e5f\u79f0\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u4e0d\u4e00\u81f4\u95ee\u9898. \u5728\u673a\u5668\u5b66\u4e60\u4e2d, \u6709\u4e2a\u91cd\u8981\u7684\u6982\u5ff5: \u201c\u8fc7\u62df\u5408\u201d, \u6240\u8c13\u7684\u8fc7\u62df\u5408, \u5c31\u662f\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u8868\u73b0\u5f97\u5f88\u597d, \u4f46\u662f\u5728\u6d4b\u8bd5\u96c6\u8868\u73b0\u5f97\u8f83\u5dee, \u4e5f\u5c31\u662f\u8bf4\u6a21\u578b\u5728\u6700\u7ec8\u7684\u8868\u73b0\u4e0a\u5e76\u4e0d\u80fd\u8fbe\u5230\u6211\u4eec\u7684\u9884\u671f, \u8fd9\u5c31\u662f\u6a21\u578b\u80fd\u529b\u4e0d\u4e00\u81f4\u95ee\u9898. \u539f\u59cb\u7684 GPT-3 \u5c31\u662f\u975e\u4e00\u81f4\u6a21\u578b, \u7c7b\u4f3cGPT-3 \u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u90fd\u662f\u57fa\u4e8e\u6765\u81ea\u4e92\u8054\u7f51\u7684\u5927\u91cf\u6587\u672c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3, \u80fd\u591f\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6587\u672c, \u4f46\u5b83\u4eec\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u4ea7\u751f\u7b26\u5408\u4eba\u7c7b\u671f\u671b\u7684\u8f93\u51fa. ChatGPT \u4e3a\u4e86\u89e3\u51b3\u6a21\u578b\u7684\u4e0d\u4e00\u81f4\u95ee\u9898, \u4f7f\u7528\u4e86\u4eba\u7c7b\u53cd\u9988\u6765\u6307\u5bfc\u5b66\u4e60\u8fc7\u7a0b, \u5bf9\u5176\u8fdb\u884c\u4e86\u8fdb\u4e00\u6b65\u8bad\u7ec3. \u6240\u4f7f\u7528\u7684\u5177\u4f53\u6280\u672f\u5c31\u662f\u5f3a\u5316\u5b66\u4e60(RLHF) .","title":"5.1 ChatGPT\u539f\u7406"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#52","text":"\u5f3a\u5316\u5b66\u4e60\uff08Reinforcement Learning, RL\uff09, \u53c8\u79f0\u518d\u52b1\u5b66\u4e60\u3001\u8bc4\u4ef7\u5b66\u4e60\u6216\u589e\u5f3a\u5b66\u4e60, \u662f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7684\u4e00\u79cd, \u7528\u4e8e\u63cf\u8ff0\u548c\u89e3\u51b3\u667a\u80fd\u4f53\uff08agent\uff09\u5728\u4e0e\u73af\u5883\u7684\u4ea4\u4e92\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u5b66\u4e60\u7b56\u7565\u4ee5\u8fbe\u6210\u56de\u62a5\u6700\u5927\u5316\u6216\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u95ee\u9898. \u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u4fe1\u606f: \u4e00\u79cd\u673a\u5668\u5b66\u4e60\u65b9\u6cd5 \u5173\u6ce8\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4ea4\u4e92 \u76ee\u6807\u662f\u8ffd\u6c42\u6700\u5927\u56de\u62a5 \u5f3a\u5316\u5b66\u4e60\u7684\u67b6\u6784 \u4e0b\u56fe\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u6d41\u7a0b\u6574\u4f53\u67b6\u6784, \u5176\u4e2d\u5927\u8111\u6307\u4ee3\u667a\u80fd\u4f53agent, \u5730\u7403\u6307\u4ee3\u73af\u5883environment, \u4ece\u5f53\u524d\u7684\u72b6\u6001St\u51fa\u53d1, \u5728\u505a\u51fa\u4e00\u4e2a\u884c\u4e3aAt \u4e4b\u540e, \u5bf9\u73af\u5883\u4ea7\u751f\u4e86\u4e00\u4e9b\u5f71\u54cd, \u5b83\u9996\u5148\u7ed9agent\u53cd\u9988\u4e86\u4e00\u4e2a\u5956\u52b1\u4fe1\u53f7Rt\u7136\u540e\u7ed9agent\u53cd\u9988\u4e00\u4e2a\u65b0\u7684\u73af\u5883\u72b6\u6001, \u6b64\u5904\u7528Ot \u8868\u793a, \u8fdb\u800c\u878d\u6c47\u8fdb\u5165\u4e00\u4e2a\u65b0\u7684\u72b6\u6001, agent\u518d\u505a\u51fa\u65b0\u7684\u884c\u4e3a, \u5f62\u6210\u4e00\u4e2a\u5faa\u73af. \u7406\u89e3\u5f3a\u5316\u5b66\u4e60\u57fa\u672c\u8981\u7d20 \u8fd9\u91cc\u6211\u4eec\u4ee5\u4e00\u4e2a\u7b80\u5355\u5c0f\u6e38\u620fflappy bird\u4e3a\u4ee3\u8868\u4e3a\u5927\u5bb6\u8bb2\u89e3\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u8981\u7d20: Agent\uff08\u667a\u80fd\u4f53\uff09: \u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u4e3b\u4f53\u5c31\u662fAgent, \u7edf\u79f0\u4e3a\u201c\u667a\u80fd\u4f53\u201d. \u8fd9\u91cc\u5c0f\u9e1f\u5c31\u662fAgent. Environment\uff08\u73af\u5883\uff09: \u6574\u4e2a\u6e38\u620f\u7684\u5927\u80cc\u666f\u5c31\u662f\u73af\u5883\uff1b\u8d85\u7ea7\u739b\u4e3d\u4e2dAgent\u3001\u5730\u9762\u3001\u67f1\u5b50\u7ec4\u6210\u4e86\u6574\u4e2a\u73af\u5883. State\uff08\u72b6\u6001\uff09: \u5f53\u524d Environment\u548cAgent\u6240\u5904\u7684\u72b6\u6001, \u56e0\u4e3a\u5c0f\u9e1f\u4e00\u76f4\u5728\u79fb\u52a8, \u5206\u6570\u6570\u76ee\u4e5f\u5728\u4e0d\u505c\u53d8\u5316, Agent\u7684\u4f4d\u7f6e\u4e5f\u5728\u4e0d\u505c\u53d8\u5316, \u6240\u4ee5\u6574\u4e2aState\u5904\u4e8e\u53d8\u5316\u4e2d. Policy\uff08\u7b56\u7565\uff09: Policy\u7684\u610f\u601d\u5c31\u662f\u6839\u636e\u89c2\u6d4b\u5230\u7684\u72b6\u6001\u6765\u8fdb\u884c\u51b3\u7b56, \u6765\u63a7\u5236Agent\u8fd0\u52a8. \u5373\u57fa\u4e8e\u5f53\u524d\u7684State, Agent\u53ef\u4ee5\u91c7\u53d6\u54ea\u4e9bAction, \u6bd4\u5982\u5411\u4e0a\u6216\u8005\u5411\u4e0b. \u5728\u6570\u5b66\u4e0aPolicy\u4e00\u822c\u5b9a\u4e49\u4e3a\u51fd\u6570\u03c0\uff08\u6df1\u5ea6\u5b66\u4e60\u4e2dPolicy\u53ef\u4ee5\u5b9a\u4e49\u4e3a\u4e00\u4e2a\u6a21\u578b\uff09, \u8fd9\u4e2apolicy\u51fd\u6570\u03c0\u662f\u4e2a\u6982\u7387\u5bc6\u5ea6\u51fd\u6570: $$ \u03c0(a|s) = P(A=a|S=s) $$ Reward\uff08\u5956\u52b1\uff09: Agent\u5728\u5f53\u524dState\u4e0b, \u91c7\u53d6\u4e86\u67d0\u4e2a\u7279\u5b9a\u7684Action\u540e, \u4f1a\u83b7\u5f97\u73af\u5883\u7684\u4e00\u5b9a\u53cd\u9988\uff08\u6216\u5956\u52b1\uff09\u5c31\u662fReward. \u6bd4\u5982: \u5c0f\u9e1f\u987a\u5229\u901a\u8fc7\u67f1\u5b50\u83b7\u5f97\u5956\u52b1R=+1,\u5982\u679c\u8d62\u4e86\u8fd9\u573a\u6e38\u620f\u5956\u52b1R=+10000, \u6211\u4eec\u5e94\u8be5\u628a\u6253\u8d62\u6e38\u620f\u7684\u5956\u52b1\u5b9a\u4e49\u7684\u5927\u4e00\u4e9b, \u8fd9\u6837\u624d\u80fd\u6fc0\u52b1\u5b66\u5230\u7684policy\u6253\u8d62\u6e38\u620f\u800c\u4e0d\u662f\u4e00\u5473\u7684\u52a0\u5206, \u5982\u679c\u5c0f\u9e1f\u78b0\u5230\u67f1\u5b50, \u5c0f\u9e1f\u5c31\u4f1a\u6b7b, \u6e38\u620f\u7ed3\u675f, \u8fd9\u65f6\u5956\u52b1\u5c31\u8bbeR=-10000, \u5982\u679c\u8fd9\u4e00\u6b65\u4ec0\u4e48\u4e5f\u6ca1\u53d1\u751f, \u5956\u52b1\u5c31\u662fR=0, \u5f3a\u5316\u5b66\u4e60\u7684\u76ee\u6807\u5c31\u662f\u4f7f\u83b7\u5f97\u7684\u5956\u52b1\u603b\u548c\u5c3d\u91cf\u8981\u9ad8. \u5982\u4f55\u8ba9AI\u5b9e\u73b0\u81ea\u52a8\u6253\u6e38\u620f\uff1f \u7b2c\u4e00\u6b65: \u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\uff08\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff09\u5b66\u51faPolicy\u51fd\u6570, \u8be5\u6b65\u9aa4\u76ee\u7684\u662f\u7528Policy\u51fd\u6570\u6765\u63a7\u5236Agent. \u7b2c\u4e8c\u6b65: \u83b7\u53d6\u5f53\u524d\u72b6\u6001\u4e3as1, \u5e76\u5c06s1\u5e26\u5165Policy\u51fd\u6570\u6765\u8ba1\u7b97\u6982\u7387, \u4ece\u6982\u7387\u7ed3\u679c\u4e2d\u62bd\u6837\u5f97\u5230a1, \u540c\u65f6\u73af\u5883\u751f\u6210\u4e0b\u4e00\u72b6\u6001s2, \u5e76\u4e14\u7ed9Agent\u4e00\u4e2a\u5956\u52b1r1. \u7b2c\u4e09\u6b65: \u5c06\u65b0\u7684\u72b6\u6001s2\u5e26\u5165Policy\u51fd\u6570\u6765\u8ba1\u7b97\u6982\u7387, \u62bd\u53d6\u7ed3\u679c\u5f97\u5230\u65b0\u7684\u52a8\u4f5ca2\u3001\u72b6\u6001s3\u3001\u5956\u52b1r2. \u7b2c\u56db\u6b65: \u5faa\u73af2-3\u6b65\u9aa4, \u76f4\u5230\u6253\u8d62\u6e38\u620f\u6216\u8005game over, \u8fd9\u6837\u6211\u4eec\u5c31\u4f1a\u5f97\u5230\u4e00\u4e2a\u6e38\u620f\u7684trajectory\uff08\u8f68\u8ff9\uff09, \u8fd9\u4e2a\u8f68\u8ff9\u662f\u6bcf\u4e00\u6b65\u7684\u72b6\u6001, \u52a8\u4f5c, \u5956\u52b1.","title":"5.2 \u4ec0\u4e48\u662f\u5f3a\u5316\u5b66\u4e60"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#53-chatgpt","text":"\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60, \u8be5\u65b9\u6cd5\u603b\u4f53\u4e0a\u5305\u62ec\u4e09\u4e2a\u6b65\u9aa4: \u6b65\u9aa41: \u76d1\u7763\u5b66\u4e60, \u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u91cf\u5df2\u6807\u6ce8\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u8c03\u4f18, \u4ee5\u5b66\u4e60\u4ece\u7ed9\u5b9a\u7684 prompt \u5217\u8868\u751f\u6210\u8f93\u51fa\u7684\u6709\u76d1\u7763\u7684\u7b56\u7565\uff08\u5373 SFT \u6a21\u578b\uff09\uff1b \u6b65\u9aa42: \u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff08reward\uff09: \u6807\u6ce8\u8005\u4eec\u5bf9\u76f8\u5bf9\u5927\u91cf\u7684 SFT \u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u8fdb\u884c\u6536\u96c6\u5e76\u6392\u5e8f, \u8fd9\u5c31\u521b\u5efa\u4e86\u4e00\u4e2a\u7531\u6bd4\u8f83\u6570\u636e\u7ec4\u6210\u7684\u65b0\u6570\u636e\u96c6. \u5728\u6b64\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u65b0\u6a21\u578b, \u88ab\u79f0\u4e3a\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff08Reward Model, RM\uff09\uff1b \u6b65\u9aa43: \u5f3a\u5316\u5b66\u4e60\uff08PPO\u7b97\u6cd5\uff09: RM \u6a21\u578b\u7528\u4e8e\u8fdb\u4e00\u6b65\u8c03\u4f18\u548c\u6539\u8fdb SFT \u6a21\u578b, PPO \u8f93\u51fa\u7ed3\u679c\u7684\u662f\u7b56\u7565\u6a21\u5f0f. \u6b65\u9aa4 1 \u53ea\u8fdb\u884c\u4e00\u6b21, \u800c\u6b65\u9aa4 2 \u548c\u6b65\u9aa4 3 \u53ef\u4ee5\u6301\u7eed\u91cd\u590d\u8fdb\u884c: \u5728\u5f53\u524d\u6700\u4f73\u7b56\u7565\u6a21\u578b\u4e0a\u6536\u96c6\u66f4\u591a\u7684\u6bd4\u8f83\u6570\u636e, \u7528\u4e8e\u8bad\u7ec3\u65b0\u7684 RM \u6a21\u578b, \u7136\u540e\u8bad\u7ec3\u65b0\u7684\u7b56\u7565. \u63a5\u4e0b\u6765, \u5c06\u5bf9\u6bcf\u4e00\u6b65\u7684\u7ec6\u8282\u8fdb\u884c\u8be6\u8ff0.","title":"5.3 ChatGPT\u5f3a\u5316\u5b66\u4e60\u6b65\u9aa4"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#54","text":"\u5de5\u4f5c\u539f\u7406: \u7b2c\u4e00\u6b65\u662f\u6536\u96c6\u6570\u636e, \u4ee5\u8bad\u7ec3\u6709\u76d1\u7763\u7684\u7b56\u7565\u6a21\u578b. \u6570\u636e\u6536\u96c6: \u9009\u62e9\u4e00\u4e2a\u63d0\u793a\u5217\u8868, \u6807\u6ce8\u4eba\u5458\u6309\u8981\u6c42\u5199\u4e0b\u9884\u671f\u7684\u8f93\u51fa. \u5bf9\u4e8e ChatGPT, \u4f7f\u7528\u4e86\u4e24\u79cd\u4e0d\u540c\u7684 prompt \u6765\u6e90: \u4e00\u4e9b\u662f\u76f4\u63a5\u4f7f\u7528\u6807\u6ce8\u4eba\u5458\u6216\u7814\u7a76\u4eba\u5458\u51c6\u5907\u7684, \u53e6\u4e00\u4e9b\u662f\u4ece OpenAI \u7684 API \u8bf7\u6c42\uff08\u5373\u4ece GPT-3 \u7528\u6237\u90a3\u91cc\uff09\u83b7\u53d6\u7684. \u867d\u7136\u6574\u4e2a\u8fc7\u7a0b\u7f13\u6162\u4e14\u6602\u8d35, \u4f46\u6700\u7ec8\u5f97\u5230\u7684\u7ed3\u679c\u662f\u4e00\u4e2a\u76f8\u5bf9\u8f83\u5c0f\u3001\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6, \u53ef\u7528\u4e8e\u8c03\u4f18\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578b. \u6a21\u578b\u9009\u62e9: ChatGPT \u7684\u5f00\u53d1\u4eba\u5458\u9009\u62e9\u4e86 GPT-3.5 \u7cfb\u5217\u4e2d\u7684\u9884\u8bad\u7ec3\u6a21\u578b, \u800c\u4e0d\u662f\u5bf9\u539f\u59cb GPT-3 \u6a21\u578b\u8fdb\u884c\u8c03\u4f18. \u4f7f\u7528\u7684\u57fa\u7ebf\u6a21\u578b\u662f\u6700\u65b0\u7248\u7684 text-davinci-003\uff08\u901a\u8fc7\u5bf9\u7a0b\u5e8f\u4ee3\u7801\u8c03\u4f18\u7684 GPT-3 \u6a21\u578b\uff09 \u7531\u4e8e\u6b64\u6b65\u9aa4\u7684\u6570\u636e\u91cf\u6709\u9650, \u8be5\u8fc7\u7a0b\u83b7\u5f97\u7684 SFT \u6a21\u578b\u53ef\u80fd\u4f1a\u8f93\u51fa\u4ecd\u7136\u5e76\u975e\u7528\u6237\u5173\u6ce8\u7684\u6587\u672c, \u5e76\u4e14\u901a\u5e38\u4f1a\u51fa\u73b0\u4e0d\u4e00\u81f4\u95ee\u9898. \u8fd9\u91cc\u7684\u95ee\u9898\u662f\u76d1\u7763\u5b66\u4e60\u6b65\u9aa4\u5177\u6709\u9ad8\u53ef\u6269\u5c55\u6027\u6210\u672c. \u4e3a\u4e86\u514b\u670d\u8fd9\u4e2a\u95ee\u9898, \u4f7f\u7528\u7684\u7b56\u7565\u662f\u8ba9\u4eba\u5de5\u6807\u6ce8\u8005\u5bf9 SFT \u6a21\u578b\u7684\u4e0d\u540c\u8f93\u51fa\u8fdb\u884c\u6392\u5e8f\u4ee5\u521b\u5efa RM \u6a21\u578b, \u800c\u4e0d\u662f\u8ba9\u4eba\u5de5\u6807\u6ce8\u8005\u521b\u5efa\u4e00\u4e2a\u66f4\u5927\u7684\u7cbe\u9009\u6570\u636e\u96c6.","title":"5.4 \u76d1\u7763\u8c03\u4f18\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#55","text":"\u8fd9\u4e00\u6b65\u7684\u76ee\u6807\u662f\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u76ee\u6807\u51fd\u6570. \u8be5\u51fd\u6570\u7684\u76ee\u7684\u662f\u4e3a SFT \u6a21\u578b\u8f93\u51fa\u8fdb\u884c\u6253\u5206, \u8fd9\u4ee3\u8868\u8fd9\u4e9b\u8f93\u51fa\u5bf9\u4e8e\u4eba\u7c7b\u6765\u8bf4\u53ef\u53d6\u7a0b\u5ea6\u6709\u591a\u5927. \u8fd9\u5f3a\u6709\u529b\u5730\u53cd\u6620\u4e86\u9009\u5b9a\u7684\u4eba\u7c7b\u6807\u6ce8\u8005\u7684\u5177\u4f53\u504f\u597d\u4ee5\u53ca\u4ed6\u4eec\u540c\u610f\u9075\u5faa\u7684\u5171\u540c\u51c6\u5219. \u6700\u540e, \u8fd9\u4e2a\u8fc7\u7a0b\u5c06\u4ece\u6570\u636e\u4e2d\u5f97\u5230\u6a21\u4eff\u4eba\u7c7b\u504f\u597d\u7684\u7cfb\u7edf. \u5de5\u4f5c\u539f\u7406: \u4ece\u95ee\u9898\u5e93\u4e2d\u9009\u62e9\u95ee\u9898\uff08prompt\uff09, SFT \u6a21\u578b\u4e3a\u6bcf\u4e2a prompt \u751f\u6210\u591a\u4e2a\u8f93\u51fa\uff084 \u5230 9 \u4e4b\u95f4\u7684\u4efb\u610f\u503c\uff09 \u6807\u6ce8\u8005\u5c06\u8f93\u51fa\u4ece\u6700\u4f73\u5230\u6700\u5dee\u6392\u5e8f. \u7ed3\u679c\u662f\u4e00\u4e2a\u65b0\u7684\u6807\u7b7e\u6570\u636e\u96c6, \u8be5\u6570\u636e\u96c6\u7684\u5927\u5c0f\u5927\u7ea6\u662f\u7528\u4e8e SFT \u6a21\u578b\u7684\u7cbe\u786e\u6570\u636e\u96c6\u7684 10 \u500d\uff1b \u6b64\u65b0\u6570\u636e\u7528\u4e8e\u8bad\u7ec3 RM \u6a21\u578b . \u8be5\u6a21\u578b\u5c06 SFT \u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u8f93\u5165, \u5e76\u6309\u4f18\u5148\u987a\u5e8f\u5bf9\u5b83\u4eec\u8fdb\u884c\u6392\u5e8f. \u6a21\u578b\u9009\u62e9: RM\u6a21\u578b\u662fGPT-3\u7684\u84b8\u998f\u7248\u672c\uff08\u53c2\u6570\u91cf\u4e3a6\u4ebf\uff09, \u76ee\u7684\u662f\u901a\u8fc7\u8be5\u8bad\u7ec3\u6a21\u578b\u5f97\u5230\u4e00\u4e2a\u9884\u6d4b\u503c\uff08\u5f97\u5206\uff09, \u6a21\u578b\u635f\u5931\u51fd\u6570\u4e3a\u4e0b\u56fe\u8868\u793a: \u516c\u5f0f\u53c2\u6570\u89e3\u6790: x\u4ee3\u8868prompt\u539f\u59cb\u8f93\u5165, yw\u4ee3\u8868SFT\u6a21\u578b\u8f93\u51fa\u7684\u5f97\u5206\u8f83\u9ad8\u7684\u7ed3\u679c, yl\u4ee3\u8868SFT\u6a21\u578b\u8f93\u51fa\u5f97\u5206\u8f83\u4f4e\u7684\u7ed3\u679c, r\u03b8\u4ee3\u8868RM\u6a21\u578b\u5373GPT-3\u6a21\u578b, \u03c3\u4ee3\u8868sigmoid\u51fd\u6570, K\u4ee3\u8868SFT \u6a21\u578b\u4e3a\u6bcf\u4e2a prompt \u751f\u6210\u591a\u4e2a\u8f93\u51fa, \u8fd9\u91ccK\u4e2a\u4efb\u90092\u4e2a\u6765\u6a21\u578b\u8bad\u7ec3.","title":"5.5 \u8bad\u7ec3\u5956\u52b1\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#56","text":"\u8fd9\u4e00\u6b65\u91cc\u5f3a\u5316\u5b66\u4e60\u88ab\u5e94\u7528\u4e8e\u901a\u8fc7\u4f18\u5316 RM \u6a21\u578b\u6765\u8c03\u4f18 SFT \u6a21\u578b. \u6240\u4f7f\u7528\u7684\u7279\u5b9a\u7b97\u6cd5\u79f0\u4e3a\u8fd1\u7aef\u7b56\u7565\u4f18\u5316\uff08PPO, Proximal Policy Optimization\uff09, \u800c\u8c03\u4f18\u6a21\u578b\u79f0\u4e3a\u8fd1\u6bb5\u7b56\u7565\u4f18\u5316\u6a21\u578b. \u5de5\u4f5c\u539f\u7406: (\u660e\u786e\u4efb\u52a1: \u6a21\u578b\u662f\u901a\u8fc7RL\u6765\u66f4\u65b0) \u7b2c\u4e00\u6b65: \u8f93\u5165prompt(\u6307\u4ee3\u95ee\u9898) \u7b2c\u4e8c\u6b65: \u5c06prompt\u8f93\u5165\u5f3a\u5316\u5b66\u4e60\u6a21\u578b (\u8fd9\u91cc\u76f4\u63a5\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3aChatGPT\u6a21\u578b\u3010\u76d1\u7763\u5b66\u4e60\u5fae\u8c03\u540e\u7684\u3011), \u5f97\u5230\u4e00\u4e2a\u8f93\u51fa\u7ed3\u679c \u7b2c\u4e09\u6b65: \u5c06\u7b2c\u4e8c\u6b65\u5f97\u5230\u7684\u7ed3\u679c\u8f93\u5165\u5230RM\u5956\u52b1\u6a21\u578b\u4e2d, \u7136\u540e\u5f97\u5230\u4e00\u4e2a\u5956\u52b1\u5206\u6570. \u751f\u6210\u7684\u5206\u6570\u4f1a\u57fa\u4e8ePPO\u7b97\u6cd5\u4f18\u5316\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u3002\u6bd4\u5982\uff1a\u5982\u679c\u5956\u52b1\u5206\u6570\u6bd4\u8f83\u4f4e, \u4ee3\u8868ChatGPT\u6a21\u578b\u8f93\u51fa\u7ed3\u679c\u4e0d\u5bf9, \u6b64\u65f6\u9700\u8981\u5229\u7528PPO\u7b97\u6cd5\u66f4\u65b0ChatGPT\u6a21\u578b\u53c2\u6570 \u7b2c\u56db\u6b65: \u5faa\u73af\u4e0a\u8ff0\u6b65\u9aa4, \u4e0d\u65ad\u66f4\u65b0ChatGPT\u3001RM\u6a21\u578b.","title":"5.6 \u5f3a\u5316\u5b66\u4e60\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#57-chatgpt","text":"\u4f18\u70b9: \u56de\u7b54\u7406\u6027\u53c8\u5168\u9762, ChatGPT\u66f4\u80fd\u505a\u5230\u591a\u89d2\u5ea6\u5168\u65b9\u4f4d\u56de\u7b54 \u964d\u4f4e\u5b66\u4e60\u6210\u672c, \u53ef\u4ee5\u5feb\u901f\u83b7\u53d6\u95ee\u9898\u7b54\u6848 \u7f3a\u70b9: ChatGPT \u670d\u52a1\u4e0d\u7a33\u5b9a \u5bb9\u6613\u4e00\u672c\u6b63\u7ecf\u7684\"\u80e1\u8bf4\u516b\u9053\"","title":"5.7 ChatGPT\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/01-ChatGPT%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86.html#6","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u8bb2\u8ff0\u4e86ChatGPT\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u91cd\u70b9\u5bf9\u6bd4\u4e86N-gram\u8bed\u8a00\u6a21\u578b\u548c\u795e\u7ecf\u7f51\u7edc\u8bed\u8a00\u6a21\u578b\u7684\u533a\u522b\uff0c\u4ee5\u53caGPT\u7cfb\u5217\u6a21\u578b\u7684\u5bf9\u6bd4.","title":"6 \u5c0f\u7ed3"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html","text":"LLM\u4e3b\u6d41\u5f00\u6e90\u5927\u6a21\u578b\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3LLM\u4e3b\u6d41\u5f00\u6e90\u5927\u6a21\u578b. \u638c\u63e1ChatGLM\u3001LLaMA\u3001Bloom\u7b49\u57fa\u7840\u5927\u6a21\u578b\u7684\u539f\u7406 1 LLM\u4e3b\u6d41\u5927\u6a21\u578b\u7c7b\u522b \u00b6 \u968f\u7740ChatGPT\u8fc5\u901f\u706b\u7206\uff0c\u5f15\u53d1\u4e86\u5927\u6a21\u578b\u7684\u65f6\u4ee3\u53d8\u9769\uff0c\u56fd\u5185\u5916\u5404\u5927\u516c\u53f8\u4e5f\u5feb\u901f\u8ddf\u8fdb\u751f\u6210\u5f0fAI\u5e02\u573a\uff0c\u8fd1\u767e\u6b3e\u5927\u6a21\u578b\u53d1\u5e03\u53ca\u5e94\u7528\u3002 \u76ee\u524d\uff0c\u5f00\u6e90\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u6709\u4e09\u5927\u7c7b\uff1a ChatGLM-6B\u884d\u751f\u7684\u5927\u6a21\u578b\uff08wenda\u3001ChatSQL\u7b49\uff09 LLaMA\u884d\u751f\u7684\u5927\u6a21\u578b\uff08Alpaca\u3001Vicuna\u3001BELLE\u3001Phoenix\u3001Chimera\u7b49\uff09 Bloom\u884d\u751f\u7684\u5927\u6a21\u578b\uff08Bloomz\u3001BELLE\u3001Phoenix\u7b49\uff09 2 ChatGLM-6B\u6a21\u578b \u00b6 ChatGLM-6B \u662f\u6e05\u534e\u5927\u5b66\u63d0\u51fa\u7684\u4e00\u4e2a\u5f00\u6e90\u3001\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u7684\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e General Language Model (GLM) \u67b6\u6784\uff0c\u5177\u6709 62 \u4ebf\u53c2\u6570\u3002\u8be5\u6a21\u578b\u4f7f\u7528\u4e86\u548c ChatGPT \u76f8\u4f3c\u7684\u6280\u672f\uff0c\u7ecf\u8fc7\u7ea6 1T \u6807\u8bc6\u7b26\u7684\u4e2d\u82f1\u53cc\u8bed\u8bad\u7ec3(\u4e2d\u82f1\u6587\u6bd4\u4f8b\u4e3a 1:1)\uff0c\u8f85\u4ee5\u76d1\u7763\u5fae\u8c03\u3001\u53cd\u9988\u81ea\u52a9\u3001\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u7b49\u6280\u672f\u7684\u52a0\u6301\uff0c62 \u4ebf\u53c2\u6570\u7684 ChatGLM-6B \u5df2\u7ecf\u80fd\u751f\u6210\u76f8\u5f53\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u7684\u56de\u7b54\uff08\u76ee\u524d\u4e2d\u6587\u652f\u6301\u6700\u597d\uff09\u3002 2.1 \u8bad\u7ec3\u76ee\u6807 \u00b6 GLM\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u56de\u5f52\u7a7a\u767d\u586b\u5145\u76ee\u6807\u7684\u901a\u7528\u9884\u8bad\u7ec3\u6846\u67b6\u3002GLM \u5c06 NLU \u4efb\u52a1\u8f6c\u5316\u4e3a\u5305\u542b\u4efb\u52a1\u63cf\u8ff0\u7684\u5b8c\u5f62\u586b\u7a7a\u95ee\u9898\uff0c\u53ef\u4ee5\u901a\u8fc7\u81ea\u56de\u5f52\u751f\u6210\u7684\u65b9\u5f0f\u6765\u56de\u7b54\u3002\u81ea\u56de\u5f52\u7a7a\u767d\u586b\u5145\u76ee\u6807\u662f\u6307\u5728\u8f93\u5165\u6587\u672c\u4e2d\u968f\u673a\u6316\u53bb\u4e00\u4e9b\u8fde\u7eed\u7684\u6587\u672c\u7247\u6bb5\uff0c\u7136\u540e\u8bad\u7ec3\u6a21\u578b\u6309\u7167\u4efb\u610f\u987a\u5e8f\u91cd\u5efa\u8fd9\u4e9b\u7247\u6bb5\u3002\u5b8c\u5f62\u586b\u7a7a\u95ee\u9898\u662f\u6307\u5728\u8f93\u5165\u6587\u672c\u4e2d\u7528\u4e00\u4e2a\u7279\u6b8a\u7684\u7b26\u53f7\uff08\u5982[MASK]\uff09\u66ff\u6362\u6389\u4e00\u4e2a\u6216\u591a\u4e2a\u8bcd\uff0c\u7136\u540e\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u88ab\u66ff\u6362\u6389\u7684\u8bcd\u3002 \u4e0a\u56fe\u8bf4\u660e\u4e86GLM\u7684\u5b9e\u73b0\u601d\u60f3\uff08\u8bad\u7ec3\u76ee\u6807\uff09\uff1a \u539f\u59cb\u6587\u672c x=[x_1, x_2,...,x_6] x=[x_1, x_2,...,x_6] \u968f\u673a\u8fdb\u884c\u8fde\u7eed mask\uff0c\u8fd9\u91cc\u5047\u8bbe mask \u6389 [x_3] [x_3] \u548c [x_5,x_6]\u200b [x_5,x_6]\u200b \uff08GLM-130B\u4e2d\uff0cmask\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u8bed\u548c\u957f\u77ed\u843d\u6216\u6587\u7ae0\uff09. \u5c06 [x_3] [x_3] \u548c [x_5,x_6] [x_5,x_6] \u66ff\u6362\u4e3a [M] \u6807\u5fd7\uff0c\u5e76\u6253\u4e71 Part B \u7684\u987a\u5e8f\u3002\u4e3a\u4e86\u6355\u6349\u8de8\u5ea6\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\uff0c\u968f\u673a\u4ea4\u6362\u8de8\u5ea6\u7684\u987a\u5e8f\u3002 GLM \u81ea\u56de\u5f52\u5730\u751f\u6210 Part B\u3002 \u6bcf\u4e2a\u7247\u6bb5\u5728\u8f93\u5165\u65f6\u524d\u9762\u52a0\u4e0a [S]\uff0c\u5728\u8f93\u51fa\u65f6\u540e\u9762\u52a0\u4e0a [E]\u3002 \u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u8868\u793a\u4e0d\u540c\u7247\u6bb5\u4e4b\u95f4\u548c\u7247\u6bb5\u5185\u90e8\u7684\u4f4d\u7f6e\u5173\u7cfb\u3002 \u81ea\u6ce8\u610f\u529b\u63a9\u7801\u3002 \u7070\u8272\u533a\u57df\u88ab\u63a9\u76d6\u3002Part A \u7684\u8bcd\u8bed\u53ef\u4ee5\u81ea\u6211\u770b\u5230\uff08\u56fe\u84dd\u8272\u6846\uff09\uff0c\u4f46\u4e0d\u80fd\u770b\u5230 Part B\u3002 Part B \u7684\u8bcd\u8bed\u53ef\u4ee5\u770b\u5230 Part A \u548c Part B \u4e2d\u7684\u524d\u9762\u7684\u8bcd\u8bed\uff08\u56fe\u9ec4\u8272\u548c\u7eff\u8272\u6846\u5bf9\u5e94\u4e24\u4e2a\u7247\u6bb5\uff09\u3002 [M] := [MASK]\uff0c[S] := [START]\uff0c[E] := [END] \u6ce8\u610f\uff1a Position1 \u548c Position2 \u662f\u8f93\u5165\u7684\u4e8c\u7ef4\u7f16\u7801\uff0c\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u8868\u793a\u7247\u6bb5\u5728\u539f\u59cb\u6587\u672c\u4e2d\u7684\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u8868\u793a\u7247\u6bb5\u5185\u90e8\u7684\u76f8\u5bf9\u4f4d\u7f6e\u3002 \u5047\u8bbe\u539f\u59cb\u6587\u672c\u662f x=[x_1, x_2,...,x_6] x=[x_1, x_2,...,x_6] \uff0c\u5176\u4e2d [x_3] [x_3] \u548c [x_5,x_6] [x_5,x_6] \u88ab\u6316\u53bb\u3002\u90a3\u4e48\uff0c\u88ab\u6316\u53bb\u7684\u7247\u6bb5\u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4f4d\u7f6e\u7f16\u7801\u5c31\u662f\u5b83\u4eec\u5728\u539f\u59cb\u6587\u672c\u4e2d\u7684\u7d22\u5f15\uff0c\u5373 [x_3] [x_3] \u6765\u81ea\u7247\u6bb5 3\uff0c [x_5,x_6] [x_5,x_6] \u6765\u81ea\u7247\u6bb5 5\u3002\u5728\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4f4d\u7f6e\u7f16\u7801\u5c31\u662f\u5b83\u4eec\u5728\u7247\u6bb5\u4e2d\u7684\u7d22\u5f15\uff0c\u5373 0 \u548c 1\u3002\u56e0\u6b64\uff0c x_3 x_3 \u7684\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u662f[3, 0]\uff0c x_5 x_5 \u7684\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u662f[5, 0]\uff0c x_6\u200b x_6\u200b \u7684\u4e8c\u7ef4\u7f16\u7801\u662f[5, 1]\u3002 \u540c\u6837\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 x_1 x_1 \u7684\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u662f[1, 0]\uff0c x_2 x_2 \u7684\u4f4d\u7f6e\u7f16\u7801\u662f[2, 0]\uff0c x_4 x_4 \u7684\u4f4d\u7f6e\u7f16\u7801\u662f[4, 0]\u3002 2.2 \u6a21\u578b\u7ed3\u6784 \u00b6 \u91c7\u7528transformer\u7684decoder\u6a21\u5757\uff0c\u56e0\u4e3a\u65e0\u8bba\u662f\u5bf9\u4e8e\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u8fd8\u662f\u81ea\u7136\u8bed\u8a00\u751f\u6210\u7c7b\u4efb\u52a1\uff0cGLM\u90fd\u662f\u770b\u6210\u751f\u6210\u4efb\u52a1\u505a\u3002\u4f46\u662f\u8fd9\u91cc\u53ea\u80fd\u8bf4\u7c7bdeocder, \u56e0\u4e3adecoder\u662f\u5355\u5411\u7684\uff0c\u4f46\u662fGLM\u67d0\u4e9b\u4f4d\u7f6e\u53ef\u4ee5\u770b\u5230\u53cc\u5411\u7684\uff0c\u56e0\u6b64\u53c8\u88ab\u79f0\u4e3aPrefix -Decoder. \u76f8\u6bd4\u539f\u59cbDecoder\u6a21\u5757\uff0c\u6a21\u578b\u7ed3\u6784\u6709\u5982\u4e0b\u6539\u52a8\u70b9\uff1a embedding \u5c42\u68af\u5ea6\u7f29\u51cf \uff1a\u4e3a\u4e86\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u51cf\u5c0f\u4e86 embedding \u5c42\u7684\u68af\u5ea6\u3002\u68af\u5ea6\u7f29\u51cf\u7684\u6548\u679c\u76f8\u5f53\u4e8e\u628a embedding \u5c42\u7684\u68af\u5ea6\u7f29\u5c0f\u4e86 10 \u500d\uff0c\u51cf\u5c0f\u4e86\u68af\u5ea6\u7684\u8303\u6570\u3002 layer normalization \uff1a\u91c7\u7528\u4e86\u57fa\u4e8e Deep Norm \u7684 post layer norm\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u66ff\u6362ReLU\u6fc0\u6d3b\u51fd\u6570\u91c7\u7528\u4e86 GeGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002 2.3 \u6a21\u578b\u914d\u7f6e(6B) \u00b6 \u914d\u7f6e \u6570\u636e \u53c2\u6570 6.2B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 28 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1T \u8bcd\u8868\u5927\u5c0f 130528 \u6700\u5927\u957f\u5ea6 2048 2.4 \u786c\u4ef6\u8981\u6c42 \u00b6 \u91cf\u5316\u7b49\u7ea7 \u6700\u4f4eGPU\u663e\u5b58\uff08\u63a8\u7406\uff09 \u6700\u4f4eGPU\u663e\u5b58\uff08\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\uff09 FP16(\u65e0\u91cf\u5316) 13GB 14GB INT8 10GB 9GB INT4 6GB 7GB 2.5 \u6a21\u578b\u7279\u70b9 \u00b6 \u4f18\u70b9 1.\u8f83\u4f4e\u7684\u90e8\u7f72\u95e8\u69db\uff1a INT4 \u7cbe\u5ea6\u4e0b\uff0c\u53ea\u97006GB\u663e\u5b58\uff0c\u4f7f\u5f97 ChatGLM-6B \u53ef\u4ee5\u90e8\u7f72\u5728\u6d88\u8d39\u7ea7\u663e\u5361\u4e0a\u8fdb\u884c\u63a8\u7406\u3002 2.\u66f4\u957f\u7684\u5e8f\u5217\u957f\u5ea6\uff1a \u76f8\u6bd4 GLM-10B\uff08\u5e8f\u5217\u957f\u5ea61024\uff09\uff0cChatGLM2-6B \u5e8f\u5217\u957f\u5ea6\u8fbe32K\uff0c\u652f\u6301\u66f4\u957f\u5bf9\u8bdd\u548c\u5e94\u7528\u3002 \u4eba\u7c7b\u7c7b\u610f\u56fe\u5bf9\u9f50\u8bad\u7ec3 \u7f3a\u70b9\uff1a \u6a21\u578b\u5bb9\u91cf\u5c0f\uff0c\u76f8\u5bf9\u8f83\u5f31\u7684\u6a21\u578b\u8bb0\u5fc6\u548c\u8bed\u8a00\u80fd\u529b\u3002 \u8f83\u5f31\u7684\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u3002 2.6 \u884d\u751f\u5e94\u7528 \u00b6 langchain-ChatGLM\uff1a\u57fa\u4e8e langchain \u7684 ChatGLM \u5e94\u7528\uff0c\u5b9e\u73b0\u57fa\u4e8e\u53ef\u6269\u5c55\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\u3002 \u95fb\u8fbe\uff1a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8c03\u7528\u5e73\u53f0\uff0c\u57fa\u4e8e ChatGLM-6B \u5b9e\u73b0\u4e86\u7c7b ChatPDF \u529f\u80fd 2.7 \u8fed\u4ee3\u7248\u672c \u00b6 ChatGLM2-6B\uff1aChatGLM2-6B\u662fChatGLM-6B\u7684\u7b2c\u4e8c\u4ee3\u7248\u672c\uff0c\u76f8\u6bd4\u7b2c\u4e00\u4ee3\uff0c\u5b83\u5e26\u6765\u4e86\u4e00\u7cfb\u5217\u663e\u8457\u7684\u4f18\u52bf\uff1a \u66f4\u5f3a\u5927\u7684\u6027\u80fd\uff1a\u5728\u5404\u9879\u5bf9\u8bdd\u4efb\u52a1\u4e2d\uff0cChatGLM2-6B\u76f8\u6bd4ChatGLM-6B\u6709\u4e86\u5de8\u5927\u7684\u63d0\u5347\u3002\u4f8b\u5982\uff0c\u5728\u6570\u5b66\u4efb\u52a1\u4e0a\uff0c\u6027\u80fd\u63d0\u5347\u4e86\u6574\u6574571%\u3002 \u66f4\u957f\u7684\u4e0a\u4e0b\u6587\uff1aChatGLM2-6B\u91c7\u7528\u4e86FlashAttention\u6280\u672f\uff0c\u4f7f\u5176\u652f\u630132K\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u800cChatGLM-6B\u53ea\u80fd\u652f\u63012K\u3002\u8fd9\u4f7f\u5f97ChatGLM2-6B\u80fd\u591f\u8fdb\u884c\u66f4\u591a\u8f6e\u6b21\u7684\u5bf9\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u8bfb\u53d6\u66f4\u957f\u7684\u6587\u6863\u8fdb\u884c\u76f8\u5173\u7684\u63d0\u53d6\u548c\u95ee\u7b54\u3002 \u66f4\u9ad8\u6548\u7684\u63a8\u7406\uff1aChatGLM2-6B\u5f15\u5165\u4e86Multi-Query Attention\u6280\u672f\uff0c\u5728\u66f4\u4f4e\u7684\u663e\u5b58\u8d44\u6e90\u4e0b\u4ee5\u66f4\u5feb\u7684\u901f\u5ea6\u8fdb\u884c\u63a8\u7406\uff0c\u76f8\u6bd4\u7b2c\u4e00\u4ee3\u63d0\u5347\u4e8642%\u3002\u540c\u65f6\uff0cINT4\u91cf\u5316\u6a21\u578b\u4e2d\uff0c6G\u663e\u5b58\u7684\u5bf9\u8bdd\u957f\u5ea6\u75311K\u63d0\u5347\u5230\u4e868K\u3002 ChatGLM3-6B\uff1aChatGLM3-6B\u662fChatGLM-6B\u7684\u7b2c\u4e09\u4ee3\u7248\u672c\uff0c\u76f8\u6bd4\u524d\u4e24\u4ee3\uff0c\u9664\u4e86\u7ee7\u627f\u4e4b\u524d\u4f18\u52bf\u5916\uff0c\u76f8\u5f53\u4e8e\u5168\u9762\u5347\u7ea7\uff1a \u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\uff1a\u572810\u4f59\u4e2a\u56fd\u9645\u6807\u51c6\u56fe\u6587\u8bc4\u6d4b\u96c6\u4e0a\u53d6\u5f97SOTA \u4ee3\u7801\u589e\u5f3a\u6a21\u5757\uff1a\u6839\u636e\u7528\u6237\u9700\u6c42\u751f\u6210\u4ee3\u7801\u5e76\u6267\u884c\uff0c\u81ea\u52a8\u5b8c\u6210\u6570\u636e\u5206\u6790\u3001\u6587\u4ef6\u5904\u7406\u7b49\u590d\u6742\u4efb\u52a1 \u7f51\u7edc\u641c\u7d22\u589e\u5f3a\uff1a\u80fd\u81ea\u52a8\u6839\u636e\u95ee\u9898\u5728\u4e92\u8054\u7f51\u4e0a\u67e5\u627e\u76f8\u5173\u8d44\u6599\u5e76\u5728\u56de\u7b54\u65f6\u63d0\u4f9b\u53c2\u8003\u76f8\u5173\u6587\u732e\u6216\u8005\u6587\u7ae0\u94fe\u63a5 \u8bed\u4e49\u80fd\u529b\u4e0e\u903b\u8f91\u80fd\u529b\u5927\u5927\u589e\u5f3a\u3002 3 LLaMA\u6a21\u578b \u00b6 LLaMA\uff08Large Language Model Meta AI\uff09\uff0c\u7531 Meta AI \u4e8e2023\u5e74\u53d1\u5e03\u7684\u4e00\u4e2a\u5f00\u653e\u4e14\u9ad8\u6548\u7684\u5927\u578b\u57fa\u7840\u8bed\u8a00\u6a21\u578b\uff0c\u5171\u6709 7B\u300113B\u300133B\u300165B\uff08650 \u4ebf\uff09\u56db\u79cd\u7248\u672c\u3002 LLaMA\u8bad\u7ec3\u6570\u636e\u662f\u4ee5\u82f1\u8bed\u4e3a\u4e3b\u7684\u62c9\u4e01\u8bed\u7cfb\uff0c\u53e6\u5916\u8fd8\u5305\u542b\u4e86\u6765\u81ea GitHub \u7684\u4ee3\u7801\u6570\u636e\u3002\u8bad\u7ec3\u6570\u636e\u4ee5\u82f1\u6587\u4e3a\u4e3b\uff0c\u4e0d\u5305\u542b\u4e2d\u97e9\u65e5\u6587\uff0c\u6240\u6709\u8bad\u7ec3\u6570\u636e\u90fd\u662f\u5f00\u6e90\u7684\u3002\u5176\u4e2dLLaMA-65B \u548c LLaMA-33B \u662f\u5728 1.4\u4e07\u4ebf (1.4T) \u4e2a token\u4e0a\u8bad\u7ec3\u7684\uff0c\u800c\u6700\u5c0f\u7684\u6a21\u578b LLaMA-7B \u548cLLaMA-13B \u662f\u5728 1\u4e07\u4ebf (1T) \u4e2a token \u4e0a\u8bad\u7ec3\u7684\u3002 3.1 \u8bad\u7ec3\u76ee\u6807 \u00b6 \u5728**\u8bad\u7ec3\u76ee\u6807**\u4e0a\uff0cLLaMA \u7684\u8bad\u7ec3\u76ee\u6807\u662f\u8bed\u8a00\u6a21\u578b\uff0c\u5373\u6839\u636e\u5df2\u6709\u7684\u4e0a\u6587\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002 \u5173\u4e8e**tokenizer**\uff0cLLaMA \u7684\u8bad\u7ec3\u8bed\u6599\u4ee5\u82f1\u6587\u4e3a\u4e3b\uff0c\u4f7f\u7528\u4e86BPE\u5206\u8bcd\u7b97\u6cd5\u4f5c\u4e3a tokenizer\uff0c\u8bcd\u8868\u5927\u5c0f\u53ea\u6709 32000\u3002\u8bcd\u8868\u91cc\u7684\u4e2d\u6587 token \u5f88\u5c11\uff0c\u53ea\u6709\u51e0\u767e\u4e2a\uff0cLLaMA tokenizer \u5bf9\u4e2d\u6587\u5206\u8bcd\u7684\u7f16\u7801\u6548\u7387\u6bd4\u8f83\u4f4e\u3002 3.2 \u6a21\u578b\u7ed3\u6784 \u00b6 \u548c GPT \u7cfb\u5217\u4e00\u6837\uff0cLLaMA \u6a21\u578b\u4e5f\u662f Decoder-only\u67b6\u6784\uff0c\u4f46\u7ed3\u5408\u524d\u4eba\u7684\u5de5\u4f5c\u505a\u4e86\u4e00\u4e9b\u6539\u8fdb\uff0c\u6bd4\u5982\uff1a Pre-normalization \uff1a\u4e3a\u4e86\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u6ca1\u6709\u4f7f\u7528\u4f20\u7edf\u7684 post layer norm\uff0c\u800c\u662f\u4f7f\u7528\u4e86 pre layer Norm\uff0c\u540c\u65f6\u4f7f\u7528 RMSNorm\u5f52\u4e00\u5316\u51fd\u6570\uff08RMS Norm\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u53bb\u6389\u4e86\u51cf\u53bb\u5747\u503c\u7684\u90e8\u5206\uff0c\u7b80\u5316\u4e86Layer Norm \u7684\u8ba1\u7b97\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u7ea6 7%\u223c64% \u7684\u8ba1\u7b97\u65f6\u95f4\uff09\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u5c06 ReLU \u975e\u7ebf\u6027\u66ff\u6362\u4e3a SwiGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002 3.3 \u6a21\u578b\u914d\u7f6e\uff087B\uff09 \u00b6 \u914d\u7f6e \u6570\u636e \u53c2\u6570 6.7B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 32 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1T \u8bcd\u8868\u5927\u5c0f 32000 \u6700\u5927\u957f\u5ea6 2048 3.4 \u786c\u4ef6\u8981\u6c42 \u00b6 65B\u7684\u6a21\u578b\uff0c\u57282048\u4e2a80G\u7684A100 GPU\u4e0a\uff0c\u53ef\u4ee5\u8fbe\u5230380 tokens/sec/GPU\u7684\u901f\u5ea6\u3002\u8bad\u7ec31.4T tokens\u9700\u898121\u5929\u3002 3.5 \u6a21\u578b\u7279\u70b9 \u00b6 \u4f18\u70b9 \u5177\u6709 130 \u4ebf\u53c2\u6570\u7684 LLaMA \u6a21\u578b\u300c\u5728\u5927\u591a\u6570\u57fa\u51c6\u4e0a\u300d\u53ef\u4ee5\u80dc\u8fc7 GPT-3\uff08 \u53c2\u6570\u91cf\u8fbe 1750 \u4ebf\uff09\u3002 \u53ef\u4ee5\u5728\u5355\u5757 V100 GPU \u4e0a\u8fd0\u884c\uff1b\u800c\u6700\u5927\u7684 650 \u4ebf\u53c2\u6570\u7684 LLaMA \u6a21\u578b\u53ef\u4ee5\u5ab2\u7f8e\u8c37\u6b4c\u7684 Chinchilla-70B \u548c PaLM-540B\u3002 \u7f3a\u70b9\uff1a \u4f1a\u4ea7\u751f\u504f\u89c1\u6027\u3001\u6709\u6bd2\u6216\u8005\u865a\u5047\u7684\u5185\u5bb9. \u5728\u4e2d\u6587\u4e0a\u6548\u679c\u5dee\uff0c\u8bad\u7ec3\u8bed\u6599\u4e0d\u5305\u542b\u4e2d\u6587\u6216\u8005\u4e00\u4e2a\u6c49\u5b57\u5207\u5206\u4e3a\u591a\u4e2a token\uff0c\u7f16\u7801\u6548\u7387\u4f4e\uff0c\u6a21\u578b\u5b66\u4e60\u96be\u5ea6\u5927\u3002 3.6 \u884d\u751f\u5e94\u7528 \u00b6 Alpaca: \u65af\u5766\u798f\u5927\u5b66\u5728 52k \u6761\u82f1\u6587\u6307\u4ee4\u9075\u5faa\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u4e86 7B \u89c4\u6a21\u7684 LLaMA\u3002 Vicuna: \u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u5728 ShareGPT \u6536\u96c6\u7684\u7528\u6237\u5171\u4eab\u5bf9\u8bdd\u6570\u636e\u4e0a\uff0c\u5fae\u8c03\u4e86 13B \u89c4\u6a21\u7684 LLaMA\u3002 BELLE: \u94fe\u5bb6\u4ec5\u4f7f\u7528\u7531 ChatGPT \u751f\u4ea7\u7684\u6570\u636e\uff0c\u5bf9 LLaMA \u8fdb\u884c\u4e86\u6307\u4ee4\u5fae\u8c03\uff0c\u5e76\u9488\u5bf9\u4e2d\u6587\u8fdb\u884c\u4e86\u4f18\u5316\u3002 Chinese LLaMA\uff1a \u6269\u5145\u4e2d\u6587\u8bcd\u8868\uff1a\u5e38\u89c1\u505a\u6cd5\uff1a\u5728\u4e2d\u6587\u8bed\u6599\u4e0a\u4f7f\u7528 Sentence Piece \u8bad\u7ec3\u4e00\u4e2a\u4e2d\u6587 tokenizer\uff0c\u4f7f\u7528\u4e86 20000 \u4e2a\u4e2d\u6587\u8bcd\u6c47\u3002\u7136\u540e\u5c06\u4e2d\u6587 tokenizer \u4e0e\u539f\u59cb\u7684 LLaMA tokenizer \u5408\u5e76\u8d77\u6765\uff0c\u901a\u8fc7\u7ec4\u5408\u4e8c\u8005\u7684\u8bcd\u6c47\u8868\uff0c\u6700\u7ec8\u83b7\u5f97\u4e00\u4e2a\u5408\u5e76\u7684 tokenizer\uff0c\u79f0\u4e3a Chinese LLaMA tokenizer\u3002\u8bcd\u8868\u5927\u5c0f\u4e3a 49953\u3002 3.7 \u8fed\u4ee3\u7248\u672c \u00b6 LLaMA 2\uff08Open Foundation and Fine-Tuned Chat Models\uff09\uff1aLLaMA 2\u662fLLaMA\u6a21\u578b\u7684\u5347\u7ea7\u8fed\u4ee3\u7248\u672c\uff0c\u5176\u6a21\u578b\u67b6\u6784\u57fa\u672c\u548cllama\u4e00\u6837\u3002\u4e0d\u540c\u70b9\uff1a LLama2\u8bad\u7ec3\u8bed\u6599\u76f8\u6bd4LLaMA\u591a\u51fa40%\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u662f\u7531\u4e4b\u524d\u76842048\u5347\u7ea7\u52304096\uff0c\u53ef\u4ee5\u7406\u89e3\u548c\u751f\u6210\u66f4\u957f\u7684\u6587\u672c\u3002 \u65b0\u589e\u9884\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u6ce8\u91cd\u5b89\u5168&\u9690\u79c1\u95ee\u9898\u3002 \u8bad\u7ec3\u51fa\u4e86chat\u7248\u672c\uff1allama-2-chat: SFT, RLHF. 4 BLOOM\u6a21\u578b \u00b6 BLOOM\u7cfb\u5217\u6a21\u578b\u662f\u7531 Hugging Face\u516c\u53f8\u7684BigScience \u56e2\u961f\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002\u8bad\u7ec3\u6570\u636e\u5305\u542b\u4e86\u82f1\u8bed\u3001\u4e2d\u6587\u3001\u6cd5\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u8461\u8404\u7259\u8bed\u7b49\u5171 46 \u79cd\u8bed\u8a00\uff0c\u53e6\u5916\u8fd8\u5305\u542b 13 \u79cd\u7f16\u7a0b\u8bed\u8a00\u30021.5TB \u7ecf\u8fc7\u53bb\u91cd\u548c\u6e05\u6d17\u7684\u6587\u672c\uff0c\u8f6c\u6362\u4e3a 350B \u7684 tokens\u3002\u8bad\u7ec3\u6570\u636e\u7684\u8bed\u8a00\u5206\u5e03\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ef\u4ee5\u770b\u5230\u4e2d\u6587\u8bed\u6599\u5360\u6bd4\u4e3a 16.2% \u6309\u7167\u6a21\u578b\u53c2\u6570\u91cf\uff0cBLOOM \u6a21\u578b\u6709 560M\u30011.1B\u30011.7B\u30013B\u30017.1B \u548c 176B \u8fd9\u51e0\u4e2a\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u3002 4.1 \u8bad\u7ec3\u76ee\u6807 \u00b6 \u5728**\u8bad\u7ec3\u76ee\u6807**\u4e0a\uff0cLLaMA \u7684\u8bad\u7ec3\u76ee\u6807\u662f\u8bed\u8a00\u6a21\u578b\uff0c\u5373\u6839\u636e\u5df2\u6709\u7684\u4e0a\u6587\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002 \u5173\u4e8e**tokenizer**\uff0cBLOOM \u5728\u591a\u8bed\u79cd\u8bed\u6599\u4e0a\u4f7f\u7528 Byte Pair Encoding(BPE)\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\u5f97\u5230 tokenizer\uff0c\u8bcd\u8868\u5927\u5c0f\u4e3a 250880\u3002 4.2 \u6a21\u578b\u7ed3\u6784 \u00b6 \u548c GPT \u7cfb\u5217\u4e00\u6837\uff0cLLaMA \u6a21\u578b\u4e5f\u662f Decoder-only\u67b6\u6784\uff0c\u4f46\u7ed3\u5408\u524d\u4eba\u7684\u5de5\u4f5c\u505a\u4e86\u4e00\u4e9b\u6539\u8fdb\uff0c\u6bd4\u5982\uff1a embedding layer norm \uff1a\u5728 embedding \u5c42\u540e\u6dfb\u52a0\u4e86\u4e00\u4e2a layer normalization\uff0c\u6765\u4f7f\u8bad\u7ec3\u66f4\u52a0\u7a33\u5b9a\u3002 layer normalization \uff1a\u4e3a\u4e86\u63d0\u5347\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\uff0c\u6ca1\u6709\u4f7f\u7528\u4f20\u7edf\u7684 post layer norm\uff0c\u800c\u662f\u4f7f\u7528\u4e86 pre layer Norm\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u91c7\u7528\u4e86 GeLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 ALiBi\u3002\u76f8\u6bd4\u4e8e\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0cALiBi \u7684\u5916\u63a8\u6027\u66f4\u597d\uff0c\u5373\u867d\u7136\u8bad\u7ec3\u9636\u6bb5\u7684\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u4e3a 2048\uff0c\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5904\u7406\u66f4\u957f\u7684\u5e8f\u5217\u3002 4.3 \u6a21\u578b\u914d\u7f6e\uff08176B\uff09 \u00b6 \u914d\u7f6e \u6570\u636e \u53c2\u6570 176B \u9690\u85cf\u5c42\u7ef4\u5ea6 14336 \u5c42\u6570 70 \u6ce8\u610f\u529b\u5934\u6570 112 \u8bad\u7ec3\u6570\u636e 366B \u8bcd\u8868\u5927\u5c0f 250880 \u6700\u5927\u957f\u5ea6 2048 4.4 \u786c\u4ef6\u8981\u6c42 \u00b6 176B-BLOOM \u6a21\u578b\u5728384 \u5f20 NVIDIA A100 80GB GPU\u4e0a\uff0c\u8bad\u7ec3\u4e8e 2022 \u5e74 3 \u6708\u81f3 7 \u6708\u671f\u95f4\uff0c\u8017\u65f6\u7ea6 3.5 \u4e2a\u6708\u5b8c\u6210 (\u7ea6 100 \u4e07\u8ba1\u7b97\u65f6)\uff0c\u7b97\u529b\u6210\u672c\u8d85\u8fc7300\u4e07\u6b27\u5143 4.5 \u6a21\u578b\u7279\u70b9 \u00b6 \u4f18\u70b9 \u5177\u6709\u826f\u597d\u7684\u591a\u8bed\u8a00\u9002\u5e94\u6027\uff0c\u80fd\u591f\u5728\u591a\u79cd\u8bed\u8a00\u95f4\u8fdb\u884c\u5207\u6362\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3 \u7f3a\u70b9\uff1a \u4f1a\u4ea7\u751f\u504f\u89c1\u6027\u3001\u6709\u6bd2\u6216\u8005\u865a\u5047\u7684\u5185\u5bb9. 4.6 \u884d\u751f\u5e94\u7528 \u00b6 \u8f69\u8f95: \u91d1\u878d\u9886\u57df\u5927\u6a21\u578b\uff0c\u5ea6\u5c0f\u6ee1\u5728 BLOOM-176B \u7684\u57fa\u7840\u4e0a\u9488\u5bf9\u4e2d\u6587\u901a\u7528\u9886\u57df\u548c\u91d1\u878d\u9886\u57df\u8fdb\u884c\u4e86\u9488\u5bf9\u6027\u7684\u9884\u8bad\u7ec3\u4e0e\u5fae\u8c03\u3002 BELLE: \u94fe\u5bb6\u4ec5\u4f7f\u7528\u7531 ChatGPT \u751f\u4ea7\u7684\u6570\u636e\uff0c\u5bf9 BLOOMZ-7B1-mt \u8fdb\u884c\u4e86\u6307\u4ee4\u5fae\u8c03\u3002 5 Baichuan-7B\u6a21\u578b \u00b6 Baichuan-7B\u7531\u767e\u5ddd\u667a\u80fd\u4e8e2023\u5e746\u6708\u53d1\u5e03\u7684\u4e00\u4e2a\u5f00\u653e\u4e14\u53ef\u5546\u7528\u7684\u5927\u578b\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u5176\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\uff0c\u662f\u5728\u7ea6 1.2\u4e07\u4ebf (1.2T) \u4e2a token\u4e0a\u8bad\u7ec3\u768470\u4ebf\u53c2\u6570\u6a21\u578b\u3002 5.1 \u8bad\u7ec3\u76ee\u6807 \u00b6 \u5728**\u8bad\u7ec3\u76ee\u6807**\u4e0a\uff0cBaichuan-7B \u7684\u8bad\u7ec3\u76ee\u6807\u4e5f\u662f\u8bed\u8a00\u6a21\u578b\uff0c\u5373\u6839\u636e\u5df2\u6709\u7684\u4e0a\u6587\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002 \u5173\u4e8e**tokenizer**\uff0c\u4f7f\u7528\u4e86BPE\u5206\u8bcd\u7b97\u6cd5\u4f5c\u4e3a tokenizer\uff0c\u8bcd\u8868\u5927\u5c0f64000\u3002 \u5173\u4e8e**\u6570\u636e**\uff0c\u539f\u59cb\u6570\u636e\u5305\u62ec\u5f00\u6e90\u7684\u4e2d\u82f1\u6587\u6570\u636e\u548c\u81ea\u884c\u6293\u53d6\u7684\u4e2d\u6587\u4e92\u8054\u7f51\u6570\u636e\uff0c\u4ee5\u53ca\u90e8\u5206\u9ad8\u8d28\u91cf\u77e5\u8bc6\u6027\u6570\u636e\u3002 5.2 \u6a21\u578b\u7ed3\u6784 \u00b6 \u548c LLaMA \u4e00\u6837\u7684\u6a21\u578b\u8bbe\u8ba1\uff0c\u4e5f\u662f Decoder-only\u67b6\u6784\uff0c\u4f46\u7ed3\u5408\u524d\u4eba\u7684\u5de5\u4f5c\u505a\u4e86\u4e00\u4e9b\u6539\u8fdb\uff0c\u6bd4\u5982\uff1a Pre-normalization \uff1a\u4e3a\u4e86\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u6ca1\u6709\u4f7f\u7528\u4f20\u7edf\u7684 post layer norm\uff0c\u800c\u662f\u4f7f\u7528\u4e86 pre layer Norm\uff0c\u540c\u65f6\u4f7f\u7528 RMSNorm\u5f52\u4e00\u5316\u51fd\u6570\uff08RMS Norm\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u53bb\u6389\u4e86\u51cf\u53bb\u5747\u503c\u7684\u90e8\u5206\uff0c\u7b80\u5316\u4e86Layer Norm \u7684\u8ba1\u7b97\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u7ea6 7%\u223c64% \u7684\u8ba1\u7b97\u65f6\u95f4\uff09\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u4f7f\u7528 SwiGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002 5.3 \u6a21\u578b\u914d\u7f6e\uff087B\uff09 \u00b6 \u914d\u7f6e \u6570\u636e \u53c2\u6570 7B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 32 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1.2T \u8bcd\u8868\u5927\u5c0f 64000 \u6700\u5927\u957f\u5ea6 4096 5.4 \u6a21\u578b\u7279\u70b9 \u00b6 baichuan-7B**\u5177\u6709\u8f83\u5f3a\u7684\u901a\u7528\u578b\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e**\u81ea\u7136\u8bed\u8a00\u5904\u7406 \u3001\u673a\u5668\u7ffb\u8bd1\u3001\u95ee\u7b54\u7cfb\u7edf\u7b49\u9886\u57df\uff0c\u5728\u667a\u80fd\u5ba2\u670d\u3001\u91d1\u878d\u3001\u533b\u7597\u3001\u6559\u80b2\u3001**\u4eba\u5de5\u667a\u80fd**\u7b49\u5404\u884c\u5404\u4e1a\u90fd\u5177\u6709\u5f88\u9ad8\u7684\u6f5c\u529b\u548c\u5e94\u7528\u524d\u666f\u3002 \u5728\u6807\u51c6\u7684\u4e2d\u6587\u548c\u82f1\u6587\u6743\u5a01 benchmark\uff08C-EVAL/MMLU\uff09\u4e0a\u5747\u53d6\u5f97\u4e86\u540c\u53c2\u6570\u89c4\u6a21\u4e0b\u7684\u6700\u597d\u6548\u679c\u3002 5.5 \u8fed\u4ee3\u7248\u672c \u00b6 Baichuan-13B \u662f\u7531\u767e\u5ddd\u667a\u80fd\u7ee7 Baichuan-7B \u4e4b\u540e\u5f00\u53d1\u7684\u5305\u542b 130 \u4ebf\u53c2\u6570\u7684\u5f00\u6e90\u53ef\u5546\u7528\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6743\u5a01\u7684\u4e2d\u6587\u548c\u82f1\u6587 benchmark \u4e0a\u5747\u53d6\u5f97\u540c\u5c3a\u5bf8\u6700\u597d\u7684\u6548\u679c\u3002Baichuan-13B \u6709\u5982\u4e0b\u51e0\u4e2a\u7279\u70b9\uff1a \u66f4\u5927\u5c3a\u5bf8\u3001\u66f4\u591a\u6570\u636e \uff1aBaichuan-13B \u53c2\u6570\u91cf\u8fbe\u5230 130 \u4ebf\uff0c\u5e76\u4e14\u5728\u9ad8\u8d28\u91cf\u7684\u8bed\u6599\u4e0a\u8bad\u7ec3\u4e86 1.4 \u4e07\u4ebf tokens\uff0c\u662f\u5f53\u524d\u5f00\u6e90 13B \u5c3a\u5bf8\u4e0b\u8bad\u7ec3\u6570\u636e\u91cf\u6700\u591a\u7684\u6a21\u578b\u3002\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\uff0c\u4f7f\u7528 ALiBi \u4f4d\u7f6e\u7f16\u7801\uff0c\u4e0a\u4e0b\u6587\u7a97\u53e3\u957f\u5ea6\u4e3a 4096\u3002 \u66f4\u9ad8\u6548\u7684\u63a8\u7406 \uff1a\u540c\u65f6\u5f00\u6e90\u4e86 int8 \u548c int4 \u7684\u91cf\u5316\u7248\u672c\uff0c\u76f8\u5bf9\u975e\u91cf\u5316\u7248\u672c\u5728\u51e0\u4e4e\u6ca1\u6709\u6548\u679c\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u5927\u5927\u964d\u4f4e\u4e86\u90e8\u7f72\u7684\u673a\u5668\u8d44\u6e90\u95e8\u69db\uff0c\u53ef\u4ee5\u90e8\u7f72\u5728\u5982 Nvidia 3090 \u8fd9\u6837\u7684\u6d88\u8d39\u7ea7\u663e\u5361\u4e0a\u3002 \u5f00\u6e90\u514d\u8d39\u53ef\u5546\u7528 \uff1aBaichuan-13B \u4e0d\u4ec5\u5bf9\u5b66\u672f\u7814\u7a76\u5b8c\u5168\u5f00\u653e\uff0c\u5f00\u53d1\u8005\u4e5f\u4ec5\u9700\u90ae\u4ef6\u7533\u8bf7\u5e76\u83b7\u5f97\u5b98\u65b9\u5546\u7528\u8bb8\u53ef\u540e\uff0c\u5373\u53ef\u4ee5\u514d\u8d39\u5546\u7528\u3002 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86LLM\u4e3b\u6d41\u7684\u5f00\u6e90\u5927\u6a21\u578b\uff0c\u5bf9\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u76ee\u6807\u3001\u4f18\u7f3a\u70b9\u8fdb\u884c\u4e86\u5206\u6790\u548c\u603b\u7ed3\u3002","title":"2.2 LLM\u4e3b\u6d41\u5f00\u6e90\u4ee3\u8868\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#llm","text":"","title":"LLM\u4e3b\u6d41\u5f00\u6e90\u5927\u6a21\u578b\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#_1","text":"\u4e86\u89e3LLM\u4e3b\u6d41\u5f00\u6e90\u5927\u6a21\u578b. \u638c\u63e1ChatGLM\u3001LLaMA\u3001Bloom\u7b49\u57fa\u7840\u5927\u6a21\u578b\u7684\u539f\u7406","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#1-llm","text":"\u968f\u7740ChatGPT\u8fc5\u901f\u706b\u7206\uff0c\u5f15\u53d1\u4e86\u5927\u6a21\u578b\u7684\u65f6\u4ee3\u53d8\u9769\uff0c\u56fd\u5185\u5916\u5404\u5927\u516c\u53f8\u4e5f\u5feb\u901f\u8ddf\u8fdb\u751f\u6210\u5f0fAI\u5e02\u573a\uff0c\u8fd1\u767e\u6b3e\u5927\u6a21\u578b\u53d1\u5e03\u53ca\u5e94\u7528\u3002 \u76ee\u524d\uff0c\u5f00\u6e90\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u6709\u4e09\u5927\u7c7b\uff1a ChatGLM-6B\u884d\u751f\u7684\u5927\u6a21\u578b\uff08wenda\u3001ChatSQL\u7b49\uff09 LLaMA\u884d\u751f\u7684\u5927\u6a21\u578b\uff08Alpaca\u3001Vicuna\u3001BELLE\u3001Phoenix\u3001Chimera\u7b49\uff09 Bloom\u884d\u751f\u7684\u5927\u6a21\u578b\uff08Bloomz\u3001BELLE\u3001Phoenix\u7b49\uff09","title":"1 LLM\u4e3b\u6d41\u5927\u6a21\u578b\u7c7b\u522b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#2-chatglm-6b","text":"ChatGLM-6B \u662f\u6e05\u534e\u5927\u5b66\u63d0\u51fa\u7684\u4e00\u4e2a\u5f00\u6e90\u3001\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\u7684\u5bf9\u8bdd\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e General Language Model (GLM) \u67b6\u6784\uff0c\u5177\u6709 62 \u4ebf\u53c2\u6570\u3002\u8be5\u6a21\u578b\u4f7f\u7528\u4e86\u548c ChatGPT \u76f8\u4f3c\u7684\u6280\u672f\uff0c\u7ecf\u8fc7\u7ea6 1T \u6807\u8bc6\u7b26\u7684\u4e2d\u82f1\u53cc\u8bed\u8bad\u7ec3(\u4e2d\u82f1\u6587\u6bd4\u4f8b\u4e3a 1:1)\uff0c\u8f85\u4ee5\u76d1\u7763\u5fae\u8c03\u3001\u53cd\u9988\u81ea\u52a9\u3001\u4eba\u7c7b\u53cd\u9988\u5f3a\u5316\u5b66\u4e60\u7b49\u6280\u672f\u7684\u52a0\u6301\uff0c62 \u4ebf\u53c2\u6570\u7684 ChatGLM-6B \u5df2\u7ecf\u80fd\u751f\u6210\u76f8\u5f53\u7b26\u5408\u4eba\u7c7b\u504f\u597d\u7684\u56de\u7b54\uff08\u76ee\u524d\u4e2d\u6587\u652f\u6301\u6700\u597d\uff09\u3002","title":"2 ChatGLM-6B\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#21","text":"GLM\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u56de\u5f52\u7a7a\u767d\u586b\u5145\u76ee\u6807\u7684\u901a\u7528\u9884\u8bad\u7ec3\u6846\u67b6\u3002GLM \u5c06 NLU \u4efb\u52a1\u8f6c\u5316\u4e3a\u5305\u542b\u4efb\u52a1\u63cf\u8ff0\u7684\u5b8c\u5f62\u586b\u7a7a\u95ee\u9898\uff0c\u53ef\u4ee5\u901a\u8fc7\u81ea\u56de\u5f52\u751f\u6210\u7684\u65b9\u5f0f\u6765\u56de\u7b54\u3002\u81ea\u56de\u5f52\u7a7a\u767d\u586b\u5145\u76ee\u6807\u662f\u6307\u5728\u8f93\u5165\u6587\u672c\u4e2d\u968f\u673a\u6316\u53bb\u4e00\u4e9b\u8fde\u7eed\u7684\u6587\u672c\u7247\u6bb5\uff0c\u7136\u540e\u8bad\u7ec3\u6a21\u578b\u6309\u7167\u4efb\u610f\u987a\u5e8f\u91cd\u5efa\u8fd9\u4e9b\u7247\u6bb5\u3002\u5b8c\u5f62\u586b\u7a7a\u95ee\u9898\u662f\u6307\u5728\u8f93\u5165\u6587\u672c\u4e2d\u7528\u4e00\u4e2a\u7279\u6b8a\u7684\u7b26\u53f7\uff08\u5982[MASK]\uff09\u66ff\u6362\u6389\u4e00\u4e2a\u6216\u591a\u4e2a\u8bcd\uff0c\u7136\u540e\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u88ab\u66ff\u6362\u6389\u7684\u8bcd\u3002 \u4e0a\u56fe\u8bf4\u660e\u4e86GLM\u7684\u5b9e\u73b0\u601d\u60f3\uff08\u8bad\u7ec3\u76ee\u6807\uff09\uff1a \u539f\u59cb\u6587\u672c x=[x_1, x_2,...,x_6] x=[x_1, x_2,...,x_6] \u968f\u673a\u8fdb\u884c\u8fde\u7eed mask\uff0c\u8fd9\u91cc\u5047\u8bbe mask \u6389 [x_3] [x_3] \u548c [x_5,x_6]\u200b [x_5,x_6]\u200b \uff08GLM-130B\u4e2d\uff0cmask\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u8bed\u548c\u957f\u77ed\u843d\u6216\u6587\u7ae0\uff09. \u5c06 [x_3] [x_3] \u548c [x_5,x_6] [x_5,x_6] \u66ff\u6362\u4e3a [M] \u6807\u5fd7\uff0c\u5e76\u6253\u4e71 Part B \u7684\u987a\u5e8f\u3002\u4e3a\u4e86\u6355\u6349\u8de8\u5ea6\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\uff0c\u968f\u673a\u4ea4\u6362\u8de8\u5ea6\u7684\u987a\u5e8f\u3002 GLM \u81ea\u56de\u5f52\u5730\u751f\u6210 Part B\u3002 \u6bcf\u4e2a\u7247\u6bb5\u5728\u8f93\u5165\u65f6\u524d\u9762\u52a0\u4e0a [S]\uff0c\u5728\u8f93\u51fa\u65f6\u540e\u9762\u52a0\u4e0a [E]\u3002 \u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u8868\u793a\u4e0d\u540c\u7247\u6bb5\u4e4b\u95f4\u548c\u7247\u6bb5\u5185\u90e8\u7684\u4f4d\u7f6e\u5173\u7cfb\u3002 \u81ea\u6ce8\u610f\u529b\u63a9\u7801\u3002 \u7070\u8272\u533a\u57df\u88ab\u63a9\u76d6\u3002Part A \u7684\u8bcd\u8bed\u53ef\u4ee5\u81ea\u6211\u770b\u5230\uff08\u56fe\u84dd\u8272\u6846\uff09\uff0c\u4f46\u4e0d\u80fd\u770b\u5230 Part B\u3002 Part B \u7684\u8bcd\u8bed\u53ef\u4ee5\u770b\u5230 Part A \u548c Part B \u4e2d\u7684\u524d\u9762\u7684\u8bcd\u8bed\uff08\u56fe\u9ec4\u8272\u548c\u7eff\u8272\u6846\u5bf9\u5e94\u4e24\u4e2a\u7247\u6bb5\uff09\u3002 [M] := [MASK]\uff0c[S] := [START]\uff0c[E] := [END] \u6ce8\u610f\uff1a Position1 \u548c Position2 \u662f\u8f93\u5165\u7684\u4e8c\u7ef4\u7f16\u7801\uff0c\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u8868\u793a\u7247\u6bb5\u5728\u539f\u59cb\u6587\u672c\u4e2d\u7684\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u8868\u793a\u7247\u6bb5\u5185\u90e8\u7684\u76f8\u5bf9\u4f4d\u7f6e\u3002 \u5047\u8bbe\u539f\u59cb\u6587\u672c\u662f x=[x_1, x_2,...,x_6] x=[x_1, x_2,...,x_6] \uff0c\u5176\u4e2d [x_3] [x_3] \u548c [x_5,x_6] [x_5,x_6] \u88ab\u6316\u53bb\u3002\u90a3\u4e48\uff0c\u88ab\u6316\u53bb\u7684\u7247\u6bb5\u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4f4d\u7f6e\u7f16\u7801\u5c31\u662f\u5b83\u4eec\u5728\u539f\u59cb\u6587\u672c\u4e2d\u7684\u7d22\u5f15\uff0c\u5373 [x_3] [x_3] \u6765\u81ea\u7247\u6bb5 3\uff0c [x_5,x_6] [x_5,x_6] \u6765\u81ea\u7247\u6bb5 5\u3002\u5728\u7b2c\u4e8c\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u4f4d\u7f6e\u7f16\u7801\u5c31\u662f\u5b83\u4eec\u5728\u7247\u6bb5\u4e2d\u7684\u7d22\u5f15\uff0c\u5373 0 \u548c 1\u3002\u56e0\u6b64\uff0c x_3 x_3 \u7684\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u662f[3, 0]\uff0c x_5 x_5 \u7684\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u662f[5, 0]\uff0c x_6\u200b x_6\u200b \u7684\u4e8c\u7ef4\u7f16\u7801\u662f[5, 1]\u3002 \u540c\u6837\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230 x_1 x_1 \u7684\u4e8c\u7ef4\u4f4d\u7f6e\u7f16\u7801\u662f[1, 0]\uff0c x_2 x_2 \u7684\u4f4d\u7f6e\u7f16\u7801\u662f[2, 0]\uff0c x_4 x_4 \u7684\u4f4d\u7f6e\u7f16\u7801\u662f[4, 0]\u3002","title":"2.1 \u8bad\u7ec3\u76ee\u6807"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#22","text":"\u91c7\u7528transformer\u7684decoder\u6a21\u5757\uff0c\u56e0\u4e3a\u65e0\u8bba\u662f\u5bf9\u4e8e\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u8fd8\u662f\u81ea\u7136\u8bed\u8a00\u751f\u6210\u7c7b\u4efb\u52a1\uff0cGLM\u90fd\u662f\u770b\u6210\u751f\u6210\u4efb\u52a1\u505a\u3002\u4f46\u662f\u8fd9\u91cc\u53ea\u80fd\u8bf4\u7c7bdeocder, \u56e0\u4e3adecoder\u662f\u5355\u5411\u7684\uff0c\u4f46\u662fGLM\u67d0\u4e9b\u4f4d\u7f6e\u53ef\u4ee5\u770b\u5230\u53cc\u5411\u7684\uff0c\u56e0\u6b64\u53c8\u88ab\u79f0\u4e3aPrefix -Decoder. \u76f8\u6bd4\u539f\u59cbDecoder\u6a21\u5757\uff0c\u6a21\u578b\u7ed3\u6784\u6709\u5982\u4e0b\u6539\u52a8\u70b9\uff1a embedding \u5c42\u68af\u5ea6\u7f29\u51cf \uff1a\u4e3a\u4e86\u63d0\u5347\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u51cf\u5c0f\u4e86 embedding \u5c42\u7684\u68af\u5ea6\u3002\u68af\u5ea6\u7f29\u51cf\u7684\u6548\u679c\u76f8\u5f53\u4e8e\u628a embedding \u5c42\u7684\u68af\u5ea6\u7f29\u5c0f\u4e86 10 \u500d\uff0c\u51cf\u5c0f\u4e86\u68af\u5ea6\u7684\u8303\u6570\u3002 layer normalization \uff1a\u91c7\u7528\u4e86\u57fa\u4e8e Deep Norm \u7684 post layer norm\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u66ff\u6362ReLU\u6fc0\u6d3b\u51fd\u6570\u91c7\u7528\u4e86 GeGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002","title":"2.2 \u6a21\u578b\u7ed3\u6784"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#23-6b","text":"\u914d\u7f6e \u6570\u636e \u53c2\u6570 6.2B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 28 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1T \u8bcd\u8868\u5927\u5c0f 130528 \u6700\u5927\u957f\u5ea6 2048","title":"2.3 \u6a21\u578b\u914d\u7f6e(6B)"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#24","text":"\u91cf\u5316\u7b49\u7ea7 \u6700\u4f4eGPU\u663e\u5b58\uff08\u63a8\u7406\uff09 \u6700\u4f4eGPU\u663e\u5b58\uff08\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\uff09 FP16(\u65e0\u91cf\u5316) 13GB 14GB INT8 10GB 9GB INT4 6GB 7GB","title":"2.4 \u786c\u4ef6\u8981\u6c42"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#25","text":"\u4f18\u70b9 1.\u8f83\u4f4e\u7684\u90e8\u7f72\u95e8\u69db\uff1a INT4 \u7cbe\u5ea6\u4e0b\uff0c\u53ea\u97006GB\u663e\u5b58\uff0c\u4f7f\u5f97 ChatGLM-6B \u53ef\u4ee5\u90e8\u7f72\u5728\u6d88\u8d39\u7ea7\u663e\u5361\u4e0a\u8fdb\u884c\u63a8\u7406\u3002 2.\u66f4\u957f\u7684\u5e8f\u5217\u957f\u5ea6\uff1a \u76f8\u6bd4 GLM-10B\uff08\u5e8f\u5217\u957f\u5ea61024\uff09\uff0cChatGLM2-6B \u5e8f\u5217\u957f\u5ea6\u8fbe32K\uff0c\u652f\u6301\u66f4\u957f\u5bf9\u8bdd\u548c\u5e94\u7528\u3002 \u4eba\u7c7b\u7c7b\u610f\u56fe\u5bf9\u9f50\u8bad\u7ec3 \u7f3a\u70b9\uff1a \u6a21\u578b\u5bb9\u91cf\u5c0f\uff0c\u76f8\u5bf9\u8f83\u5f31\u7684\u6a21\u578b\u8bb0\u5fc6\u548c\u8bed\u8a00\u80fd\u529b\u3002 \u8f83\u5f31\u7684\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u3002","title":"2.5 \u6a21\u578b\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#26","text":"langchain-ChatGLM\uff1a\u57fa\u4e8e langchain \u7684 ChatGLM \u5e94\u7528\uff0c\u5b9e\u73b0\u57fa\u4e8e\u53ef\u6269\u5c55\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\u3002 \u95fb\u8fbe\uff1a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8c03\u7528\u5e73\u53f0\uff0c\u57fa\u4e8e ChatGLM-6B \u5b9e\u73b0\u4e86\u7c7b ChatPDF \u529f\u80fd","title":"2.6 \u884d\u751f\u5e94\u7528"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#27","text":"ChatGLM2-6B\uff1aChatGLM2-6B\u662fChatGLM-6B\u7684\u7b2c\u4e8c\u4ee3\u7248\u672c\uff0c\u76f8\u6bd4\u7b2c\u4e00\u4ee3\uff0c\u5b83\u5e26\u6765\u4e86\u4e00\u7cfb\u5217\u663e\u8457\u7684\u4f18\u52bf\uff1a \u66f4\u5f3a\u5927\u7684\u6027\u80fd\uff1a\u5728\u5404\u9879\u5bf9\u8bdd\u4efb\u52a1\u4e2d\uff0cChatGLM2-6B\u76f8\u6bd4ChatGLM-6B\u6709\u4e86\u5de8\u5927\u7684\u63d0\u5347\u3002\u4f8b\u5982\uff0c\u5728\u6570\u5b66\u4efb\u52a1\u4e0a\uff0c\u6027\u80fd\u63d0\u5347\u4e86\u6574\u6574571%\u3002 \u66f4\u957f\u7684\u4e0a\u4e0b\u6587\uff1aChatGLM2-6B\u91c7\u7528\u4e86FlashAttention\u6280\u672f\uff0c\u4f7f\u5176\u652f\u630132K\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u800cChatGLM-6B\u53ea\u80fd\u652f\u63012K\u3002\u8fd9\u4f7f\u5f97ChatGLM2-6B\u80fd\u591f\u8fdb\u884c\u66f4\u591a\u8f6e\u6b21\u7684\u5bf9\u8bdd\uff0c\u4e5f\u53ef\u4ee5\u8bfb\u53d6\u66f4\u957f\u7684\u6587\u6863\u8fdb\u884c\u76f8\u5173\u7684\u63d0\u53d6\u548c\u95ee\u7b54\u3002 \u66f4\u9ad8\u6548\u7684\u63a8\u7406\uff1aChatGLM2-6B\u5f15\u5165\u4e86Multi-Query Attention\u6280\u672f\uff0c\u5728\u66f4\u4f4e\u7684\u663e\u5b58\u8d44\u6e90\u4e0b\u4ee5\u66f4\u5feb\u7684\u901f\u5ea6\u8fdb\u884c\u63a8\u7406\uff0c\u76f8\u6bd4\u7b2c\u4e00\u4ee3\u63d0\u5347\u4e8642%\u3002\u540c\u65f6\uff0cINT4\u91cf\u5316\u6a21\u578b\u4e2d\uff0c6G\u663e\u5b58\u7684\u5bf9\u8bdd\u957f\u5ea6\u75311K\u63d0\u5347\u5230\u4e868K\u3002 ChatGLM3-6B\uff1aChatGLM3-6B\u662fChatGLM-6B\u7684\u7b2c\u4e09\u4ee3\u7248\u672c\uff0c\u76f8\u6bd4\u524d\u4e24\u4ee3\uff0c\u9664\u4e86\u7ee7\u627f\u4e4b\u524d\u4f18\u52bf\u5916\uff0c\u76f8\u5f53\u4e8e\u5168\u9762\u5347\u7ea7\uff1a \u591a\u6a21\u6001\u7406\u89e3\u80fd\u529b\uff1a\u572810\u4f59\u4e2a\u56fd\u9645\u6807\u51c6\u56fe\u6587\u8bc4\u6d4b\u96c6\u4e0a\u53d6\u5f97SOTA \u4ee3\u7801\u589e\u5f3a\u6a21\u5757\uff1a\u6839\u636e\u7528\u6237\u9700\u6c42\u751f\u6210\u4ee3\u7801\u5e76\u6267\u884c\uff0c\u81ea\u52a8\u5b8c\u6210\u6570\u636e\u5206\u6790\u3001\u6587\u4ef6\u5904\u7406\u7b49\u590d\u6742\u4efb\u52a1 \u7f51\u7edc\u641c\u7d22\u589e\u5f3a\uff1a\u80fd\u81ea\u52a8\u6839\u636e\u95ee\u9898\u5728\u4e92\u8054\u7f51\u4e0a\u67e5\u627e\u76f8\u5173\u8d44\u6599\u5e76\u5728\u56de\u7b54\u65f6\u63d0\u4f9b\u53c2\u8003\u76f8\u5173\u6587\u732e\u6216\u8005\u6587\u7ae0\u94fe\u63a5 \u8bed\u4e49\u80fd\u529b\u4e0e\u903b\u8f91\u80fd\u529b\u5927\u5927\u589e\u5f3a\u3002","title":"2.7 \u8fed\u4ee3\u7248\u672c"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#3-llama","text":"LLaMA\uff08Large Language Model Meta AI\uff09\uff0c\u7531 Meta AI \u4e8e2023\u5e74\u53d1\u5e03\u7684\u4e00\u4e2a\u5f00\u653e\u4e14\u9ad8\u6548\u7684\u5927\u578b\u57fa\u7840\u8bed\u8a00\u6a21\u578b\uff0c\u5171\u6709 7B\u300113B\u300133B\u300165B\uff08650 \u4ebf\uff09\u56db\u79cd\u7248\u672c\u3002 LLaMA\u8bad\u7ec3\u6570\u636e\u662f\u4ee5\u82f1\u8bed\u4e3a\u4e3b\u7684\u62c9\u4e01\u8bed\u7cfb\uff0c\u53e6\u5916\u8fd8\u5305\u542b\u4e86\u6765\u81ea GitHub \u7684\u4ee3\u7801\u6570\u636e\u3002\u8bad\u7ec3\u6570\u636e\u4ee5\u82f1\u6587\u4e3a\u4e3b\uff0c\u4e0d\u5305\u542b\u4e2d\u97e9\u65e5\u6587\uff0c\u6240\u6709\u8bad\u7ec3\u6570\u636e\u90fd\u662f\u5f00\u6e90\u7684\u3002\u5176\u4e2dLLaMA-65B \u548c LLaMA-33B \u662f\u5728 1.4\u4e07\u4ebf (1.4T) \u4e2a token\u4e0a\u8bad\u7ec3\u7684\uff0c\u800c\u6700\u5c0f\u7684\u6a21\u578b LLaMA-7B \u548cLLaMA-13B \u662f\u5728 1\u4e07\u4ebf (1T) \u4e2a token \u4e0a\u8bad\u7ec3\u7684\u3002","title":"3 LLaMA\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#31","text":"\u5728**\u8bad\u7ec3\u76ee\u6807**\u4e0a\uff0cLLaMA \u7684\u8bad\u7ec3\u76ee\u6807\u662f\u8bed\u8a00\u6a21\u578b\uff0c\u5373\u6839\u636e\u5df2\u6709\u7684\u4e0a\u6587\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002 \u5173\u4e8e**tokenizer**\uff0cLLaMA \u7684\u8bad\u7ec3\u8bed\u6599\u4ee5\u82f1\u6587\u4e3a\u4e3b\uff0c\u4f7f\u7528\u4e86BPE\u5206\u8bcd\u7b97\u6cd5\u4f5c\u4e3a tokenizer\uff0c\u8bcd\u8868\u5927\u5c0f\u53ea\u6709 32000\u3002\u8bcd\u8868\u91cc\u7684\u4e2d\u6587 token \u5f88\u5c11\uff0c\u53ea\u6709\u51e0\u767e\u4e2a\uff0cLLaMA tokenizer \u5bf9\u4e2d\u6587\u5206\u8bcd\u7684\u7f16\u7801\u6548\u7387\u6bd4\u8f83\u4f4e\u3002","title":"3.1 \u8bad\u7ec3\u76ee\u6807"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#32","text":"\u548c GPT \u7cfb\u5217\u4e00\u6837\uff0cLLaMA \u6a21\u578b\u4e5f\u662f Decoder-only\u67b6\u6784\uff0c\u4f46\u7ed3\u5408\u524d\u4eba\u7684\u5de5\u4f5c\u505a\u4e86\u4e00\u4e9b\u6539\u8fdb\uff0c\u6bd4\u5982\uff1a Pre-normalization \uff1a\u4e3a\u4e86\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u6ca1\u6709\u4f7f\u7528\u4f20\u7edf\u7684 post layer norm\uff0c\u800c\u662f\u4f7f\u7528\u4e86 pre layer Norm\uff0c\u540c\u65f6\u4f7f\u7528 RMSNorm\u5f52\u4e00\u5316\u51fd\u6570\uff08RMS Norm\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u53bb\u6389\u4e86\u51cf\u53bb\u5747\u503c\u7684\u90e8\u5206\uff0c\u7b80\u5316\u4e86Layer Norm \u7684\u8ba1\u7b97\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u7ea6 7%\u223c64% \u7684\u8ba1\u7b97\u65f6\u95f4\uff09\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u5c06 ReLU \u975e\u7ebf\u6027\u66ff\u6362\u4e3a SwiGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002","title":"3.2 \u6a21\u578b\u7ed3\u6784"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#33-7b","text":"\u914d\u7f6e \u6570\u636e \u53c2\u6570 6.7B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 32 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1T \u8bcd\u8868\u5927\u5c0f 32000 \u6700\u5927\u957f\u5ea6 2048","title":"3.3 \u6a21\u578b\u914d\u7f6e\uff087B\uff09"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#34","text":"65B\u7684\u6a21\u578b\uff0c\u57282048\u4e2a80G\u7684A100 GPU\u4e0a\uff0c\u53ef\u4ee5\u8fbe\u5230380 tokens/sec/GPU\u7684\u901f\u5ea6\u3002\u8bad\u7ec31.4T tokens\u9700\u898121\u5929\u3002","title":"3.4 \u786c\u4ef6\u8981\u6c42"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#35","text":"\u4f18\u70b9 \u5177\u6709 130 \u4ebf\u53c2\u6570\u7684 LLaMA \u6a21\u578b\u300c\u5728\u5927\u591a\u6570\u57fa\u51c6\u4e0a\u300d\u53ef\u4ee5\u80dc\u8fc7 GPT-3\uff08 \u53c2\u6570\u91cf\u8fbe 1750 \u4ebf\uff09\u3002 \u53ef\u4ee5\u5728\u5355\u5757 V100 GPU \u4e0a\u8fd0\u884c\uff1b\u800c\u6700\u5927\u7684 650 \u4ebf\u53c2\u6570\u7684 LLaMA \u6a21\u578b\u53ef\u4ee5\u5ab2\u7f8e\u8c37\u6b4c\u7684 Chinchilla-70B \u548c PaLM-540B\u3002 \u7f3a\u70b9\uff1a \u4f1a\u4ea7\u751f\u504f\u89c1\u6027\u3001\u6709\u6bd2\u6216\u8005\u865a\u5047\u7684\u5185\u5bb9. \u5728\u4e2d\u6587\u4e0a\u6548\u679c\u5dee\uff0c\u8bad\u7ec3\u8bed\u6599\u4e0d\u5305\u542b\u4e2d\u6587\u6216\u8005\u4e00\u4e2a\u6c49\u5b57\u5207\u5206\u4e3a\u591a\u4e2a token\uff0c\u7f16\u7801\u6548\u7387\u4f4e\uff0c\u6a21\u578b\u5b66\u4e60\u96be\u5ea6\u5927\u3002","title":"3.5 \u6a21\u578b\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#36","text":"Alpaca: \u65af\u5766\u798f\u5927\u5b66\u5728 52k \u6761\u82f1\u6587\u6307\u4ee4\u9075\u5faa\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u4e86 7B \u89c4\u6a21\u7684 LLaMA\u3002 Vicuna: \u52a0\u5dde\u5927\u5b66\u4f2f\u514b\u5229\u5206\u6821\u5728 ShareGPT \u6536\u96c6\u7684\u7528\u6237\u5171\u4eab\u5bf9\u8bdd\u6570\u636e\u4e0a\uff0c\u5fae\u8c03\u4e86 13B \u89c4\u6a21\u7684 LLaMA\u3002 BELLE: \u94fe\u5bb6\u4ec5\u4f7f\u7528\u7531 ChatGPT \u751f\u4ea7\u7684\u6570\u636e\uff0c\u5bf9 LLaMA \u8fdb\u884c\u4e86\u6307\u4ee4\u5fae\u8c03\uff0c\u5e76\u9488\u5bf9\u4e2d\u6587\u8fdb\u884c\u4e86\u4f18\u5316\u3002 Chinese LLaMA\uff1a \u6269\u5145\u4e2d\u6587\u8bcd\u8868\uff1a\u5e38\u89c1\u505a\u6cd5\uff1a\u5728\u4e2d\u6587\u8bed\u6599\u4e0a\u4f7f\u7528 Sentence Piece \u8bad\u7ec3\u4e00\u4e2a\u4e2d\u6587 tokenizer\uff0c\u4f7f\u7528\u4e86 20000 \u4e2a\u4e2d\u6587\u8bcd\u6c47\u3002\u7136\u540e\u5c06\u4e2d\u6587 tokenizer \u4e0e\u539f\u59cb\u7684 LLaMA tokenizer \u5408\u5e76\u8d77\u6765\uff0c\u901a\u8fc7\u7ec4\u5408\u4e8c\u8005\u7684\u8bcd\u6c47\u8868\uff0c\u6700\u7ec8\u83b7\u5f97\u4e00\u4e2a\u5408\u5e76\u7684 tokenizer\uff0c\u79f0\u4e3a Chinese LLaMA tokenizer\u3002\u8bcd\u8868\u5927\u5c0f\u4e3a 49953\u3002","title":"3.6 \u884d\u751f\u5e94\u7528"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#37","text":"LLaMA 2\uff08Open Foundation and Fine-Tuned Chat Models\uff09\uff1aLLaMA 2\u662fLLaMA\u6a21\u578b\u7684\u5347\u7ea7\u8fed\u4ee3\u7248\u672c\uff0c\u5176\u6a21\u578b\u67b6\u6784\u57fa\u672c\u548cllama\u4e00\u6837\u3002\u4e0d\u540c\u70b9\uff1a LLama2\u8bad\u7ec3\u8bed\u6599\u76f8\u6bd4LLaMA\u591a\u51fa40%\uff0c\u4e0a\u4e0b\u6587\u957f\u5ea6\u662f\u7531\u4e4b\u524d\u76842048\u5347\u7ea7\u52304096\uff0c\u53ef\u4ee5\u7406\u89e3\u548c\u751f\u6210\u66f4\u957f\u7684\u6587\u672c\u3002 \u65b0\u589e\u9884\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u6ce8\u91cd\u5b89\u5168&\u9690\u79c1\u95ee\u9898\u3002 \u8bad\u7ec3\u51fa\u4e86chat\u7248\u672c\uff1allama-2-chat: SFT, RLHF.","title":"3.7 \u8fed\u4ee3\u7248\u672c"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#4-bloom","text":"BLOOM\u7cfb\u5217\u6a21\u578b\u662f\u7531 Hugging Face\u516c\u53f8\u7684BigScience \u56e2\u961f\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u3002\u8bad\u7ec3\u6570\u636e\u5305\u542b\u4e86\u82f1\u8bed\u3001\u4e2d\u6587\u3001\u6cd5\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u8461\u8404\u7259\u8bed\u7b49\u5171 46 \u79cd\u8bed\u8a00\uff0c\u53e6\u5916\u8fd8\u5305\u542b 13 \u79cd\u7f16\u7a0b\u8bed\u8a00\u30021.5TB \u7ecf\u8fc7\u53bb\u91cd\u548c\u6e05\u6d17\u7684\u6587\u672c\uff0c\u8f6c\u6362\u4e3a 350B \u7684 tokens\u3002\u8bad\u7ec3\u6570\u636e\u7684\u8bed\u8a00\u5206\u5e03\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u53ef\u4ee5\u770b\u5230\u4e2d\u6587\u8bed\u6599\u5360\u6bd4\u4e3a 16.2% \u6309\u7167\u6a21\u578b\u53c2\u6570\u91cf\uff0cBLOOM \u6a21\u578b\u6709 560M\u30011.1B\u30011.7B\u30013B\u30017.1B \u548c 176B \u8fd9\u51e0\u4e2a\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u7684\u6a21\u578b\u3002","title":"4 BLOOM\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#41","text":"\u5728**\u8bad\u7ec3\u76ee\u6807**\u4e0a\uff0cLLaMA \u7684\u8bad\u7ec3\u76ee\u6807\u662f\u8bed\u8a00\u6a21\u578b\uff0c\u5373\u6839\u636e\u5df2\u6709\u7684\u4e0a\u6587\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002 \u5173\u4e8e**tokenizer**\uff0cBLOOM \u5728\u591a\u8bed\u79cd\u8bed\u6599\u4e0a\u4f7f\u7528 Byte Pair Encoding(BPE)\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\u5f97\u5230 tokenizer\uff0c\u8bcd\u8868\u5927\u5c0f\u4e3a 250880\u3002","title":"4.1 \u8bad\u7ec3\u76ee\u6807"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#42","text":"\u548c GPT \u7cfb\u5217\u4e00\u6837\uff0cLLaMA \u6a21\u578b\u4e5f\u662f Decoder-only\u67b6\u6784\uff0c\u4f46\u7ed3\u5408\u524d\u4eba\u7684\u5de5\u4f5c\u505a\u4e86\u4e00\u4e9b\u6539\u8fdb\uff0c\u6bd4\u5982\uff1a embedding layer norm \uff1a\u5728 embedding \u5c42\u540e\u6dfb\u52a0\u4e86\u4e00\u4e2a layer normalization\uff0c\u6765\u4f7f\u8bad\u7ec3\u66f4\u52a0\u7a33\u5b9a\u3002 layer normalization \uff1a\u4e3a\u4e86\u63d0\u5347\u8bad\u7ec3\u7684\u7a33\u5b9a\u6027\uff0c\u6ca1\u6709\u4f7f\u7528\u4f20\u7edf\u7684 post layer norm\uff0c\u800c\u662f\u4f7f\u7528\u4e86 pre layer Norm\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u91c7\u7528\u4e86 GeLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u53bb\u9664\u4e86\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0c\u91c7\u7528\u4e86\u76f8\u5bf9\u4f4d\u7f6e\u7f16\u7801 ALiBi\u3002\u76f8\u6bd4\u4e8e\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff0cALiBi \u7684\u5916\u63a8\u6027\u66f4\u597d\uff0c\u5373\u867d\u7136\u8bad\u7ec3\u9636\u6bb5\u7684\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u4e3a 2048\uff0c\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u53ef\u4ee5\u5904\u7406\u66f4\u957f\u7684\u5e8f\u5217\u3002","title":"4.2 \u6a21\u578b\u7ed3\u6784"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#43-176b","text":"\u914d\u7f6e \u6570\u636e \u53c2\u6570 176B \u9690\u85cf\u5c42\u7ef4\u5ea6 14336 \u5c42\u6570 70 \u6ce8\u610f\u529b\u5934\u6570 112 \u8bad\u7ec3\u6570\u636e 366B \u8bcd\u8868\u5927\u5c0f 250880 \u6700\u5927\u957f\u5ea6 2048","title":"4.3 \u6a21\u578b\u914d\u7f6e\uff08176B\uff09"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#44","text":"176B-BLOOM \u6a21\u578b\u5728384 \u5f20 NVIDIA A100 80GB GPU\u4e0a\uff0c\u8bad\u7ec3\u4e8e 2022 \u5e74 3 \u6708\u81f3 7 \u6708\u671f\u95f4\uff0c\u8017\u65f6\u7ea6 3.5 \u4e2a\u6708\u5b8c\u6210 (\u7ea6 100 \u4e07\u8ba1\u7b97\u65f6)\uff0c\u7b97\u529b\u6210\u672c\u8d85\u8fc7300\u4e07\u6b27\u5143","title":"4.4 \u786c\u4ef6\u8981\u6c42"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#45","text":"\u4f18\u70b9 \u5177\u6709\u826f\u597d\u7684\u591a\u8bed\u8a00\u9002\u5e94\u6027\uff0c\u80fd\u591f\u5728\u591a\u79cd\u8bed\u8a00\u95f4\u8fdb\u884c\u5207\u6362\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3 \u7f3a\u70b9\uff1a \u4f1a\u4ea7\u751f\u504f\u89c1\u6027\u3001\u6709\u6bd2\u6216\u8005\u865a\u5047\u7684\u5185\u5bb9.","title":"4.5 \u6a21\u578b\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#46","text":"\u8f69\u8f95: \u91d1\u878d\u9886\u57df\u5927\u6a21\u578b\uff0c\u5ea6\u5c0f\u6ee1\u5728 BLOOM-176B \u7684\u57fa\u7840\u4e0a\u9488\u5bf9\u4e2d\u6587\u901a\u7528\u9886\u57df\u548c\u91d1\u878d\u9886\u57df\u8fdb\u884c\u4e86\u9488\u5bf9\u6027\u7684\u9884\u8bad\u7ec3\u4e0e\u5fae\u8c03\u3002 BELLE: \u94fe\u5bb6\u4ec5\u4f7f\u7528\u7531 ChatGPT \u751f\u4ea7\u7684\u6570\u636e\uff0c\u5bf9 BLOOMZ-7B1-mt \u8fdb\u884c\u4e86\u6307\u4ee4\u5fae\u8c03\u3002","title":"4.6 \u884d\u751f\u5e94\u7528"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#5-baichuan-7b","text":"Baichuan-7B\u7531\u767e\u5ddd\u667a\u80fd\u4e8e2023\u5e746\u6708\u53d1\u5e03\u7684\u4e00\u4e2a\u5f00\u653e\u4e14\u53ef\u5546\u7528\u7684\u5927\u578b\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u5176\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\uff0c\u662f\u5728\u7ea6 1.2\u4e07\u4ebf (1.2T) \u4e2a token\u4e0a\u8bad\u7ec3\u768470\u4ebf\u53c2\u6570\u6a21\u578b\u3002","title":"5 Baichuan-7B\u6a21\u578b"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#51","text":"\u5728**\u8bad\u7ec3\u76ee\u6807**\u4e0a\uff0cBaichuan-7B \u7684\u8bad\u7ec3\u76ee\u6807\u4e5f\u662f\u8bed\u8a00\u6a21\u578b\uff0c\u5373\u6839\u636e\u5df2\u6709\u7684\u4e0a\u6587\u53bb\u9884\u6d4b\u4e0b\u4e00\u4e2a\u8bcd\u3002 \u5173\u4e8e**tokenizer**\uff0c\u4f7f\u7528\u4e86BPE\u5206\u8bcd\u7b97\u6cd5\u4f5c\u4e3a tokenizer\uff0c\u8bcd\u8868\u5927\u5c0f64000\u3002 \u5173\u4e8e**\u6570\u636e**\uff0c\u539f\u59cb\u6570\u636e\u5305\u62ec\u5f00\u6e90\u7684\u4e2d\u82f1\u6587\u6570\u636e\u548c\u81ea\u884c\u6293\u53d6\u7684\u4e2d\u6587\u4e92\u8054\u7f51\u6570\u636e\uff0c\u4ee5\u53ca\u90e8\u5206\u9ad8\u8d28\u91cf\u77e5\u8bc6\u6027\u6570\u636e\u3002","title":"5.1 \u8bad\u7ec3\u76ee\u6807"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#52","text":"\u548c LLaMA \u4e00\u6837\u7684\u6a21\u578b\u8bbe\u8ba1\uff0c\u4e5f\u662f Decoder-only\u67b6\u6784\uff0c\u4f46\u7ed3\u5408\u524d\u4eba\u7684\u5de5\u4f5c\u505a\u4e86\u4e00\u4e9b\u6539\u8fdb\uff0c\u6bd4\u5982\uff1a Pre-normalization \uff1a\u4e3a\u4e86\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u6ca1\u6709\u4f7f\u7528\u4f20\u7edf\u7684 post layer norm\uff0c\u800c\u662f\u4f7f\u7528\u4e86 pre layer Norm\uff0c\u540c\u65f6\u4f7f\u7528 RMSNorm\u5f52\u4e00\u5316\u51fd\u6570\uff08RMS Norm\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u53bb\u6389\u4e86\u51cf\u53bb\u5747\u503c\u7684\u90e8\u5206\uff0c\u7b80\u5316\u4e86Layer Norm \u7684\u8ba1\u7b97\uff0c\u53ef\u4ee5\u5728\u51cf\u5c11\u7ea6 7%\u223c64% \u7684\u8ba1\u7b97\u65f6\u95f4\uff09\u3002 \u6fc0\u6d3b\u51fd\u6570 \uff1a\u4f7f\u7528 SwiGLU \u6fc0\u6d3b\u51fd\u6570\u3002 \u4f4d\u7f6e\u7f16\u7801 \uff1a\u91c7\u7528\u4e86\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801 RoPE\u3002","title":"5.2 \u6a21\u578b\u7ed3\u6784"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#53-7b","text":"\u914d\u7f6e \u6570\u636e \u53c2\u6570 7B \u9690\u85cf\u5c42\u7ef4\u5ea6 4096 \u5c42\u6570 32 \u6ce8\u610f\u529b\u5934\u6570 32 \u8bad\u7ec3\u6570\u636e 1.2T \u8bcd\u8868\u5927\u5c0f 64000 \u6700\u5927\u957f\u5ea6 4096","title":"5.3 \u6a21\u578b\u914d\u7f6e\uff087B\uff09"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#54","text":"baichuan-7B**\u5177\u6709\u8f83\u5f3a\u7684\u901a\u7528\u578b\uff0c\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e**\u81ea\u7136\u8bed\u8a00\u5904\u7406 \u3001\u673a\u5668\u7ffb\u8bd1\u3001\u95ee\u7b54\u7cfb\u7edf\u7b49\u9886\u57df\uff0c\u5728\u667a\u80fd\u5ba2\u670d\u3001\u91d1\u878d\u3001\u533b\u7597\u3001\u6559\u80b2\u3001**\u4eba\u5de5\u667a\u80fd**\u7b49\u5404\u884c\u5404\u4e1a\u90fd\u5177\u6709\u5f88\u9ad8\u7684\u6f5c\u529b\u548c\u5e94\u7528\u524d\u666f\u3002 \u5728\u6807\u51c6\u7684\u4e2d\u6587\u548c\u82f1\u6587\u6743\u5a01 benchmark\uff08C-EVAL/MMLU\uff09\u4e0a\u5747\u53d6\u5f97\u4e86\u540c\u53c2\u6570\u89c4\u6a21\u4e0b\u7684\u6700\u597d\u6548\u679c\u3002","title":"5.4 \u6a21\u578b\u7279\u70b9"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#55","text":"Baichuan-13B \u662f\u7531\u767e\u5ddd\u667a\u80fd\u7ee7 Baichuan-7B \u4e4b\u540e\u5f00\u53d1\u7684\u5305\u542b 130 \u4ebf\u53c2\u6570\u7684\u5f00\u6e90\u53ef\u5546\u7528\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6743\u5a01\u7684\u4e2d\u6587\u548c\u82f1\u6587 benchmark \u4e0a\u5747\u53d6\u5f97\u540c\u5c3a\u5bf8\u6700\u597d\u7684\u6548\u679c\u3002Baichuan-13B \u6709\u5982\u4e0b\u51e0\u4e2a\u7279\u70b9\uff1a \u66f4\u5927\u5c3a\u5bf8\u3001\u66f4\u591a\u6570\u636e \uff1aBaichuan-13B \u53c2\u6570\u91cf\u8fbe\u5230 130 \u4ebf\uff0c\u5e76\u4e14\u5728\u9ad8\u8d28\u91cf\u7684\u8bed\u6599\u4e0a\u8bad\u7ec3\u4e86 1.4 \u4e07\u4ebf tokens\uff0c\u662f\u5f53\u524d\u5f00\u6e90 13B \u5c3a\u5bf8\u4e0b\u8bad\u7ec3\u6570\u636e\u91cf\u6700\u591a\u7684\u6a21\u578b\u3002\u652f\u6301\u4e2d\u82f1\u53cc\u8bed\uff0c\u4f7f\u7528 ALiBi \u4f4d\u7f6e\u7f16\u7801\uff0c\u4e0a\u4e0b\u6587\u7a97\u53e3\u957f\u5ea6\u4e3a 4096\u3002 \u66f4\u9ad8\u6548\u7684\u63a8\u7406 \uff1a\u540c\u65f6\u5f00\u6e90\u4e86 int8 \u548c int4 \u7684\u91cf\u5316\u7248\u672c\uff0c\u76f8\u5bf9\u975e\u91cf\u5316\u7248\u672c\u5728\u51e0\u4e4e\u6ca1\u6709\u6548\u679c\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u5927\u5927\u964d\u4f4e\u4e86\u90e8\u7f72\u7684\u673a\u5668\u8d44\u6e90\u95e8\u69db\uff0c\u53ef\u4ee5\u90e8\u7f72\u5728\u5982 Nvidia 3090 \u8fd9\u6837\u7684\u6d88\u8d39\u7ea7\u663e\u5361\u4e0a\u3002 \u5f00\u6e90\u514d\u8d39\u53ef\u5546\u7528 \uff1aBaichuan-13B \u4e0d\u4ec5\u5bf9\u5b66\u672f\u7814\u7a76\u5b8c\u5168\u5f00\u653e\uff0c\u5f00\u53d1\u8005\u4e5f\u4ec5\u9700\u90ae\u4ef6\u7533\u8bf7\u5e76\u83b7\u5f97\u5b98\u65b9\u5546\u7528\u8bb8\u53ef\u540e\uff0c\u5373\u53ef\u4ee5\u514d\u8d39\u5546\u7528\u3002","title":"5.5 \u8fed\u4ee3\u7248\u672c"},{"location":"%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E4%B8%BB%E6%B5%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/02-LLM%E4%B8%BB%E6%B5%81%E5%BC%80%E6%BA%90%E4%BB%A3%E8%A1%A8%E6%A8%A1%E5%9E%8B.html#_2","text":"\u672c\u5c0f\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86LLM\u4e3b\u6d41\u7684\u5f00\u6e90\u5927\u6a21\u578b\uff0c\u5bf9\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u76ee\u6807\u3001\u4f18\u7f3a\u70b9\u8fdb\u884c\u4e86\u5206\u6790\u548c\u603b\u7ed3\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html","text":"\u57fa\u4e8eGPT2\u642d\u5efa\u533b\u7597\u95ee\u8bca\u673a\u5668\u4eba \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u533b\u7597\u95ee\u8bca\u673a\u5668\u4eba\u7684\u5f00\u53d1\u80cc\u666f. \u4e86\u89e3\u4f01\u4e1a\u4e2d\u804a\u5929\u673a\u5668\u4eba\u7684\u5e94\u7528\u573a\u666f \u638c\u63e1\u57fa\u4e8eGPT2\u6a21\u578b\u642d\u5efa\u533b\u7597\u95ee\u8bca\u673a\u5668\u4eba\u7684\u5b9e\u73b0\u8fc7\u7a0b \u9879\u76ee\u80cc\u666f \u00b6 \u804a\u5929\u673a\u5668\u4eba\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u667a\u80fd\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u7684\u81ea\u7136\u8bed\u8a00\u4ea4\u6d41\uff0c\u4e0e\u7528\u6237\u8fdb\u884c\u5bf9\u8bdd\u548c\u4e92\u52a8\u3002\u804a\u5929\u673a\u5668\u4eba\u80fd\u591f\u7406\u89e3\u7528\u6237\u7684\u95ee\u9898\u6216\u6307\u4ee4\uff0c\u5e76\u7ed9\u51fa\u76f8\u5e94\u7684\u56de\u7b54\u6216\u5efa\u8bae\u3002\u5176\u76ee\u6807\u662f\u63d0\u4f9b\u53cb\u597d\u3001\u667a\u80fd\u3001\u81ea\u7136\u7684\u5bf9\u8bdd\u4f53\u9a8c. \u5f53\u524d\uff0c\u804a\u5929\u673a\u5668\u4eba\u5728\u591a\u4e2a\u9886\u57df\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\u3002\u9996\u5148\uff0c\u5b83\u4eec\u5e38\u7528\u4e8e\u5728\u7ebf\u5ba2\u670d\u7cfb\u7edf\uff0c\u80fd\u591f\u5feb\u901f\u3001\u51c6\u786e\u5730\u56de\u7b54\u7528\u6237\u7684\u5e38\u89c1\u95ee\u9898\uff0c\u89e3\u51b3\u7591\u95ee\u3002\u5176\u6b21\uff0c\u804a\u5929\u673a\u5668\u4eba\u53ef\u4ee5\u4f5c\u4e3a\u4e2a\u4eba\u52a9\u624b\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u63a8\u8350\u3001\u5efa\u8bae\u548c\u65e5\u7a0b\u5b89\u6392\u7b49\u670d\u52a1\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002\u6b64\u5916\uff0c\u804a\u5929\u673a\u5668\u4eba\u8fd8\u88ab\u5e94\u7528\u4e8e\u793e\u4ea4\u5a31\u4e50\u3001\u8bed\u8a00\u5b66\u4e60\u3001\u65c5\u6e38\u6307\u5357\u7b49\u9886\u57df\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u6709\u8da3\u3001\u4fbf\u6377\u7684\u5bf9\u8bdd\u4f53\u9a8c. \u5e38\u89c1\u7684\u76f8\u5173\u804a\u5929\u673a\u5668\u4eba\u4ea7\u54c1\uff1a \u5fae\u8f6f\u5c0f\u51b0\uff1a\u5fae\u8f6f\u516c\u53f8\u5f00\u53d1\u3002\u5b83\u5177\u5907\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u60c5\u611f\u5206\u6790\u548c\u5bf9\u8bdd\u751f\u6210\u7b49\u529f\u80fd\uff0c\u80fd\u591f\u4e0e\u7528\u6237\u8fdb\u884c\u667a\u80fd\u5bf9\u8bdd\uff0c\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u548c\u5a31\u4e50\u7b49\u670d\u52a1\u3002 \u963f\u91cc\u4e91\u5c0f\u871c\uff1a\u963f\u91cc\u4e91\u516c\u53f8\u63a8\u51fa\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u667a\u80fd\u5bf9\u8bdd\u670d\u52a1\u3002\u5b83\u5177\u5907\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5bf9\u8bdd\u7ba1\u7406\u80fd\u529b\uff0c\u652f\u6301\u591a\u9886\u57df\u7684\u5e94\u7528\u573a\u666f\uff0c\u5982\u5728\u7ebf\u5ba2\u670d\u3001\u667a\u80fd\u52a9\u624b\u548c\u865a\u62df\u5bfc\u8d2d\u7b49\u3002 \u767e\u5ea6\u667a\u80fd\u4e91\u5c0f\u5ea6\uff1a\u767e\u5ea6\u667a\u80fd\u4e91\u5f00\u53d1\uff0c\u63d0\u4f9b\u4e86\u591a\u9886\u57df\u7684\u667a\u80fd\u5bf9\u8bdd\u80fd\u529b\u3002\u5c0f\u5ea6\u673a\u5668\u4eba\u53ef\u5e94\u7528\u4e8e\u5bb6\u5ead\u52a9\u7406\u3001\u667a\u80fd\u97f3\u7bb1\u548c\u79fb\u52a8\u5e94\u7528\u7b49\u573a\u666f\uff0c\u901a\u8fc7\u8bed\u97f3\u548c\u6587\u672c\u4ea4\u4e92\u4e0e\u7528\u6237\u8fdb\u884c\u667a\u80fd\u5bf9\u8bdd\uff0c\u63d0\u4f9b\u4fe1\u606f\u67e5\u8be2\u3001\u97f3\u4e50\u64ad\u653e\u548c\u65e5\u7a0b\u5b89\u6392\u7b49\u529f\u80fd\u3002 \u672c\u9879\u76ee\u57fa\u4e8e\u533b\u7597\u9886\u57df\u6570\u636e\u6784\u5efa\u4e86\u667a\u80fd\u533b\u7597\u95ee\u7b54\u7cfb\u7edf,\u76ee\u7684\u662f\u4e3a\u4e3a\u7528\u6237\u63d0\u4f9b\u51c6\u786e\u3001\u9ad8\u6548\u3001\u4f18\u8d28\u7684\u533b\u7597\u95ee\u7b54\u670d\u52a1\u3002 \u73af\u5883\u51c6\u5907 \u00b6 python3.6\u3001 transformers==4.2.0 \u3001 pytorch==1.7.0 \u9879\u76ee\u6574\u4f53\u7ed3\u6784 \u00b6 1. \u6570\u636e\u4ecb\u7ecd \u00b6 \u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u6587\u4ef6\uff1amedical_train.txt, medical_valid.txt 1.1 \u6570\u636e\u5c55\u793a \u00b6 medical_train.txt, medical_valid.txt\u6587\u4ef6\u7684\u5185\u5bb9\u5747\u4e3a\u5bf9\u8bdd\u6587\u672c \u539f\u59cbtrain\u6587\u6863\u4e2d\u4e2d\u4e00\u5171\u5305\u542b91487\u6761\u6570\u636e\uff0cvalid\u6587\u6863\u4e2d\u5305\u542b1244\u6761\u6570\u636e \u6bcf\u4e24\u884c\u6570\u636e\u4e3a\u4e00\u6bb5\u5bf9\u8bdd\u5185\u5bb9\uff0c\u6ce8\u610f\uff1a\u5982\u679c\u60f3\u8981\u5b9e\u73b0\u591a\u8f6e\u5bf9\u8bdd\uff0c\u90a3\u4e48\u4e0d\u540c\u5bf9\u8bdd\u95f4\u5b9e\u73b0\u591a\u6761\u5bf9\u8bdd\u8bed\u53e5\u5bf9\u5373\u53ef 2.\u6570\u636e\u5904\u7406 \u00b6 \u76ee\u7684\uff1a\u5c06\u4e2d\u6587\u6587\u672c\u6570\u636e\u5904\u7406\u6210\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u7684\u5f20\u91cf\u5f62\u5f0f\u3002 \u5b9e\u73b0\u8fc7\u7a0b\uff1a \u8fd0\u884cpreprocess.py\uff0c\u5bf9data/medical_train.txt\u5bf9\u8bdd\u8bed\u6599\u8fdb\u884ctokenize\uff0c\u7136\u540e\u8fdb\u884c\u5e8f\u5217\u5316\u4fdd\u5b58\u5230data/medical_train.txt.pkl\u3002medical_train.pkl\u4e2d\u5e8f\u5217\u5316\u7684\u5bf9\u8c61\u7684\u7c7b\u578b\u4e3aList[List],\u8bb0\u5f55\u5bf9\u8bdd\u5217\u8868\u4e2d,\u6bcf\u4e2a\u5bf9\u8bdd\u5305\u542b\u7684token\u3002 python preprocess . py train_path data / medical_train . txt -- \u300b save_path data / medical_train . pkl \u6570\u636e\u5904\u7406\u57fa\u672c\u6d41\u7a0b\uff1a 2.1 \u6570\u636e\u5f20\u91cf\u8f6c\u6362 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/preprocess.py # \u5bfc\u5165\u5206\u8bcd\u5668 from transformers import BertTokenizerFast # \u5c06\u6570\u636e\u4fdd\u5b58\u4e3apkl\u6587\u4ef6\uff0c\u65b9\u4fbf\u4e0b\u6b21\u8bfb\u53d6 import pickle # \u8bfb\u53d6\u6570\u636e\u7684\u8fdb\u5ea6\u6761\u5c55\u793a from tqdm import tqdm def preprocess ( train_txt_path , train_pkl_path ): \"\"\" \u5bf9\u539f\u59cb\u8bed\u6599\u8fdb\u884ctokenize\uff0c\u5c06\u6bcf\u6bb5\u5bf9\u8bdd\u5904\u7406\u6210\u5982\u4e0b\u5f62\u5f0f\uff1a\"[CLS]utterance1[SEP]utterance2[SEP]utterance3[SEP]\" \"\"\" '''\u521d\u59cb\u5316tokenizer\uff0c\u4f7f\u7528BertTokenizerFast. \u4ece\u9884\u8bad\u7ec3\u7684\u4e2d\u6587Bert\u6a21\u578b\uff08bert-base-chinese\uff09\u521b\u5efa\u4e00\u4e2atokenizer\u5bf9\u8c61''' tokenizer = BertTokenizerFast . from_pretrained ( 'bert-base-chinese' , sep_token = \"[SEP]\" , pad_token = \"[PAD]\" , cls_token = \"[CLS]\" ) sep_id = tokenizer . sep_token_id # \u83b7\u53d6\u5206\u9694\u7b26[SEP]\u7684token ID cls_id = tokenizer . cls_token_id # \u83b7\u53d6\u8d77\u59cb\u7b26[CLS]\u7684token ID # \u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u96c6 with open ( train_txt_path , 'rb' ) as f : data = f . read () . decode ( \"utf-8\" ) # \u4ee5UTF-8\u7f16\u7801\u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9 # \u6839\u636e\u6362\u884c\u7b26\u533a\u5206\u4e0d\u540c\u7684\u5bf9\u8bdd\u6bb5\u843d\uff0c\u9700\u8981\u533a\u5206Windows\u548cLinux\u73af\u5883\u4e0b\u7684\u6362\u884c\u7b26 if \" \\r\\n \" in data : train_data = data . split ( \" \\r\\n\\r\\n \" ) else : train_data = data . split ( \" \\n\\n \" ) print ( len ( train_data )) # \u6253\u5370\u5bf9\u8bdd\u6bb5\u843d\u6570\u91cf # \u5f00\u59cb\u8fdb\u884ctokenize # \u4fdd\u5b58\u6240\u6709\u7684\u5bf9\u8bdd\u6570\u636e,\u6bcf\u6761\u6570\u636e\u7684\u683c\u5f0f\u4e3a\uff1a\"[CLS]seq1[SEP]seq2[SEP]seq3[SEP]\" dialogue_len = [] # \u8bb0\u5f55\u6240\u6709\u5bf9\u8bddtokenize\u4e4b\u540e\u7684\u957f\u5ea6\uff0c\u7528\u4e8e\u7edf\u8ba1\u4e2d\u4f4d\u6570\u4e0e\u5747\u503c dialogue_list = [] # \u8bb0\u5f55\u6240\u6709\u5bf9\u8bdd for index , dialogue in enumerate ( tqdm ( train_data )): if \" \\r\\n \" in data : sequences = dialogue . split ( \" \\r\\n \" ) else : sequences = dialogue . split ( \" \\n \" ) input_ids = [ cls_id ] # \u6bcf\u4e2adialogue\u4ee5[CLS]\u5f00\u5934 for sequence in sequences : # \u5c06\u6bcf\u4e2a\u5bf9\u8bdd\u53e5\u5b50\u8fdb\u884ctokenize\uff0c\u5e76\u5c06\u7ed3\u679c\u62fc\u63a5\u5230input_ids\u5217\u8868\u4e2d input_ids += tokenizer . encode ( sequence , add_special_tokens = False ) input_ids . append ( sep_id ) # \u6bcf\u4e2aseq\u4e4b\u540e\u6dfb\u52a0[SEP]\uff0c\u8868\u793aseqs\u4f1a\u8bdd\u7ed3\u675f dialogue_len . append ( len ( input_ids )) # \u5c06\u5bf9\u8bdd\u7684tokenize\u540e\u7684\u957f\u5ea6\u6dfb\u52a0\u5230\u5bf9\u8bdd\u957f\u5ea6\u5217\u8868\u4e2d dialogue_list . append ( input_ids ) # \u5c06tokenize\u540e\u7684\u5bf9\u8bdd\u6dfb\u52a0\u5230\u5bf9\u8bdd\u5217\u8868\u4e2d print ( f 'dialogue_len---> { dialogue_len } ' ) # \u6253\u5370\u5bf9\u8bdd\u957f\u5ea6\u5217\u8868 print ( f 'dialogue_list---> { dialogue_list } ' ) # \u6253\u5370 # \u4fdd\u5b58pkl\u6587\u4ef6\u6570\u636e with open ( train_pkl_path , \"wb\" ) as f : pickle . dump ( dialogue_list , f ) 2.2 \u6570\u636e\u5f20\u91cf\u518d\u6b21\u5c01\u88c5 \u00b6 2.2.1 \u5c01\u88c5DataSet\u5bf9\u8c61 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/dataset.py from torch.utils.data import Dataset # \u5bfc\u5165Dataset\u6a21\u5757\uff0c\u7528\u4e8e\u5b9a\u4e49\u81ea\u5b9a\u4e49\u6570\u636e\u96c6 import torch # \u5bfc\u5165torch\u6a21\u5757\uff0c\u7528\u4e8e\u5904\u7406\u5f20\u91cf\u548c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc class MyDataset ( Dataset ): \"\"\" \u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7c7b\uff0c\u7ee7\u627f\u81eaDataset\u7c7b \"\"\" def __init__ ( self , input_list , max_len ): \"\"\" \u521d\u59cb\u5316\u51fd\u6570\uff0c\u7528\u4e8e\u8bbe\u7f6e\u6570\u636e\u96c6\u7684\u5c5e\u6027 :param input_list: \u8f93\u5165\u5217\u8868\uff0c\u5305\u542b\u6240\u6709\u5bf9\u8bdd\u7684tokenize\u540e\u7684\u8f93\u5165\u5e8f\u5217 :param max_len: \u6700\u5927\u5e8f\u5217\u957f\u5ea6\uff0c\u7528\u4e8e\u5bf9\u8f93\u5165\u8fdb\u884c\u622a\u65ad\u6216\u586b\u5145 \"\"\" self . input_list = input_list # \u5c06\u8f93\u5165\u5217\u8868\u8d4b\u503c\u7ed9\u6570\u636e\u96c6\u7684input_list\u5c5e\u6027 self . max_len = max_len # \u5c06\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u8d4b\u503c\u7ed9\u6570\u636e\u96c6\u7684max_len\u5c5e\u6027 def __len__ ( self ): \"\"\" \u83b7\u53d6\u6570\u636e\u96c6\u7684\u957f\u5ea6 :return: \u6570\u636e\u96c6\u7684\u957f\u5ea6 \"\"\" return len ( self . input_list ) # \u8fd4\u56de\u6570\u636e\u96c6\u7684\u957f\u5ea6 def __getitem__ ( self , index ): \"\"\" \u6839\u636e\u7ed9\u5b9a\u7d22\u5f15\u83b7\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u4e00\u4e2a\u6837\u672c :param index: \u6837\u672c\u7684\u7d22\u5f15 :return: \u6837\u672c\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf \"\"\" input_ids = self . input_list [ index ] # \u83b7\u53d6\u7ed9\u5b9a\u7d22\u5f15\u5904\u7684\u8f93\u5165\u5e8f\u5217 input_ids = input_ids [: self . max_len ] # \u6839\u636e\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u5bf9\u8f93\u5165\u8fdb\u884c\u622a\u65ad\u6216\u586b\u5145 input_ids = torch . tensor ( input_ids , dtype = torch . long ) # \u5c06\u8f93\u5165\u5e8f\u5217\u8f6c\u6362\u4e3along\u7c7b\u578b return input_ids # \u8fd4\u56de\u6837\u672c\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf 2.2.2 \u5c01\u88c5DataLoader\u5bf9\u8c61 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/dataloader.py # \u5bfc\u5165rnn_utils\u6a21\u5757\uff0c\u7528\u4e8e\u5904\u7406\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\u7684\u586b\u5145\u548c\u6392\u5e8f import torch.nn.utils.rnn as rnn_utils # \u5bfc\u5165Dataset\u548cDataLoader\u6a21\u5757\uff0c\u7528\u4e8e\u52a0\u8f7d\u548c\u5904\u7406\u6570\u636e\u96c6 from torch.utils.data import Dataset , DataLoader import torch # \u5bfc\u5165torch\u6a21\u5757\uff0c\u7528\u4e8e\u5904\u7406\u5f20\u91cf\u548c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc import pickle # \u5bfc\u5165pickle\u6a21\u5757\uff0c\u7528\u4e8e\u5e8f\u5217\u5316\u548c\u53cd\u5e8f\u5217\u5316Python\u5bf9\u8c61 from dataset import * # \u5bfc\u5165\u81ea\u5b9a\u4e49\u7684\u6570\u636e\u96c6\u7c7b def load_dataset ( train_path ): \"\"\" \u52a0\u8f7d\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 :param train_path: \u8bad\u7ec3\u6570\u636e\u96c6\u8def\u5f84 :return: \u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6 \"\"\" with open ( train_path , \"rb\" ) as f : input_list = pickle . load ( f ) # \u4ece\u6587\u4ef6\u4e2d\u52a0\u8f7d\u8f93\u5165\u5217\u8868 # \u5212\u5206\u8bad\u7ec3\u96c6\u4e0e\u9a8c\u8bc1\u96c6 print ( len ( input_list )) # \u6253\u5370\u8f93\u5165\u5217\u8868\u7684\u957f\u5ea6 input_list_train = input_list [ 200 :] # \u5c06\u8f93\u5165\u5217\u8868\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u90e8\u5206 input_list_val = input_list [: 200 ] # \u5c06\u8f93\u5165\u5217\u8868\u5212\u5206\u4e3a\u9a8c\u8bc1\u96c6\u90e8\u5206 train_dataset = MyDataset ( input_list_train , 200 ) # \u521b\u5efa\u8bad\u7ec3\u6570\u636e\u96c6\u5bf9\u8c61 val_dataset = MyDataset ( input_list_val , 200 ) # \u521b\u5efa\u9a8c\u8bc1\u6570\u636e\u96c6\u5bf9\u8c61 return train_dataset , val_dataset # \u8fd4\u56de\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6 def collate_fn ( batch ): \"\"\" \u81ea\u5b9a\u4e49\u7684collate_fn\u51fd\u6570\uff0c\u7528\u4e8e\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u6837\u672c\u8fdb\u884c\u6279\u5904\u7406 :param batch: \u6837\u672c\u5217\u8868 :return: \u7ecf\u8fc7\u586b\u5145\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf\u548c\u6807\u7b7e\u5e8f\u5217\u5f20\u91cf \"\"\" # \u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5176\u957f\u5ea6\u4e00\u81f4 input_ids = rnn_utils . pad_sequence ( batch , batch_first = True , padding_value = 0 ) # \u5bf9\u6807\u7b7e\u5e8f\u5217\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5176\u957f\u5ea6\u4e00\u81f4 labels = rnn_utils . pad_sequence ( batch , batch_first = True , padding_value =- 100 ) return input_ids , labels # \u8fd4\u56de\u7ecf\u8fc7\u586b\u5145\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf\u548c\u6807\u7b7e\u5e8f\u5217\u5f20\u91cf def get_dataloader ( train_path ): \"\"\" \u83b7\u53d6\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 :param train_path: \u8bad\u7ec3\u6570\u636e\u96c6\u8def\u5f84 :return: \u8bad\u7ec3\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 \"\"\" # \u52a0\u8f7d\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6 train_dataset , val_dataset = load_dataset ( train_path ) # \u521b\u5efa\u8bad\u7ec3\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 train_dataloader = DataLoader ( train_dataset , batch_size = 4 , shuffle = True , collate_fn = collate_fn , drop_last = True ) # \u521b\u5efa\u9a8c\u8bc1\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 validate_dataloader = DataLoader ( val_dataset , batch_size = 4 , shuffle = True , collate_fn = collate_fn , drop_last = True ) return train_dataloader , validate_dataloader 3. \u6a21\u578b\u642d\u5efa \u00b6 3.1 \u6a21\u578b\u67b6\u6784\u4ecb\u7ecd \u00b6 \u6a21\u578b\u67b6\u6784\u89e3\u6790\uff1a \u8f93\u5165\u5c42\uff1a\u8bcd\u5d4c\u5165\u5c42\uff1aWordEmbedding +\u4f4d\u7f6e\u5d4c\u5165\u5c42\uff1aPositionEmbedding \u4e2d\u95f4\u5c42\uff1aTransformer\u7684Decoder\u6a21\u5757---12\u5c42 \u8f93\u51fa\u5c42\uff1aLayerNorm\u5c42+\u7ebf\u6027\u5168\u8fde\u63a5\u5c42 \u6a21\u578b\u4e3b\u8981\u53c2\u6570\u7b80\u4ecb(\u8be6\u89c1\u6a21\u578b\u7684config.json\u6587\u4ef6): n_embd: 768 n_head: 12 n_layer: 12 n_positions: 1024 vocab_size: 21128 3.2 GPT2\u6a21\u578b\u51c6\u5907 \u00b6 \u672c\u6b21\u9879\u76ee\u4f7f\u7528GPT2\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u989d\u5916\u642d\u5efaModel\u7c7b\uff0c\u4e0b\u9762\u4ee3\u7801\u662f\u5982\u4f55\u76f4\u63a5\u52a0\u8f7d\u4f7f\u7528GPT2\u9884\u8bad\u7ec3\u6a21\u578b \u4ee3\u7801\u793a\u4f8b: from transformers import GPT2LMHeadModel , GPT2Config # \u521b\u5efa\u6a21\u578b if params . pretrained_model : # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b model = GPT2LMHeadModel . from_pretrained ( params . pretrained_model ) else : # \u521d\u59cb\u5316\u6a21\u578b model_config = GPT2Config . from_json_file ( params . config_json ) model = GPT2LMHeadModel ( config = model_config ) 4. \u6a21\u578b\u8bad\u7ec3\u548c\u9a8c\u8bc1 \u00b6 \u4e3b\u8981\u4ee3\u7801 \u4ee3\u7801\u8def\u5f84 \u8bad\u7ec3\u4e3b\u51fd\u6570\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/train.py \u8f85\u52a9\u5de5\u5177\u7c7b\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/functions_tools.py trian.py\u4ee3\u7801\u89e3\u6790 import torch import os from datetime import datetime import transformers from transformers import GPT2LMHeadModel , GPT2Config from transformers import BertTokenizerFast from functions_tools import * from parameter_config import * from data_preprocess.dataloader import * from pytorch_tools import EarlyStopping def train_epoch ( model , train_dataloader , optimizer , scheduler , epoch , args ): model . train () device = args . device # \u5bf9\u4e8eignore_index\u7684label token\u4e0d\u8ba1\u7b97\u68af\u5ea6 ignore_index = args . ignore_index epoch_start_time = datetime . now () total_loss = 0 # \u8bb0\u5f55\u4e0b\u6574\u4e2aepoch\u7684loss\u7684\u603b\u548c # epoch_correct_num:\u6bcf\u4e2aepoch\u4e2d,output\u9884\u6d4b\u6b63\u786e\u7684word\u7684\u6570\u91cf # epoch_total_num: \u6bcf\u4e2aepoch\u4e2d,output\u9884\u6d4b\u7684word\u7684\u603b\u6570\u91cf epoch_correct_num , epoch_total_num = 0 , 0 for batch_idx , ( input_ids , labels ) in enumerate ( train_dataloader ): input_ids = input_ids . to ( device ) labels = labels . to ( device ) outputs = model . forward ( input_ids , labels = labels ) logits = outputs . logits loss = outputs . loss loss = loss . mean () # \u7edf\u8ba1\u8be5batch\u7684\u9884\u6d4btoken\u7684\u6b63\u786e\u6570\u4e0e\u603b\u6570 batch_correct_num , batch_total_num = calculate_acc ( logits , labels , ignore_index = ignore_index ) # \u7edf\u8ba1\u8be5epoch\u7684\u9884\u6d4btoken\u7684\u6b63\u786e\u6570\u4e0e\u603b\u6570 epoch_correct_num += batch_correct_num epoch_total_num += batch_total_num # \u8ba1\u7b97\u8be5batch\u7684accuracy batch_acc = batch_correct_num / batch_total_num total_loss += loss . item () if args . gradient_accumulation_steps > 1 : loss = loss / args . gradient_accumulation_steps loss . backward () # \u68af\u5ea6\u88c1\u526a # \u907f\u514d\u68af\u5ea6\u7206\u70b8\u7684\u65b9\u5f0f\u3002 torch . nn . utils . clip_grad_norm_ ( model . parameters (), args . max_grad_norm ) # \u8fdb\u884c\u4e00\u5b9astep\u7684\u68af\u5ea6\u7d2f\u8ba1\u4e4b\u540e\uff0c\u66f4\u65b0\u53c2\u6570 if ( batch_idx + 1 ) % args . gradient_accumulation_steps == 0 : # \u66f4\u65b0\u53c2\u6570 optimizer . step () # \u66f4\u65b0\u5b66\u4e60\u7387 scheduler . step () # \u6e05\u7a7a\u68af\u5ea6\u4fe1\u606f optimizer . zero_grad () if ( batch_idx + 1 ) % args . loss_step == 0 : print ( \"batch {} of epoch {} , loss {} , batch_acc {} , lr {} \" . format ( batch_idx + 1 , epoch + 1 , loss . item () * args . gradient_accumulation_steps , batch_acc , scheduler . get_lr ())) del input_ids , outputs # \u8bb0\u5f55\u5f53\u524depoch\u7684\u5e73\u5747loss\u4e0eaccuracy epoch_mean_loss = total_loss / len ( train_dataloader ) epoch_mean_acc = epoch_correct_num / epoch_total_num print ( \"epoch {} : loss {} , predict_acc {} \" . format ( epoch + 1 , epoch_mean_loss , epoch_mean_acc )) # save model if epoch % 10 == 0 or epoch == args . epochs : print ( 'saving model for epoch {} ' . format ( epoch + 1 )) model_path = os . path . join ( args . save_model_path , 'bj_epoch {} ' . format ( epoch + 1 )) if not os . path . exists ( model_path ): os . mkdir ( model_path ) model . save_pretrained ( model_path ) print ( 'epoch {} finished' . format ( epoch + 1 )) epoch_finish_time = datetime . now () print ( 'time for one epoch: {} ' . format ( epoch_finish_time - epoch_start_time )) return epoch_mean_loss def validate_epoch ( model , validate_dataloader , epoch , args ): print ( \"start validating\" ) model . eval () device = args . device ignore_index = args . ignore_index epoch_start_time = datetime . now () total_loss = 0 # \u6355\u83b7cuda out of memory exception with torch . no_grad (): for batch_idx , ( input_ids , labels ) in enumerate ( validate_dataloader ): input_ids = input_ids . to ( device ) labels = labels . to ( device ) outputs = model . forward ( input_ids , labels = labels ) logits = outputs . logits loss = outputs . loss loss = loss . mean () total_loss += loss . item () del input_ids , outputs # \u8bb0\u5f55\u5f53\u524depoch\u7684\u5e73\u5747loss epoch_mean_loss = total_loss / len ( validate_dataloader ) print ( \"validate epoch {} : loss {} \" . format ( epoch + 1 , epoch_mean_loss )) epoch_finish_time = datetime . now () print ( 'time for validating one epoch: {} ' . format ( epoch_finish_time - epoch_start_time )) return epoch_mean_loss def train ( model , train_dataloader , validate_dataloader , args ): # early_stopping = EarlyStopping(patience=0, verbose=True) t_total = len ( train_dataloader ) // args . gradient_accumulation_steps * args . epochs optimizer = transformers . AdamW ( model . parameters (), lr = args . lr , eps = args . eps ) ''' \u8fd9\u91cc\u5bf9\u4e8e\u6a21\u578b\u7684\u53c2\u6570\uff0c\u5206\u522b\u5c31\u884c\u6743\u91cd\u53c2\u6570\u7684\u8870\u51cf\u4f18\u5316\uff1a\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u4ee5\u53ca\u5b66\u4e60\u7387\u9884\u70ed\u5904\u7406\u4f18\u5316\uff1a \u5728\u521d\u59cb\u9636\u6bb5\u5c06\u5b66\u4e60\u7387\u4ece\u8f83\u5c0f\u7684\u503c\u9010\u6b65\u589e\u52a0\u5230\u8bbe\u5b9a\u7684\u521d\u59cb\u503c\uff0c\u7136\u540e\u6309\u7167\u8bbe\u5b9a\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\u8fdb\u884c\u8bad\u7ec3\u3002 \u5b66\u4e60\u7387\u9884\u70ed\u7684\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u5728\u521d\u59cb\u9636\u6bb5\u66f4\u5feb\u5730\u9002\u5e94\u6570\u636e\uff0c\u907f\u514d\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u56e0\u4e3a\u5b66\u4e60\u7387\u8fc7\u5927\u5bfc\u81f4\u7684\u68af\u5ea6\u7206\u70b8\u7b49\u95ee\u9898\uff0c \u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u548c\u6cdb\u5316\u6027\u80fd\u3002 optimizer\uff1a \u4f18\u5316\u5668 num_warmup_steps\uff1a\u521d\u59cb\u9884\u70ed\u6b65\u6570 num_training_steps\uff1a\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u7684\u603b\u6b65\u6570 ''' scheduler = transformers . get_linear_schedule_with_warmup ( optimizer , num_warmup_steps = args . warmup_steps , num_training_steps = t_total ) print ( 'starting training' ) # \u7528\u4e8e\u8bb0\u5f55\u6bcf\u4e2aepoch\u8bad\u7ec3\u548c\u9a8c\u8bc1\u7684loss train_losses , validate_losses = [], [] # \u8bb0\u5f55\u9a8c\u8bc1\u96c6\u7684\u6700\u5c0floss best_val_loss = 10000 # \u5f00\u59cb\u8bad\u7ec3 for epoch in range ( args . epochs ): # ========== train ========== # train_loss = train_epoch ( model = model , train_dataloader = train_dataloader , optimizer = optimizer , scheduler = scheduler , epoch = epoch , args = args ) train_losses . append ( train_loss ) # ========== validate ========== # validate_loss = validate_epoch ( model = model , validate_dataloader = validate_dataloader , epoch = epoch , args = args ) validate_losses . append ( validate_loss ) # \u4fdd\u5b58\u5f53\u524d\u56f0\u60d1\u5ea6\u6700\u4f4e\u7684\u6a21\u578b\uff0c\u56f0\u60d1\u5ea6\u4f4e\uff0c\u6a21\u578b\u7684\u751f\u6210\u6548\u679c\u4e0d\u4e00\u5b9a\u4f1a\u8d8a\u597d if validate_loss < best_val_loss : best_val_loss = validate_loss print ( 'saving current best model for epoch {} ' . format ( epoch + 1 )) model_path = os . path . join ( args . save_model_path , 'min_ppl_model_bj' . format ( epoch + 1 )) if not os . path . exists ( model_path ): os . mkdir ( model_path ) model . save_pretrained ( model_path ) def main (): # \u521d\u59cb\u5316\u914d\u7f6e\u53c2\u6570 params = ParameterConfig () # \u8bbe\u7f6e\u4f7f\u7528\u54ea\u4e9b\u663e\u5361\u8fdb\u884c\u8bad\u7ec3:\u9ed8\u8ba4\u4e3a0 os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = '0' # \u521d\u59cb\u5316tokenizer tokenizer = BertTokenizerFast ( params . vocab_path , sep_token = \"[SEP]\" , pad_token = \"[PAD]\" , cls_token = \"[CLS]\" ) # \u521b\u5efa\u6a21\u578b\u7684\u8f93\u51fa\u76ee\u5f55 if not os . path . exists ( params . save_model_path ): os . mkdir ( params . save_model_path ) # \u521b\u5efa\u6a21\u578b if params . pretrained_model : # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b model = GPT2LMHeadModel . from_pretrained ( params . pretrained_model ) else : # \u521d\u59cb\u5316\u6a21\u578b model_config = GPT2Config . from_json_file ( params . config_json ) model = GPT2LMHeadModel ( config = model_config ) model = model . to ( params . device ) assert model . config . vocab_size == tokenizer . vocab_size # \u8ba1\u7b97\u6a21\u578b\u53c2\u6570\u6570\u91cf num_parameters = 0 parameters = model . parameters () for parameter in parameters : num_parameters += parameter . numel () print ( f '\u6a21\u578b\u53c2\u6570\u603b\u91cf---\u300b { num_parameters } ' ) # \u52a0\u8f7d\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 # ========= Loading Dataset ========= # train_dataloader , validate_dataloader = get_dataloader ( params . train_path ) train ( model , train_dataloader , validate_dataloader , params ) if __name__ == '__main__' : main () functions_tools.py\u4ee3\u7801\u89e3\u6790 import torch import torch.nn.functional as F def calculate_acc ( logit , labels , ignore_index =- 100 ): logit = logit [:, : - 1 , :] . contiguous () . view ( - 1 , logit . size ( - 1 )) labels = labels [:, 1 :] . contiguous () . view ( - 1 ) _ , logit = logit . max ( dim =- 1 ) # \u5bf9\u4e8e\u6bcf\u6761\u6570\u636e\uff0c\u8fd4\u56de\u6700\u5927\u7684index ''' \u5728 PyTorch \u4e2d\uff0clabels.ne(ignore_index) \u8868\u793a\u5c06\u6807\u7b7e\u5f20\u91cf labels \u4e2d\u7684\u503c\u4e0d\u7b49\u4e8e ignore_index \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a True\uff0c\u7b49\u4e8e ignore_index \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a False\u3002 \u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u88ab\u7528\u4e8e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4ee5\u8fc7\u6ee4\u6389 ignore_index \u5bf9\u635f\u5931\u7684\u8d21\u732e ''' # \u8fdb\u884c\u975e\u8fd0\u7b97\uff0c\u8fd4\u56de\u4e00\u4e2atensor\uff0c\u82e5labels\u7684\u7b2ci\u4e2a\u4f4d\u7f6e\u4e3apad_id\uff0c\u5219\u7f6e\u4e3a0\uff0c\u5426\u5219\u4e3a1 non_pad_mask = labels . ne ( ignore_index ) ''' \u5728 PyTorch \u4e2d\uff0c logit.eq(labels) \u8868\u793a\u5c06\u6a21\u578b\u7684\u9884\u6d4b\u8f93\u51fa\u503c logit \u4e2d\u7b49\u4e8e\u6807\u7b7e\u5f20\u91cf labels \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a True\uff0c\u4e0d\u7b49\u4e8e\u6807\u7b7e\u5f20\u91cf labels \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a False\u3002\u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u88ab\u7528\u4e8e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4ee5\u6807\u8bb0\u51fa\u9884\u6d4b\u8f93\u51fa\u503c\u548c\u6807\u7b7e\u503c\u76f8\u7b49\u7684\u4f4d\u7f6e\u3002 masked_select(non_pad_mask) \u8868\u793a\u5c06\u5f20\u91cf\u4e2d\u975e\u586b\u5145\u6807\u8bb0\u7684\u4f4d\u7f6e\u9009\u51fa\u6765\u3002\u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u88ab\u7528\u4e8e\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u8fc7\u6ee4\u6389\u586b\u5145\u6807\u8bb0\u5bf9\u635f\u5931\u7684\u5f71\u54cd\u3002 ''' n_correct = logit . eq ( labels ) . masked_select ( non_pad_mask ) . sum () . item () n_word = non_pad_mask . sum () . item () return n_correct , n_word 5. \u6a21\u578b\u9884\u6d4b\uff08\u4eba\u673a\u4ea4\u4e92\uff09 \u00b6 \u8fd0\u884cinteract.py\uff0c\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u8fdb\u884c\u4eba\u673a\u4ea4\u4e92\uff0c\u8f93\u5165Ctrl+Z\u7ed3\u675f\u5bf9\u8bdd\u4e4b\u540e\uff0c\u804a\u5929\u8bb0\u5f55\u5c06\u4fdd\u5b58\u5230sample\u76ee\u5f55\u4e0b\u7684sample.txt\u6587\u4ef6\u4e2d\u3002 import os from datetime import datetime from transformers import GPT2LMHeadModel from transformers import BertTokenizerFast import torch.nn.functional as F from parameter_config import * PAD = '[PAD]' pad_id = 0 def top_k_top_p_filtering ( logits , top_k = 0 , top_p = 0.0 , filter_value =- float ( 'Inf' )): \"\"\"\u4f7f\u7528top-k\u548c/\u6216nucleus\uff08top-p\uff09\u7b5b\u9009\u6765\u8fc7\u6ee4logits\u7684\u5206\u5e03 \u53c2\u6570: logits: logits\u7684\u5206\u5e03\uff0c\u5f62\u72b6\u4e3a\uff08\u8bcd\u6c47\u5927\u5c0f\uff09 top_k > 0: \u4fdd\u7559\u6982\u7387\u6700\u9ad8\u7684top k\u4e2a\u6807\u8bb0\uff08top-k\u7b5b\u9009\uff09\u3002 top_p > 0.0: \u4fdd\u7559\u7d2f\u79ef\u6982\u7387\u5927\u4e8e\u7b49\u4e8etop_p\u7684top\u6807\u8bb0\uff08nucleus\u7b5b\u9009\uff09\u3002 \"\"\" assert logits . dim () == 1 # batch size 1 for now - could be updated for more but the code would be less clear top_k = min ( top_k , logits . size ( - 1 )) # Safety check print ( f 'top_k----> { top_k } ' ) if top_k > 0 : # Remove all tokens with a probability less than the last token of the top-k # torch.topk()\u8fd4\u56de\u6700\u540e\u4e00\u7ef4\u6700\u5927\u7684top_k\u4e2a\u5143\u7d20\uff0c\u8fd4\u56de\u503c\u4e3a\u4e8c\u7ef4(values,indices) # ...\u8868\u793a\u5176\u4ed6\u7ef4\u5ea6\u7531\u8ba1\u7b97\u673a\u81ea\u884c\u63a8\u65ad print ( f 'torch.topk(logits, top_k)--> { torch . topk ( logits , top_k ) } ' ) indices_to_remove = logits < torch . topk ( logits , top_k )[ 0 ][ ... , - 1 , None ] logits [ indices_to_remove ] = filter_value # \u5bf9\u4e8etopk\u4e4b\u5916\u7684\u5176\u4ed6\u5143\u7d20\u7684logits\u503c\u8bbe\u4e3a\u8d1f\u65e0\u7a77 if top_p > 0.0 : sorted_logits , sorted_indices = torch . sort ( logits , descending = True ) # \u5bf9logits\u8fdb\u884c\u9012\u51cf\u6392\u5e8f print ( f 'sorted_logits--> { sorted_logits } ' ) print ( f 'sorted_indices--> { sorted_indices } ' ) cumulative_probs = torch . cumsum ( F . softmax ( sorted_logits , dim =- 1 ), dim =- 1 ) # Remove tokens with cumulative probability above the threshold sorted_indices_to_remove = cumulative_probs > top_p # Shift the indices to the right to keep also the first token above the threshold sorted_indices_to_remove [ ... , 1 :] = sorted_indices_to_remove [ ... , : - 1 ] . clone () sorted_indices_to_remove [ ... , 0 ] = 0 indices_to_remove = sorted_indices [ sorted_indices_to_remove ] logits [ indices_to_remove ] = filter_value return logits def main (): pconf = ParameterConfig () # \u5f53\u7528\u6237\u4f7f\u7528GPU,\u5e76\u4e14GPU\u53ef\u7528\u65f6 device = 'cuda' if torch . cuda . is_available () else 'cpu' print ( 'using device: {} ' . format ( device )) os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = '0' tokenizer = BertTokenizerFast ( vocab_file = pconf . vocab_path , sep_token = \"[SEP]\" , pad_token = \"[PAD]\" , cls_token = \"[CLS]\" ) model = GPT2LMHeadModel . from_pretrained ( './save_model/epoch25' ) model = model . to ( device ) model . eval () # \u4fdd\u5b58\u804a\u5929\u8bb0\u5f55\u7684\u6587\u4ef6\u8def\u5f84 if pconf . save_samples_path : if not os . path . exists ( pconf . save_samples_path ): os . makedirs ( pconf . save_samples_path ) samples_file = open ( pconf . save_samples_path + '/samples.txt' , 'a' , encoding = 'utf8' ) samples_file . write ( \"\u804a\u5929\u8bb0\u5f55 {} : \\n \" . format ( datetime . now ())) # \u5b58\u50a8\u804a\u5929\u8bb0\u5f55\uff0c\u6bcf\u4e2autterance\u4ee5token\u7684id\u7684\u5f62\u5f0f\u8fdb\u884c\u5b58\u50a8 history = [] print ( '\u5f00\u59cb\u548cchatbot\u804a\u5929\uff0c\u8f93\u5165CTRL + Z\u4ee5\u9000\u51fa' ) while True : try : text = input ( \"user:\" ) # text = \"\u4f60\u597d\" if pconf . save_samples_path : samples_file . write ( \"user: {} \\n \" . format ( text )) text_ids = tokenizer . encode ( text , add_special_tokens = False ) print ( f 'text_ids--> { text_ids } ' ) print ( '*' * 80 ) history . append ( text_ids ) input_ids = [ tokenizer . cls_token_id ] # \u6bcf\u4e2ainput\u4ee5[CLS]\u4e3a\u5f00\u5934 print ( f 'history---. { history } ' ) print ( f 'input_ids---. { input_ids } ' ) print ( '*' * 80 ) print ( f 'history[-pconf.max_history_len:]--> { history [ - pconf . max_history_len :] } ' ) for history_id , history_utr in enumerate ( history [ - pconf . max_history_len :]): input_ids . extend ( history_utr ) print ( input_ids ) input_ids . append ( tokenizer . sep_token_id ) print ( input_ids ) print ( '*' * 80 ) print ( f 'new_inut---> { input_ids } ' ) input_ids = torch . tensor ( input_ids ) . long () . to ( device ) input_ids = input_ids . unsqueeze ( 0 ) print ( f 'las--inputs_ids { input_ids } ' ) response = [] # \u6839\u636econtext\uff0c\u751f\u6210\u7684response # \u6700\u591a\u751f\u6210max_len\u4e2atoken for _ in range ( pconf . max_len ): outputs = model ( input_ids = input_ids ) logits = outputs . logits print ( f 'logits---> { logits } ' ) print ( f 'logits---> { logits . shape } ' ) print ( '*' * 80 ) next_token_logits = logits [ 0 , - 1 , :] # \u5bf9\u4e8e\u5df2\u751f\u6210\u7684\u7ed3\u679cgenerated\u4e2d\u7684\u6bcf\u4e2atoken\u6dfb\u52a0\u4e00\u4e2a\u91cd\u590d\u60e9\u7f5a\u9879\uff0c\u964d\u4f4e\u5176\u751f\u6210\u6982\u7387 print ( f 'next_token_logits--> { next_token_logits } ' ) for id in set ( response ): print ( f 'id---> { id } ' ) next_token_logits [ id ] /= pconf . repetition_penalty # \u5bf9\u4e8e[UNK]\u7684\u6982\u7387\u8bbe\u4e3a\u65e0\u7a77\u5c0f\uff0c\u4e5f\u5c31\u662f\u8bf4\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0d\u53ef\u80fd\u662f[UNK]\u8fd9\u4e2atoken next_token_logits [ tokenizer . convert_tokens_to_ids ( '[UNK]' )] = - float ( 'Inf' ) filtered_logits = top_k_top_p_filtering ( next_token_logits , top_k = pconf . topk , top_p = pconf . topp ) print ( f 'filtered_logits--> { filtered_logits } ' ) # torch.multinomial\u8868\u793a\u4ece\u5019\u9009\u96c6\u5408\u4e2d\u65e0\u653e\u56de\u5730\u8fdb\u884c\u62bd\u53d6num_samples\u4e2a\u5143\u7d20\uff0c\u6743\u91cd\u8d8a\u9ad8\uff0c\u62bd\u5230\u7684\u51e0\u7387\u8d8a\u9ad8\uff0c\u8fd4\u56de\u5143\u7d20\u7684\u4e0b\u6807 next_token = torch . multinomial ( F . softmax ( filtered_logits , dim =- 1 ), num_samples = 1 ) print ( f 'next_token--> { next_token } ' ) if next_token == tokenizer . sep_token_id : # \u9047\u5230[SEP]\u5219\u8868\u660eresponse\u751f\u6210\u7ed3\u675f break response . append ( next_token . item ()) input_ids = torch . cat (( input_ids , next_token . unsqueeze ( 0 )), dim = 1 ) # his_text = tokenizer.convert_ids_to_tokens(curr_input_tensor.tolist()) # print(\"his_text:{}\".format(his_text)) print ( f 'response--> { response } ' ) history . append ( response ) text = tokenizer . convert_ids_to_tokens ( response ) print ( \"chatbot:\" + \"\" . join ( text )) if pconf . save_samples_path : samples_file . write ( \"chatbot: {} \\n \" . format ( \"\" . join ( text ))) except KeyboardInterrupt : if pconf . save_samples_path : samples_file . close () break if __name__ == '__main__' : main ()","title":"5.1 \u533b\u7597\u95ee\u8bca\u673a\u5668\u4eba\u5b9e\u73b0"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#gpt2","text":"","title":"\u57fa\u4e8eGPT2\u642d\u5efa\u533b\u7597\u95ee\u8bca\u673a\u5668\u4eba"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#_1","text":"\u7406\u89e3\u533b\u7597\u95ee\u8bca\u673a\u5668\u4eba\u7684\u5f00\u53d1\u80cc\u666f. \u4e86\u89e3\u4f01\u4e1a\u4e2d\u804a\u5929\u673a\u5668\u4eba\u7684\u5e94\u7528\u573a\u666f \u638c\u63e1\u57fa\u4e8eGPT2\u6a21\u578b\u642d\u5efa\u533b\u7597\u95ee\u8bca\u673a\u5668\u4eba\u7684\u5b9e\u73b0\u8fc7\u7a0b","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#_2","text":"\u804a\u5929\u673a\u5668\u4eba\u662f\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u7684\u667a\u80fd\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u7684\u81ea\u7136\u8bed\u8a00\u4ea4\u6d41\uff0c\u4e0e\u7528\u6237\u8fdb\u884c\u5bf9\u8bdd\u548c\u4e92\u52a8\u3002\u804a\u5929\u673a\u5668\u4eba\u80fd\u591f\u7406\u89e3\u7528\u6237\u7684\u95ee\u9898\u6216\u6307\u4ee4\uff0c\u5e76\u7ed9\u51fa\u76f8\u5e94\u7684\u56de\u7b54\u6216\u5efa\u8bae\u3002\u5176\u76ee\u6807\u662f\u63d0\u4f9b\u53cb\u597d\u3001\u667a\u80fd\u3001\u81ea\u7136\u7684\u5bf9\u8bdd\u4f53\u9a8c. \u5f53\u524d\uff0c\u804a\u5929\u673a\u5668\u4eba\u5728\u591a\u4e2a\u9886\u57df\u5f97\u5230\u5e7f\u6cdb\u5e94\u7528\u3002\u9996\u5148\uff0c\u5b83\u4eec\u5e38\u7528\u4e8e\u5728\u7ebf\u5ba2\u670d\u7cfb\u7edf\uff0c\u80fd\u591f\u5feb\u901f\u3001\u51c6\u786e\u5730\u56de\u7b54\u7528\u6237\u7684\u5e38\u89c1\u95ee\u9898\uff0c\u89e3\u51b3\u7591\u95ee\u3002\u5176\u6b21\uff0c\u804a\u5929\u673a\u5668\u4eba\u53ef\u4ee5\u4f5c\u4e3a\u4e2a\u4eba\u52a9\u624b\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u63a8\u8350\u3001\u5efa\u8bae\u548c\u65e5\u7a0b\u5b89\u6392\u7b49\u670d\u52a1\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002\u6b64\u5916\uff0c\u804a\u5929\u673a\u5668\u4eba\u8fd8\u88ab\u5e94\u7528\u4e8e\u793e\u4ea4\u5a31\u4e50\u3001\u8bed\u8a00\u5b66\u4e60\u3001\u65c5\u6e38\u6307\u5357\u7b49\u9886\u57df\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u6709\u8da3\u3001\u4fbf\u6377\u7684\u5bf9\u8bdd\u4f53\u9a8c. \u5e38\u89c1\u7684\u76f8\u5173\u804a\u5929\u673a\u5668\u4eba\u4ea7\u54c1\uff1a \u5fae\u8f6f\u5c0f\u51b0\uff1a\u5fae\u8f6f\u516c\u53f8\u5f00\u53d1\u3002\u5b83\u5177\u5907\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u60c5\u611f\u5206\u6790\u548c\u5bf9\u8bdd\u751f\u6210\u7b49\u529f\u80fd\uff0c\u80fd\u591f\u4e0e\u7528\u6237\u8fdb\u884c\u667a\u80fd\u5bf9\u8bdd\uff0c\u63d0\u4f9b\u60c5\u611f\u652f\u6301\u548c\u5a31\u4e50\u7b49\u670d\u52a1\u3002 \u963f\u91cc\u4e91\u5c0f\u871c\uff1a\u963f\u91cc\u4e91\u516c\u53f8\u63a8\u51fa\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u667a\u80fd\u5bf9\u8bdd\u670d\u52a1\u3002\u5b83\u5177\u5907\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5bf9\u8bdd\u7ba1\u7406\u80fd\u529b\uff0c\u652f\u6301\u591a\u9886\u57df\u7684\u5e94\u7528\u573a\u666f\uff0c\u5982\u5728\u7ebf\u5ba2\u670d\u3001\u667a\u80fd\u52a9\u624b\u548c\u865a\u62df\u5bfc\u8d2d\u7b49\u3002 \u767e\u5ea6\u667a\u80fd\u4e91\u5c0f\u5ea6\uff1a\u767e\u5ea6\u667a\u80fd\u4e91\u5f00\u53d1\uff0c\u63d0\u4f9b\u4e86\u591a\u9886\u57df\u7684\u667a\u80fd\u5bf9\u8bdd\u80fd\u529b\u3002\u5c0f\u5ea6\u673a\u5668\u4eba\u53ef\u5e94\u7528\u4e8e\u5bb6\u5ead\u52a9\u7406\u3001\u667a\u80fd\u97f3\u7bb1\u548c\u79fb\u52a8\u5e94\u7528\u7b49\u573a\u666f\uff0c\u901a\u8fc7\u8bed\u97f3\u548c\u6587\u672c\u4ea4\u4e92\u4e0e\u7528\u6237\u8fdb\u884c\u667a\u80fd\u5bf9\u8bdd\uff0c\u63d0\u4f9b\u4fe1\u606f\u67e5\u8be2\u3001\u97f3\u4e50\u64ad\u653e\u548c\u65e5\u7a0b\u5b89\u6392\u7b49\u529f\u80fd\u3002 \u672c\u9879\u76ee\u57fa\u4e8e\u533b\u7597\u9886\u57df\u6570\u636e\u6784\u5efa\u4e86\u667a\u80fd\u533b\u7597\u95ee\u7b54\u7cfb\u7edf,\u76ee\u7684\u662f\u4e3a\u4e3a\u7528\u6237\u63d0\u4f9b\u51c6\u786e\u3001\u9ad8\u6548\u3001\u4f18\u8d28\u7684\u533b\u7597\u95ee\u7b54\u670d\u52a1\u3002","title":"\u9879\u76ee\u80cc\u666f"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#_3","text":"python3.6\u3001 transformers==4.2.0 \u3001 pytorch==1.7.0","title":"\u73af\u5883\u51c6\u5907"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#_4","text":"","title":"\u9879\u76ee\u6574\u4f53\u7ed3\u6784"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#1","text":"\u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/ptune_chatglm/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u6587\u4ef6\uff1amedical_train.txt, medical_valid.txt","title":"1. \u6570\u636e\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#11","text":"medical_train.txt, medical_valid.txt\u6587\u4ef6\u7684\u5185\u5bb9\u5747\u4e3a\u5bf9\u8bdd\u6587\u672c \u539f\u59cbtrain\u6587\u6863\u4e2d\u4e2d\u4e00\u5171\u5305\u542b91487\u6761\u6570\u636e\uff0cvalid\u6587\u6863\u4e2d\u5305\u542b1244\u6761\u6570\u636e \u6bcf\u4e24\u884c\u6570\u636e\u4e3a\u4e00\u6bb5\u5bf9\u8bdd\u5185\u5bb9\uff0c\u6ce8\u610f\uff1a\u5982\u679c\u60f3\u8981\u5b9e\u73b0\u591a\u8f6e\u5bf9\u8bdd\uff0c\u90a3\u4e48\u4e0d\u540c\u5bf9\u8bdd\u95f4\u5b9e\u73b0\u591a\u6761\u5bf9\u8bdd\u8bed\u53e5\u5bf9\u5373\u53ef","title":"1.1 \u6570\u636e\u5c55\u793a"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#2","text":"\u76ee\u7684\uff1a\u5c06\u4e2d\u6587\u6587\u672c\u6570\u636e\u5904\u7406\u6210\u6a21\u578b\u80fd\u591f\u8bc6\u522b\u7684\u5f20\u91cf\u5f62\u5f0f\u3002 \u5b9e\u73b0\u8fc7\u7a0b\uff1a \u8fd0\u884cpreprocess.py\uff0c\u5bf9data/medical_train.txt\u5bf9\u8bdd\u8bed\u6599\u8fdb\u884ctokenize\uff0c\u7136\u540e\u8fdb\u884c\u5e8f\u5217\u5316\u4fdd\u5b58\u5230data/medical_train.txt.pkl\u3002medical_train.pkl\u4e2d\u5e8f\u5217\u5316\u7684\u5bf9\u8c61\u7684\u7c7b\u578b\u4e3aList[List],\u8bb0\u5f55\u5bf9\u8bdd\u5217\u8868\u4e2d,\u6bcf\u4e2a\u5bf9\u8bdd\u5305\u542b\u7684token\u3002 python preprocess . py train_path data / medical_train . txt -- \u300b save_path data / medical_train . pkl \u6570\u636e\u5904\u7406\u57fa\u672c\u6d41\u7a0b\uff1a","title":"2.\u6570\u636e\u5904\u7406"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#21","text":"\u4ee3\u7801\u8def\u5f84\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/preprocess.py # \u5bfc\u5165\u5206\u8bcd\u5668 from transformers import BertTokenizerFast # \u5c06\u6570\u636e\u4fdd\u5b58\u4e3apkl\u6587\u4ef6\uff0c\u65b9\u4fbf\u4e0b\u6b21\u8bfb\u53d6 import pickle # \u8bfb\u53d6\u6570\u636e\u7684\u8fdb\u5ea6\u6761\u5c55\u793a from tqdm import tqdm def preprocess ( train_txt_path , train_pkl_path ): \"\"\" \u5bf9\u539f\u59cb\u8bed\u6599\u8fdb\u884ctokenize\uff0c\u5c06\u6bcf\u6bb5\u5bf9\u8bdd\u5904\u7406\u6210\u5982\u4e0b\u5f62\u5f0f\uff1a\"[CLS]utterance1[SEP]utterance2[SEP]utterance3[SEP]\" \"\"\" '''\u521d\u59cb\u5316tokenizer\uff0c\u4f7f\u7528BertTokenizerFast. \u4ece\u9884\u8bad\u7ec3\u7684\u4e2d\u6587Bert\u6a21\u578b\uff08bert-base-chinese\uff09\u521b\u5efa\u4e00\u4e2atokenizer\u5bf9\u8c61''' tokenizer = BertTokenizerFast . from_pretrained ( 'bert-base-chinese' , sep_token = \"[SEP]\" , pad_token = \"[PAD]\" , cls_token = \"[CLS]\" ) sep_id = tokenizer . sep_token_id # \u83b7\u53d6\u5206\u9694\u7b26[SEP]\u7684token ID cls_id = tokenizer . cls_token_id # \u83b7\u53d6\u8d77\u59cb\u7b26[CLS]\u7684token ID # \u8bfb\u53d6\u8bad\u7ec3\u6570\u636e\u96c6 with open ( train_txt_path , 'rb' ) as f : data = f . read () . decode ( \"utf-8\" ) # \u4ee5UTF-8\u7f16\u7801\u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9 # \u6839\u636e\u6362\u884c\u7b26\u533a\u5206\u4e0d\u540c\u7684\u5bf9\u8bdd\u6bb5\u843d\uff0c\u9700\u8981\u533a\u5206Windows\u548cLinux\u73af\u5883\u4e0b\u7684\u6362\u884c\u7b26 if \" \\r\\n \" in data : train_data = data . split ( \" \\r\\n\\r\\n \" ) else : train_data = data . split ( \" \\n\\n \" ) print ( len ( train_data )) # \u6253\u5370\u5bf9\u8bdd\u6bb5\u843d\u6570\u91cf # \u5f00\u59cb\u8fdb\u884ctokenize # \u4fdd\u5b58\u6240\u6709\u7684\u5bf9\u8bdd\u6570\u636e,\u6bcf\u6761\u6570\u636e\u7684\u683c\u5f0f\u4e3a\uff1a\"[CLS]seq1[SEP]seq2[SEP]seq3[SEP]\" dialogue_len = [] # \u8bb0\u5f55\u6240\u6709\u5bf9\u8bddtokenize\u4e4b\u540e\u7684\u957f\u5ea6\uff0c\u7528\u4e8e\u7edf\u8ba1\u4e2d\u4f4d\u6570\u4e0e\u5747\u503c dialogue_list = [] # \u8bb0\u5f55\u6240\u6709\u5bf9\u8bdd for index , dialogue in enumerate ( tqdm ( train_data )): if \" \\r\\n \" in data : sequences = dialogue . split ( \" \\r\\n \" ) else : sequences = dialogue . split ( \" \\n \" ) input_ids = [ cls_id ] # \u6bcf\u4e2adialogue\u4ee5[CLS]\u5f00\u5934 for sequence in sequences : # \u5c06\u6bcf\u4e2a\u5bf9\u8bdd\u53e5\u5b50\u8fdb\u884ctokenize\uff0c\u5e76\u5c06\u7ed3\u679c\u62fc\u63a5\u5230input_ids\u5217\u8868\u4e2d input_ids += tokenizer . encode ( sequence , add_special_tokens = False ) input_ids . append ( sep_id ) # \u6bcf\u4e2aseq\u4e4b\u540e\u6dfb\u52a0[SEP]\uff0c\u8868\u793aseqs\u4f1a\u8bdd\u7ed3\u675f dialogue_len . append ( len ( input_ids )) # \u5c06\u5bf9\u8bdd\u7684tokenize\u540e\u7684\u957f\u5ea6\u6dfb\u52a0\u5230\u5bf9\u8bdd\u957f\u5ea6\u5217\u8868\u4e2d dialogue_list . append ( input_ids ) # \u5c06tokenize\u540e\u7684\u5bf9\u8bdd\u6dfb\u52a0\u5230\u5bf9\u8bdd\u5217\u8868\u4e2d print ( f 'dialogue_len---> { dialogue_len } ' ) # \u6253\u5370\u5bf9\u8bdd\u957f\u5ea6\u5217\u8868 print ( f 'dialogue_list---> { dialogue_list } ' ) # \u6253\u5370 # \u4fdd\u5b58pkl\u6587\u4ef6\u6570\u636e with open ( train_pkl_path , \"wb\" ) as f : pickle . dump ( dialogue_list , f )","title":"2.1 \u6570\u636e\u5f20\u91cf\u8f6c\u6362"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#22","text":"","title":"2.2 \u6570\u636e\u5f20\u91cf\u518d\u6b21\u5c01\u88c5"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#221-dataset","text":"\u4ee3\u7801\u8def\u5f84\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/dataset.py from torch.utils.data import Dataset # \u5bfc\u5165Dataset\u6a21\u5757\uff0c\u7528\u4e8e\u5b9a\u4e49\u81ea\u5b9a\u4e49\u6570\u636e\u96c6 import torch # \u5bfc\u5165torch\u6a21\u5757\uff0c\u7528\u4e8e\u5904\u7406\u5f20\u91cf\u548c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc class MyDataset ( Dataset ): \"\"\" \u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u7c7b\uff0c\u7ee7\u627f\u81eaDataset\u7c7b \"\"\" def __init__ ( self , input_list , max_len ): \"\"\" \u521d\u59cb\u5316\u51fd\u6570\uff0c\u7528\u4e8e\u8bbe\u7f6e\u6570\u636e\u96c6\u7684\u5c5e\u6027 :param input_list: \u8f93\u5165\u5217\u8868\uff0c\u5305\u542b\u6240\u6709\u5bf9\u8bdd\u7684tokenize\u540e\u7684\u8f93\u5165\u5e8f\u5217 :param max_len: \u6700\u5927\u5e8f\u5217\u957f\u5ea6\uff0c\u7528\u4e8e\u5bf9\u8f93\u5165\u8fdb\u884c\u622a\u65ad\u6216\u586b\u5145 \"\"\" self . input_list = input_list # \u5c06\u8f93\u5165\u5217\u8868\u8d4b\u503c\u7ed9\u6570\u636e\u96c6\u7684input_list\u5c5e\u6027 self . max_len = max_len # \u5c06\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u8d4b\u503c\u7ed9\u6570\u636e\u96c6\u7684max_len\u5c5e\u6027 def __len__ ( self ): \"\"\" \u83b7\u53d6\u6570\u636e\u96c6\u7684\u957f\u5ea6 :return: \u6570\u636e\u96c6\u7684\u957f\u5ea6 \"\"\" return len ( self . input_list ) # \u8fd4\u56de\u6570\u636e\u96c6\u7684\u957f\u5ea6 def __getitem__ ( self , index ): \"\"\" \u6839\u636e\u7ed9\u5b9a\u7d22\u5f15\u83b7\u53d6\u6570\u636e\u96c6\u4e2d\u7684\u4e00\u4e2a\u6837\u672c :param index: \u6837\u672c\u7684\u7d22\u5f15 :return: \u6837\u672c\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf \"\"\" input_ids = self . input_list [ index ] # \u83b7\u53d6\u7ed9\u5b9a\u7d22\u5f15\u5904\u7684\u8f93\u5165\u5e8f\u5217 input_ids = input_ids [: self . max_len ] # \u6839\u636e\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u5bf9\u8f93\u5165\u8fdb\u884c\u622a\u65ad\u6216\u586b\u5145 input_ids = torch . tensor ( input_ids , dtype = torch . long ) # \u5c06\u8f93\u5165\u5e8f\u5217\u8f6c\u6362\u4e3along\u7c7b\u578b return input_ids # \u8fd4\u56de\u6837\u672c\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf","title":"2.2.1 \u5c01\u88c5DataSet\u5bf9\u8c61"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#222-dataloader","text":"\u4ee3\u7801\u8def\u5f84\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/dataloader.py # \u5bfc\u5165rnn_utils\u6a21\u5757\uff0c\u7528\u4e8e\u5904\u7406\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\u7684\u586b\u5145\u548c\u6392\u5e8f import torch.nn.utils.rnn as rnn_utils # \u5bfc\u5165Dataset\u548cDataLoader\u6a21\u5757\uff0c\u7528\u4e8e\u52a0\u8f7d\u548c\u5904\u7406\u6570\u636e\u96c6 from torch.utils.data import Dataset , DataLoader import torch # \u5bfc\u5165torch\u6a21\u5757\uff0c\u7528\u4e8e\u5904\u7406\u5f20\u91cf\u548c\u6784\u5efa\u795e\u7ecf\u7f51\u7edc import pickle # \u5bfc\u5165pickle\u6a21\u5757\uff0c\u7528\u4e8e\u5e8f\u5217\u5316\u548c\u53cd\u5e8f\u5217\u5316Python\u5bf9\u8c61 from dataset import * # \u5bfc\u5165\u81ea\u5b9a\u4e49\u7684\u6570\u636e\u96c6\u7c7b def load_dataset ( train_path ): \"\"\" \u52a0\u8f7d\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 :param train_path: \u8bad\u7ec3\u6570\u636e\u96c6\u8def\u5f84 :return: \u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6 \"\"\" with open ( train_path , \"rb\" ) as f : input_list = pickle . load ( f ) # \u4ece\u6587\u4ef6\u4e2d\u52a0\u8f7d\u8f93\u5165\u5217\u8868 # \u5212\u5206\u8bad\u7ec3\u96c6\u4e0e\u9a8c\u8bc1\u96c6 print ( len ( input_list )) # \u6253\u5370\u8f93\u5165\u5217\u8868\u7684\u957f\u5ea6 input_list_train = input_list [ 200 :] # \u5c06\u8f93\u5165\u5217\u8868\u5212\u5206\u4e3a\u8bad\u7ec3\u96c6\u90e8\u5206 input_list_val = input_list [: 200 ] # \u5c06\u8f93\u5165\u5217\u8868\u5212\u5206\u4e3a\u9a8c\u8bc1\u96c6\u90e8\u5206 train_dataset = MyDataset ( input_list_train , 200 ) # \u521b\u5efa\u8bad\u7ec3\u6570\u636e\u96c6\u5bf9\u8c61 val_dataset = MyDataset ( input_list_val , 200 ) # \u521b\u5efa\u9a8c\u8bc1\u6570\u636e\u96c6\u5bf9\u8c61 return train_dataset , val_dataset # \u8fd4\u56de\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6 def collate_fn ( batch ): \"\"\" \u81ea\u5b9a\u4e49\u7684collate_fn\u51fd\u6570\uff0c\u7528\u4e8e\u5c06\u6570\u636e\u96c6\u4e2d\u7684\u6837\u672c\u8fdb\u884c\u6279\u5904\u7406 :param batch: \u6837\u672c\u5217\u8868 :return: \u7ecf\u8fc7\u586b\u5145\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf\u548c\u6807\u7b7e\u5e8f\u5217\u5f20\u91cf \"\"\" # \u5bf9\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5176\u957f\u5ea6\u4e00\u81f4 input_ids = rnn_utils . pad_sequence ( batch , batch_first = True , padding_value = 0 ) # \u5bf9\u6807\u7b7e\u5e8f\u5217\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5176\u957f\u5ea6\u4e00\u81f4 labels = rnn_utils . pad_sequence ( batch , batch_first = True , padding_value =- 100 ) return input_ids , labels # \u8fd4\u56de\u7ecf\u8fc7\u586b\u5145\u7684\u8f93\u5165\u5e8f\u5217\u5f20\u91cf\u548c\u6807\u7b7e\u5e8f\u5217\u5f20\u91cf def get_dataloader ( train_path ): \"\"\" \u83b7\u53d6\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 :param train_path: \u8bad\u7ec3\u6570\u636e\u96c6\u8def\u5f84 :return: \u8bad\u7ec3\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61\u548c\u9a8c\u8bc1\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 \"\"\" # \u52a0\u8f7d\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u9a8c\u8bc1\u6570\u636e\u96c6 train_dataset , val_dataset = load_dataset ( train_path ) # \u521b\u5efa\u8bad\u7ec3\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 train_dataloader = DataLoader ( train_dataset , batch_size = 4 , shuffle = True , collate_fn = collate_fn , drop_last = True ) # \u521b\u5efa\u9a8c\u8bc1\u6570\u636e\u96c6\u7684DataLoader\u5bf9\u8c61 validate_dataloader = DataLoader ( val_dataset , batch_size = 4 , shuffle = True , collate_fn = collate_fn , drop_last = True ) return train_dataloader , validate_dataloader","title":"2.2.2 \u5c01\u88c5DataLoader\u5bf9\u8c61"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#3","text":"","title":"3. \u6a21\u578b\u642d\u5efa"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#31","text":"\u6a21\u578b\u67b6\u6784\u89e3\u6790\uff1a \u8f93\u5165\u5c42\uff1a\u8bcd\u5d4c\u5165\u5c42\uff1aWordEmbedding +\u4f4d\u7f6e\u5d4c\u5165\u5c42\uff1aPositionEmbedding \u4e2d\u95f4\u5c42\uff1aTransformer\u7684Decoder\u6a21\u5757---12\u5c42 \u8f93\u51fa\u5c42\uff1aLayerNorm\u5c42+\u7ebf\u6027\u5168\u8fde\u63a5\u5c42 \u6a21\u578b\u4e3b\u8981\u53c2\u6570\u7b80\u4ecb(\u8be6\u89c1\u6a21\u578b\u7684config.json\u6587\u4ef6): n_embd: 768 n_head: 12 n_layer: 12 n_positions: 1024 vocab_size: 21128","title":"3.1 \u6a21\u578b\u67b6\u6784\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#32-gpt2","text":"\u672c\u6b21\u9879\u76ee\u4f7f\u7528GPT2\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u989d\u5916\u642d\u5efaModel\u7c7b\uff0c\u4e0b\u9762\u4ee3\u7801\u662f\u5982\u4f55\u76f4\u63a5\u52a0\u8f7d\u4f7f\u7528GPT2\u9884\u8bad\u7ec3\u6a21\u578b \u4ee3\u7801\u793a\u4f8b: from transformers import GPT2LMHeadModel , GPT2Config # \u521b\u5efa\u6a21\u578b if params . pretrained_model : # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b model = GPT2LMHeadModel . from_pretrained ( params . pretrained_model ) else : # \u521d\u59cb\u5316\u6a21\u578b model_config = GPT2Config . from_json_file ( params . config_json ) model = GPT2LMHeadModel ( config = model_config )","title":"3.2 GPT2\u6a21\u578b\u51c6\u5907"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#4","text":"\u4e3b\u8981\u4ee3\u7801 \u4ee3\u7801\u8def\u5f84 \u8bad\u7ec3\u4e3b\u51fd\u6570\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/train.py \u8f85\u52a9\u5de5\u5177\u7c7b\uff1a/home/user/ProjectStudy/Gpt2_Chatbot/data_preprocess/functions_tools.py trian.py\u4ee3\u7801\u89e3\u6790 import torch import os from datetime import datetime import transformers from transformers import GPT2LMHeadModel , GPT2Config from transformers import BertTokenizerFast from functions_tools import * from parameter_config import * from data_preprocess.dataloader import * from pytorch_tools import EarlyStopping def train_epoch ( model , train_dataloader , optimizer , scheduler , epoch , args ): model . train () device = args . device # \u5bf9\u4e8eignore_index\u7684label token\u4e0d\u8ba1\u7b97\u68af\u5ea6 ignore_index = args . ignore_index epoch_start_time = datetime . now () total_loss = 0 # \u8bb0\u5f55\u4e0b\u6574\u4e2aepoch\u7684loss\u7684\u603b\u548c # epoch_correct_num:\u6bcf\u4e2aepoch\u4e2d,output\u9884\u6d4b\u6b63\u786e\u7684word\u7684\u6570\u91cf # epoch_total_num: \u6bcf\u4e2aepoch\u4e2d,output\u9884\u6d4b\u7684word\u7684\u603b\u6570\u91cf epoch_correct_num , epoch_total_num = 0 , 0 for batch_idx , ( input_ids , labels ) in enumerate ( train_dataloader ): input_ids = input_ids . to ( device ) labels = labels . to ( device ) outputs = model . forward ( input_ids , labels = labels ) logits = outputs . logits loss = outputs . loss loss = loss . mean () # \u7edf\u8ba1\u8be5batch\u7684\u9884\u6d4btoken\u7684\u6b63\u786e\u6570\u4e0e\u603b\u6570 batch_correct_num , batch_total_num = calculate_acc ( logits , labels , ignore_index = ignore_index ) # \u7edf\u8ba1\u8be5epoch\u7684\u9884\u6d4btoken\u7684\u6b63\u786e\u6570\u4e0e\u603b\u6570 epoch_correct_num += batch_correct_num epoch_total_num += batch_total_num # \u8ba1\u7b97\u8be5batch\u7684accuracy batch_acc = batch_correct_num / batch_total_num total_loss += loss . item () if args . gradient_accumulation_steps > 1 : loss = loss / args . gradient_accumulation_steps loss . backward () # \u68af\u5ea6\u88c1\u526a # \u907f\u514d\u68af\u5ea6\u7206\u70b8\u7684\u65b9\u5f0f\u3002 torch . nn . utils . clip_grad_norm_ ( model . parameters (), args . max_grad_norm ) # \u8fdb\u884c\u4e00\u5b9astep\u7684\u68af\u5ea6\u7d2f\u8ba1\u4e4b\u540e\uff0c\u66f4\u65b0\u53c2\u6570 if ( batch_idx + 1 ) % args . gradient_accumulation_steps == 0 : # \u66f4\u65b0\u53c2\u6570 optimizer . step () # \u66f4\u65b0\u5b66\u4e60\u7387 scheduler . step () # \u6e05\u7a7a\u68af\u5ea6\u4fe1\u606f optimizer . zero_grad () if ( batch_idx + 1 ) % args . loss_step == 0 : print ( \"batch {} of epoch {} , loss {} , batch_acc {} , lr {} \" . format ( batch_idx + 1 , epoch + 1 , loss . item () * args . gradient_accumulation_steps , batch_acc , scheduler . get_lr ())) del input_ids , outputs # \u8bb0\u5f55\u5f53\u524depoch\u7684\u5e73\u5747loss\u4e0eaccuracy epoch_mean_loss = total_loss / len ( train_dataloader ) epoch_mean_acc = epoch_correct_num / epoch_total_num print ( \"epoch {} : loss {} , predict_acc {} \" . format ( epoch + 1 , epoch_mean_loss , epoch_mean_acc )) # save model if epoch % 10 == 0 or epoch == args . epochs : print ( 'saving model for epoch {} ' . format ( epoch + 1 )) model_path = os . path . join ( args . save_model_path , 'bj_epoch {} ' . format ( epoch + 1 )) if not os . path . exists ( model_path ): os . mkdir ( model_path ) model . save_pretrained ( model_path ) print ( 'epoch {} finished' . format ( epoch + 1 )) epoch_finish_time = datetime . now () print ( 'time for one epoch: {} ' . format ( epoch_finish_time - epoch_start_time )) return epoch_mean_loss def validate_epoch ( model , validate_dataloader , epoch , args ): print ( \"start validating\" ) model . eval () device = args . device ignore_index = args . ignore_index epoch_start_time = datetime . now () total_loss = 0 # \u6355\u83b7cuda out of memory exception with torch . no_grad (): for batch_idx , ( input_ids , labels ) in enumerate ( validate_dataloader ): input_ids = input_ids . to ( device ) labels = labels . to ( device ) outputs = model . forward ( input_ids , labels = labels ) logits = outputs . logits loss = outputs . loss loss = loss . mean () total_loss += loss . item () del input_ids , outputs # \u8bb0\u5f55\u5f53\u524depoch\u7684\u5e73\u5747loss epoch_mean_loss = total_loss / len ( validate_dataloader ) print ( \"validate epoch {} : loss {} \" . format ( epoch + 1 , epoch_mean_loss )) epoch_finish_time = datetime . now () print ( 'time for validating one epoch: {} ' . format ( epoch_finish_time - epoch_start_time )) return epoch_mean_loss def train ( model , train_dataloader , validate_dataloader , args ): # early_stopping = EarlyStopping(patience=0, verbose=True) t_total = len ( train_dataloader ) // args . gradient_accumulation_steps * args . epochs optimizer = transformers . AdamW ( model . parameters (), lr = args . lr , eps = args . eps ) ''' \u8fd9\u91cc\u5bf9\u4e8e\u6a21\u578b\u7684\u53c2\u6570\uff0c\u5206\u522b\u5c31\u884c\u6743\u91cd\u53c2\u6570\u7684\u8870\u51cf\u4f18\u5316\uff1a\u9632\u6b62\u8fc7\u62df\u5408\uff0c\u4ee5\u53ca\u5b66\u4e60\u7387\u9884\u70ed\u5904\u7406\u4f18\u5316\uff1a \u5728\u521d\u59cb\u9636\u6bb5\u5c06\u5b66\u4e60\u7387\u4ece\u8f83\u5c0f\u7684\u503c\u9010\u6b65\u589e\u52a0\u5230\u8bbe\u5b9a\u7684\u521d\u59cb\u503c\uff0c\u7136\u540e\u6309\u7167\u8bbe\u5b9a\u7684\u5b66\u4e60\u7387\u8c03\u6574\u7b56\u7565\u8fdb\u884c\u8bad\u7ec3\u3002 \u5b66\u4e60\u7387\u9884\u70ed\u7684\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u5728\u521d\u59cb\u9636\u6bb5\u66f4\u5feb\u5730\u9002\u5e94\u6570\u636e\uff0c\u907f\u514d\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u56e0\u4e3a\u5b66\u4e60\u7387\u8fc7\u5927\u5bfc\u81f4\u7684\u68af\u5ea6\u7206\u70b8\u7b49\u95ee\u9898\uff0c \u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u548c\u6cdb\u5316\u6027\u80fd\u3002 optimizer\uff1a \u4f18\u5316\u5668 num_warmup_steps\uff1a\u521d\u59cb\u9884\u70ed\u6b65\u6570 num_training_steps\uff1a\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u7684\u603b\u6b65\u6570 ''' scheduler = transformers . get_linear_schedule_with_warmup ( optimizer , num_warmup_steps = args . warmup_steps , num_training_steps = t_total ) print ( 'starting training' ) # \u7528\u4e8e\u8bb0\u5f55\u6bcf\u4e2aepoch\u8bad\u7ec3\u548c\u9a8c\u8bc1\u7684loss train_losses , validate_losses = [], [] # \u8bb0\u5f55\u9a8c\u8bc1\u96c6\u7684\u6700\u5c0floss best_val_loss = 10000 # \u5f00\u59cb\u8bad\u7ec3 for epoch in range ( args . epochs ): # ========== train ========== # train_loss = train_epoch ( model = model , train_dataloader = train_dataloader , optimizer = optimizer , scheduler = scheduler , epoch = epoch , args = args ) train_losses . append ( train_loss ) # ========== validate ========== # validate_loss = validate_epoch ( model = model , validate_dataloader = validate_dataloader , epoch = epoch , args = args ) validate_losses . append ( validate_loss ) # \u4fdd\u5b58\u5f53\u524d\u56f0\u60d1\u5ea6\u6700\u4f4e\u7684\u6a21\u578b\uff0c\u56f0\u60d1\u5ea6\u4f4e\uff0c\u6a21\u578b\u7684\u751f\u6210\u6548\u679c\u4e0d\u4e00\u5b9a\u4f1a\u8d8a\u597d if validate_loss < best_val_loss : best_val_loss = validate_loss print ( 'saving current best model for epoch {} ' . format ( epoch + 1 )) model_path = os . path . join ( args . save_model_path , 'min_ppl_model_bj' . format ( epoch + 1 )) if not os . path . exists ( model_path ): os . mkdir ( model_path ) model . save_pretrained ( model_path ) def main (): # \u521d\u59cb\u5316\u914d\u7f6e\u53c2\u6570 params = ParameterConfig () # \u8bbe\u7f6e\u4f7f\u7528\u54ea\u4e9b\u663e\u5361\u8fdb\u884c\u8bad\u7ec3:\u9ed8\u8ba4\u4e3a0 os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = '0' # \u521d\u59cb\u5316tokenizer tokenizer = BertTokenizerFast ( params . vocab_path , sep_token = \"[SEP]\" , pad_token = \"[PAD]\" , cls_token = \"[CLS]\" ) # \u521b\u5efa\u6a21\u578b\u7684\u8f93\u51fa\u76ee\u5f55 if not os . path . exists ( params . save_model_path ): os . mkdir ( params . save_model_path ) # \u521b\u5efa\u6a21\u578b if params . pretrained_model : # \u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b model = GPT2LMHeadModel . from_pretrained ( params . pretrained_model ) else : # \u521d\u59cb\u5316\u6a21\u578b model_config = GPT2Config . from_json_file ( params . config_json ) model = GPT2LMHeadModel ( config = model_config ) model = model . to ( params . device ) assert model . config . vocab_size == tokenizer . vocab_size # \u8ba1\u7b97\u6a21\u578b\u53c2\u6570\u6570\u91cf num_parameters = 0 parameters = model . parameters () for parameter in parameters : num_parameters += parameter . numel () print ( f '\u6a21\u578b\u53c2\u6570\u603b\u91cf---\u300b { num_parameters } ' ) # \u52a0\u8f7d\u8bad\u7ec3\u96c6\u548c\u9a8c\u8bc1\u96c6 # ========= Loading Dataset ========= # train_dataloader , validate_dataloader = get_dataloader ( params . train_path ) train ( model , train_dataloader , validate_dataloader , params ) if __name__ == '__main__' : main () functions_tools.py\u4ee3\u7801\u89e3\u6790 import torch import torch.nn.functional as F def calculate_acc ( logit , labels , ignore_index =- 100 ): logit = logit [:, : - 1 , :] . contiguous () . view ( - 1 , logit . size ( - 1 )) labels = labels [:, 1 :] . contiguous () . view ( - 1 ) _ , logit = logit . max ( dim =- 1 ) # \u5bf9\u4e8e\u6bcf\u6761\u6570\u636e\uff0c\u8fd4\u56de\u6700\u5927\u7684index ''' \u5728 PyTorch \u4e2d\uff0clabels.ne(ignore_index) \u8868\u793a\u5c06\u6807\u7b7e\u5f20\u91cf labels \u4e2d\u7684\u503c\u4e0d\u7b49\u4e8e ignore_index \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a True\uff0c\u7b49\u4e8e ignore_index \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a False\u3002 \u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u88ab\u7528\u4e8e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4ee5\u8fc7\u6ee4\u6389 ignore_index \u5bf9\u635f\u5931\u7684\u8d21\u732e ''' # \u8fdb\u884c\u975e\u8fd0\u7b97\uff0c\u8fd4\u56de\u4e00\u4e2atensor\uff0c\u82e5labels\u7684\u7b2ci\u4e2a\u4f4d\u7f6e\u4e3apad_id\uff0c\u5219\u7f6e\u4e3a0\uff0c\u5426\u5219\u4e3a1 non_pad_mask = labels . ne ( ignore_index ) ''' \u5728 PyTorch \u4e2d\uff0c logit.eq(labels) \u8868\u793a\u5c06\u6a21\u578b\u7684\u9884\u6d4b\u8f93\u51fa\u503c logit \u4e2d\u7b49\u4e8e\u6807\u7b7e\u5f20\u91cf labels \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a True\uff0c\u4e0d\u7b49\u4e8e\u6807\u7b7e\u5f20\u91cf labels \u7684\u4f4d\u7f6e\u6807\u8bb0\u4e3a False\u3002\u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u88ab\u7528\u4e8e\u8ba1\u7b97\u4ea4\u53c9\u71b5\u635f\u5931\uff0c\u4ee5\u6807\u8bb0\u51fa\u9884\u6d4b\u8f93\u51fa\u503c\u548c\u6807\u7b7e\u503c\u76f8\u7b49\u7684\u4f4d\u7f6e\u3002 masked_select(non_pad_mask) \u8868\u793a\u5c06\u5f20\u91cf\u4e2d\u975e\u586b\u5145\u6807\u8bb0\u7684\u4f4d\u7f6e\u9009\u51fa\u6765\u3002\u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u88ab\u7528\u4e8e\u8ba1\u7b97\u635f\u5931\u65f6\uff0c\u8fc7\u6ee4\u6389\u586b\u5145\u6807\u8bb0\u5bf9\u635f\u5931\u7684\u5f71\u54cd\u3002 ''' n_correct = logit . eq ( labels ) . masked_select ( non_pad_mask ) . sum () . item () n_word = non_pad_mask . sum () . item () return n_correct , n_word","title":"4. \u6a21\u578b\u8bad\u7ec3\u548c\u9a8c\u8bc1"},{"location":"%E7%AC%AC%E4%BA%94%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8EGPT2%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA/01-%E5%8C%BB%E7%96%97%E9%97%AE%E8%AF%8A%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AE%9E%E7%8E%B0.html#5","text":"\u8fd0\u884cinteract.py\uff0c\u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6a21\u578b\uff0c\u8fdb\u884c\u4eba\u673a\u4ea4\u4e92\uff0c\u8f93\u5165Ctrl+Z\u7ed3\u675f\u5bf9\u8bdd\u4e4b\u540e\uff0c\u804a\u5929\u8bb0\u5f55\u5c06\u4fdd\u5b58\u5230sample\u76ee\u5f55\u4e0b\u7684sample.txt\u6587\u4ef6\u4e2d\u3002 import os from datetime import datetime from transformers import GPT2LMHeadModel from transformers import BertTokenizerFast import torch.nn.functional as F from parameter_config import * PAD = '[PAD]' pad_id = 0 def top_k_top_p_filtering ( logits , top_k = 0 , top_p = 0.0 , filter_value =- float ( 'Inf' )): \"\"\"\u4f7f\u7528top-k\u548c/\u6216nucleus\uff08top-p\uff09\u7b5b\u9009\u6765\u8fc7\u6ee4logits\u7684\u5206\u5e03 \u53c2\u6570: logits: logits\u7684\u5206\u5e03\uff0c\u5f62\u72b6\u4e3a\uff08\u8bcd\u6c47\u5927\u5c0f\uff09 top_k > 0: \u4fdd\u7559\u6982\u7387\u6700\u9ad8\u7684top k\u4e2a\u6807\u8bb0\uff08top-k\u7b5b\u9009\uff09\u3002 top_p > 0.0: \u4fdd\u7559\u7d2f\u79ef\u6982\u7387\u5927\u4e8e\u7b49\u4e8etop_p\u7684top\u6807\u8bb0\uff08nucleus\u7b5b\u9009\uff09\u3002 \"\"\" assert logits . dim () == 1 # batch size 1 for now - could be updated for more but the code would be less clear top_k = min ( top_k , logits . size ( - 1 )) # Safety check print ( f 'top_k----> { top_k } ' ) if top_k > 0 : # Remove all tokens with a probability less than the last token of the top-k # torch.topk()\u8fd4\u56de\u6700\u540e\u4e00\u7ef4\u6700\u5927\u7684top_k\u4e2a\u5143\u7d20\uff0c\u8fd4\u56de\u503c\u4e3a\u4e8c\u7ef4(values,indices) # ...\u8868\u793a\u5176\u4ed6\u7ef4\u5ea6\u7531\u8ba1\u7b97\u673a\u81ea\u884c\u63a8\u65ad print ( f 'torch.topk(logits, top_k)--> { torch . topk ( logits , top_k ) } ' ) indices_to_remove = logits < torch . topk ( logits , top_k )[ 0 ][ ... , - 1 , None ] logits [ indices_to_remove ] = filter_value # \u5bf9\u4e8etopk\u4e4b\u5916\u7684\u5176\u4ed6\u5143\u7d20\u7684logits\u503c\u8bbe\u4e3a\u8d1f\u65e0\u7a77 if top_p > 0.0 : sorted_logits , sorted_indices = torch . sort ( logits , descending = True ) # \u5bf9logits\u8fdb\u884c\u9012\u51cf\u6392\u5e8f print ( f 'sorted_logits--> { sorted_logits } ' ) print ( f 'sorted_indices--> { sorted_indices } ' ) cumulative_probs = torch . cumsum ( F . softmax ( sorted_logits , dim =- 1 ), dim =- 1 ) # Remove tokens with cumulative probability above the threshold sorted_indices_to_remove = cumulative_probs > top_p # Shift the indices to the right to keep also the first token above the threshold sorted_indices_to_remove [ ... , 1 :] = sorted_indices_to_remove [ ... , : - 1 ] . clone () sorted_indices_to_remove [ ... , 0 ] = 0 indices_to_remove = sorted_indices [ sorted_indices_to_remove ] logits [ indices_to_remove ] = filter_value return logits def main (): pconf = ParameterConfig () # \u5f53\u7528\u6237\u4f7f\u7528GPU,\u5e76\u4e14GPU\u53ef\u7528\u65f6 device = 'cuda' if torch . cuda . is_available () else 'cpu' print ( 'using device: {} ' . format ( device )) os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = '0' tokenizer = BertTokenizerFast ( vocab_file = pconf . vocab_path , sep_token = \"[SEP]\" , pad_token = \"[PAD]\" , cls_token = \"[CLS]\" ) model = GPT2LMHeadModel . from_pretrained ( './save_model/epoch25' ) model = model . to ( device ) model . eval () # \u4fdd\u5b58\u804a\u5929\u8bb0\u5f55\u7684\u6587\u4ef6\u8def\u5f84 if pconf . save_samples_path : if not os . path . exists ( pconf . save_samples_path ): os . makedirs ( pconf . save_samples_path ) samples_file = open ( pconf . save_samples_path + '/samples.txt' , 'a' , encoding = 'utf8' ) samples_file . write ( \"\u804a\u5929\u8bb0\u5f55 {} : \\n \" . format ( datetime . now ())) # \u5b58\u50a8\u804a\u5929\u8bb0\u5f55\uff0c\u6bcf\u4e2autterance\u4ee5token\u7684id\u7684\u5f62\u5f0f\u8fdb\u884c\u5b58\u50a8 history = [] print ( '\u5f00\u59cb\u548cchatbot\u804a\u5929\uff0c\u8f93\u5165CTRL + Z\u4ee5\u9000\u51fa' ) while True : try : text = input ( \"user:\" ) # text = \"\u4f60\u597d\" if pconf . save_samples_path : samples_file . write ( \"user: {} \\n \" . format ( text )) text_ids = tokenizer . encode ( text , add_special_tokens = False ) print ( f 'text_ids--> { text_ids } ' ) print ( '*' * 80 ) history . append ( text_ids ) input_ids = [ tokenizer . cls_token_id ] # \u6bcf\u4e2ainput\u4ee5[CLS]\u4e3a\u5f00\u5934 print ( f 'history---. { history } ' ) print ( f 'input_ids---. { input_ids } ' ) print ( '*' * 80 ) print ( f 'history[-pconf.max_history_len:]--> { history [ - pconf . max_history_len :] } ' ) for history_id , history_utr in enumerate ( history [ - pconf . max_history_len :]): input_ids . extend ( history_utr ) print ( input_ids ) input_ids . append ( tokenizer . sep_token_id ) print ( input_ids ) print ( '*' * 80 ) print ( f 'new_inut---> { input_ids } ' ) input_ids = torch . tensor ( input_ids ) . long () . to ( device ) input_ids = input_ids . unsqueeze ( 0 ) print ( f 'las--inputs_ids { input_ids } ' ) response = [] # \u6839\u636econtext\uff0c\u751f\u6210\u7684response # \u6700\u591a\u751f\u6210max_len\u4e2atoken for _ in range ( pconf . max_len ): outputs = model ( input_ids = input_ids ) logits = outputs . logits print ( f 'logits---> { logits } ' ) print ( f 'logits---> { logits . shape } ' ) print ( '*' * 80 ) next_token_logits = logits [ 0 , - 1 , :] # \u5bf9\u4e8e\u5df2\u751f\u6210\u7684\u7ed3\u679cgenerated\u4e2d\u7684\u6bcf\u4e2atoken\u6dfb\u52a0\u4e00\u4e2a\u91cd\u590d\u60e9\u7f5a\u9879\uff0c\u964d\u4f4e\u5176\u751f\u6210\u6982\u7387 print ( f 'next_token_logits--> { next_token_logits } ' ) for id in set ( response ): print ( f 'id---> { id } ' ) next_token_logits [ id ] /= pconf . repetition_penalty # \u5bf9\u4e8e[UNK]\u7684\u6982\u7387\u8bbe\u4e3a\u65e0\u7a77\u5c0f\uff0c\u4e5f\u5c31\u662f\u8bf4\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u4e0d\u53ef\u80fd\u662f[UNK]\u8fd9\u4e2atoken next_token_logits [ tokenizer . convert_tokens_to_ids ( '[UNK]' )] = - float ( 'Inf' ) filtered_logits = top_k_top_p_filtering ( next_token_logits , top_k = pconf . topk , top_p = pconf . topp ) print ( f 'filtered_logits--> { filtered_logits } ' ) # torch.multinomial\u8868\u793a\u4ece\u5019\u9009\u96c6\u5408\u4e2d\u65e0\u653e\u56de\u5730\u8fdb\u884c\u62bd\u53d6num_samples\u4e2a\u5143\u7d20\uff0c\u6743\u91cd\u8d8a\u9ad8\uff0c\u62bd\u5230\u7684\u51e0\u7387\u8d8a\u9ad8\uff0c\u8fd4\u56de\u5143\u7d20\u7684\u4e0b\u6807 next_token = torch . multinomial ( F . softmax ( filtered_logits , dim =- 1 ), num_samples = 1 ) print ( f 'next_token--> { next_token } ' ) if next_token == tokenizer . sep_token_id : # \u9047\u5230[SEP]\u5219\u8868\u660eresponse\u751f\u6210\u7ed3\u675f break response . append ( next_token . item ()) input_ids = torch . cat (( input_ids , next_token . unsqueeze ( 0 )), dim = 1 ) # his_text = tokenizer.convert_ids_to_tokens(curr_input_tensor.tolist()) # print(\"his_text:{}\".format(his_text)) print ( f 'response--> { response } ' ) history . append ( response ) text = tokenizer . convert_ids_to_tokens ( response ) print ( \"chatbot:\" + \"\" . join ( text )) if pconf . save_samples_path : samples_file . write ( \"chatbot: {} \\n \" . format ( \"\" . join ( text ))) except KeyboardInterrupt : if pconf . save_samples_path : samples_file . close () break if __name__ == '__main__' : main ()","title":"5. \u6a21\u578b\u9884\u6d4b\uff08\u4eba\u673a\u4ea4\u4e92\uff09"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html","text":"LangChain\u7684\u4ecb\u7ecd\u548c\u5165\u95e8 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u4ec0\u4e48\u662fLangChain \u660e\u786eLangChain\u4e3b\u8981\u7ec4\u4ef6\u7684\u4f5c\u7528 \u4e86\u89e3LangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f 1 \u4ec0\u4e48\u662fLangChain \u00b6 LangChain\u7531 Harrison Chase \u521b\u5efa\u4e8e2022\u5e7410\u6708\uff0c\u5b83\u662f\u56f4\u7ed5LLMs\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5efa\u7acb\u7684\u4e00\u4e2a\u6846\u67b6\uff0cLLMs\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u6d77\u91cf\u6570\u636e\u6765\u5206\u6790\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0cGPT3.5\u3001GPT4\u662fLLMs\u6700\u5148\u8fdb\u7684\u4ee3\u8868\uff0c\u56fd\u5185\u767e\u5ea6\u7684\u6587\u5fc3\u4e00\u8a00\u3001\u963f\u91cc\u7684\u901a\u4e49\u5343\u95ee\u4e5f\u5c5e\u4e8eLLMs\u3002LangChain\u81ea\u8eab\u5e76\u4e0d\u5f00\u53d1LLMs\uff0c\u5b83\u7684\u6838\u5fc3\u7406\u5ff5\u662f\u4e3a\u5404\u79cdLLMs\u5b9e\u73b0\u901a\u7528\u7684\u63a5\u53e3\uff0c\u628aLLMs\u76f8\u5173\u7684\u7ec4\u4ef6\u201c\u94fe\u63a5\u201d\u5728\u4e00\u8d77\uff0c\u7b80\u5316LLMs\u5e94\u7528\u7684\u5f00\u53d1\u96be\u5ea6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u5feb\u901f\u5730\u5f00\u53d1\u590d\u6742\u7684LLMs\u5e94\u7528\u3002LangChain\u76ee\u524d\u6709\u4e24\u4e2a\u8bed\u8a00\u7684\u5b9e\u73b0\uff1apython\u3002 \u672c\u7ae0\u8282\u5c06\u4f1a\u4ece\u4e24\u4e2a\u65b9\u9762\u5168\u9762\u4ecb\u7ecdLangChain\uff1a\u4e00\u4e2a\u662fLangChain\u7ec4\u4ef6\u7684\u57fa\u672c\u6982\u5ff5\u548c\u5e94\u7528\uff1b\u53e6\u4e00\u4e2a\u662fLangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f\u3002 2 LangChain\u4e3b\u8981\u7ec4\u4ef6 \u00b6 \u4e00\u4e2aLangChain\u7684\u5e94\u7528\u662f\u9700\u8981\u591a\u4e2a\u7ec4\u4ef6\u5171\u540c\u5b9e\u73b0\u7684\uff0cLangChain\u4e3b\u8981\u652f\u63016\u79cd\u7ec4\u4ef6\uff1a Models\uff1a\u6a21\u578b\uff0c\u5404\u79cd\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6a21\u578b\u96c6\u6210\uff0c\u6bd4\u5982GPT-4 Prompts\uff1a\u63d0\u793a\uff0c\u5305\u62ec\u63d0\u793a\u7ba1\u7406\u3001\u63d0\u793a\u4f18\u5316\u548c\u63d0\u793a\u5e8f\u5217\u5316 Memory\uff1a\u8bb0\u5fc6\uff0c\u7528\u6765\u4fdd\u5b58\u548c\u6a21\u578b\u4ea4\u4e92\u65f6\u7684\u4e0a\u4e0b\u6587\u72b6\u6001 Indexes\uff1a\u7d22\u5f15\uff0c\u7528\u6765\u7ed3\u6784\u5316\u6587\u6863\uff0c\u4ee5\u4fbf\u548c\u6a21\u578b\u4ea4\u4e92 Chains\uff1a\u94fe\uff0c\u4e00\u7cfb\u5217\u5bf9\u5404\u79cd\u7ec4\u4ef6\u7684\u8c03\u7528 Agents\uff1a\u4ee3\u7406\uff0c\u51b3\u5b9a\u6a21\u578b\u91c7\u53d6\u54ea\u4e9b\u884c\u52a8\uff0c\u6267\u884c\u5e76\u4e14\u89c2\u5bdf\u6d41\u7a0b\uff0c\u76f4\u5230\u5b8c\u6210\u4e3a\u6b62 2.1 Models \u00b6 \u73b0\u5728\u5e02\u9762\u4e0a\u7684\u6a21\u578b\u591a\u5982\u725b\u6bdb\uff0c\u5404\u79cd\u5404\u6837\u7684\u6a21\u578b\u4e0d\u65ad\u51fa\u73b0\uff0cLangChain\u6a21\u578b\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u4e0e\u5404\u79cd\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u4e3a\u6240\u6709\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u7cbe\u7b80\u7684\u7edf\u4e00\u63a5\u53e3\u3002 LangChain\u76ee\u524d\u652f\u6301\u4e09\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff1aLLMs\u3001Chat Models(\u804a\u5929\u6a21\u578b)\u3001Embeddings Models(\u5d4c\u5165\u6a21\u578b\uff09. LLMs: \u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u6587\u672c\u5b57\u7b26\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u6587\u672c\u5b57\u7b26. \u804a\u5929\u6a21\u578b: \u57fa\u4e8eLLMs, \u4e0d\u540c\u7684\u662f\u5b83\u63a5\u6536\u804a\u5929\u6d88(\u4e00\u79cd\u7279\u5b9a\u683c\u5f0f\u7684\u6570\u636e)\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u804a\u5929\u6d88\u606f. \u6587\u672c\u5d4c\u5165\u6a21\u578b: \u6587\u672c\u5d4c\u5165\u6a21\u578b\u63a5\u6536\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u8fd4\u56de\u7684\u662f\u6d6e\u70b9\u6570\u5217\u8868. LangChain\u652f\u6301\u7684\u4e09\u7c7b\u6a21\u578b\uff0c\u5b83\u4eec\u7684\u4f7f\u7528\u573a\u666f\u4e0d\u540c\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u4e0d\u540c\uff0c\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9879\u76ee\u9700\u8981\u9009\u62e9\u76f8\u5e94\u3002 2.1.1 LLMs (\u5927\u8bed\u8a00\u6a21\u578b) \u00b6 LLMs\u4f7f\u7528\u573a\u666f\u6700\u591a\uff0c\u5e38\u7528\u5927\u6a21\u578b\u7684\u4e0b\u8f7d\u5e93\uff1a https://huggingface.co/models \uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5GPT\u6a21\u578b\u4e3a\u4f8b, \u4f7f\u7528\u8be5\u7c7b\u6a21\u578b\u7684\u7ec4\u4ef6\uff1a \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1alangchain\u548copenai pip install openai = =0.28 pip install langchain \u6ce8\u610f\uff0c\u5728\u4f7f\u7528openai\u6a21\u578b\u4e4b\u524d\uff0c\u5fc5\u987b\u5f00\u901aOpenAI API\u670d\u52a1\uff0c\u9700\u8981\u83b7\u5f97API Token\u3002 \u7b2c\u4e8c\u6b65\uff1a\u7533\u8bf7API Token \u7b2c\u4e09\u90e8\uff1a\u4ee3\u7801\u5b9e\u73b0 # \u5bfc\u5165OpenAI\u6a21\u578b from langchain.llms import OpenAI import os os.environ[\"OPENAI_API_KEY\"] = \"\u4f60\u7684OpenAI API token\" llm = OpenAI(model_name=\"text-davinci-003\", n=2, temperature=0.3) llm(\"\u7ed9\u6211\u8bb2\u4e00\u4e2a\u7b11\u8bdd\") # \u7b54\u6848\uff1a\u4e00\u4e2a\u7334\u5b50\u53bb\u6cb3\u91cc\u6d17\u6fa1\uff0c\u6d17\u5b8c\u540e\u4ed6\u770b\u89c1\u81ea\u5df1\u7684\u5f71\u5b50\uff0c\u4ed6\u89c9\u5f97\u81ea\u5df1\u592a\u7626\u4e86\uff0c\u4e8e\u662f\u4ed6\u53c8\u628a\u5934\u653e\u8fdb\u6cb3\u91cc\u6d17\u4e86\u4e00\u904d\uff01 # \u4f7f\u7528generate\u65b9\u6cd5\u53ef\u4ee5\u540c\u65f6\u63a5\u6536\u591a\u4e2a\u8f93\u5165\uff0c\u5e76\u4e14\u8fd4\u56detoken\u4f7f\u7528\u4fe1\u606f llm.generate([\"\u7ed9\u6211\u8bb2\u4e00\u4e2a\u6545\u4e8b\", \"\u7ed9\u6211\u8bb2\u4e00\u4e2a\u7b11\u8bdd\"]) # \u7b54\u6848\uff1a# generations=[ # [Generation(text='\\n\\n\u4e00\u4e2a\u53eb\u739b\u4e3d\u7684\u5c0f\u5973\u5b69\uff0c\u6709\u4e00\u53ea\u53eb\u6bdb\u6bdb\u7684\u5c0f\u732b\u3002\\n\\n\u6bcf\u5929\u665a\u4e0a\uff0c\u739b\u4e3d\u90fd\u4f1a\u548c\u6bdb\u6bdb\u4e00\u8d77\u73a9\u800d\uff0c\u4e00\u8d77\u8df3\u821e\uff0c\u4e00\u8d77\u5531\u6b4c\uff0c\u4e00\u8d77\u73a9\u6e38\u620f\u3002\\n\\n\u6709\u4e00\u5929\uff0c\u739b\u4e3d\u548c\u6bdb\u6bdb\u4e00\u8d77\u53bb\u6d77\u8fb9\u73a9\uff0c\u7a81\u7136\uff0c\u6bdb\u6bdb\u88ab\u4e00\u53ea\u6d77\u9e25\u6293\u8d70\u4e86\u3002\u739b\u4e3d\u975e\u5e38\u4f24\u5fc3\uff0c\u5979\u8dd1\u5230\u6d77\u8fb9\u54ed\u4e86\u8d77\u6765\uff0c\u54ed\u7740\u558a\u7740\u6bdb\u6bdb\u7684', # generation_info={'finish_reason': 'length', 'logprobs': None}), # Generation(text='\\n\\n\u4e00\u4e2a\u53eb\u5c0f\u660e\u7684\u7537\u5b69\uff0c\u4ed6\u5f88\u559c\u6b22\u63a2\u9669\u3002\u6709\u4e00\u5929\uff0c\u4ed6\u548c\u4ed6\u7684\u670b\u53cb\u4eec\u4e00\u8d77\u53bb\u68ee\u6797\u91cc\u73a9\uff0c\u7a81\u7136\uff0c\u4ed6\u53d1\u73b0\u4e00\u4e2a\u6d1e\u7a74\uff0c\u4ed6\u975e\u5e38\u597d\u5947\uff0c\u4e8e\u662f\u4ed6\u51b3\u5b9a\u53bb\u770b\u770b\u6d1e\u7a74\u91cc\u9762\u5230\u5e95\u6709\u4ec0\u4e48\u3002\\n\\n\u4ed6\u8d70\u8fdb\u6d1e\u7a74\uff0c\u91cc\u9762\u9ed1\u6697\u800c\u53c8\u6f6e\u6e7f\uff0c\u4ed6\u7ee7\u7eed\u524d\u884c\uff0c\u7a81\u7136\uff0c\u4ed6\u770b\u5230\u4e00\u53ea\u5927\u8001\u864e\uff0c\u5b83\u6b63\u5728\u5403\u4e00\u53ea\u5c0f\u5154\u5b50\u3002', # generation_info={'finish_reason': 'length', 'logprobs': None})], # [Generation(text='\\n\\n\u4e24\u4e2a\u718a\u5728\u68ee\u6797\u91cc\u8d70\uff0c\u4e00\u4e2a\u718a\u8bf4\uff1a\u201c\u563f\uff0c\u4f60\u77e5\u9053\u4e3a\u4ec0\u4e48\u6811\u6797\u91cc\u6ca1\u6709\u8def\u5417\uff1f\u201d\u53e6\u4e00\u4e2a\u718a\u56de\u7b54\uff1a\u201c\u4e0d\u77e5\u9053\uff0c\u4e3a\u4ec0\u4e48\uff1f\u201d\u7b2c\u4e00\u4e2a\u718a\u8bf4\uff1a\u201c\u56e0\u4e3a\u5b83\u4eec\u90fd\u5728\u7ed5\u6811\u6797\u8dd1\uff01\u201d', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\n\u4e24\u4e2a\u718a\u5728\u68ee\u6797\u91cc\u62d4\u841d\u535c\uff0c\u4e00\u4e2a\u718a\u62d4\u51fa\u4e00\u4e2a\u841d\u535c\uff0c\u53e6\u4e00\u4e2a\u718a\u8bf4\uff1a\u201c\u4f60\u62d4\u7684\u592a\u6162\u4e86\uff0c\u6211\u62d4\u7684\u5feb\u4e00\u70b9\uff01\u201d', # generation_info={'finish_reason': 'stop', 'logprobs': None})] 2.1.2 Chat Models (\u804a\u5929\u6a21\u578b) \u00b6 \u804a\u5929\u6d88\u606f\u5305\u542b\u4e0b\u9762\u51e0\u79cd\u7c7b\u578b\uff0c\u4f7f\u7528\u65f6\u9700\u8981\u6309\u7167\u7ea6\u5b9a\u4f20\u5165\u5408\u9002\u7684\u503c\uff1a AIMessage: \u7528\u6765\u4fdd\u5b58LLM\u7684\u54cd\u5e94\uff0c\u4ee5\u4fbf\u5728\u4e0b\u6b21\u8bf7\u6c42\u65f6\u628a\u8fd9\u4e9b\u4fe1\u606f\u4f20\u56de\u7ed9LLM. HumanMessage: \u53d1\u9001\u7ed9LLMs\u7684\u63d0\u793a\u4fe1\u606f\uff0c\u6bd4\u5982\u201c\u5b9e\u73b0\u4e00\u4e2a\u5feb\u901f\u6392\u5e8f\u65b9\u6cd5\u201d. SystemMessage: \u8bbe\u7f6eLLM\u6a21\u578b\u7684\u884c\u4e3a\u65b9\u5f0f\u548c\u76ee\u6807\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u7ed9\u51fa\u5177\u4f53\u7684\u6307\u793a\uff0c\u6bd4\u5982\u201c\u4f5c\u4e3a\u4e00\u4e2a\u4ee3\u7801\u4e13\u5bb6\u201d\uff0c\u6216\u8005\u201c\u8fd4\u56dejson\u683c\u5f0f\u201d. ChatMessage: ChatMessage\u53ef\u4ee5\u63a5\u6536\u4efb\u610f\u5f62\u5f0f\u7684\u503c\uff0c\u4f46\u662f\u5728\u5927\u591a\u6570\u65f6\u95f4\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u4e0a\u9762\u7684\u4e09\u79cd\u7c7b\u578b. LangChain\u652f\u6301\u7684\u5e38\u89c1\u804a\u5929\u6a21\u578b\u6709\uff1a \u6a21\u578b \u63cf\u8ff0 ChatOpenAI OpenAI\u804a\u5929\u6a21\u578b AzureChatOpenAI Azure\u63d0\u4f9b\u7684OpenAI\u804a\u5929\u6a21\u578b PromptLayerChatOpenAI \u57fa\u4e8eOpenAI\u7684\u63d0\u793a\u6a21\u7248\u5e73\u53f0 \u4e3e\u4f8b\u8bf4\u660e\uff1a from langchain.chat_models import ChatOpenAI from langchain.schema import ( AIMessage, HumanMessage, SystemMessage ) import os os.environ[\"OPENAI_API_KEY\"] = \"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\" chat = ChatOpenAI(temperature=0) messages = [ SystemMessage(content = \"\u8fd4\u56dejson object\uff0c\u4e0d\u8981\u7eaf\u6587\u672c\uff0c\u6309\u7167\u6bcf\u9879\u53c2\u6570\u62c6\u5206\uff0c\u4e0d\u8981\u8bf4\u660e\u548c\u89e3\u91ca\u4fe1\u606f\"), HumanMessage(content = \"\u544a\u8bc9\u6211model Y\u6c7d\u8f66\u7684\u5c3a\u5bf8\u53c2\u6570\") ] print(chat(messages)) # \u7b54\u6848\uff1a# content='{\\n \"\u8f66\u957f\": \"4,750 mm\",\\n \"\u8f66\u5bbd\": \"1,921 mm\",\\n \"\u8f66\u9ad8\": \"1,624 mm\",\\n \"\u8f74\u8ddd\": \"2,890 mm\",\\n \"\u6700\u5c0f\u79bb\u5730\u95f4\u9699\": \"162 mm\",\\n \"\u884c\u674e\u7bb1\u5bb9\u79ef\": \"1,900 L\"\\n}' additional_kwargs={} example=False 2.1.3 \u63d0\u793a\u6a21\u677f \u00b6 \u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c\u6a21\u578b\u9ed8\u8ba4\u662f\u8fd4\u56de\u7eaf\u6587\u672c\u7ed3\u679c\u7684\uff0c\u5982\u679c\u9700\u8981\u8fd4\u56dejson\u683c\u5f0f\uff0c\u9700\u8981\u4e0d\u65ad\u4f18\u5316SystemMessage\u3002\u90a3\u4e48\u6709\u4ec0\u4e48\u7b80\u5355\u7684\u65b9\u5f0f\u5feb\u901f\u8ba9\u6a21\u578b\u8fd4\u56de\u60f3\u8981\u7684\u6570\u636e\u5462\uff1f\u5c31\u662f\u63d0\u793a\u6a21\u7248\u3002 \u63d0\u793a\u6a21\u677f\u5c31\u662f\u628a\u4e00\u4e9b\u5e38\u89c1\u7684\u63d0\u793a\u6574\u7406\u6210\u6a21\u677f\uff0c\u7528\u6237\u53ea\u9700\u8981\u4fee\u6539\u6a21\u677f\u4e2d\u7279\u5b9a\u7684\u8bcd\u8bed\uff0c\u5c31\u80fd\u5feb\u901f\u51c6\u786e\u5730\u544a\u8bc9\u6a21\u578b\u81ea\u5df1\u7684\u9700\u6c42\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a \u7b2c\u4e00\u6b65\uff1a\u5bfc\u5165\u4f9d\u8d56 from langchain.chat_models import ChatOpenAI from langchain.prompts import ( ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate, ) from langchain.schema import ( AIMessage, HumanMessage, SystemMessage ) \u7b2c\u4e8c\u6b65\uff1a\u5b9e\u73b0\u63d0\u793a\u6a21\u677f\uff1a system_template = \"\u4f60\u662f\u4e00\u4e2a\u628a {input_language} \u7ffb\u8bd1\u6210 {output_language} \u7684\u52a9\u624b\" system_message_prompt = SystemMessagePromptTemplate . from_template ( system_template ) human_template = \" {text} \" human_message_prompt = HumanMessagePromptTemplate . from_template ( human_template ) chat_prompt = ChatPromptTemplate . from_messages ([ system_message_prompt , human_message_prompt ]) messages = chat_prompt . format_prompt ( input_language = \"\u82f1\u8bed\" , output_language = \"\u6c49\u8bed\" , text = \"I love programming.\" ) print ( messages ) #messages=[SystemMessage(content='\u4f60\u662f\u4e00\u4e2a\u628a\u82f1\u8bed\u7ffb\u8bd1\u6210\u6c49\u8bed\u7684\u52a9\u624b', additional_kwargs={}), HumanMessage(content='I love programming.', additional_kwargs={}, example=False)] chat = ChatOpenAI ( temperature = 0 ) print ( chat ( messages . to_messages ())) # content='\u6211\u559c\u6b22\u7f16\u7a0b\u3002' additional_kwargs={} example=False 2.1.4 Embeddings Models(\u5d4c\u5165\u6a21\u578b) \u00b6 Embeddings Models\u7279\u70b9\uff1a\u5c06\u5b57\u7b26\u4e32\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u4e00\u4e2a\u6d6e\u52a8\u6570\u7684\u5217\u8868\u3002\u5728NLP\u4e2d\uff0cEmbedding\u7684\u4f5c\u7528\u5c31\u662f\u5c06\u6570\u636e\u8fdb\u884c\u6587\u672c\u5411\u91cf\u5316\u3002 Embeddings Models\u53ef\u4ee5\u4e3a\u6587\u672c\u521b\u5efa\u5411\u91cf\u6620\u5c04\uff0c\u8fd9\u6837\u5c31\u80fd\u5728\u5411\u91cf\u7a7a\u95f4\u91cc\u53bb\u8003\u8651\u6587\u672c\uff0c\u6267\u884c\u8bf8\u5982\u8bed\u4e49\u641c\u7d22\u4e4b\u7c7b\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982\u8bf4\u5bfb\u627e\u76f8\u4f3c\u7684\u6587\u672c\u7247\u6bb5\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u4e00\u4e2aOpenAI\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u4f8b\u5b50\u8fdb\u884c\u8bf4\u660e\uff1a from langchain.embeddings import OpenAIEmbeddings open_embed = OpenAIEmbeddings () text = \"\u8fd9\u662f\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863\u3002\" query_result = open_embed . embed_query ( text ) doc_result = open_embed . embed_documents ([ text ]) print ( query_result ) # [-0.009422866627573967, 0.004315766040235758, 0.002380653750151396, ...] \u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5206\u522b\u4f7f\u7528\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u8fdb\u884c\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\uff0c\u4ed6\u4eec\u6700\u5927\u4e0d\u540c\u5728\u4e8e\uff1aembed_query()\u63a5\u6536\u4e00\u4e2a\u5b57\u7b26\u4e32\u7684\u8f93\u5165\uff0c\u800cembed_documents\u53ef\u4ee5\u63a5\u6536\u4e00\u7ec4\u5b57\u7b26\u4e32\u3002 LangChain\u96c6\u6210\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u6709\uff1a AzureOpenAI\u3001Cohere\u3001Hugging Face Hub\u3001OpenAI\u3001Llama-cpp\u3001SentenceTransformers 2.2 Prompts \u00b6 Prompt\u662f\u6307\u5f53\u7528\u6237\u8f93\u5165\u4fe1\u606f\u7ed9\u6a21\u578b\u65f6\u52a0\u5165\u7684\u63d0\u793a\uff0c\u8fd9\u4e2a\u63d0\u793a\u7684\u5f62\u5f0f\u53ef\u4ee5\u662fzero-shot\u6216\u8005few-shot\u7b49\u65b9\u5f0f\uff0c\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u7406\u89e3\u66f4\u4e3a\u590d\u6742\u7684\u4e1a\u52a1\u573a\u666f\u4ee5\u4fbf\u66f4\u597d\u7684\u89e3\u51b3\u95ee\u9898\u3002 \u63d0\u793a\u6a21\u677f\uff1a\u5982\u679c\u4f60\u6709\u4e86\u4e00\u4e2a\u8d77\u4f5c\u7528\u7684\u63d0\u793a\uff0c\u4f60\u53ef\u80fd\u60f3\u628a\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u6a21\u677f\u7528\u4e8e\u89e3\u51b3\u5176\u4ed6\u95ee\u9898\uff0cLangChain\u5c31\u63d0\u4f9b\u4e86PromptTemplates\u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u4f60\u66f4\u65b9\u4fbf\u7684\u6784\u5efa\u63d0\u793a\u3002 zero-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate from langchain.llms import OpenAI template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) prompt_text = prompt . format ( lastname = \"\u738b\" ) # result: \u6211\u7684\u90bb\u5c45\u59d3\u738b\uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57 # \u8c03\u7528OpenAI llm = OpenAI ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u53eb\u738b\u7231\u6155\u3002 few-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate , FewShotPromptTemplate from langchain.llms import OpenAI examples = [ { \"word\" : \"\u5f00\u5fc3\" , \"antonym\" : \"\u96be\u8fc7\" }, { \"word\" : \"\u9ad8\" , \"antonym\" : \"\u77ee\" }, ] example_template = \"\"\" \u5355\u8bcd: {word} \u53cd\u4e49\u8bcd: {antonym} \\\\ n \"\"\" example_prompt = PromptTemplate ( input_variables = [ \"word\" , \"antonym\" ], template = example_template , ) few_shot_prompt = FewShotPromptTemplate ( examples = examples , example_prompt = example_prompt , prefix = \"\u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd\" , suffix = \"\u5355\u8bcd: {input} \\\\ n\u53cd\u4e49\u8bcd:\" , input_variables = [ \"input\" ], example_separator = \" \\\\ n\" , ) prompt_text = few_shot_prompt . format ( input = \"\u7c97\" ) print ( prompt_text ) # \u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd # \u5355\u8bcd: \u5f00\u5fc3 # \u53cd\u4e49\u8bcd: \u96be\u8fc7 # \u5355\u8bcd: \u9ad8 # \u53cd\u4e49\u8bcd: \u77ee # \u5355\u8bcd: \u7c97 # \u53cd\u4e49\u8bcd: # \u8c03\u7528OpenAI llm = OpenAI ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u7ec6 2.3 Chains(\u94fe) \u00b6 \u5728LangChain\u4e2d\uff0cChains\u63cf\u8ff0\u4e86\u5c06LLM\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7ed3\u5408\u8d77\u6765\u5b8c\u6210\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u8fc7\u7a0b. \u9488\u5bf9\u4e0a\u4e00\u5c0f\u8282\u7684\u63d0\u793a\u6a21\u7248\u4f8b\u5b50\uff0czero-shot\u91cc\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u94fe\u6765\u8fde\u63a5\u63d0\u793a\u6a21\u7248\u7ec4\u4ef6\u548c\u6a21\u578b\uff0c\u8fdb\u800c\u53ef\u4ee5\u5b9e\u73b0\u4ee3\u7801\u7684\u66f4\u6539\uff1a from langchain import PromptTemplate from langchain.llms import OpenAI from langchain.chains import LLMChain # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = OpenAI ( temperature = 0.9 ) chain = LLMChain ( llm = llm , prompt = prompt ) # \u6267\u884c\u94fe print ( chain . run ( \"\u738b\" )) # \u53ef\u4ee5\u53eb\u738b\u5b50\uff0c\u4e5f\u53ef\u4ee5\u53eb\u5c0f\u738b\u6216\u8005\u5c0f\u738b\u5b50\u7b49\u3002\u3002 \u5982\u679c\u4f60\u60f3\u5c06\u7b2c\u4e00\u4e2a\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff0c\u76f4\u63a5\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u6a21\u578b\u7684\u8f93\u5165\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528LangChain\u7684SimpleSequentialChain, \u4ee3\u7801\u5982\u4e0b\uff1a from langchain import PromptTemplate from langchain.llms import OpenAI from langchain.chains import LLMChain , SimpleSequentialChain # \u521b\u5efa\u7b2c\u4e00\u6761\u94fe template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" first_prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = OpenAI ( temperature = 0.9 ) first_chain = LLMChain ( llm = llm , prompt = first_prompt ) # \u521b\u5efa\u7b2c\u4e8c\u6761\u94fe second_prompt = PromptTemplate ( input_variables = [ \"child_name\" ], template = \"\u90bb\u5c45\u7684\u513f\u5b50\u540d\u5b57\u53eb {child_name} \uff0c\u7ed9\u4ed6\u8d77\u4e00\u4e2a\u5c0f\u540d\" , ) second_chain = LLMChain ( llm = llm , prompt = second_prompt ) # \u94fe\u63a5\u4e24\u6761\u94fe overall_chain = SimpleSequentialChain ( chains = [ first_chain , second_chain ], verbose = True ) # \u6267\u884c\u94fe\uff0c\u53ea\u9700\u8981\u4f20\u5165\u7b2c\u4e00\u4e2a\u53c2\u6570 catchphrase = overall_chain . run ( \"\u738b\" ) 2.4 Agents (\u4ee3\u7406) \u00b6 \u5728 LangChain \u4e2d Agents \u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e\u7528\u6237\u7684\u9700\u6c42\uff0c\u6765\u8bbf\u95ee\u4e00\u4e9b\u7b2c\u4e09\u65b9\u5de5\u5177(\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u6216\u8005\u6570\u636e\u5e93)\uff0c\u8fdb\u800c\u6765\u89e3\u51b3\u76f8\u5173\u9700\u6c42\u95ee\u9898\u3002 \u4e3a\u4ec0\u4e48\u8981\u501f\u52a9\u7b2c\u4e09\u65b9\u5e93\uff1f \u56e0\u4e3a\u5927\u6a21\u578b\u867d\u7136\u975e\u5e38\u5f3a\u5927\uff0c\u4f46\u662f\u4e5f\u5177\u5907\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u6bd4\u5982\u4e0d\u80fd\u56de\u7b54\u5b9e\u65f6\u4fe1\u606f\u3001\u5904\u7406\u6570\u5b66\u903b\u8f91\u95ee\u9898\u4ecd\u7136\u975e\u5e38\u7684\u521d\u7ea7\u7b49\u7b49\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u501f\u52a9\u7b2c\u4e09\u65b9\u5de5\u5177\u6765\u8f85\u52a9\u5927\u6a21\u578b\u7684\u5e94\u7528\u3002 \u51e0\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a \u4ee3\u7406\uff1a \u8d1f\u8d23\u63a7\u5236\u6574\u6bb5\u4ee3\u7801\u7684\u903b\u8f91\u548c\u6267\u884c\uff0c\u4ee3\u7406\u66b4\u9732\u4e86\u4e00\u4e2a\u63a5\u53e3\uff0c\u7528\u6765\u63a5\u6536\u7528\u6237\u8f93\u5165\uff0c\u5e76\u8fd4\u56deAgentAction\u6216AgentFinish\u3002 AgentAction\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177 AgentFinish\u610f\u5473\u7740\u4ee3\u7406\u7684\u5de5\u4f5c\u5b8c\u6210\u4e86\uff0c\u8fd4\u56de\u7ed9\u7528\u6237\u7ed3\u679c\u3002 \u5de5\u5177\uff1a \u7b2c\u4e09\u65b9\u670d\u52a1\u7684\u96c6\u6210\uff0c\u6bd4\u5982\u8c37\u6b4c\u3001bing\u7b49\u7b49 \u5de5\u5177\u5305\uff1a \u4e00\u4e9b\u96c6\u6210\u597d\u4e86\u4ee3\u7406\u5305\uff0c\u6bd4\u5982 create_csv_agent \u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u89e3\u8bfbcsv\u6587\u4ef6\u3002 \u6a21\u578b\u89e3\u51b3csv\u6587\u4ef6\u793a\u4f8b\uff1a from langchain.agents import create_csv_agent from langchain.llms import OpenAI agent = create_csv_agent ( OpenAI ( temperature = 0 ), 'data.csv' , verbose = True ) agent . run ( \"\u4e00\u5171\u6709\u591a\u5c11\u884c\u6570\u636e?\" ) \u4ee3\u7406\u6267\u884c\u5668: \u8d1f\u8d23\u8fed\u4ee3\u8fd0\u884c\u4ee3\u7406\u7684\u5faa\u73af\uff0c\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u7684\u6807\u51c6\u3002 \u73b0\u5728\u6211\u4eec\u5b9e\u73b0\u4e00\u4e2a\u4f7f\u7528\u4ee3\u7406\u7684\u4f8b\u5b50\uff1a\u5047\u5982\u6211\u4eec\u5728\u5317\u4eac\uff0c\u60f3\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u544a\u8bc9\u6211\u4eec\u660e\u5929\u7a7f\u4ec0\u4e48\u8863\u670d\uff0c\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u77e5\u9053\u660e\u5929\u7684\u5929\u6c14\uff0c\u6211\u4eec\u501f\u52a9\u4e8e serpapi \u6765\u67e5\u8be2\u5929\u6c14\uff0c\u5e76\u4f20\u9012\u7ed9\u6a21\u578b\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a from langchain.agents import load_tools from langchain.agents import initialize_agent from langchain.agents import AgentType from langchain.llms import OpenAI llm = OpenAI ( temperature = 0 ) tools = load_tools ([ \"serpapi\" ], llm = llm ) agent = initialize_agent ( tools , llm , agent = AgentType . ZERO_SHOT_REACT_DESCRIPTION , verbose = True ) agent . run ( \"\u660e\u5929\u5728\u5317\u4eac\u7a7f\u4ec0\u4e48\u8863\u670d\u5408\u9002?\" ) \u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd0\u884c\u8fd9\u4e2a\u793a\u4f8b\u9700\u8981\u7533\u8bf7 serpapi token\uff0c\u5e76\u4e14\u8bbe\u7f6e\u5230\u73af\u5883\u53d8\u91cf SERPAPI_API_KEY \uff0c\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\u5305 google-search-results LangChain\u652f\u6301\u7684\u5de5\u5177\u5982\u4e0b\uff1a \u5de5\u5177 \u63cf\u8ff0 Bing Search Bing\u641c\u7d22 Google Search Google\u641c\u7d22 Google Serper API \u4e00\u4e2a\u4ecegoogle\u641c\u7d22\u63d0\u53d6\u6570\u636e\u7684API Python REPL \u6267\u884cpython\u4ee3\u7801 Requests \u6267\u884cpython\u4ee3\u7801 2.5 Memory \u00b6 \u5927\u6a21\u578b\u672c\u8eab\u4e0d\u5177\u5907\u4e0a\u4e0b\u6587\u7684\u6982\u5ff5\uff0c\u5b83\u5e76\u4e0d\u4fdd\u5b58\u4e0a\u6b21\u4ea4\u4e92\u7684\u5185\u5bb9\uff0cChatGPT\u4e4b\u6240\u4ee5\u80fd\u591f\u548c\u4eba\u6b63\u5e38\u6c9f\u901a\u5bf9\u8bdd\uff0c\u56e0\u4e3a\u5b83\u8fdb\u884c\u4e86\u4e00\u5c42\u5c01\u88c5\uff0c\u5c06\u5386\u53f2\u8bb0\u5f55\u56de\u4f20\u7ed9\u4e86\u6a21\u578b\u3002 \u56e0\u6b64 LangChain \u4e5f\u63d0\u4f9b\u4e86Memory\u7ec4\u4ef6, Memory\u5206\u4e3a\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u671f\u8bb0\u5fc6\u548c\u957f\u671f\u8bb0\u5fc6\u3002\u77ed\u671f\u8bb0\u5fc6\u4e00\u822c\u6307\u5355\u4e00\u4f1a\u8bdd\u65f6\u4f20\u9012\u6570\u636e\uff0c\u957f\u671f\u8bb0\u5fc6\u5219\u662f\u5904\u7406\u591a\u4e2a\u4f1a\u8bdd\u65f6\u83b7\u53d6\u548c\u66f4\u65b0\u4fe1\u606f\u3002 \u76ee\u524d\u7684Memory\u7ec4\u4ef6\u53ea\u9700\u8981\u8003\u8651ChatMessageHistory\u3002\u4e3e\u4f8b\u5206\u6790\uff1a from langchain.memory import ChatMessageHistory history = ChatMessageHistory () history . add_user_message ( \"\u5728\u5417\uff1f\" ) history . add_ai_message ( \"\u6709\u4ec0\u4e48\u4e8b?\" ) print ( history . messages ) # [HumanMessage(content='\u5728\u5417\uff1f', additional_kwargs={}), AIMessage(content='\u6709\u4ec0\u4e48\u4e8b?', additional_kwargs={})] \u548cOpenAI\u7ed3\u5408\uff0c\u76f4\u63a5\u4f7f\u7528 ConversationChain \uff1a from langchain import ConversationChain from langchain.llms import OpenAI llm = OpenAI ( temperature = 0 ) conversation = ConversationChain ( llm = llm , verbose = True ) conversation . predict ( input = \"\u5c0f\u660e\u67091\u53ea\u732b\" ) conversation . predict ( input = \"\u5c0f\u521a\u67092\u53ea\u72d7\" ) conversation . predict ( input = \"\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u6709\u51e0\u53ea\u5ba0\u7269?\" ) \u5982\u679c\u8981\u50cfchatGPT\u4e00\u6837\uff0c\u957f\u671f\u4fdd\u5b58\u5386\u53f2\u6d88\u606f\uff0c\uff0c\u53ef\u4ee5\u4f7f\u7528 messages_to_dict \u65b9\u6cd5 from langchain.memory import ChatMessageHistory from langchain.schema import messages_from_dict , messages_to_dict history = ChatMessageHistory () history . add_user_message ( \"hi!\" ) history . add_ai_message ( \"whats up?\" ) dicts = messages_to_dict ( history . messages ) print ( dicts ) # [{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}}}, # {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}}}] # \u8bfb\u53d6\u5386\u53f2\u6d88\u606f new_messages = messages_from_dict ( dicts ) print ( new_messages ) #[HumanMessage(content='hi!', additional_kwargs={}), # AIMessage(content='whats up?', additional_kwargs={})] 2.6 Indexes (\u7d22\u5f15) \u00b6 Indexes\u7ec4\u4ef6\u7684\u76ee\u7684\u662f\u8ba9LangChain\u5177\u5907\u5904\u7406\u6587\u6863\u5904\u7406\u7684\u80fd\u529b\uff0c\u5305\u62ec\uff1a\u6587\u6863\u52a0\u8f7d\u3001\u68c0\u7d22\u7b49\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u7684\u6587\u6863\u4e0d\u5c40\u9650\u4e8etxt\u3001pdf\u7b49\u6587\u672c\u7c7b\u5185\u5bb9\uff0c\u8fd8\u6db5\u76d6email\u3001\u533a\u5757\u94fe\u3001\u89c6\u9891\u7b49\u5185\u5bb9\u3002 Indexes\u7ec4\u4ef6\u4e3b\u8981\u5305\u542b\u7c7b\u578b\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u6587\u672c\u5206\u5272\u5668 VectorStores \u68c0\u7d22\u5668 2.6.1 \u6587\u6863\u52a0\u8f7d\u5668 \u00b6 \u6587\u6863\u52a0\u8f7d\u5668\u4e3b\u8981\u57fa\u4e8e Unstructured \u5305\uff0c Unstructured \u662f\u4e00\u4e2apython\u5305\uff0c\u53ef\u4ee5\u628a\u5404\u79cd\u7c7b\u578b\u7684\u6587\u4ef6\u8f6c\u6362\u6210\u6587\u672c\u3002 \u6587\u6863\u52a0\u8f7d\u5668\u4f7f\u7528\u8d77\u6765\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5f15\u5165\u76f8\u5e94\u7684loader\u5de5\u5177\uff1a from langchain.document_loaders import TextLoader loader = TextLoader ( '../state_of_the_union.txt' , encoding = 'utf8' ) documents = loader . load () LangChain\u652f\u6301\u7684\u6587\u6863\u52a0\u8f7d\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 CSV CSV\u95ee\u4ef7 JSON Files \u52a0\u8f7dJSON\u6587\u4ef6 Jupyter Notebook \u52a0\u8f7dnotebook\u6587\u4ef6 Markdown \u52a0\u8f7dmarkdown\u6587\u4ef6 Microsoft PowerPoint \u52a0\u8f7dppt\u6587\u4ef6 PDF \u52a0\u8f7dpdf\u6587\u4ef6 Images \u52a0\u8f7d\u56fe\u7247 File Directory \u52a0\u8f7d\u76ee\u5f55\u4e0b\u6240\u6709\u6587\u4ef6 HTML \u7f51\u9875 2.6.2 \u6587\u6863\u5206\u5272\u5668 \u00b6 \u7531\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u7684\u5b57\u7b26\u957f\u5ea6\u6709\u9650\u5236\uff0c\u6211\u4eec\u5728\u78b0\u5230\u5f88\u957f\u7684\u6587\u672c\u65f6\uff0c\u9700\u8981\u628a\u6587\u672c\u5206\u5272\u6210\u591a\u4e2a\u5c0f\u7684\u6587\u672c\u7247\u6bb5\u3002 \u6587\u672c\u5206\u5272\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u6309\u7167\u5b57\u7b26\u957f\u5ea6\u8fdb\u884c\u5206\u5272\uff0c\u4f46\u662f\u8fd9\u4f1a\u5e26\u6765\u5f88\u591a\u95ee\u9898\uff0c\u6bd4\u5982\u8bf4\u5982\u679c\u6587\u672c\u662f\u4e00\u6bb5\u4ee3\u7801\uff0c\u4e00\u4e2a\u51fd\u6570\u88ab\u5206\u5272\u5230\u4e24\u6bb5\u4e4b\u540e\u5c31\u6210\u4e86\u6ca1\u6709\u610f\u4e49\u7684\u5b57\u7b26\uff0c\u6240\u4ee5\u6574\u4f53\u7684\u539f\u5219\u662f\u628a\u8bed\u4e49\u76f8\u5173\u7684\u6587\u672c\u7247\u6bb5\u653e\u5728\u4e00\u8d77\u3002 LangChain\u4e2d\u6700\u57fa\u672c\u7684\u6587\u672c\u5206\u5272\u5668\u662f CharacterTextSplitter \uff0c\u5b83\u6309\u7167\u6307\u5b9a\u7684\u5206\u9694\u7b26\uff08\u9ed8\u8ba4\u201c\\n\\n\u201d\uff09\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u8003\u8651\u6587\u672c\u7247\u6bb5\u7684\u6700\u5927\u957f\u5ea6\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a from langchain.text_splitter import CharacterTextSplitter # \u521d\u59cb\u5b57\u7b26\u4e32 state_of_the_union = \"...\" text_splitter = CharacterTextSplitter ( separator = \" \\\\ n \\\\ n\" , chunk_size = 1000 , chunk_overlap = 200 , length_function = len , ) texts = text_splitter . create_documents ([ state_of_the_union ]) \u9664\u4e86CharacterTextSplitter\u5206\u5272\u5668\uff0cLangChain\u8fd8\u652f\u6301\u5176\u4ed6\u6587\u6863\u5206\u5272\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 LatexTextSplitter \u6cbf\u7740Latex\u6807\u9898\u3001\u6807\u9898\u3001\u679a\u4e3e\u7b49\u5206\u5272\u6587\u672c\u3002 MarkdownTextSplitter \u6cbf\u7740Markdown\u7684\u6807\u9898\u3001\u4ee3\u7801\u5757\u6216\u6c34\u5e73\u89c4\u5219\u6765\u5206\u5272\u6587\u672c\u3002 TokenTextSplitter \u6839\u636eopenAI\u7684token\u6570\u8fdb\u884c\u5206\u5272 PythonCodeTextSplitter \u6cbf\u7740Python\u7c7b\u548c\u65b9\u6cd5\u7684\u5b9a\u4e49\u5206\u5272\u6587\u672c\u3002 2.6.3 VectorStores \u00b6 VectorStores\u662f\u4e00\u79cd\u7279\u6b8a\u7c7b\u578b\u7684\u6570\u636e\u5e93\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u5b58\u50a8\u7531\u5d4c\u5165\u521b\u5efa\u7684\u5411\u91cf\uff0c\u63d0\u4f9b\u76f8\u4f3c\u67e5\u8be2\u7b49\u529f\u80fd\u3002\u6211\u4eec\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a Chroma \u7ec4\u4ef6\u4f5c\u4e3a\u4f8b\u5b50\uff1a from langchain.embeddings.openai import OpenAIEmbeddings from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import Chroma # pku.txt\u5185\u5bb9\uff1a<https://www.pku.edu.cn/about.html> with open ( './pku.txt' ) as f : state_of_the_union = f . read () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_text ( state_of_the_union ) embeddings = OpenAIEmbeddings () docsearch = Chroma . from_texts ( texts , embeddings ) query = \"1937\u5e74\u5317\u4eac\u5927\u5b66\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\" docs = docsearch . similarity_search ( query ) print ( docs ) LangChain\u652f\u6301\u7684VectorStore\u5982\u4e0b\uff1a VectorStore \u63cf\u8ff0 Chroma \u4e00\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u6570\u636e\u5e93 ElasticSearch ElasticSearch Milvus \u7528\u4e8e\u5b58\u50a8\u3001\u7d22\u5f15\u548c\u7ba1\u7406\u7531\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u4ea7\u751f\u7684\u5927\u91cf\u5d4c\u5165\u5411\u91cf\u7684\u6570\u636e\u5e93 Redis \u57fa\u4e8eredis\u7684\u68c0\u7d22\u5668 FAISS Facebook AI\u76f8\u4f3c\u6027\u641c\u7d22\u670d\u52a1 Pinecone \u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u529f\u80fd\u7684\u5411\u91cf\u6570\u636e\u5e93 2.6.4 \u68c0\u7d22\u5668 \u00b6 \u68c0\u7d22\u5668\u662f\u4e00\u79cd\u4fbf\u4e8e\u6a21\u578b\u67e5\u8be2\u7684\u5b58\u50a8\u6570\u636e\u7684\u65b9\u5f0f\uff0cLangChain\u7ea6\u5b9a\u68c0\u7d22\u5668\u7ec4\u4ef6\u81f3\u5c11\u6709\u4e00\u4e2a\u65b9\u6cd5 get_relevant_texts \uff0c\u8fd9\u4e2a\u65b9\u6cd5\u63a5\u6536\u67e5\u8be2\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u4e00\u7ec4\u6587\u6863\u3002 from langchain.document_loaders import TextLoader from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import FAISS from langchain.embeddings import OpenAIEmbeddings loader = TextLoader ( '../../../state_of_the_union.txt' ) documents = loader . load () text_splitter = CharacterTextSplitter ( chunk_size = 1000 , chunk_overlap = 0 ) texts = text_splitter . split_documents ( documents ) embeddings = OpenAIEmbeddings () db = FAISS . from_documents ( texts , embeddings ) retriever = db . as_retriever () docs = retriever . get_relevant_documents ( \"what did he say about ketanji brown jackson\" ) LangChain\u652f\u6301\u7684\u68c0\u7d22\u5668\u7ec4\u4ef6\u5982\u4e0b\uff1a \u68c0\u7d22\u5668 \u4ecb\u7ecd Azure Cognitive Search Retriever Amazon ACS\u68c0\u7d22\u670d\u52a1 ChatGPT Plugin Retriever ChatGPT\u68c0\u7d22\u63d2\u4ef6 Databerry Databerry\u68c0\u7d22 ElasticSearch BM25 ElasticSearch\u68c0\u7d22\u5668 Metal Metal\u68c0\u7d22\u5668 Pinecone Hybrid Search Pinecone\u68c0\u7d22\u670d\u52a1 SVM Retriever SVM\u68c0\u7d22\u5668 TF-IDF Retriever TF-IDF\u68c0\u7d22\u5668 VectorStore Retriever VectorStore\u68c0\u7d22\u5668 Vespa retriever \u4e00\u4e2a\u652f\u6301\u7ed3\u6784\u5316\u6587\u672c\u548c\u5411\u91cf\u641c\u7d22\u7684\u5e73\u53f0 Weaviate Hybrid Search \u4e00\u4e2a\u5f00\u6e90\u7684\u5411\u91cf\u641c\u7d22\u5f15\u64ce Wikipedia \u652f\u6301wikipedia\u5185\u5bb9\u68c0\u7d22 3 LangChain\u4f7f\u7528\u573a\u666f \u00b6 \u4e2a\u4eba\u52a9\u624b \u57fa\u4e8e\u6587\u6863\u7684\u95ee\u7b54\u7cfb\u7edf \u804a\u5929\u673a\u5668\u4eba Tabular\u6570\u636e\u67e5\u8be2 API\u4ea4\u4e92 \u4fe1\u606f\u63d0\u53d6 \u6587\u6863\u603b\u7ed3 4 \u672c\u7ae0\u5c0f\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u5bf9LangChain\u6846\u67b6\u57fa\u7840\u77e5\u8bc6\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u8ba9\u6211\u4eec\u5bf9LangChain\u6709\u4e86\u4e00\u4e2a\u521d\u6b65\u8ba4\u8bc6\uff0c\u4e86\u89e3\u4e86LangChain\u7684\u4f7f\u7528\u573a\u666f\u3002","title":"8.1 LangChain\u57fa\u7840\u77e5\u8bc6\u56de\u987e"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#langchain","text":"","title":"LangChain\u7684\u4ecb\u7ecd\u548c\u5165\u95e8"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#_1","text":"\u7406\u89e3\u4ec0\u4e48\u662fLangChain \u660e\u786eLangChain\u4e3b\u8981\u7ec4\u4ef6\u7684\u4f5c\u7528 \u4e86\u89e3LangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#1-langchain","text":"LangChain\u7531 Harrison Chase \u521b\u5efa\u4e8e2022\u5e7410\u6708\uff0c\u5b83\u662f\u56f4\u7ed5LLMs\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5efa\u7acb\u7684\u4e00\u4e2a\u6846\u67b6\uff0cLLMs\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u6d77\u91cf\u6570\u636e\u6765\u5206\u6790\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0cGPT3.5\u3001GPT4\u662fLLMs\u6700\u5148\u8fdb\u7684\u4ee3\u8868\uff0c\u56fd\u5185\u767e\u5ea6\u7684\u6587\u5fc3\u4e00\u8a00\u3001\u963f\u91cc\u7684\u901a\u4e49\u5343\u95ee\u4e5f\u5c5e\u4e8eLLMs\u3002LangChain\u81ea\u8eab\u5e76\u4e0d\u5f00\u53d1LLMs\uff0c\u5b83\u7684\u6838\u5fc3\u7406\u5ff5\u662f\u4e3a\u5404\u79cdLLMs\u5b9e\u73b0\u901a\u7528\u7684\u63a5\u53e3\uff0c\u628aLLMs\u76f8\u5173\u7684\u7ec4\u4ef6\u201c\u94fe\u63a5\u201d\u5728\u4e00\u8d77\uff0c\u7b80\u5316LLMs\u5e94\u7528\u7684\u5f00\u53d1\u96be\u5ea6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u5feb\u901f\u5730\u5f00\u53d1\u590d\u6742\u7684LLMs\u5e94\u7528\u3002LangChain\u76ee\u524d\u6709\u4e24\u4e2a\u8bed\u8a00\u7684\u5b9e\u73b0\uff1apython\u3002 \u672c\u7ae0\u8282\u5c06\u4f1a\u4ece\u4e24\u4e2a\u65b9\u9762\u5168\u9762\u4ecb\u7ecdLangChain\uff1a\u4e00\u4e2a\u662fLangChain\u7ec4\u4ef6\u7684\u57fa\u672c\u6982\u5ff5\u548c\u5e94\u7528\uff1b\u53e6\u4e00\u4e2a\u662fLangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f\u3002","title":"1 \u4ec0\u4e48\u662fLangChain"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#2-langchain","text":"\u4e00\u4e2aLangChain\u7684\u5e94\u7528\u662f\u9700\u8981\u591a\u4e2a\u7ec4\u4ef6\u5171\u540c\u5b9e\u73b0\u7684\uff0cLangChain\u4e3b\u8981\u652f\u63016\u79cd\u7ec4\u4ef6\uff1a Models\uff1a\u6a21\u578b\uff0c\u5404\u79cd\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6a21\u578b\u96c6\u6210\uff0c\u6bd4\u5982GPT-4 Prompts\uff1a\u63d0\u793a\uff0c\u5305\u62ec\u63d0\u793a\u7ba1\u7406\u3001\u63d0\u793a\u4f18\u5316\u548c\u63d0\u793a\u5e8f\u5217\u5316 Memory\uff1a\u8bb0\u5fc6\uff0c\u7528\u6765\u4fdd\u5b58\u548c\u6a21\u578b\u4ea4\u4e92\u65f6\u7684\u4e0a\u4e0b\u6587\u72b6\u6001 Indexes\uff1a\u7d22\u5f15\uff0c\u7528\u6765\u7ed3\u6784\u5316\u6587\u6863\uff0c\u4ee5\u4fbf\u548c\u6a21\u578b\u4ea4\u4e92 Chains\uff1a\u94fe\uff0c\u4e00\u7cfb\u5217\u5bf9\u5404\u79cd\u7ec4\u4ef6\u7684\u8c03\u7528 Agents\uff1a\u4ee3\u7406\uff0c\u51b3\u5b9a\u6a21\u578b\u91c7\u53d6\u54ea\u4e9b\u884c\u52a8\uff0c\u6267\u884c\u5e76\u4e14\u89c2\u5bdf\u6d41\u7a0b\uff0c\u76f4\u5230\u5b8c\u6210\u4e3a\u6b62","title":"2 LangChain\u4e3b\u8981\u7ec4\u4ef6"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#21-models","text":"\u73b0\u5728\u5e02\u9762\u4e0a\u7684\u6a21\u578b\u591a\u5982\u725b\u6bdb\uff0c\u5404\u79cd\u5404\u6837\u7684\u6a21\u578b\u4e0d\u65ad\u51fa\u73b0\uff0cLangChain\u6a21\u578b\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u4e0e\u5404\u79cd\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u4e3a\u6240\u6709\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u7cbe\u7b80\u7684\u7edf\u4e00\u63a5\u53e3\u3002 LangChain\u76ee\u524d\u652f\u6301\u4e09\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff1aLLMs\u3001Chat Models(\u804a\u5929\u6a21\u578b)\u3001Embeddings Models(\u5d4c\u5165\u6a21\u578b\uff09. LLMs: \u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u6587\u672c\u5b57\u7b26\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u6587\u672c\u5b57\u7b26. \u804a\u5929\u6a21\u578b: \u57fa\u4e8eLLMs, \u4e0d\u540c\u7684\u662f\u5b83\u63a5\u6536\u804a\u5929\u6d88(\u4e00\u79cd\u7279\u5b9a\u683c\u5f0f\u7684\u6570\u636e)\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u804a\u5929\u6d88\u606f. \u6587\u672c\u5d4c\u5165\u6a21\u578b: \u6587\u672c\u5d4c\u5165\u6a21\u578b\u63a5\u6536\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u8fd4\u56de\u7684\u662f\u6d6e\u70b9\u6570\u5217\u8868. LangChain\u652f\u6301\u7684\u4e09\u7c7b\u6a21\u578b\uff0c\u5b83\u4eec\u7684\u4f7f\u7528\u573a\u666f\u4e0d\u540c\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u4e0d\u540c\uff0c\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9879\u76ee\u9700\u8981\u9009\u62e9\u76f8\u5e94\u3002","title":"2.1 Models"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#211-llms","text":"LLMs\u4f7f\u7528\u573a\u666f\u6700\u591a\uff0c\u5e38\u7528\u5927\u6a21\u578b\u7684\u4e0b\u8f7d\u5e93\uff1a https://huggingface.co/models \uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5GPT\u6a21\u578b\u4e3a\u4f8b, \u4f7f\u7528\u8be5\u7c7b\u6a21\u578b\u7684\u7ec4\u4ef6\uff1a \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1alangchain\u548copenai pip install openai = =0.28 pip install langchain \u6ce8\u610f\uff0c\u5728\u4f7f\u7528openai\u6a21\u578b\u4e4b\u524d\uff0c\u5fc5\u987b\u5f00\u901aOpenAI API\u670d\u52a1\uff0c\u9700\u8981\u83b7\u5f97API Token\u3002 \u7b2c\u4e8c\u6b65\uff1a\u7533\u8bf7API Token \u7b2c\u4e09\u90e8\uff1a\u4ee3\u7801\u5b9e\u73b0 # \u5bfc\u5165OpenAI\u6a21\u578b from langchain.llms import OpenAI import os os.environ[\"OPENAI_API_KEY\"] = \"\u4f60\u7684OpenAI API token\" llm = OpenAI(model_name=\"text-davinci-003\", n=2, temperature=0.3) llm(\"\u7ed9\u6211\u8bb2\u4e00\u4e2a\u7b11\u8bdd\") # \u7b54\u6848\uff1a\u4e00\u4e2a\u7334\u5b50\u53bb\u6cb3\u91cc\u6d17\u6fa1\uff0c\u6d17\u5b8c\u540e\u4ed6\u770b\u89c1\u81ea\u5df1\u7684\u5f71\u5b50\uff0c\u4ed6\u89c9\u5f97\u81ea\u5df1\u592a\u7626\u4e86\uff0c\u4e8e\u662f\u4ed6\u53c8\u628a\u5934\u653e\u8fdb\u6cb3\u91cc\u6d17\u4e86\u4e00\u904d\uff01 # \u4f7f\u7528generate\u65b9\u6cd5\u53ef\u4ee5\u540c\u65f6\u63a5\u6536\u591a\u4e2a\u8f93\u5165\uff0c\u5e76\u4e14\u8fd4\u56detoken\u4f7f\u7528\u4fe1\u606f llm.generate([\"\u7ed9\u6211\u8bb2\u4e00\u4e2a\u6545\u4e8b\", \"\u7ed9\u6211\u8bb2\u4e00\u4e2a\u7b11\u8bdd\"]) # \u7b54\u6848\uff1a# generations=[ # [Generation(text='\\n\\n\u4e00\u4e2a\u53eb\u739b\u4e3d\u7684\u5c0f\u5973\u5b69\uff0c\u6709\u4e00\u53ea\u53eb\u6bdb\u6bdb\u7684\u5c0f\u732b\u3002\\n\\n\u6bcf\u5929\u665a\u4e0a\uff0c\u739b\u4e3d\u90fd\u4f1a\u548c\u6bdb\u6bdb\u4e00\u8d77\u73a9\u800d\uff0c\u4e00\u8d77\u8df3\u821e\uff0c\u4e00\u8d77\u5531\u6b4c\uff0c\u4e00\u8d77\u73a9\u6e38\u620f\u3002\\n\\n\u6709\u4e00\u5929\uff0c\u739b\u4e3d\u548c\u6bdb\u6bdb\u4e00\u8d77\u53bb\u6d77\u8fb9\u73a9\uff0c\u7a81\u7136\uff0c\u6bdb\u6bdb\u88ab\u4e00\u53ea\u6d77\u9e25\u6293\u8d70\u4e86\u3002\u739b\u4e3d\u975e\u5e38\u4f24\u5fc3\uff0c\u5979\u8dd1\u5230\u6d77\u8fb9\u54ed\u4e86\u8d77\u6765\uff0c\u54ed\u7740\u558a\u7740\u6bdb\u6bdb\u7684', # generation_info={'finish_reason': 'length', 'logprobs': None}), # Generation(text='\\n\\n\u4e00\u4e2a\u53eb\u5c0f\u660e\u7684\u7537\u5b69\uff0c\u4ed6\u5f88\u559c\u6b22\u63a2\u9669\u3002\u6709\u4e00\u5929\uff0c\u4ed6\u548c\u4ed6\u7684\u670b\u53cb\u4eec\u4e00\u8d77\u53bb\u68ee\u6797\u91cc\u73a9\uff0c\u7a81\u7136\uff0c\u4ed6\u53d1\u73b0\u4e00\u4e2a\u6d1e\u7a74\uff0c\u4ed6\u975e\u5e38\u597d\u5947\uff0c\u4e8e\u662f\u4ed6\u51b3\u5b9a\u53bb\u770b\u770b\u6d1e\u7a74\u91cc\u9762\u5230\u5e95\u6709\u4ec0\u4e48\u3002\\n\\n\u4ed6\u8d70\u8fdb\u6d1e\u7a74\uff0c\u91cc\u9762\u9ed1\u6697\u800c\u53c8\u6f6e\u6e7f\uff0c\u4ed6\u7ee7\u7eed\u524d\u884c\uff0c\u7a81\u7136\uff0c\u4ed6\u770b\u5230\u4e00\u53ea\u5927\u8001\u864e\uff0c\u5b83\u6b63\u5728\u5403\u4e00\u53ea\u5c0f\u5154\u5b50\u3002', # generation_info={'finish_reason': 'length', 'logprobs': None})], # [Generation(text='\\n\\n\u4e24\u4e2a\u718a\u5728\u68ee\u6797\u91cc\u8d70\uff0c\u4e00\u4e2a\u718a\u8bf4\uff1a\u201c\u563f\uff0c\u4f60\u77e5\u9053\u4e3a\u4ec0\u4e48\u6811\u6797\u91cc\u6ca1\u6709\u8def\u5417\uff1f\u201d\u53e6\u4e00\u4e2a\u718a\u56de\u7b54\uff1a\u201c\u4e0d\u77e5\u9053\uff0c\u4e3a\u4ec0\u4e48\uff1f\u201d\u7b2c\u4e00\u4e2a\u718a\u8bf4\uff1a\u201c\u56e0\u4e3a\u5b83\u4eec\u90fd\u5728\u7ed5\u6811\u6797\u8dd1\uff01\u201d', generation_info={'finish_reason': 'stop', 'logprobs': None}), Generation(text='\\n\\n\u4e24\u4e2a\u718a\u5728\u68ee\u6797\u91cc\u62d4\u841d\u535c\uff0c\u4e00\u4e2a\u718a\u62d4\u51fa\u4e00\u4e2a\u841d\u535c\uff0c\u53e6\u4e00\u4e2a\u718a\u8bf4\uff1a\u201c\u4f60\u62d4\u7684\u592a\u6162\u4e86\uff0c\u6211\u62d4\u7684\u5feb\u4e00\u70b9\uff01\u201d', # generation_info={'finish_reason': 'stop', 'logprobs': None})]","title":"2.1.1 LLMs (\u5927\u8bed\u8a00\u6a21\u578b)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#212-chat-models","text":"\u804a\u5929\u6d88\u606f\u5305\u542b\u4e0b\u9762\u51e0\u79cd\u7c7b\u578b\uff0c\u4f7f\u7528\u65f6\u9700\u8981\u6309\u7167\u7ea6\u5b9a\u4f20\u5165\u5408\u9002\u7684\u503c\uff1a AIMessage: \u7528\u6765\u4fdd\u5b58LLM\u7684\u54cd\u5e94\uff0c\u4ee5\u4fbf\u5728\u4e0b\u6b21\u8bf7\u6c42\u65f6\u628a\u8fd9\u4e9b\u4fe1\u606f\u4f20\u56de\u7ed9LLM. HumanMessage: \u53d1\u9001\u7ed9LLMs\u7684\u63d0\u793a\u4fe1\u606f\uff0c\u6bd4\u5982\u201c\u5b9e\u73b0\u4e00\u4e2a\u5feb\u901f\u6392\u5e8f\u65b9\u6cd5\u201d. SystemMessage: \u8bbe\u7f6eLLM\u6a21\u578b\u7684\u884c\u4e3a\u65b9\u5f0f\u548c\u76ee\u6807\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u7ed9\u51fa\u5177\u4f53\u7684\u6307\u793a\uff0c\u6bd4\u5982\u201c\u4f5c\u4e3a\u4e00\u4e2a\u4ee3\u7801\u4e13\u5bb6\u201d\uff0c\u6216\u8005\u201c\u8fd4\u56dejson\u683c\u5f0f\u201d. ChatMessage: ChatMessage\u53ef\u4ee5\u63a5\u6536\u4efb\u610f\u5f62\u5f0f\u7684\u503c\uff0c\u4f46\u662f\u5728\u5927\u591a\u6570\u65f6\u95f4\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u4e0a\u9762\u7684\u4e09\u79cd\u7c7b\u578b. LangChain\u652f\u6301\u7684\u5e38\u89c1\u804a\u5929\u6a21\u578b\u6709\uff1a \u6a21\u578b \u63cf\u8ff0 ChatOpenAI OpenAI\u804a\u5929\u6a21\u578b AzureChatOpenAI Azure\u63d0\u4f9b\u7684OpenAI\u804a\u5929\u6a21\u578b PromptLayerChatOpenAI \u57fa\u4e8eOpenAI\u7684\u63d0\u793a\u6a21\u7248\u5e73\u53f0 \u4e3e\u4f8b\u8bf4\u660e\uff1a from langchain.chat_models import ChatOpenAI from langchain.schema import ( AIMessage, HumanMessage, SystemMessage ) import os os.environ[\"OPENAI_API_KEY\"] = \"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\" chat = ChatOpenAI(temperature=0) messages = [ SystemMessage(content = \"\u8fd4\u56dejson object\uff0c\u4e0d\u8981\u7eaf\u6587\u672c\uff0c\u6309\u7167\u6bcf\u9879\u53c2\u6570\u62c6\u5206\uff0c\u4e0d\u8981\u8bf4\u660e\u548c\u89e3\u91ca\u4fe1\u606f\"), HumanMessage(content = \"\u544a\u8bc9\u6211model Y\u6c7d\u8f66\u7684\u5c3a\u5bf8\u53c2\u6570\") ] print(chat(messages)) # \u7b54\u6848\uff1a# content='{\\n \"\u8f66\u957f\": \"4,750 mm\",\\n \"\u8f66\u5bbd\": \"1,921 mm\",\\n \"\u8f66\u9ad8\": \"1,624 mm\",\\n \"\u8f74\u8ddd\": \"2,890 mm\",\\n \"\u6700\u5c0f\u79bb\u5730\u95f4\u9699\": \"162 mm\",\\n \"\u884c\u674e\u7bb1\u5bb9\u79ef\": \"1,900 L\"\\n}' additional_kwargs={} example=False","title":"2.1.2 Chat Models (\u804a\u5929\u6a21\u578b)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#213","text":"\u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c\u6a21\u578b\u9ed8\u8ba4\u662f\u8fd4\u56de\u7eaf\u6587\u672c\u7ed3\u679c\u7684\uff0c\u5982\u679c\u9700\u8981\u8fd4\u56dejson\u683c\u5f0f\uff0c\u9700\u8981\u4e0d\u65ad\u4f18\u5316SystemMessage\u3002\u90a3\u4e48\u6709\u4ec0\u4e48\u7b80\u5355\u7684\u65b9\u5f0f\u5feb\u901f\u8ba9\u6a21\u578b\u8fd4\u56de\u60f3\u8981\u7684\u6570\u636e\u5462\uff1f\u5c31\u662f\u63d0\u793a\u6a21\u7248\u3002 \u63d0\u793a\u6a21\u677f\u5c31\u662f\u628a\u4e00\u4e9b\u5e38\u89c1\u7684\u63d0\u793a\u6574\u7406\u6210\u6a21\u677f\uff0c\u7528\u6237\u53ea\u9700\u8981\u4fee\u6539\u6a21\u677f\u4e2d\u7279\u5b9a\u7684\u8bcd\u8bed\uff0c\u5c31\u80fd\u5feb\u901f\u51c6\u786e\u5730\u544a\u8bc9\u6a21\u578b\u81ea\u5df1\u7684\u9700\u6c42\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a \u7b2c\u4e00\u6b65\uff1a\u5bfc\u5165\u4f9d\u8d56 from langchain.chat_models import ChatOpenAI from langchain.prompts import ( ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate, ) from langchain.schema import ( AIMessage, HumanMessage, SystemMessage ) \u7b2c\u4e8c\u6b65\uff1a\u5b9e\u73b0\u63d0\u793a\u6a21\u677f\uff1a system_template = \"\u4f60\u662f\u4e00\u4e2a\u628a {input_language} \u7ffb\u8bd1\u6210 {output_language} \u7684\u52a9\u624b\" system_message_prompt = SystemMessagePromptTemplate . from_template ( system_template ) human_template = \" {text} \" human_message_prompt = HumanMessagePromptTemplate . from_template ( human_template ) chat_prompt = ChatPromptTemplate . from_messages ([ system_message_prompt , human_message_prompt ]) messages = chat_prompt . format_prompt ( input_language = \"\u82f1\u8bed\" , output_language = \"\u6c49\u8bed\" , text = \"I love programming.\" ) print ( messages ) #messages=[SystemMessage(content='\u4f60\u662f\u4e00\u4e2a\u628a\u82f1\u8bed\u7ffb\u8bd1\u6210\u6c49\u8bed\u7684\u52a9\u624b', additional_kwargs={}), HumanMessage(content='I love programming.', additional_kwargs={}, example=False)] chat = ChatOpenAI ( temperature = 0 ) print ( chat ( messages . to_messages ())) # content='\u6211\u559c\u6b22\u7f16\u7a0b\u3002' additional_kwargs={} example=False","title":"2.1.3 \u63d0\u793a\u6a21\u677f"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#214-embeddings-models","text":"Embeddings Models\u7279\u70b9\uff1a\u5c06\u5b57\u7b26\u4e32\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u4e00\u4e2a\u6d6e\u52a8\u6570\u7684\u5217\u8868\u3002\u5728NLP\u4e2d\uff0cEmbedding\u7684\u4f5c\u7528\u5c31\u662f\u5c06\u6570\u636e\u8fdb\u884c\u6587\u672c\u5411\u91cf\u5316\u3002 Embeddings Models\u53ef\u4ee5\u4e3a\u6587\u672c\u521b\u5efa\u5411\u91cf\u6620\u5c04\uff0c\u8fd9\u6837\u5c31\u80fd\u5728\u5411\u91cf\u7a7a\u95f4\u91cc\u53bb\u8003\u8651\u6587\u672c\uff0c\u6267\u884c\u8bf8\u5982\u8bed\u4e49\u641c\u7d22\u4e4b\u7c7b\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982\u8bf4\u5bfb\u627e\u76f8\u4f3c\u7684\u6587\u672c\u7247\u6bb5\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u4e00\u4e2aOpenAI\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u4f8b\u5b50\u8fdb\u884c\u8bf4\u660e\uff1a from langchain.embeddings import OpenAIEmbeddings open_embed = OpenAIEmbeddings () text = \"\u8fd9\u662f\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863\u3002\" query_result = open_embed . embed_query ( text ) doc_result = open_embed . embed_documents ([ text ]) print ( query_result ) # [-0.009422866627573967, 0.004315766040235758, 0.002380653750151396, ...] \u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5206\u522b\u4f7f\u7528\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u8fdb\u884c\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\uff0c\u4ed6\u4eec\u6700\u5927\u4e0d\u540c\u5728\u4e8e\uff1aembed_query()\u63a5\u6536\u4e00\u4e2a\u5b57\u7b26\u4e32\u7684\u8f93\u5165\uff0c\u800cembed_documents\u53ef\u4ee5\u63a5\u6536\u4e00\u7ec4\u5b57\u7b26\u4e32\u3002 LangChain\u96c6\u6210\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u6709\uff1a AzureOpenAI\u3001Cohere\u3001Hugging Face Hub\u3001OpenAI\u3001Llama-cpp\u3001SentenceTransformers","title":"2.1.4 Embeddings Models(\u5d4c\u5165\u6a21\u578b)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#22-prompts","text":"Prompt\u662f\u6307\u5f53\u7528\u6237\u8f93\u5165\u4fe1\u606f\u7ed9\u6a21\u578b\u65f6\u52a0\u5165\u7684\u63d0\u793a\uff0c\u8fd9\u4e2a\u63d0\u793a\u7684\u5f62\u5f0f\u53ef\u4ee5\u662fzero-shot\u6216\u8005few-shot\u7b49\u65b9\u5f0f\uff0c\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u7406\u89e3\u66f4\u4e3a\u590d\u6742\u7684\u4e1a\u52a1\u573a\u666f\u4ee5\u4fbf\u66f4\u597d\u7684\u89e3\u51b3\u95ee\u9898\u3002 \u63d0\u793a\u6a21\u677f\uff1a\u5982\u679c\u4f60\u6709\u4e86\u4e00\u4e2a\u8d77\u4f5c\u7528\u7684\u63d0\u793a\uff0c\u4f60\u53ef\u80fd\u60f3\u628a\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u6a21\u677f\u7528\u4e8e\u89e3\u51b3\u5176\u4ed6\u95ee\u9898\uff0cLangChain\u5c31\u63d0\u4f9b\u4e86PromptTemplates\u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u4f60\u66f4\u65b9\u4fbf\u7684\u6784\u5efa\u63d0\u793a\u3002 zero-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate from langchain.llms import OpenAI template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) prompt_text = prompt . format ( lastname = \"\u738b\" ) # result: \u6211\u7684\u90bb\u5c45\u59d3\u738b\uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57 # \u8c03\u7528OpenAI llm = OpenAI ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u53eb\u738b\u7231\u6155\u3002 few-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain import PromptTemplate , FewShotPromptTemplate from langchain.llms import OpenAI examples = [ { \"word\" : \"\u5f00\u5fc3\" , \"antonym\" : \"\u96be\u8fc7\" }, { \"word\" : \"\u9ad8\" , \"antonym\" : \"\u77ee\" }, ] example_template = \"\"\" \u5355\u8bcd: {word} \u53cd\u4e49\u8bcd: {antonym} \\\\ n \"\"\" example_prompt = PromptTemplate ( input_variables = [ \"word\" , \"antonym\" ], template = example_template , ) few_shot_prompt = FewShotPromptTemplate ( examples = examples , example_prompt = example_prompt , prefix = \"\u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd\" , suffix = \"\u5355\u8bcd: {input} \\\\ n\u53cd\u4e49\u8bcd:\" , input_variables = [ \"input\" ], example_separator = \" \\\\ n\" , ) prompt_text = few_shot_prompt . format ( input = \"\u7c97\" ) print ( prompt_text ) # \u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd # \u5355\u8bcd: \u5f00\u5fc3 # \u53cd\u4e49\u8bcd: \u96be\u8fc7 # \u5355\u8bcd: \u9ad8 # \u53cd\u4e49\u8bcd: \u77ee # \u5355\u8bcd: \u7c97 # \u53cd\u4e49\u8bcd: # \u8c03\u7528OpenAI llm = OpenAI ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u7ec6","title":"2.2 Prompts"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#23-chains","text":"\u5728LangChain\u4e2d\uff0cChains\u63cf\u8ff0\u4e86\u5c06LLM\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7ed3\u5408\u8d77\u6765\u5b8c\u6210\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u8fc7\u7a0b. \u9488\u5bf9\u4e0a\u4e00\u5c0f\u8282\u7684\u63d0\u793a\u6a21\u7248\u4f8b\u5b50\uff0czero-shot\u91cc\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u94fe\u6765\u8fde\u63a5\u63d0\u793a\u6a21\u7248\u7ec4\u4ef6\u548c\u6a21\u578b\uff0c\u8fdb\u800c\u53ef\u4ee5\u5b9e\u73b0\u4ee3\u7801\u7684\u66f4\u6539\uff1a from langchain import PromptTemplate from langchain.llms import OpenAI from langchain.chains import LLMChain # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = OpenAI ( temperature = 0.9 ) chain = LLMChain ( llm = llm , prompt = prompt ) # \u6267\u884c\u94fe print ( chain . run ( \"\u738b\" )) # \u53ef\u4ee5\u53eb\u738b\u5b50\uff0c\u4e5f\u53ef\u4ee5\u53eb\u5c0f\u738b\u6216\u8005\u5c0f\u738b\u5b50\u7b49\u3002\u3002 \u5982\u679c\u4f60\u60f3\u5c06\u7b2c\u4e00\u4e2a\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff0c\u76f4\u63a5\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u6a21\u578b\u7684\u8f93\u5165\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528LangChain\u7684SimpleSequentialChain, \u4ee3\u7801\u5982\u4e0b\uff1a from langchain import PromptTemplate from langchain.llms import OpenAI from langchain.chains import LLMChain , SimpleSequentialChain # \u521b\u5efa\u7b2c\u4e00\u6761\u94fe template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" first_prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = OpenAI ( temperature = 0.9 ) first_chain = LLMChain ( llm = llm , prompt = first_prompt ) # \u521b\u5efa\u7b2c\u4e8c\u6761\u94fe second_prompt = PromptTemplate ( input_variables = [ \"child_name\" ], template = \"\u90bb\u5c45\u7684\u513f\u5b50\u540d\u5b57\u53eb {child_name} \uff0c\u7ed9\u4ed6\u8d77\u4e00\u4e2a\u5c0f\u540d\" , ) second_chain = LLMChain ( llm = llm , prompt = second_prompt ) # \u94fe\u63a5\u4e24\u6761\u94fe overall_chain = SimpleSequentialChain ( chains = [ first_chain , second_chain ], verbose = True ) # \u6267\u884c\u94fe\uff0c\u53ea\u9700\u8981\u4f20\u5165\u7b2c\u4e00\u4e2a\u53c2\u6570 catchphrase = overall_chain . run ( \"\u738b\" )","title":"2.3 Chains(\u94fe)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#24-agents","text":"\u5728 LangChain \u4e2d Agents \u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e\u7528\u6237\u7684\u9700\u6c42\uff0c\u6765\u8bbf\u95ee\u4e00\u4e9b\u7b2c\u4e09\u65b9\u5de5\u5177(\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u6216\u8005\u6570\u636e\u5e93)\uff0c\u8fdb\u800c\u6765\u89e3\u51b3\u76f8\u5173\u9700\u6c42\u95ee\u9898\u3002 \u4e3a\u4ec0\u4e48\u8981\u501f\u52a9\u7b2c\u4e09\u65b9\u5e93\uff1f \u56e0\u4e3a\u5927\u6a21\u578b\u867d\u7136\u975e\u5e38\u5f3a\u5927\uff0c\u4f46\u662f\u4e5f\u5177\u5907\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u6bd4\u5982\u4e0d\u80fd\u56de\u7b54\u5b9e\u65f6\u4fe1\u606f\u3001\u5904\u7406\u6570\u5b66\u903b\u8f91\u95ee\u9898\u4ecd\u7136\u975e\u5e38\u7684\u521d\u7ea7\u7b49\u7b49\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u501f\u52a9\u7b2c\u4e09\u65b9\u5de5\u5177\u6765\u8f85\u52a9\u5927\u6a21\u578b\u7684\u5e94\u7528\u3002 \u51e0\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a \u4ee3\u7406\uff1a \u8d1f\u8d23\u63a7\u5236\u6574\u6bb5\u4ee3\u7801\u7684\u903b\u8f91\u548c\u6267\u884c\uff0c\u4ee3\u7406\u66b4\u9732\u4e86\u4e00\u4e2a\u63a5\u53e3\uff0c\u7528\u6765\u63a5\u6536\u7528\u6237\u8f93\u5165\uff0c\u5e76\u8fd4\u56deAgentAction\u6216AgentFinish\u3002 AgentAction\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177 AgentFinish\u610f\u5473\u7740\u4ee3\u7406\u7684\u5de5\u4f5c\u5b8c\u6210\u4e86\uff0c\u8fd4\u56de\u7ed9\u7528\u6237\u7ed3\u679c\u3002 \u5de5\u5177\uff1a \u7b2c\u4e09\u65b9\u670d\u52a1\u7684\u96c6\u6210\uff0c\u6bd4\u5982\u8c37\u6b4c\u3001bing\u7b49\u7b49 \u5de5\u5177\u5305\uff1a \u4e00\u4e9b\u96c6\u6210\u597d\u4e86\u4ee3\u7406\u5305\uff0c\u6bd4\u5982 create_csv_agent \u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u89e3\u8bfbcsv\u6587\u4ef6\u3002 \u6a21\u578b\u89e3\u51b3csv\u6587\u4ef6\u793a\u4f8b\uff1a from langchain.agents import create_csv_agent from langchain.llms import OpenAI agent = create_csv_agent ( OpenAI ( temperature = 0 ), 'data.csv' , verbose = True ) agent . run ( \"\u4e00\u5171\u6709\u591a\u5c11\u884c\u6570\u636e?\" ) \u4ee3\u7406\u6267\u884c\u5668: \u8d1f\u8d23\u8fed\u4ee3\u8fd0\u884c\u4ee3\u7406\u7684\u5faa\u73af\uff0c\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u7684\u6807\u51c6\u3002 \u73b0\u5728\u6211\u4eec\u5b9e\u73b0\u4e00\u4e2a\u4f7f\u7528\u4ee3\u7406\u7684\u4f8b\u5b50\uff1a\u5047\u5982\u6211\u4eec\u5728\u5317\u4eac\uff0c\u60f3\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u544a\u8bc9\u6211\u4eec\u660e\u5929\u7a7f\u4ec0\u4e48\u8863\u670d\uff0c\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u77e5\u9053\u660e\u5929\u7684\u5929\u6c14\uff0c\u6211\u4eec\u501f\u52a9\u4e8e serpapi \u6765\u67e5\u8be2\u5929\u6c14\uff0c\u5e76\u4f20\u9012\u7ed9\u6a21\u578b\uff0c\u4ee3\u7801\u5982\u4e0b\uff1a from langchain.agents import load_tools from langchain.agents import initialize_agent from langchain.agents import AgentType from langchain.llms import OpenAI llm = OpenAI ( temperature = 0 ) tools = load_tools ([ \"serpapi\" ], llm = llm ) agent = initialize_agent ( tools , llm , agent = AgentType . ZERO_SHOT_REACT_DESCRIPTION , verbose = True ) agent . run ( \"\u660e\u5929\u5728\u5317\u4eac\u7a7f\u4ec0\u4e48\u8863\u670d\u5408\u9002?\" ) \u8981\u6ce8\u610f\u7684\u662f\uff0c\u8fd0\u884c\u8fd9\u4e2a\u793a\u4f8b\u9700\u8981\u7533\u8bf7 serpapi token\uff0c\u5e76\u4e14\u8bbe\u7f6e\u5230\u73af\u5883\u53d8\u91cf SERPAPI_API_KEY \uff0c\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\u5305 google-search-results LangChain\u652f\u6301\u7684\u5de5\u5177\u5982\u4e0b\uff1a \u5de5\u5177 \u63cf\u8ff0 Bing Search Bing\u641c\u7d22 Google Search Google\u641c\u7d22 Google Serper API \u4e00\u4e2a\u4ecegoogle\u641c\u7d22\u63d0\u53d6\u6570\u636e\u7684API Python REPL \u6267\u884cpython\u4ee3\u7801 Requests \u6267\u884cpython\u4ee3\u7801","title":"2.4 Agents (\u4ee3\u7406)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#25-memory","text":"\u5927\u6a21\u578b\u672c\u8eab\u4e0d\u5177\u5907\u4e0a\u4e0b\u6587\u7684\u6982\u5ff5\uff0c\u5b83\u5e76\u4e0d\u4fdd\u5b58\u4e0a\u6b21\u4ea4\u4e92\u7684\u5185\u5bb9\uff0cChatGPT\u4e4b\u6240\u4ee5\u80fd\u591f\u548c\u4eba\u6b63\u5e38\u6c9f\u901a\u5bf9\u8bdd\uff0c\u56e0\u4e3a\u5b83\u8fdb\u884c\u4e86\u4e00\u5c42\u5c01\u88c5\uff0c\u5c06\u5386\u53f2\u8bb0\u5f55\u56de\u4f20\u7ed9\u4e86\u6a21\u578b\u3002 \u56e0\u6b64 LangChain \u4e5f\u63d0\u4f9b\u4e86Memory\u7ec4\u4ef6, Memory\u5206\u4e3a\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u671f\u8bb0\u5fc6\u548c\u957f\u671f\u8bb0\u5fc6\u3002\u77ed\u671f\u8bb0\u5fc6\u4e00\u822c\u6307\u5355\u4e00\u4f1a\u8bdd\u65f6\u4f20\u9012\u6570\u636e\uff0c\u957f\u671f\u8bb0\u5fc6\u5219\u662f\u5904\u7406\u591a\u4e2a\u4f1a\u8bdd\u65f6\u83b7\u53d6\u548c\u66f4\u65b0\u4fe1\u606f\u3002 \u76ee\u524d\u7684Memory\u7ec4\u4ef6\u53ea\u9700\u8981\u8003\u8651ChatMessageHistory\u3002\u4e3e\u4f8b\u5206\u6790\uff1a from langchain.memory import ChatMessageHistory history = ChatMessageHistory () history . add_user_message ( \"\u5728\u5417\uff1f\" ) history . add_ai_message ( \"\u6709\u4ec0\u4e48\u4e8b?\" ) print ( history . messages ) # [HumanMessage(content='\u5728\u5417\uff1f', additional_kwargs={}), AIMessage(content='\u6709\u4ec0\u4e48\u4e8b?', additional_kwargs={})] \u548cOpenAI\u7ed3\u5408\uff0c\u76f4\u63a5\u4f7f\u7528 ConversationChain \uff1a from langchain import ConversationChain from langchain.llms import OpenAI llm = OpenAI ( temperature = 0 ) conversation = ConversationChain ( llm = llm , verbose = True ) conversation . predict ( input = \"\u5c0f\u660e\u67091\u53ea\u732b\" ) conversation . predict ( input = \"\u5c0f\u521a\u67092\u53ea\u72d7\" ) conversation . predict ( input = \"\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u6709\u51e0\u53ea\u5ba0\u7269?\" ) \u5982\u679c\u8981\u50cfchatGPT\u4e00\u6837\uff0c\u957f\u671f\u4fdd\u5b58\u5386\u53f2\u6d88\u606f\uff0c\uff0c\u53ef\u4ee5\u4f7f\u7528 messages_to_dict \u65b9\u6cd5 from langchain.memory import ChatMessageHistory from langchain.schema import messages_from_dict , messages_to_dict history = ChatMessageHistory () history . add_user_message ( \"hi!\" ) history . add_ai_message ( \"whats up?\" ) dicts = messages_to_dict ( history . messages ) print ( dicts ) # [{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}}}, # {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}}}] # \u8bfb\u53d6\u5386\u53f2\u6d88\u606f new_messages = messages_from_dict ( dicts ) print ( new_messages ) #[HumanMessage(content='hi!', additional_kwargs={}), # AIMessage(content='whats up?', additional_kwargs={})]","title":"2.5 Memory"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#26-indexes","text":"Indexes\u7ec4\u4ef6\u7684\u76ee\u7684\u662f\u8ba9LangChain\u5177\u5907\u5904\u7406\u6587\u6863\u5904\u7406\u7684\u80fd\u529b\uff0c\u5305\u62ec\uff1a\u6587\u6863\u52a0\u8f7d\u3001\u68c0\u7d22\u7b49\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u7684\u6587\u6863\u4e0d\u5c40\u9650\u4e8etxt\u3001pdf\u7b49\u6587\u672c\u7c7b\u5185\u5bb9\uff0c\u8fd8\u6db5\u76d6email\u3001\u533a\u5757\u94fe\u3001\u89c6\u9891\u7b49\u5185\u5bb9\u3002 Indexes\u7ec4\u4ef6\u4e3b\u8981\u5305\u542b\u7c7b\u578b\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u6587\u672c\u5206\u5272\u5668 VectorStores \u68c0\u7d22\u5668","title":"2.6 Indexes (\u7d22\u5f15)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#261","text":"\u6587\u6863\u52a0\u8f7d\u5668\u4e3b\u8981\u57fa\u4e8e Unstructured \u5305\uff0c Unstructured \u662f\u4e00\u4e2apython\u5305\uff0c\u53ef\u4ee5\u628a\u5404\u79cd\u7c7b\u578b\u7684\u6587\u4ef6\u8f6c\u6362\u6210\u6587\u672c\u3002 \u6587\u6863\u52a0\u8f7d\u5668\u4f7f\u7528\u8d77\u6765\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5f15\u5165\u76f8\u5e94\u7684loader\u5de5\u5177\uff1a from langchain.document_loaders import TextLoader loader = TextLoader ( '../state_of_the_union.txt' , encoding = 'utf8' ) documents = loader . load () LangChain\u652f\u6301\u7684\u6587\u6863\u52a0\u8f7d\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 CSV CSV\u95ee\u4ef7 JSON Files \u52a0\u8f7dJSON\u6587\u4ef6 Jupyter Notebook \u52a0\u8f7dnotebook\u6587\u4ef6 Markdown \u52a0\u8f7dmarkdown\u6587\u4ef6 Microsoft PowerPoint \u52a0\u8f7dppt\u6587\u4ef6 PDF \u52a0\u8f7dpdf\u6587\u4ef6 Images \u52a0\u8f7d\u56fe\u7247 File Directory \u52a0\u8f7d\u76ee\u5f55\u4e0b\u6240\u6709\u6587\u4ef6 HTML \u7f51\u9875","title":"2.6.1 \u6587\u6863\u52a0\u8f7d\u5668"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#262","text":"\u7531\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u7684\u5b57\u7b26\u957f\u5ea6\u6709\u9650\u5236\uff0c\u6211\u4eec\u5728\u78b0\u5230\u5f88\u957f\u7684\u6587\u672c\u65f6\uff0c\u9700\u8981\u628a\u6587\u672c\u5206\u5272\u6210\u591a\u4e2a\u5c0f\u7684\u6587\u672c\u7247\u6bb5\u3002 \u6587\u672c\u5206\u5272\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u6309\u7167\u5b57\u7b26\u957f\u5ea6\u8fdb\u884c\u5206\u5272\uff0c\u4f46\u662f\u8fd9\u4f1a\u5e26\u6765\u5f88\u591a\u95ee\u9898\uff0c\u6bd4\u5982\u8bf4\u5982\u679c\u6587\u672c\u662f\u4e00\u6bb5\u4ee3\u7801\uff0c\u4e00\u4e2a\u51fd\u6570\u88ab\u5206\u5272\u5230\u4e24\u6bb5\u4e4b\u540e\u5c31\u6210\u4e86\u6ca1\u6709\u610f\u4e49\u7684\u5b57\u7b26\uff0c\u6240\u4ee5\u6574\u4f53\u7684\u539f\u5219\u662f\u628a\u8bed\u4e49\u76f8\u5173\u7684\u6587\u672c\u7247\u6bb5\u653e\u5728\u4e00\u8d77\u3002 LangChain\u4e2d\u6700\u57fa\u672c\u7684\u6587\u672c\u5206\u5272\u5668\u662f CharacterTextSplitter \uff0c\u5b83\u6309\u7167\u6307\u5b9a\u7684\u5206\u9694\u7b26\uff08\u9ed8\u8ba4\u201c\\n\\n\u201d\uff09\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u8003\u8651\u6587\u672c\u7247\u6bb5\u7684\u6700\u5927\u957f\u5ea6\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a from langchain.text_splitter import CharacterTextSplitter # \u521d\u59cb\u5b57\u7b26\u4e32 state_of_the_union = \"...\" text_splitter = CharacterTextSplitter ( separator = \" \\\\ n \\\\ n\" , chunk_size = 1000 , chunk_overlap = 200 , length_function = len , ) texts = text_splitter . create_documents ([ state_of_the_union ]) \u9664\u4e86CharacterTextSplitter\u5206\u5272\u5668\uff0cLangChain\u8fd8\u652f\u6301\u5176\u4ed6\u6587\u6863\u5206\u5272\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 LatexTextSplitter \u6cbf\u7740Latex\u6807\u9898\u3001\u6807\u9898\u3001\u679a\u4e3e\u7b49\u5206\u5272\u6587\u672c\u3002 MarkdownTextSplitter \u6cbf\u7740Markdown\u7684\u6807\u9898\u3001\u4ee3\u7801\u5757\u6216\u6c34\u5e73\u89c4\u5219\u6765\u5206\u5272\u6587\u672c\u3002 TokenTextSplitter \u6839\u636eopenAI\u7684token\u6570\u8fdb\u884c\u5206\u5272 PythonCodeTextSplitter \u6cbf\u7740Python\u7c7b\u548c\u65b9\u6cd5\u7684\u5b9a\u4e49\u5206\u5272\u6587\u672c\u3002","title":"2.6.2 \u6587\u6863\u5206\u5272\u5668"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#263-vectorstores","text":"VectorStores\u662f\u4e00\u79cd\u7279\u6b8a\u7c7b\u578b\u7684\u6570\u636e\u5e93\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u5b58\u50a8\u7531\u5d4c\u5165\u521b\u5efa\u7684\u5411\u91cf\uff0c\u63d0\u4f9b\u76f8\u4f3c\u67e5\u8be2\u7b49\u529f\u80fd\u3002\u6211\u4eec\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a Chroma \u7ec4\u4ef6\u4f5c\u4e3a\u4f8b\u5b50\uff1a from langchain.embeddings.openai import OpenAIEmbeddings from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import Chroma # pku.txt\u5185\u5bb9\uff1a<https://www.pku.edu.cn/about.html> with open ( './pku.txt' ) as f : state_of_the_union = f . read () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_text ( state_of_the_union ) embeddings = OpenAIEmbeddings () docsearch = Chroma . from_texts ( texts , embeddings ) query = \"1937\u5e74\u5317\u4eac\u5927\u5b66\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\" docs = docsearch . similarity_search ( query ) print ( docs ) LangChain\u652f\u6301\u7684VectorStore\u5982\u4e0b\uff1a VectorStore \u63cf\u8ff0 Chroma \u4e00\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u6570\u636e\u5e93 ElasticSearch ElasticSearch Milvus \u7528\u4e8e\u5b58\u50a8\u3001\u7d22\u5f15\u548c\u7ba1\u7406\u7531\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u4ea7\u751f\u7684\u5927\u91cf\u5d4c\u5165\u5411\u91cf\u7684\u6570\u636e\u5e93 Redis \u57fa\u4e8eredis\u7684\u68c0\u7d22\u5668 FAISS Facebook AI\u76f8\u4f3c\u6027\u641c\u7d22\u670d\u52a1 Pinecone \u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u529f\u80fd\u7684\u5411\u91cf\u6570\u636e\u5e93","title":"2.6.3 VectorStores"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#264","text":"\u68c0\u7d22\u5668\u662f\u4e00\u79cd\u4fbf\u4e8e\u6a21\u578b\u67e5\u8be2\u7684\u5b58\u50a8\u6570\u636e\u7684\u65b9\u5f0f\uff0cLangChain\u7ea6\u5b9a\u68c0\u7d22\u5668\u7ec4\u4ef6\u81f3\u5c11\u6709\u4e00\u4e2a\u65b9\u6cd5 get_relevant_texts \uff0c\u8fd9\u4e2a\u65b9\u6cd5\u63a5\u6536\u67e5\u8be2\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u4e00\u7ec4\u6587\u6863\u3002 from langchain.document_loaders import TextLoader from langchain.text_splitter import CharacterTextSplitter from langchain.vectorstores import FAISS from langchain.embeddings import OpenAIEmbeddings loader = TextLoader ( '../../../state_of_the_union.txt' ) documents = loader . load () text_splitter = CharacterTextSplitter ( chunk_size = 1000 , chunk_overlap = 0 ) texts = text_splitter . split_documents ( documents ) embeddings = OpenAIEmbeddings () db = FAISS . from_documents ( texts , embeddings ) retriever = db . as_retriever () docs = retriever . get_relevant_documents ( \"what did he say about ketanji brown jackson\" ) LangChain\u652f\u6301\u7684\u68c0\u7d22\u5668\u7ec4\u4ef6\u5982\u4e0b\uff1a \u68c0\u7d22\u5668 \u4ecb\u7ecd Azure Cognitive Search Retriever Amazon ACS\u68c0\u7d22\u670d\u52a1 ChatGPT Plugin Retriever ChatGPT\u68c0\u7d22\u63d2\u4ef6 Databerry Databerry\u68c0\u7d22 ElasticSearch BM25 ElasticSearch\u68c0\u7d22\u5668 Metal Metal\u68c0\u7d22\u5668 Pinecone Hybrid Search Pinecone\u68c0\u7d22\u670d\u52a1 SVM Retriever SVM\u68c0\u7d22\u5668 TF-IDF Retriever TF-IDF\u68c0\u7d22\u5668 VectorStore Retriever VectorStore\u68c0\u7d22\u5668 Vespa retriever \u4e00\u4e2a\u652f\u6301\u7ed3\u6784\u5316\u6587\u672c\u548c\u5411\u91cf\u641c\u7d22\u7684\u5e73\u53f0 Weaviate Hybrid Search \u4e00\u4e2a\u5f00\u6e90\u7684\u5411\u91cf\u641c\u7d22\u5f15\u64ce Wikipedia \u652f\u6301wikipedia\u5185\u5bb9\u68c0\u7d22","title":"2.6.4 \u68c0\u7d22\u5668"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#3-langchain","text":"\u4e2a\u4eba\u52a9\u624b \u57fa\u4e8e\u6587\u6863\u7684\u95ee\u7b54\u7cfb\u7edf \u804a\u5929\u673a\u5668\u4eba Tabular\u6570\u636e\u67e5\u8be2 API\u4ea4\u4e92 \u4fe1\u606f\u63d0\u53d6 \u6587\u6863\u603b\u7ed3","title":"3 LangChain\u4f7f\u7528\u573a\u666f"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/01-LangChain%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A5%E9%97%A8.html#4","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u5bf9LangChain\u6846\u67b6\u57fa\u7840\u77e5\u8bc6\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u8ba9\u6211\u4eec\u5bf9LangChain\u6709\u4e86\u4e00\u4e2a\u521d\u6b65\u8ba4\u8bc6\uff0c\u4e86\u89e3\u4e86LangChain\u7684\u4f7f\u7528\u573a\u666f\u3002","title":"4 \u672c\u7ae0\u5c0f\u7ed3"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html","text":"\u57fa\u4e8eLangChain + ChatGLM \u642d\u5efa\u878d\u5408\u672c\u5730\u77e5\u8bc6\u7684\u95ee\u7b54\u673a\u5668\u4eba \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u9879\u76ee\u5f00\u53d1\u80cc\u666f \u638c\u63e1\u878d\u5408\u672c\u5730\u77e5\u8bc6\u7684\u95ee\u7b54\u673a\u5668\u4eba\u5b9e\u73b0\u8fc7\u7a0b 1 \u80cc\u666f\u4ecb\u7ecd \u00b6 \u8fd1\u534a\u5e74\u4ee5\u6765\uff0c\u968f\u7740ChatGPT\u7684\u706b\u7206\uff0c\u4f7f\u5f97LLM\u6210\u4e3a\u7814\u7a76\u548c\u5e94\u7528\u7684\u70ed\u70b9\uff0c\u4f46\u662f\u5e02\u9762\u4e0a\u5927\u90e8\u5206LLM\u90fd\u5b58\u5728\u4e00\u4e2a\u5171\u540c\u7684\u95ee\u9898\uff1a\u6a21\u578b\u90fd\u662f\u57fa\u4e8e\u8fc7\u53bb\u7684\u7ecf\u9a8c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u5b8c\u6210\uff0c\u65e0\u6cd5\u83b7\u53d6\u6700\u65b0\u7684\u77e5\u8bc6\uff0c\u4ee5\u53ca\u5404\u4f01\u4e1a\u79c1\u6709\u7684\u77e5\u8bc6\u3002\u56e0\u6b64\u5f88\u591a\u4f01\u4e1a\u4e3a\u4e86\u5904\u7406\u79c1\u6709\u7684\u77e5\u8bc6\uff0c\u4e3b\u8981\u501f\u52a9\u4e00\u4e0b\u4e24\u79cd\u624b\u6bb5\u6765\u5b9e\u73b0\uff1a \u5229\u7528\u4f01\u4e1a\u79c1\u6709\u77e5\u8bc6\uff0c\u57fa\u4e8e\u5f00\u6e90\u5927\u6a21\u578b\u8fdb\u884c\u5fae\u8c03 \u57fa\u4e8eLangChain\u96c6\u6210\u5411\u91cf\u6570\u636e\u5e93\u4ee5\u53caLLM\u642d\u5efa\u672c\u5730\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\uff08RAG\uff09 \u5728\u672c\u7ae0\u4e4b\u524d\u6211\u4eec\u5df2\u7ecf\u638c\u63e1\u4e86\u57fa\u4e8e\u5927\u6a21\u578b\u7684prompt\u5fae\u8c03\u65b9\u5f0f\u3002\u56e0\u6b64\uff0c\u672c\u7ae0\u8282\u6211\u4eec\u5c06\u57fa\u4e8eLangChain+ChatGLM\u642d\u5efa\u672c\u5730\u77e5\u8bc6\u7684\u95ee\u7b54\u673a\u5668\u4eba\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u9700\u8981\u80fd\u591f\u6839\u636e\u7528\u6237\u63d0\u4f9b\u7684\u95ee\u9898\uff0c\u5728\u672c\u5730\u7684\u77e5\u8bc6\u5e93\uff08\u79bb\u7ebf\uff09\u4e2d\u67e5\u627e\u5e76\u8fd4\u56de\u76f8\u5173\u7b54\u6848\u3002 \u672c\u6b21\u9879\u76ee\u4ee5\"\u67d0\u4e1c\u5546\u54c1\u8863\u670d\"\u4e3a\u4f8b\uff0c\u4ee5\u8863\u670d\u5c5e\u6027\u6784\u5efa\u672c\u5730\u77e5\u8bc6\uff0c\u6d4b\u8bd5\u95ee\u7b54\u6548\u679c\u3002\u4f7f\u7528\u8005\u53ef\u4ee5\u81ea\u7531\u66f4\u65b0\u672c\u5730\u77e5\u8bc6\uff0c\u7528\u6237\u95ee\u9898\u7684\u7b54\u6848\u4e5f\u662f\u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u751f\u6210\u7684\u3002 2 \u9879\u76ee\u4ecb\u7ecd \u00b6 \u8be5\u9879\u76ee\u7684\u57fa\u672c\u539f\u7406\uff1a \u5176\u8fc7\u7a0b\u63cf\u8ff0\uff1a \u52a0\u8f7d\u6587\u4ef6 \u8bfb\u53d6\u6587\u4ef6 \u6587\u672c\u5206\u5272 \u6587\u672c\u5411\u91cf\u5316 \u95ee\u53e5\u5411\u91cf\u5316 \u5728\u6587\u672c\u5411\u91cf\u4e2d\u5339\u914d\u51fa\u4e0e\u95ee\u53e5\u5411\u91cf\u76f8\u4f3c\u7684top_k\u4e2a \u5339\u914d\u51fa\u7684\u6587\u672c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u548c\u95ee\u9898\u4e00\u8d77\u6dfb\u52a0\u5230prompt\u4e2d \u63d0\u4ea4\u7ed9LLM\u751f\u6210\u7b54\u6848 \u8be5\u95ee\u7b54\u673a\u5668\u4eba\u7684\u4e3b\u8981\u529f\u80fd\u5305\u62ec\uff1a \u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\uff1a\u7cfb\u7edf\u53ef\u4ee5\u6839\u636e\u7528\u6237\u7684\u63d0\u95ee\uff0c\u5728\u672c\u5730\u7684\u77e5\u8bc6\u5e93\u4e2d\u8fdb\u884c\u641c\u7d22\uff0c\u5e76\u8fd4\u56de\u76f8\u5173\u7684\u7b54\u6848\u3002 \u591a\u6a21\u578b\u652f\u6301\uff1a\u9879\u76ee\u652f\u6301\u4f7f\u7528\u4e0d\u540c\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u4ee5\u6839\u636e\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u8fdb\u884c\u4f7f\u7528\u3002 \u79bb\u7ebf\u79c1\u6709\u5316\uff1a\u53ef\u4ee5\u5c06\u8be5\u95ee\u7b54\u7cfb\u7edf\u90e8\u7f72\u5728\u672c\u5730\u73af\u5883\u4e2d\uff0c\u786e\u4fdd\u6570\u636e\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\u3002 3 \u9879\u76ee\u6d41\u7a0b \u00b6 4 \u73af\u5883\u914d\u7f6e \u00b6 4.1 \u5b89\u88c5\u4f9d\u8d56 \u00b6 \u9996\u5148\uff0c\u786e\u4fdd\u4f60\u7684\u673a\u5668\u5b89\u88c5\u4e86Python3.8-Python3.11 # \u7ec8\u7aef\u67e5\u770bpython\u7684\u7248\u672c python -- version \u7d27\u63a5\u7740\u5b89\u88c5\u9879\u76ee\u7684\u4f9d\u8d56 # \u5b89\u88c5\u5168\u90e8\u4f9d\u8d56 pip install faiss - cpu pip install langchain pip install qianfan 4.2 \u6a21\u578b\u4e0b\u8f7d \u00b6 \u5982\u9700\u5728\u672c\u5730\u6216\u79bb\u7ebf\u73af\u5883\u4e0b\u8fd0\u884c\u672c\u9879\u76ee\uff0c\u9700\u8981\u9996\u5148\u5c06\u9879\u76ee\u6240\u9700\u7684\u6a21\u578b\u4e0b\u8f7d\u81f3\u672c\u5730\uff0c\u901a\u5e38\u5f00\u6e90 LLM \u4e0e Embedding \u6a21\u578b\u53ef\u4ee5\u4ece HuggingFace \u4e0b\u8f7d\u3002 \u672c\u9879\u76ee\u4e2d\u9ed8\u8ba4\u4f7f\u7528\u7684 LLM \u6a21\u578b THUDM/ChatGLM-6B \u4e0e Embedding \u6a21\u578b moka-ai/m3e-base 5 \u4ee3\u7801\u5b9e\u73b0 \u00b6 5.1 \u81ea\u5b9a\u4e49GLM\u7c7b \u00b6 \u76ee\u7684\uff1a\u4f7f\u7528LLMs\u6a21\u5757\u5c01\u88c5ChatGLM\uff0cload\u672c\u5730\u6a21\u578b\u3002\u4f7f\u7528LLM\u6a21\u5757\u5c01\u88c5\u6211\u4eec\u7684\u6a21\u578b\u63a5\u53e3\u7684\u4e00\u4e2a\u597d\u5904\u662f\u6709\u5229\u4e8e\u540e\u7eed\u8ddfLangChain\u7684\u5176\u4ed6\u6a21\u5757\u534f\u540c\u3002 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/langchain_apply/Knowledge_QA/model.py \u5177\u4f53\u4ee3\u7801 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from langchain.llms.base import LLM from langchain.llms.utils import enforce_stop_tokens from transformers import AutoTokenizer , AutoModel from typing import List , Optional \u81ea\u5b9a\u4e49GLM\u7c7b # \u81ea\u5b9a\u4e49ChatGLM2 class ChatGLM2 ( LLM ): max_token : int = 4096 temperature : float = 0.8 top_p = 0.9 tokenizer : object = None model : object = None history = [] def __init__ ( self ): super () . __init__ () @property def _llm_type ( self ) -> str : return \"ChatGLM2\" # \u5b9a\u4e49load_model\u65b9\u6cd5\uff0c\u8fdb\u884c\u6a21\u578b\u7684\u52a0\u8f7d def load_model ( self , model_path = None ): self . tokenizer = AutoTokenizer . from_pretrained ( model_path , trust_remote_code = True ) self . model = AutoModel . from_pretrained ( model_path , trust_remote_code = True ) . float () # \u5b9e\u73b0_call\u65b9\u6cd5\uff0c\u8fdb\u884c\u6a21\u578b\u7684\u63a8\u7406 def _call ( self , prompt : str , stop : Optional [ List [ str ]] = None ) -> str : response , _ = self . model . chat ( self . tokenizer , prompt , history = self . history , max_length = self . max_token , temperature = self . temperature , top_p = self . top_p ) if stop is not None : response = enforce_stop_tokens ( response , stop ) self . history = self . history + [[ None , response ]] return response 5.2 \u6784\u5efaFaiss\u7d22\u5f15 \u00b6 \u76ee\u7684\uff1a\u6784\u5efa\u5411\u91cf\u5e93 \u4ee3\u7801\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/langchain_apply/Knowledge_QA/get_vector.py \u5177\u4f53\u4ee3\u7801 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from langchain.document_loaders import UnstructuredFileLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain.embeddings.huggingface import HuggingFaceEmbeddings from langchain.vectorstores import FAISS # \u5411\u91cf\u6570\u636e\u5e93 \u5b9a\u4e49main()\u65b9\u6cd5 def main (): # \u5b9a\u4e49\u5411\u91cf\u6a21\u578b\u8def\u5f84 EMBEDDING_MODEL = \"moka-ai/m3e-base\" # \u7b2c\u4e00\u6b65\uff1a\u52a0\u8f7d\u6587\u6863 loader = UnstructuredFileLoader ( \"\u8863\u670d\u5c5e\u6027.txt\" ) # \u5c06\u6587\u672c\u8f6c\u6210 Document \u5bf9\u8c61 data = loader . load () print ( f 'documents: { len ( data ) } ' ) # \u7b2c\u4e8c\u90e8\uff1a\u5207\u5206\u6587\u672c text_splitter = RecursiveCharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) # \u5207\u5272\u52a0\u8f7d\u7684 document split_docs = text_splitter . split_documents ( data ) # print(\"split_docs size:\",len(split_docs)) # print(split_docs) # \u7b2c\u4e09\u6b65\uff1a\u521d\u59cb\u5316 hugginFace \u7684 embeddings \u5bf9\u8c61 embeddings = HuggingFaceEmbeddings ( model_name = EMBEDDING_MODEL ) # \u7b2c\u56db\u6b65\uff1a\u5c06 document\u901a\u8fc7embeddings\u5bf9\u8c61\u8ba1\u7b97\u5f97\u5230\u5411\u91cf\u4fe1\u606f\u5e76\u6c38\u4e45\u5b58\u5165FAISS\u5411\u91cf\u6570\u636e\u5e93\uff0c\u7528\u4e8e\u540e\u7eed\u5339\u914d\u67e5\u8be2 db = FAISS . from_documents ( split_docs , embeddings ) db . save_local ( \"./faiss/product\" ) return split_docs result = main () print ( result ) 5.3 \u5b9e\u73b0QA\u672c\u5730\u77e5\u8bc6\u5e93\u95ee\u7b54 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/Users/ligang/PycharmProjects/llm/langchain_apply/Knowledge_QA/main.py \u4ee3\u7801\u5b9e\u73b0 # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from langchain import PromptTemplate from get_vector import * from model import ChatGLM2 # \u52a0\u8f7dFAISS\u5411\u91cf\u5e93 EMBEDDING_MODEL = \"moka-ai/m3e-base\" embeddings = HuggingFaceEmbeddings ( model_name = EMBEDDING_MODEL ) db = FAISS . load_local ( \"faiss/product\" , embeddings ) def get_related_content ( related_docs ): related_content = [] for doc in related_docs : related_content . append ( doc . page_content . replace ( \" \\n\\n \" , \" \\n \" )) return \" \\n \" . join ( related_content ) def define_prompt (): question = '\u6211\u8eab\u9ad8170\uff0c\u4f53\u91cd140\u65a4,\u4e70\u591a\u5927\u5c3a\u7801' docs = db . similarity_search ( question , k = 1 ) related_content = get_related_content ( docs ) PROMPT_TEMPLATE = \"\"\" \u57fa\u4e8e\u4ee5\u4e0b\u5df2\u77e5\u4fe1\u606f\uff0c\u7b80\u6d01\u548c\u4e13\u4e1a\u7684\u6765\u56de\u7b54\u7528\u6237\u7684\u95ee\u9898\u3002\u4e0d\u5141\u8bb8\u5728\u7b54\u6848\u4e2d\u6dfb\u52a0\u7f16\u9020\u6210\u5206\u3002 \u5df2\u77e5\u5185\u5bb9: {context} \u95ee\u9898: {question} \"\"\" prompt = PromptTemplate ( input_variables = [ \"context\" , \"question\" ], template = PROMPT_TEMPLATE ,) my_pmt = prompt . format ( context = related_content , question = question ) return my_pmt def qa (): llm = ChatGLM2 () llm . load_model ( \"/Users/**/PycharmProjects/llm/ChatGLM-6B/THUDM/chatglm-6b\" ) my_pmt = define_prompt () result = llm ( my_pmt ) return result if __name__ == '__main__' : result = qa () print ( result ) \u7ed3\u679c\u5c55\u793a\uff1a \u672c\u8282\u5c0f\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u57fa\u4e8eLangChain+ChatGLM-6B\u6a21\u578b\u5b9e\u73b0\u672c\u5730\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\u5b9e\u73b0\u539f\u7406+\u8fc7\u7a0b\u3002","title":"8.2 LangChain+ChatGLM-6B\u5b9e\u73b0\u672c\u5730\u77e5\u8bc6\u5e93\u95ee\u7b54"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#langchain-chatglm","text":"","title":"\u57fa\u4e8eLangChain + ChatGLM \u642d\u5efa\u878d\u5408\u672c\u5730\u77e5\u8bc6\u7684\u95ee\u7b54\u673a\u5668\u4eba"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#_1","text":"\u4e86\u89e3\u9879\u76ee\u5f00\u53d1\u80cc\u666f \u638c\u63e1\u878d\u5408\u672c\u5730\u77e5\u8bc6\u7684\u95ee\u7b54\u673a\u5668\u4eba\u5b9e\u73b0\u8fc7\u7a0b","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#1","text":"\u8fd1\u534a\u5e74\u4ee5\u6765\uff0c\u968f\u7740ChatGPT\u7684\u706b\u7206\uff0c\u4f7f\u5f97LLM\u6210\u4e3a\u7814\u7a76\u548c\u5e94\u7528\u7684\u70ed\u70b9\uff0c\u4f46\u662f\u5e02\u9762\u4e0a\u5927\u90e8\u5206LLM\u90fd\u5b58\u5728\u4e00\u4e2a\u5171\u540c\u7684\u95ee\u9898\uff1a\u6a21\u578b\u90fd\u662f\u57fa\u4e8e\u8fc7\u53bb\u7684\u7ecf\u9a8c\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u5b8c\u6210\uff0c\u65e0\u6cd5\u83b7\u53d6\u6700\u65b0\u7684\u77e5\u8bc6\uff0c\u4ee5\u53ca\u5404\u4f01\u4e1a\u79c1\u6709\u7684\u77e5\u8bc6\u3002\u56e0\u6b64\u5f88\u591a\u4f01\u4e1a\u4e3a\u4e86\u5904\u7406\u79c1\u6709\u7684\u77e5\u8bc6\uff0c\u4e3b\u8981\u501f\u52a9\u4e00\u4e0b\u4e24\u79cd\u624b\u6bb5\u6765\u5b9e\u73b0\uff1a \u5229\u7528\u4f01\u4e1a\u79c1\u6709\u77e5\u8bc6\uff0c\u57fa\u4e8e\u5f00\u6e90\u5927\u6a21\u578b\u8fdb\u884c\u5fae\u8c03 \u57fa\u4e8eLangChain\u96c6\u6210\u5411\u91cf\u6570\u636e\u5e93\u4ee5\u53caLLM\u642d\u5efa\u672c\u5730\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\uff08RAG\uff09 \u5728\u672c\u7ae0\u4e4b\u524d\u6211\u4eec\u5df2\u7ecf\u638c\u63e1\u4e86\u57fa\u4e8e\u5927\u6a21\u578b\u7684prompt\u5fae\u8c03\u65b9\u5f0f\u3002\u56e0\u6b64\uff0c\u672c\u7ae0\u8282\u6211\u4eec\u5c06\u57fa\u4e8eLangChain+ChatGLM\u642d\u5efa\u672c\u5730\u77e5\u8bc6\u7684\u95ee\u7b54\u673a\u5668\u4eba\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u9700\u8981\u80fd\u591f\u6839\u636e\u7528\u6237\u63d0\u4f9b\u7684\u95ee\u9898\uff0c\u5728\u672c\u5730\u7684\u77e5\u8bc6\u5e93\uff08\u79bb\u7ebf\uff09\u4e2d\u67e5\u627e\u5e76\u8fd4\u56de\u76f8\u5173\u7b54\u6848\u3002 \u672c\u6b21\u9879\u76ee\u4ee5\"\u67d0\u4e1c\u5546\u54c1\u8863\u670d\"\u4e3a\u4f8b\uff0c\u4ee5\u8863\u670d\u5c5e\u6027\u6784\u5efa\u672c\u5730\u77e5\u8bc6\uff0c\u6d4b\u8bd5\u95ee\u7b54\u6548\u679c\u3002\u4f7f\u7528\u8005\u53ef\u4ee5\u81ea\u7531\u66f4\u65b0\u672c\u5730\u77e5\u8bc6\uff0c\u7528\u6237\u95ee\u9898\u7684\u7b54\u6848\u4e5f\u662f\u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u751f\u6210\u7684\u3002","title":"1 \u80cc\u666f\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#2","text":"\u8be5\u9879\u76ee\u7684\u57fa\u672c\u539f\u7406\uff1a \u5176\u8fc7\u7a0b\u63cf\u8ff0\uff1a \u52a0\u8f7d\u6587\u4ef6 \u8bfb\u53d6\u6587\u4ef6 \u6587\u672c\u5206\u5272 \u6587\u672c\u5411\u91cf\u5316 \u95ee\u53e5\u5411\u91cf\u5316 \u5728\u6587\u672c\u5411\u91cf\u4e2d\u5339\u914d\u51fa\u4e0e\u95ee\u53e5\u5411\u91cf\u76f8\u4f3c\u7684top_k\u4e2a \u5339\u914d\u51fa\u7684\u6587\u672c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u548c\u95ee\u9898\u4e00\u8d77\u6dfb\u52a0\u5230prompt\u4e2d \u63d0\u4ea4\u7ed9LLM\u751f\u6210\u7b54\u6848 \u8be5\u95ee\u7b54\u673a\u5668\u4eba\u7684\u4e3b\u8981\u529f\u80fd\u5305\u62ec\uff1a \u57fa\u4e8e\u672c\u5730\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\uff1a\u7cfb\u7edf\u53ef\u4ee5\u6839\u636e\u7528\u6237\u7684\u63d0\u95ee\uff0c\u5728\u672c\u5730\u7684\u77e5\u8bc6\u5e93\u4e2d\u8fdb\u884c\u641c\u7d22\uff0c\u5e76\u8fd4\u56de\u76f8\u5173\u7684\u7b54\u6848\u3002 \u591a\u6a21\u578b\u652f\u6301\uff1a\u9879\u76ee\u652f\u6301\u4f7f\u7528\u4e0d\u540c\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u4ee5\u6839\u636e\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u8fdb\u884c\u4f7f\u7528\u3002 \u79bb\u7ebf\u79c1\u6709\u5316\uff1a\u53ef\u4ee5\u5c06\u8be5\u95ee\u7b54\u7cfb\u7edf\u90e8\u7f72\u5728\u672c\u5730\u73af\u5883\u4e2d\uff0c\u786e\u4fdd\u6570\u636e\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\u3002","title":"2 \u9879\u76ee\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#3","text":"","title":"3 \u9879\u76ee\u6d41\u7a0b"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#4","text":"","title":"4 \u73af\u5883\u914d\u7f6e"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#41","text":"\u9996\u5148\uff0c\u786e\u4fdd\u4f60\u7684\u673a\u5668\u5b89\u88c5\u4e86Python3.8-Python3.11 # \u7ec8\u7aef\u67e5\u770bpython\u7684\u7248\u672c python -- version \u7d27\u63a5\u7740\u5b89\u88c5\u9879\u76ee\u7684\u4f9d\u8d56 # \u5b89\u88c5\u5168\u90e8\u4f9d\u8d56 pip install faiss - cpu pip install langchain pip install qianfan","title":"4.1 \u5b89\u88c5\u4f9d\u8d56"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#42","text":"\u5982\u9700\u5728\u672c\u5730\u6216\u79bb\u7ebf\u73af\u5883\u4e0b\u8fd0\u884c\u672c\u9879\u76ee\uff0c\u9700\u8981\u9996\u5148\u5c06\u9879\u76ee\u6240\u9700\u7684\u6a21\u578b\u4e0b\u8f7d\u81f3\u672c\u5730\uff0c\u901a\u5e38\u5f00\u6e90 LLM \u4e0e Embedding \u6a21\u578b\u53ef\u4ee5\u4ece HuggingFace \u4e0b\u8f7d\u3002 \u672c\u9879\u76ee\u4e2d\u9ed8\u8ba4\u4f7f\u7528\u7684 LLM \u6a21\u578b THUDM/ChatGLM-6B \u4e0e Embedding \u6a21\u578b moka-ai/m3e-base","title":"4.2 \u6a21\u578b\u4e0b\u8f7d"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#5","text":"","title":"5 \u4ee3\u7801\u5b9e\u73b0"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#51-glm","text":"\u76ee\u7684\uff1a\u4f7f\u7528LLMs\u6a21\u5757\u5c01\u88c5ChatGLM\uff0cload\u672c\u5730\u6a21\u578b\u3002\u4f7f\u7528LLM\u6a21\u5757\u5c01\u88c5\u6211\u4eec\u7684\u6a21\u578b\u63a5\u53e3\u7684\u4e00\u4e2a\u597d\u5904\u662f\u6709\u5229\u4e8e\u540e\u7eed\u8ddfLangChain\u7684\u5176\u4ed6\u6a21\u5757\u534f\u540c\u3002 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/langchain_apply/Knowledge_QA/model.py \u5177\u4f53\u4ee3\u7801 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from langchain.llms.base import LLM from langchain.llms.utils import enforce_stop_tokens from transformers import AutoTokenizer , AutoModel from typing import List , Optional \u81ea\u5b9a\u4e49GLM\u7c7b # \u81ea\u5b9a\u4e49ChatGLM2 class ChatGLM2 ( LLM ): max_token : int = 4096 temperature : float = 0.8 top_p = 0.9 tokenizer : object = None model : object = None history = [] def __init__ ( self ): super () . __init__ () @property def _llm_type ( self ) -> str : return \"ChatGLM2\" # \u5b9a\u4e49load_model\u65b9\u6cd5\uff0c\u8fdb\u884c\u6a21\u578b\u7684\u52a0\u8f7d def load_model ( self , model_path = None ): self . tokenizer = AutoTokenizer . from_pretrained ( model_path , trust_remote_code = True ) self . model = AutoModel . from_pretrained ( model_path , trust_remote_code = True ) . float () # \u5b9e\u73b0_call\u65b9\u6cd5\uff0c\u8fdb\u884c\u6a21\u578b\u7684\u63a8\u7406 def _call ( self , prompt : str , stop : Optional [ List [ str ]] = None ) -> str : response , _ = self . model . chat ( self . tokenizer , prompt , history = self . history , max_length = self . max_token , temperature = self . temperature , top_p = self . top_p ) if stop is not None : response = enforce_stop_tokens ( response , stop ) self . history = self . history + [[ None , response ]] return response","title":"5.1 \u81ea\u5b9a\u4e49GLM\u7c7b"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#52-faiss","text":"\u76ee\u7684\uff1a\u6784\u5efa\u5411\u91cf\u5e93 \u4ee3\u7801\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/langchain_apply/Knowledge_QA/get_vector.py \u5177\u4f53\u4ee3\u7801 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from langchain.document_loaders import UnstructuredFileLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain.embeddings.huggingface import HuggingFaceEmbeddings from langchain.vectorstores import FAISS # \u5411\u91cf\u6570\u636e\u5e93 \u5b9a\u4e49main()\u65b9\u6cd5 def main (): # \u5b9a\u4e49\u5411\u91cf\u6a21\u578b\u8def\u5f84 EMBEDDING_MODEL = \"moka-ai/m3e-base\" # \u7b2c\u4e00\u6b65\uff1a\u52a0\u8f7d\u6587\u6863 loader = UnstructuredFileLoader ( \"\u8863\u670d\u5c5e\u6027.txt\" ) # \u5c06\u6587\u672c\u8f6c\u6210 Document \u5bf9\u8c61 data = loader . load () print ( f 'documents: { len ( data ) } ' ) # \u7b2c\u4e8c\u90e8\uff1a\u5207\u5206\u6587\u672c text_splitter = RecursiveCharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) # \u5207\u5272\u52a0\u8f7d\u7684 document split_docs = text_splitter . split_documents ( data ) # print(\"split_docs size:\",len(split_docs)) # print(split_docs) # \u7b2c\u4e09\u6b65\uff1a\u521d\u59cb\u5316 hugginFace \u7684 embeddings \u5bf9\u8c61 embeddings = HuggingFaceEmbeddings ( model_name = EMBEDDING_MODEL ) # \u7b2c\u56db\u6b65\uff1a\u5c06 document\u901a\u8fc7embeddings\u5bf9\u8c61\u8ba1\u7b97\u5f97\u5230\u5411\u91cf\u4fe1\u606f\u5e76\u6c38\u4e45\u5b58\u5165FAISS\u5411\u91cf\u6570\u636e\u5e93\uff0c\u7528\u4e8e\u540e\u7eed\u5339\u914d\u67e5\u8be2 db = FAISS . from_documents ( split_docs , embeddings ) db . save_local ( \"./faiss/product\" ) return split_docs result = main () print ( result )","title":"5.2 \u6784\u5efaFaiss\u7d22\u5f15"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#53-qa","text":"\u4ee3\u7801\u8def\u5f84\uff1a/Users/ligang/PycharmProjects/llm/langchain_apply/Knowledge_QA/main.py \u4ee3\u7801\u5b9e\u73b0 # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from langchain import PromptTemplate from get_vector import * from model import ChatGLM2 # \u52a0\u8f7dFAISS\u5411\u91cf\u5e93 EMBEDDING_MODEL = \"moka-ai/m3e-base\" embeddings = HuggingFaceEmbeddings ( model_name = EMBEDDING_MODEL ) db = FAISS . load_local ( \"faiss/product\" , embeddings ) def get_related_content ( related_docs ): related_content = [] for doc in related_docs : related_content . append ( doc . page_content . replace ( \" \\n\\n \" , \" \\n \" )) return \" \\n \" . join ( related_content ) def define_prompt (): question = '\u6211\u8eab\u9ad8170\uff0c\u4f53\u91cd140\u65a4,\u4e70\u591a\u5927\u5c3a\u7801' docs = db . similarity_search ( question , k = 1 ) related_content = get_related_content ( docs ) PROMPT_TEMPLATE = \"\"\" \u57fa\u4e8e\u4ee5\u4e0b\u5df2\u77e5\u4fe1\u606f\uff0c\u7b80\u6d01\u548c\u4e13\u4e1a\u7684\u6765\u56de\u7b54\u7528\u6237\u7684\u95ee\u9898\u3002\u4e0d\u5141\u8bb8\u5728\u7b54\u6848\u4e2d\u6dfb\u52a0\u7f16\u9020\u6210\u5206\u3002 \u5df2\u77e5\u5185\u5bb9: {context} \u95ee\u9898: {question} \"\"\" prompt = PromptTemplate ( input_variables = [ \"context\" , \"question\" ], template = PROMPT_TEMPLATE ,) my_pmt = prompt . format ( context = related_content , question = question ) return my_pmt def qa (): llm = ChatGLM2 () llm . load_model ( \"/Users/**/PycharmProjects/llm/ChatGLM-6B/THUDM/chatglm-6b\" ) my_pmt = define_prompt () result = llm ( my_pmt ) return result if __name__ == '__main__' : result = qa () print ( result ) \u7ed3\u679c\u5c55\u793a\uff1a","title":"5.3 \u5b9e\u73b0QA\u672c\u5730\u77e5\u8bc6\u5e93\u95ee\u7b54"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/02-LangChain%20%2B%20ChatGLM%20%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94.html#_2","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u57fa\u4e8eLangChain+ChatGLM-6B\u6a21\u578b\u5b9e\u73b0\u672c\u5730\u77e5\u8bc6\u5e93\u7684\u95ee\u7b54\u5b9e\u73b0\u539f\u7406+\u8fc7\u7a0b\u3002","title":"\u672c\u8282\u5c0f\u7ed3"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html","text":"LangChain\u7684\u4ecb\u7ecd\u548c\u5165\u95e8 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3\u4ec0\u4e48\u662fLangChain \u660e\u786eLangChain\u4e3b\u8981\u7ec4\u4ef6\u7684\u4f5c\u7528 \u4e86\u89e3LangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f 1 \u4ec0\u4e48\u662fLangChain \u00b6 LangChain\u7531 Harrison Chase \u521b\u5efa\u4e8e2022\u5e7410\u6708\uff0c\u5b83\u662f\u56f4\u7ed5LLMs\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5efa\u7acb\u7684\u4e00\u4e2a\u6846\u67b6\uff0cLLMs\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u6d77\u91cf\u6570\u636e\u6765\u5206\u6790\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0cGPT3.5\u3001GPT4\u662fLLMs\u6700\u5148\u8fdb\u7684\u4ee3\u8868\uff0c\u56fd\u5185\u767e\u5ea6\u7684\u6587\u5fc3\u4e00\u8a00\u3001\u963f\u91cc\u7684\u901a\u4e49\u5343\u95ee\u4e5f\u5c5e\u4e8eLLMs\u3002LangChain\u81ea\u8eab\u5e76\u4e0d\u5f00\u53d1LLMs\uff0c\u5b83\u7684\u6838\u5fc3\u7406\u5ff5\u662f\u4e3a\u5404\u79cdLLMs\u5b9e\u73b0\u901a\u7528\u7684\u63a5\u53e3\uff0c\u628aLLMs\u76f8\u5173\u7684\u7ec4\u4ef6\u201c\u94fe\u63a5\u201d\u5728\u4e00\u8d77\uff0c\u7b80\u5316LLMs\u5e94\u7528\u7684\u5f00\u53d1\u96be\u5ea6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u5feb\u901f\u5730\u5f00\u53d1\u590d\u6742\u7684LLMs\u5e94\u7528\u3002LangChain\u76ee\u524d\u6709\u4e24\u4e2a\u8bed\u8a00\u7684\u5b9e\u73b0\uff1apython\u3001nodejs\u3002 \u672c\u7ae0\u8282\u5c06\u4f1a\u4ece\u4e24\u4e2a\u65b9\u9762\u5168\u9762\u4ecb\u7ecdLangChain\uff1a\u4e00\u4e2a\u662fLangChain\u7ec4\u4ef6\u7684\u57fa\u672c\u6982\u5ff5\u548c\u5e94\u7528\uff1b\u53e6\u4e00\u4e2a\u662fLangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f\u3002 \u53c2\u8003\u5b98\u7f51\u4ecb\u7ecd\uff1a https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub 2 LangChain\u4e3b\u8981\u7ec4\u4ef6 \u00b6 \u4e00\u4e2aLangChain\u7684\u5e94\u7528\u662f\u9700\u8981\u591a\u4e2a\u7ec4\u4ef6\u5171\u540c\u5b9e\u73b0\u7684\uff0cLangChain\u4e3b\u8981\u652f\u63016\u79cd\u7ec4\u4ef6\uff1a Models\uff1a\u6a21\u578b\uff0c\u5404\u79cd\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6a21\u578b\u96c6\u6210\uff0c\u6bd4\u5982GPT-4 Prompts\uff1a\u63d0\u793a\uff0c\u5305\u62ec\u63d0\u793a\u7ba1\u7406\u3001\u63d0\u793a\u4f18\u5316\u548c\u63d0\u793a\u5e8f\u5217\u5316 Memory\uff1a\u8bb0\u5fc6\uff0c\u7528\u6765\u4fdd\u5b58\u548c\u6a21\u578b\u4ea4\u4e92\u65f6\u7684\u4e0a\u4e0b\u6587\u72b6\u6001 Indexes\uff1a\u7d22\u5f15\uff0c\u7528\u6765\u7ed3\u6784\u5316\u6587\u6863\uff0c\u4ee5\u4fbf\u548c\u6a21\u578b\u4ea4\u4e92 Chains\uff1a\u94fe\uff0c\u4e00\u7cfb\u5217\u5bf9\u5404\u79cd\u7ec4\u4ef6\u7684\u8c03\u7528 Agents\uff1a\u4ee3\u7406\uff0c\u51b3\u5b9a\u6a21\u578b\u91c7\u53d6\u54ea\u4e9b\u884c\u52a8\uff0c\u6267\u884c\u5e76\u4e14\u89c2\u5bdf\u6d41\u7a0b\uff0c\u76f4\u5230\u5b8c\u6210\u4e3a\u6b62 2.1 Models \u00b6 \u73b0\u5728\u5e02\u9762\u4e0a\u7684\u6a21\u578b\u591a\u5982\u725b\u6bdb\uff0c\u5404\u79cd\u5404\u6837\u7684\u6a21\u578b\u4e0d\u65ad\u51fa\u73b0\uff0cLangChain\u6a21\u578b\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u4e0e\u5404\u79cd\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u4e3a\u6240\u6709\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u7cbe\u7b80\u7684\u7edf\u4e00\u63a5\u53e3\u3002 LangChain\u76ee\u524d\u652f\u6301\u4e09\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff1aLLMs\u3001Chat Models(\u804a\u5929\u6a21\u578b)\u3001Embeddings Models(\u5d4c\u5165\u6a21\u578b\uff09. LLMs: \u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u6587\u672c\u5b57\u7b26\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u6587\u672c\u5b57\u7b26. \u804a\u5929\u6a21\u578b: \u57fa\u4e8eLLMs, \u4e0d\u540c\u7684\u662f\u5b83\u63a5\u6536\u804a\u5929\u6d88(\u4e00\u79cd\u7279\u5b9a\u683c\u5f0f\u7684\u6570\u636e)\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u804a\u5929\u6d88\u606f. \u6587\u672c\u5d4c\u5165\u6a21\u578b: \u6587\u672c\u5d4c\u5165\u6a21\u578b\u63a5\u6536\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u8fd4\u56de\u7684\u662f\u6d6e\u70b9\u6570\u5217\u8868. LangChain\u652f\u6301\u7684\u4e09\u7c7b\u6a21\u578b\uff0c\u5b83\u4eec\u7684\u4f7f\u7528\u573a\u666f\u4e0d\u540c\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u4e0d\u540c\uff0c\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9879\u76ee\u9700\u8981\u9009\u62e9\u76f8\u5e94\u3002 2.1.1 LLMs (\u5927\u8bed\u8a00\u6a21\u578b) \u00b6 LLMs\u4f7f\u7528\u573a\u666f\u6700\u591a\uff0c\u5e38\u7528\u5927\u6a21\u578b\u7684\u4e0b\u8f7d\u5e93\uff1a https://huggingface.co/models \uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u300c\u6587\u5fc3\u4e00\u8a00\u300d\u6a21\u578b\u4e3a\u4f8b, \u4f7f\u7528\u8be5\u7c7b\u6a21\u578b\u7684\u7ec4\u4ef6\uff1a \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1alangchain\u548copenai pip install openai = =0.28 pip install langchain pip install qianfan \u6ce8\u610f\uff0c\u5728\u4f7f\u7528openai\u6a21\u578b\u4e4b\u524d\uff0c\u5fc5\u987b\u5f00\u901aOpenAI API\u670d\u52a1\uff0c\u9700\u8981\u83b7\u5f97API Token\u3002 \u7b2c\u4e8c\u6b65\uff1a\u501f\u52a9\u767e\u5ea6\u667a\u80fd\u4e91--\u5343\u5e06\u5927\u6a21\u578b\u5e73\u53f0\uff1a\u7533\u8bf7API Key \u4ee5\u53caSecret Key \u60f3\u8bf7\u89c1\u9644\u4ef6\u624b\u518c \u7b2c\u4e09\u90e8\uff1a\u4ee3\u7801\u5b9e\u73b0 import os from langchain_community.llms import QianfanLLMEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanLLMEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) res = llm ( \"\u5e2e\u6211\u8bb2\u4e2a\u7b11\u8bdd\u5427\" ) print ( res ) ##\u6253\u5370\u7ed3\u679c\uff1a \u5f53\u7136\u53ef\u4ee5 \uff01 \u8fd9\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u7b11\u8bdd \uff1a \u6709\u4e00\u5929 \uff0c \u4e00\u53ea\u5c0f\u9e1f\u98de\u5230\u4e00\u680b\u5927\u623f\u5b50\u524d \uff0c \u5927\u58f0\u558a\u9053 \uff1a\u201c \u5356\u62a5 \uff01 \u5356\u62a5 \uff01\u201d \u53ef\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5b83\u7ee7\u7eed\u558a\u9053 \uff1a\u201c \u563f \uff0c \u6709\u4eba\u5728\u5417 \uff1f \u5356\u62a5 \uff01\u201d \u8fd9\u6b21\u8fd8\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5c0f\u9e1f\u60f3\u4e86\u60f3 \uff0c \u4e8e\u662f\u8bf4 \uff1a\u201c \u5bf9\u4e0d\u8d77 \uff0c \u6253\u6270\u4e86 \uff01 \u6211\u53ea\u662f\u60f3\u77e5\u9053 \uff0c \u8fd9\u91cc\u6709\u4eba\u60f3\u4e70\u5929\u5802\u5417 \uff1f\u201d \u542c\u5230\u8fd9\u4e2a\u7b11\u8bdd \uff0c \u6211\u5e0c\u671b\u4f60\u4e5f\u80fd\u5f00\u5fc3\u8d77\u6765 \uff01 2.1.2 Chat Models (\u804a\u5929\u6a21\u578b) \u00b6 \u804a\u5929\u6d88\u606f\u5305\u542b\u4e0b\u9762\u51e0\u79cd\u7c7b\u578b\uff0c\u4f7f\u7528\u65f6\u9700\u8981\u6309\u7167\u7ea6\u5b9a\u4f20\u5165\u5408\u9002\u7684\u503c\uff1a AIMessage: \u5c31\u662f AI \u8f93\u51fa\u7684\u6d88\u606f\uff0c\u53ef\u4ee5\u662f\u9488\u5bf9\u95ee\u9898\u7684\u56de\u7b54. HumanMessage: \u4eba\u7c7b\u6d88\u606f\u5c31\u662f\u7528\u6237\u4fe1\u606f\uff0c\u7531\u4eba\u7ed9\u51fa\u7684\u4fe1\u606f\u53d1\u9001\u7ed9LLMs\u7684\u63d0\u793a\u4fe1\u606f\uff0c\u6bd4\u5982\u201c\u5b9e\u73b0\u4e00\u4e2a\u5feb\u901f\u6392\u5e8f\u65b9\u6cd5\u201d. SystemMessage: \u53ef\u4ee5\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u5177\u4f53\u6240\u5904\u7684\u73af\u5883\u548c\u80cc\u666f\uff0c\u5982\u89d2\u8272\u626e\u6f14\u7b49\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u7ed9\u51fa\u5177\u4f53\u7684\u6307\u793a\uff0c\u6bd4\u5982\u201c\u4f5c\u4e3a\u4e00\u4e2a\u4ee3\u7801\u4e13\u5bb6\u201d\uff0c\u6216\u8005\u201c\u8fd4\u56dejson\u683c\u5f0f\u201d. ChatMessage: Chat \u6d88\u606f\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u89d2\u8272\u7684\u53c2\u6570\uff0c\u4f46\u662f\u5728\u5927\u591a\u6570\u65f6\u95f4\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u4e0a\u9762\u7684\u4e09\u79cd\u7c7b\u578b. LangChain\u652f\u6301\u7684\u5e38\u89c1\u804a\u5929\u6a21\u578b\u6709\uff1a \u6a21\u578b \u63cf\u8ff0 ChatOpenAI OpenAI\u804a\u5929\u6a21\u578b AzureChatOpenAI Azure\u63d0\u4f9b\u7684OpenAI\u804a\u5929\u6a21\u578b PromptLayerChatOpenAI \u57fa\u4e8eOpenAI\u7684\u63d0\u793a\u6a21\u7248\u5e73\u53f0 \u4e3e\u4f8b\u8bf4\u660e\uff1a import os from langchain_community.chat_models import QianfanChatEndpoint from langchain_core.messages import HumanMessage os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) messages = [ HumanMessage ( content = \"\u7ed9\u6211\u5199\u4e00\u9996\u5510\u8bd7\" ) ] res = chat ( messages ) print ( res ) # \u6253\u5370\u7ed3\u679c\uff1a ''' content='\u597d\u7684\uff0c\u4ee5\u4e0b\u662f\u6211\u4e3a\u60a8\u521b\u4f5c\u7684\u5510\u8bd7\uff1a\\n\\n\u9752\u5c71\u4f9d\u65e7\u5728\uff0c\u51e0\u5ea6\u5915\u9633\u7ea2\u3002\\n\u767d\u53d1\u6e14\u6a35\u6c5f\u6e1a\u4e0a\uff0c\u60ef\u770b\u79cb\u6708\u6625\u98ce\u3002\\n\u4e00\u58f6\u6d4a\u9152\u559c\u76f8\u9022\uff0c\u53e4\u4eca\u591a\u5c11\u4e8b\uff0c\u90fd\u4ed8\u7b11\u8c08\u4e2d\u3002' ''' 2.1.3 \u63d0\u793a\u6a21\u677f \u00b6 \u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c\u6a21\u578b\u9ed8\u8ba4\u662f\u8fd4\u56de\u7eaf\u6587\u672c\u7ed3\u679c\u7684\uff0c\u5982\u679c\u60f3\u8ba9\u6a21\u578b\u8fd4\u56de\u60f3\u8981\u7684\u6570\u636e\u683c\u5f0f\uff08\u6bd4\u5982json\u683c\u5f0f\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528\u63d0\u793a\u6a21\u7248\u3002 \u63d0\u793a\u6a21\u677f\u5c31\u662f\u628a\u4e00\u4e9b\u5e38\u89c1\u7684\u63d0\u793a\u6574\u7406\u6210\u6a21\u677f\uff0c\u7528\u6237\u53ea\u9700\u8981\u4fee\u6539\u6a21\u677f\u4e2d\u7279\u5b9a\u7684\u8bcd\u8bed\uff0c\u5c31\u80fd\u5feb\u901f\u51c6\u786e\u5730\u544a\u8bc9\u6a21\u578b\u81ea\u5df1\u7684\u9700\u6c42\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a import os from langchain.chat_models import QianfanChatEndpoint from langchain_core.prompts import ChatPromptTemplate os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u539f\u59cb\u6a21\u677f template_str = \"\"\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002 \\n \u5bf9\u4e8e\u552e\u4ef7\u4e3a {price} \u5143\u7684 {flower_name} \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f \u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26 \"\"\" # \u6839\u636e\u539f\u59cb\u6a21\u677f\u521b\u5efaLangChain\u63d0\u793a\u6a21\u677f promp_emplate = ChatPromptTemplate . from_template ( template_str ) prompt = promp_emplate . format_messages ( flower_name = [ \"\u73ab\u7470\" ], price = '50' ) print ( 'prompt-->' , prompt ) # prompt\u663e\u793a\uff1a ''' prompt--> [HumanMessage(content=\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002\\n\\n\u5bf9\u4e8e\u552e\u4ef7\u4e3a 50 \u5143\u7684 ['\u73ab\u7470'] \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f\\n\u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26\\n# \")] ''' # \u5b9e\u4f8b\u5316\u6a21\u578b chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) # \u6253\u5370\u7ed3\u679c result = chat ( prompt ) print ( result ) # \u7ed3\u679c\u5c55\u793a\uff1a ''' content='\u73ab\u7470\u9c9c\u82b1 \u552e\u4ef750\u5143\\n\u7eaf\u624b\u5de5\u7f16\u7ec7\u82b1\u675f\uff0c\u9876\u7ea7\u73ab\u7470\u54c1\u79cd\\n\u6563\u53d1\u6d53\u90c1\u9999\u6c14\uff0c\u6e29\u6696\u4eba\u5fc3\u6249\\n\u767d\u8272\u6216\u7c89\u7ea2\u8272\uff0c\u5a07\u8273\u6b32\u6ef4\\n\u8ba9\u7231\u60c5\u4e0e\u6d6a\u6f2b\u4f34\u968f\u4f60\u6bcf\u4e00\u5929\uff01#' ''' 2.1.4 Embeddings Models(\u5d4c\u5165\u6a21\u578b) \u00b6 Embeddings Models\u7279\u70b9\uff1a\u5c06\u5b57\u7b26\u4e32\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u4e00\u4e2a\u6d6e\u52a8\u6570\u7684\u5217\u8868\u3002\u5728NLP\u4e2d\uff0cEmbedding\u7684\u4f5c\u7528\u5c31\u662f\u5c06\u6570\u636e\u8fdb\u884c\u6587\u672c\u5411\u91cf\u5316\u3002 Embeddings Models\u53ef\u4ee5\u4e3a\u6587\u672c\u521b\u5efa\u5411\u91cf\u6620\u5c04\uff0c\u8fd9\u6837\u5c31\u80fd\u5728\u5411\u91cf\u7a7a\u95f4\u91cc\u53bb\u8003\u8651\u6587\u672c\uff0c\u6267\u884c\u8bf8\u5982\u8bed\u4e49\u641c\u7d22\u4e4b\u7c7b\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982\u8bf4\u5bfb\u627e\u76f8\u4f3c\u7684\u6587\u672c\u7247\u6bb5\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u4e00\u4e2aOpenAI\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u4f8b\u5b50\u8fdb\u884c\u8bf4\u660e\uff1a import os from langchain_community.embeddings import QianfanEmbeddingsEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" embed = QianfanEmbeddingsEndpoint () res1 = embed . embed_query ( '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' ) print ( res1 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [0.039765920490026474, 0.02263435162603855, -0.01889650709927082, ...., ''' res2 = embed . embed_documents ([ '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' , '\u8fd9\u662f\u7b2c\u4e8c\u4e2a\u6d4b\u8bd5\u6587\u6863' ]) print ( res2 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [[0.03977284952998161, 0.022625437006354332, -0.01892162673175335, ...., ''' \u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5206\u522b\u4f7f\u7528\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u8fdb\u884c\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\uff0c\u4ed6\u4eec\u6700\u5927\u4e0d\u540c\u5728\u4e8e\uff1aembed_query()\u63a5\u6536\u4e00\u4e2a\u5b57\u7b26\u4e32\u7684\u8f93\u5165\uff0c\u800cembed_documents\u53ef\u4ee5\u63a5\u6536\u4e00\u7ec4\u5b57\u7b26\u4e32\u3002 LangChain\u96c6\u6210\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u6709\uff1a AzureOpenAI\u3001Baidu Qianfan\u3001Hugging Face Hub\u3001OpenAI\u3001Llama-cpp\u3001SentenceTransformers 2.2 Prompts \u00b6 Prompt\u662f\u6307\u5f53\u7528\u6237\u8f93\u5165\u4fe1\u606f\u7ed9\u6a21\u578b\u65f6\u52a0\u5165\u7684\u63d0\u793a\uff0c\u8fd9\u4e2a\u63d0\u793a\u7684\u5f62\u5f0f\u53ef\u4ee5\u662fzero-shot\u6216\u8005few-shot\u7b49\u65b9\u5f0f\uff0c\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u7406\u89e3\u66f4\u4e3a\u590d\u6742\u7684\u4e1a\u52a1\u573a\u666f\u4ee5\u4fbf\u66f4\u597d\u7684\u89e3\u51b3\u95ee\u9898\u3002 \u63d0\u793a\u6a21\u677f\uff1a\u5982\u679c\u4f60\u6709\u4e86\u4e00\u4e2a\u8d77\u4f5c\u7528\u7684\u63d0\u793a\uff0c\u4f60\u53ef\u80fd\u60f3\u628a\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u6a21\u677f\u7528\u4e8e\u89e3\u51b3\u5176\u4ed6\u95ee\u9898\uff0cLangChain\u5c31\u63d0\u4f9b\u4e86PromptTemplates\u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u4f60\u66f4\u65b9\u4fbf\u7684\u6784\u5efa\u63d0\u793a\u3002 zero-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain_core.prompts import PromptTemplate from langchain_community.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) prompt_text = prompt . format ( lastname = \"\u738b\" ) print ( prompt_text ) # result: \u6211\u7684\u90bb\u5c45\u59d3\u738b\uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57 llm = QianfanLLMEndpoint () result = llm ( prompt_text ) print ( result ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u7ed9\u90bb\u5c45\u7684\u513f\u5b50\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u68d2\u7684\u4e8b\u60c5\uff01\u5728\u8003\u8651\u540d\u5b57\u65f6\uff0c\u901a\u5e38\u4f1a\u8003\u8651\u4e00\u4e9b\u57fa\u672c\u7684\u56e0\u7d20\uff0c\u6bd4\u5982\u540d\u5b57\u7684\u542b\u4e49\u3001\u8bfb\u97f3\u3001\u4e66\u5199\u7b49\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5efa\u8bae\uff1a \u5982\u679c\u60a8\u60f3\u8981\u4e00\u4e2a\u7b80\u5355\u7684\u540d\u5b57\uff0c\u90a3\u4e48\u53ef\u4ee5\u8003\u8651\u738b\u7166\u5b87\u3002\u8fd9\u4e2a\u540d\u5b57\u5bd3\u610f\u7740\u9633\u5149\u548c\u5bbd\u5e7f\u7684\u5b87\u5b99\uff0c\u8868\u793a\u5b69\u5b50\u5e94\u8be5\u50cf\u592a\u9633\u4e00\u6837\u6e29\u6696\u3001\u660e\u6717\uff0c\u53c8\u5982\u5b87\u5b99\u822c\u5bbd\u5e7f\u5305\u5bb9\u3002 \u53e6\u4e00\u4e2a\u9009\u62e9\u662f\u738b\u8c26\u5609\u3002\u8fd9\u4e2a\u540d\u5b57\u610f\u4e3a\u8c26\u865a\u3001\u9ad8\u5c1a\uff0c\u540c\u65f6\u4e5f\u8868\u793a\u5609\u5956\u548c\u5e86\u795d\u3002\u5982\u679c\u90bb\u5c45\u6709\u7279\u522b\u671f\u671b\u4ed6\u7684\u513f\u5b50\u5c06\u6765\u6210\u4e3a\u6709\u9053\u5fb7\u3001\u6709\u4fee\u517b\u7684\u4eba\uff0c\u8fd9\u4e2a\u540d\u5b57\u53ef\u80fd\u662f\u4e00\u4e2a\u4e0d\u9519\u7684\u9009\u62e9\u3002 \u5f53\u7136\uff0c\u8fd9\u53ea\u662f\u4e00\u4e9b\u5efa\u8bae\uff0c\u6700\u7ec8\u7684\u51b3\u5b9a\u5e94\u8be5\u57fa\u4e8e\u738b\u5148\u751f\u7684\u4e2a\u4eba\u559c\u597d\u548c\u671f\u671b\u3002\u8bf7\u786e\u4fdd\u540d\u5b57\u6613\u4e8e\u4e66\u5199\u548c\u53d1\u97f3\uff0c\u5e76\u4e14\u4e0e\u60a8\u548c\u90bb\u5c45\u7684\u59d3\u6c0f\u642d\u914d\u5f97\u5f53\u3002\u795d\u738b\u5148\u751f\u548c\u4ed6\u7684\u513f\u5b50\u4e00\u5207\u987a\u5229\uff01 ''' few-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain_core.prompts import PromptTemplate , FewShotPromptTemplate from langchain_community.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" examples = [ { \"word\" : \"\u5f00\u5fc3\" , \"antonym\" : \"\u96be\u8fc7\" }, { \"word\" : \"\u9ad8\" , \"antonym\" : \"\u77ee\" }, ] example_template = \"\"\" \u5355\u8bcd: {word} \u53cd\u4e49\u8bcd: {antonym} \\\\ n \"\"\" example_prompt = PromptTemplate ( input_variables = [ \"word\" , \"antonym\" ], template = example_template , ) few_shot_prompt = FewShotPromptTemplate ( examples = examples , example_prompt = example_prompt , prefix = \"\u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd\" , suffix = \"\u5355\u8bcd: {input} \\\\ n\u53cd\u4e49\u8bcd:\" , input_variables = [ \"input\" ], example_separator = \" \\\\ n\" , ) prompt_text = few_shot_prompt . format ( input = \"\u7c97\" ) print ( prompt_text ) print ( '*' * 80 ) # \u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd # \u5355\u8bcd: \u5f00\u5fc3 # \u53cd\u4e49\u8bcd: \u96be\u8fc7 # \u5355\u8bcd: \u9ad8 # \u53cd\u4e49\u8bcd: \u77ee # \u5355\u8bcd: \u7c97 # \u53cd\u4e49\u8bcd: # \u8c03\u7528OpenAI llm = QianfanLLMEndpoint ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u7ec6 2.3 Chains(\u94fe) \u00b6 \u5728LangChain\u4e2d\uff0cChains\u63cf\u8ff0\u4e86\u5c06LLM\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7ed3\u5408\u8d77\u6765\u5b8c\u6210\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u8fc7\u7a0b. \u9488\u5bf9\u4e0a\u4e00\u5c0f\u8282\u7684\u63d0\u793a\u6a21\u7248\u4f8b\u5b50\uff0czero-shot\u91cc\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u94fe\u6765\u8fde\u63a5\u63d0\u793a\u6a21\u7248\u7ec4\u4ef6\u548c\u6a21\u578b\uff0c\u8fdb\u800c\u53ef\u4ee5\u5b9e\u73b0\u4ee3\u7801\u7684\u66f4\u6539\uff1a from langchain_core.prompts import PromptTemplate from langchain_community.llms import QianfanLLMEndpoint from langchain.chains import LLMChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint () chain = LLMChain ( llm = llm , prompt = prompt ) # \u6267\u884c\u94fe print ( chain . run ( \"\u738b\" )) # \u6253\u5370\u7ed3\u679c ''' \u7ed9\u90bb\u5c45\u5bb6\u7684\u65b0\u751f\u513f\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u91cd\u8981\u7684\u4e8b\u60c5\uff0c\u9700\u8981\u8003\u8651\u5230\u5f88\u591a\u56e0\u7d20\uff0c\u5305\u62ec\u5bb6\u5ead\u4f20\u7edf\u3001\u7236\u6bcd\u7684\u504f\u597d\u3001\u540d\u5b57\u7684\u542b\u4e49\u7b49\u7b49\u3002\u5728\u8fd9\u4e2a\u60c5\u51b5\u4e0b\uff0c\u738b\u5148\u751f\u548c\u592a\u592a\u53ef\u80fd\u4f1a\u60f3\u8981\u4e00\u4e2a\u65e2\u4f20\u7edf\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u7684\u540d\u5b57\u3002 \u57fa\u4e8e\u8fd9\u4e9b\u8003\u8651\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u9002\u5408\u7537\u5b69\u7684\u540d\u5b57\uff1a 1. \u738b\u6893\u8f69\uff08Zi Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u6709\u4f20\u7edf\u7684\u542b\u4e49\uff08\u6893\u662f\u6811\u6728\u7684\u610f\u601d\uff0c\u8f69\u662f\u9ad8\u8fdc\u7684\u610f\u601d\uff09\uff0c\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u3002 2. \u738b\u5b87\u7fd4\uff08Yu Xiang\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u5305\u542b\u4e86\u5b87\u5b99\u7684\u542b\u4e49\uff08\u5b87\u662f\u5b87\u5b99\u7684\u610f\u601d\uff0c\u7fd4\u662f\u98de\u7fd4\u7684\u610f\u601d\uff09\uff0c\u53c8\u6709\u5e0c\u671b\u4ed6\u513f\u5b50\u80fd\u50cf\u9e1f\u513f\u4e00\u6837\u81ea\u7531\u98de\u7fd4\u7684\u5bd3\u610f\u3002 3. \u738b\u5b87\u8f69\uff08Yu Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u4e5f\u6709\u540c\u6837\u7684\u542b\u4e49\uff0c\u800c\u4e14\u4e5f\u6709\u4e00\u79cd\u7a33\u91cd\u548c\u5bbd\u5e7f\u7684\u611f\u89c9\u3002 4. \u738b\u535a\u8fdc\uff08Bo Yuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u7684\u542b\u4e49\u662f\u535a\u5b66\u800c\u8fdc\u5fd7\uff0c\u65e2\u4f53\u73b0\u4e86\u7236\u6bcd\u7684\u671f\u671b\uff0c\u53c8\u6709\u4e00\u79cd\u6e05\u65b0\u660e\u5feb\u7684\u611f\u89c9\u3002 \u8bf7\u6ce8\u610f\uff0c\u5728\u9009\u62e9\u540d\u5b57\u65f6\uff0c\u8fd8\u9700\u8981\u8003\u8651\u540d\u5b57\u5728\u793e\u533a\u4e2d\u7684\u53d7\u6b22\u8fce\u7a0b\u5ea6\uff0c\u4ee5\u786e\u4fdd\u8fd9\u4e2a\u540d\u5b57\u4e0d\u4f1a\u5f15\u8d77\u4efb\u4f55\u95ee\u9898\u6216\u8bef\u89e3\u3002\u6b64\u5916\uff0c\u5982\u679c\u738b\u5148\u751f\u548c\u592a\u592a\u6709\u4efb\u4f55\u7279\u5b9a\u7684\u504f\u597d\u6216\u671f\u671b\uff0c\u4ed6\u4eec\u4e5f\u5e94\u8be5\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002 \u4ee5\u4e0a\u5c31\u662f\u6211\u4e3a\u738b\u5148\u751f\u7684\u513f\u5b50\u63d0\u51fa\u7684\u4e00\u4e9b\u540d\u5b57\u5efa\u8bae\uff0c\u5e0c\u671b\u80fd\u5e2e\u52a9\u5230\u4f60\u4eec\u3002 ''' \u5982\u679c\u4f60\u60f3\u5c06\u7b2c\u4e00\u4e2a\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff0c\u76f4\u63a5\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u6a21\u578b\u7684\u8f93\u5165\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528LangChain\u7684SimpleSequentialChain, \u4ee3\u7801\u5982\u4e0b\uff1a from langchain_core.prompts import PromptTemplate from langchain_community.llms import QianfanLLMEndpoint from langchain.chains import LLMChain , SimpleSequentialChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u7b2c\u4e00\u6761\u94fe template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" first_prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint ( temperature = 0.9 ) first_chain = LLMChain ( llm = llm , prompt = first_prompt ) # \u521b\u5efa\u7b2c\u4e8c\u6761\u94fe second_prompt = PromptTemplate ( input_variables = [ \"child_name\" ], template = \"\u90bb\u5c45\u7684\u513f\u5b50\u540d\u5b57\u53eb {child_name} \uff0c\u7ed9\u4ed6\u8d77\u4e00\u4e2a\u5c0f\u540d\" , ) second_chain = LLMChain ( llm = llm , prompt = second_prompt ) # \u94fe\u63a5\u4e24\u6761\u94fe # verbose=True\u53ef\u4ee5\u663e\u793a\u63a8\u7406\u8fc7\u7a0b overall_chain = SimpleSequentialChain ( chains = [ first_chain , second_chain ], verbose = True ) print ( overall_chain ) # \u6267\u884c\u94fe\uff0c\u53ea\u9700\u8981\u4f20\u5165\u7b2c\u4e00\u4e2a\u53c2\u6570 catchphrase = overall_chain . run ( \"\u738b\" ) print ( catchphrase ) # ''' \u5f53\u7136\uff0c\u7ed9\u90bb\u5c45\u7684\u5b69\u5b50\u8d77\u5c0f\u540d\u4e5f\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u66f4\u52a0\u4eb2\u8fd1\u548c\u4eb2\u5207\u3002\u8003\u8651\u5230\u4e0a\u8ff0\u540d\u5b57\u7684\u542b\u4e49\u548c\u97f3\u97f5\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5c0f\u540d\u7684\u5efa\u8bae\uff1a 1. \u6893\u8f69\u5b9d\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u6893\u8f69\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u5b9d\u201d\uff0c\u8868\u793a\u4eb2\u5207\u548c\u559c\u7231\u3002 2. \u5b87\u5e06\u5c0f\u5b50\uff1a\u5bf9\u5e94\u201c\u738b\u5b87\u5e06\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b50\u201d\uff0c\u663e\u5f97\u6d3b\u6cfc\u53ef\u7231\u3002 3. \u745e\u9633\u5c0f\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u745e\u9633\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b9d\u201d\uff0c\u663e\u5f97\u4eb2\u5207\u6e29\u6696\u3002 4. \u535a\u6587\u5b9d\u8d1d\uff1a\u5bf9\u5e94\u201c\u738b\u535a\u6587\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u8d1d\u201d\uff0c\u8868\u793a\u5bf9\u4ed6\u7684\u559c\u7231\u548c\u5475\u62a4\u3002 5. \u6d69\u5b87\u5c0f\u661f\uff1a\u5bf9\u5e94\u201c\u738b\u6d69\u5b87\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u661f\u201d\uff0c\u663e\u5f97\u5145\u6ee1\u6d3b\u529b\u548c\u5e0c\u671b\u3002 ''' 2.4 Agents (\u4ee3\u7406) \u00b6 Agents \u4e5f\u5c31\u662f\u4ee3\u7406\uff0c\u5b83\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u6765\u9009\u62e9\u4e00\u7cfb\u5217\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002 \u5728 LangChain \u4e2d Agents \u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e\u7528\u6237\u7684\u9700\u6c42\uff0c\u6765\u8bbf\u95ee\u4e00\u4e9b\u7b2c\u4e09\u65b9\u5de5\u5177(\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u6216\u8005\u6570\u636e\u5e93)\uff0c\u8fdb\u800c\u6765\u89e3\u51b3\u76f8\u5173\u9700\u6c42\u95ee\u9898\u3002 \u4e3a\u4ec0\u4e48\u8981\u501f\u52a9\u7b2c\u4e09\u65b9\u5e93\uff1f \u56e0\u4e3a\u5927\u6a21\u578b\u867d\u7136\u975e\u5e38\u5f3a\u5927\uff0c\u4f46\u662f\u4e5f\u5177\u5907\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u6bd4\u5982\u4e0d\u80fd\u56de\u7b54\u5b9e\u65f6\u4fe1\u606f\u3001\u5904\u7406\u6570\u5b66\u903b\u8f91\u95ee\u9898\u4ecd\u7136\u975e\u5e38\u7684\u521d\u7ea7\u7b49\u7b49\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u501f\u52a9\u7b2c\u4e09\u65b9\u5de5\u5177\u6765\u8f85\u52a9\u5927\u6a21\u578b\u7684\u5e94\u7528\u3002 \u51e0\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a Agent\u4ee3\u7406\uff1a \u5236\u5b9a\u8ba1\u5212\u548c\u601d\u8003\u4e0b\u4e00\u6b65\u9700\u8981\u91c7\u53d6\u7684\u884c\u52a8\u3002 \u8d1f\u8d23\u63a7\u5236\u6574\u6bb5\u4ee3\u7801\u7684\u903b\u8f91\u548c\u6267\u884c\uff0c\u4ee3\u7406\u66b4\u9732\u4e86\u4e00\u4e2a\u63a5\u53e3\uff0c\u7528\u6765\u63a5\u6536\u7528\u6237\u8f93\u5165\u3002 LangChain \u63d0\u4f9b\u4e86\u4e0d\u540c\u7c7b\u578b\u7684\u4ee3\u7406\uff08\u4e3b\u8981\u7f57\u5217\u4e00\u4e0b\u4e09\u79cd\uff09: zero-shot-react-description: \u4ee3\u7406\u4f7f\u7528ReAct\u6846\u67b6\uff0c\u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u6765\u786e\u5b9a\u8981\u4f7f\u7528\u7684\u5de5\u5177.\u6b64\u4ee3\u7406\u4f7f\u7528 ReAct \u6846\u67b6\u786e\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177 \u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u3002\u7f3a\u4e4f \u4f1a\u8bdd\u5f0f\u8bb0\u5fc6\u3002 structured-chat-zero-shot-react-description\uff1a\u80fd\u591f\u4f7f\u7528\u591a\u8f93\u5165\u5de5\u5177\uff0c\u7ed3\u6784\u5316\u7684\u53c2\u6570\u8f93\u5165\u3002 conversational-react-description\uff1a\u8fd9\u4e2a\u4ee3\u7406\u7a0b\u5e8f\u65e8\u5728\u7528\u4e8e\u5bf9\u8bdd\u73af\u5883\u4e2d\u3002\u63d0\u793a\u8bbe\u8ba1\u65e8\u5728\u4f7f\u4ee3\u7406\u7a0b\u5e8f\u6709\u52a9\u4e8e\u5bf9\u8bdd\u3002 \u5b83\u4f7f\u7528ReAct\u6846\u67b6\u6765\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177\uff0c\u5e76\u4f7f\u7528\u5185\u5b58\u6765\u8bb0\u5fc6\u5148\u524d\u7684\u5bf9\u8bdd\u4ea4\u4e92\u3002 Tool\u5de5\u5177\uff1a \u89e3\u51b3\u95ee\u9898\u7684\u5de5\u5177 \u7b2c\u4e09\u65b9\u670d\u52a1\u7684\u96c6\u6210\uff0c\u4f8b\u5982\u8ba1\u7b97\u3001\u7f51\u7edc(\u8c37\u6b4c\u3001bing)\u3001\u4ee3\u7801\u6267\u884c\u7b49\u7b49 Toolkit\u5de5\u5177\u5305\uff1a \u7528\u4e8e\u5b8c\u6210\u7279\u5b9a\u76ee\u6807\u6240\u9700\u8981\u7684\u5de5\u5177\u7ec4\uff0c\u6bd4\u5982 create_csv_agent \u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u89e3\u8bfbcsv\u6587\u4ef6\u3002 AgentExecutor\u4ee3\u7406\u6267\u884c\u5668: \u5b83\u5c06\u4ee3\u7406\u548c\u5de5\u5177\u5217\u8868\u5305\u88c5\u5728\u4e00\u8d77, \u8d1f\u8d23\u8fed\u4ee3\u8fd0\u884c\u4ee3\u7406\u7684\u5faa\u73af\uff0c\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u7684\u6807\u51c6\u3002 \u8fd9\u662f\u5b9e\u9645\u8c03\u7528agent\u5e76\u6267\u884c\u5176\u9009\u62e9\u7684\u52a8\u4f5c\u90e8\u5206\u3002 \u73b0\u5728\u6211\u4eec\u5b9e\u73b0\u4e00\u4e2a\u4f7f\u7528\u4ee3\u7406\u7684\u4f8b\u5b50\uff1a\u5047\u8bbe\u6211\u4eec\u60f3\u67e5\u8be2\u4e00\u4e0b\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\uff1f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u4e2a\u4ee3\u7406\u5de5\u5177\uff0c\u8ba9Agents\u9009\u62e9\u6267\u884c\u3002\u4ee3\u7801\u5982\u4e0b\uff1a # pip install duckduckgo-search import os from langchain.agents import load_tools from langchain.agents import initialize_agent from langchain.agents import AgentType from langchain_community.chat_models import QianfanChatEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # 2 \u5b9e\u4f8b\u5316\u5927\u6a21\u578b llm = QianfanChatEndpoint () # 3 \u8bbe\u7f6e\u5de5\u5177 # \"serpapi\"\u5b9e\u65f6\u8054\u7f51\u641c\u7d20\u5de5\u5177\u3001\"math\": \u6570\u5b66\u8ba1\u7b97\u7684\u5de5\u5177 # tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm) tools = load_tools ([ \"ddg-search\" , \"llm-math\" ], llm = llm ) # 4 \u5b9e\u4f8b\u5316\u4ee3\u7406Agent:\u8fd4\u56de AgentExecutor \u7c7b\u578b\u7684\u5b9e\u4f8b agent = initialize_agent ( tools , llm , agent = AgentType . ZERO_SHOT_REACT_DESCRIPTION , verbose = True ) print ( 'agent' , agent ) # 5 \u51c6\u5907\u63d0\u793a\u8bcd from langchain import PromptTemplate prompt_template = \"\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\" prompt = PromptTemplate . from_template ( prompt_template ) print ( 'prompt-->' , prompt ) # 6 \u4ee3\u7406Agent\u5de5\u4f5c agent . run ( prompt ) \u6ce8\u610f\uff0c\u5982\u679c\u8fd0\u884c\u8fd9\u4e2a\u793a\u4f8b\u4f60\u8981\u4f7f\u7528serpapi\uff0c \u9700\u8981\u7533\u8bf7 serpapi token\uff0c\u5e76\u4e14\u8bbe\u7f6e\u5230\u73af\u5883\u53d8\u91cf SERPAPI_API_KEY \uff0c\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\u5305 google-search-results \u67e5\u8be2\u6240\u6709\u5de5\u5177\u7684\u540d\u79f0 from langchain.agents import get_all_tool_names results = get_all_tool_names () print ( results ) # ['python_repl', 'requests', 'requests_get', 'requests_post', 'requests_patch', 'requests_put', 'requests_delete', 'terminal', 'sleep', 'wolfram-alpha', 'google-search', 'google-search-results-json', 'searx-search-results-json', 'bing-search', 'metaphor-search', 'ddg-search', 'google-serper', 'google-scholar', 'google-serper-results-json', 'searchapi', 'searchapi-results-json', 'serpapi', 'dalle-image-generator', 'twilio', 'searx-search', 'wikipedia', 'arxiv', 'golden-query', 'pubmed', 'human', 'awslambda', 'sceneXplain', 'graphql', 'openweathermap-api', 'dataforseo-api-search', 'dataforseo-api-search-json', 'eleven_labs_text2speech', 'google_cloud_texttospeech', 'news-api', 'tmdb-api', 'podcast-api', 'memorize', 'llm-math', 'open-meteo-api'] LangChain\u652f\u6301\u7684\u5de5\u5177\u5982\u4e0b\uff1a \u5de5\u5177 \u63cf\u8ff0 Bing Search Bing\u641c\u7d22 Google Search Google\u641c\u7d22 Google Serper API \u4e00\u4e2a\u4ecegoogle\u641c\u7d22\u63d0\u53d6\u6570\u636e\u7684API Python REPL \u6267\u884cpython\u4ee3\u7801 Requests \u6267\u884cpython\u4ee3\u7801 2.5 Memory \u00b6 \u5927\u6a21\u578b\u672c\u8eab\u4e0d\u5177\u5907\u4e0a\u4e0b\u6587\u7684\u6982\u5ff5\uff0c\u5b83\u5e76\u4e0d\u4fdd\u5b58\u4e0a\u6b21\u4ea4\u4e92\u7684\u5185\u5bb9\uff0cChatGPT\u4e4b\u6240\u4ee5\u80fd\u591f\u548c\u4eba\u6b63\u5e38\u6c9f\u901a\u5bf9\u8bdd\uff0c\u56e0\u4e3a\u5b83\u8fdb\u884c\u4e86\u4e00\u5c42\u5c01\u88c5\uff0c\u5c06\u5386\u53f2\u8bb0\u5f55\u56de\u4f20\u7ed9\u4e86\u6a21\u578b\u3002 \u56e0\u6b64 LangChain \u4e5f\u63d0\u4f9b\u4e86Memory\u7ec4\u4ef6, Memory\u5206\u4e3a\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u671f\u8bb0\u5fc6\u548c\u957f\u671f\u8bb0\u5fc6\u3002\u77ed\u671f\u8bb0\u5fc6\u4e00\u822c\u6307\u5355\u4e00\u4f1a\u8bdd\u65f6\u4f20\u9012\u6570\u636e\uff0c\u957f\u671f\u8bb0\u5fc6\u5219\u662f\u5904\u7406\u591a\u4e2a\u4f1a\u8bdd\u65f6\u83b7\u53d6\u548c\u66f4\u65b0\u4fe1\u606f\u3002 \u76ee\u524d\u7684Memory\u7ec4\u4ef6\u53ea\u9700\u8981\u8003\u8651ChatMessageHistory\u3002\u4e3e\u4f8b\u5206\u6790\uff1a from langchain.memory import ChatMessageHistory history = ChatMessageHistory () history . add_user_message ( \"\u5728\u5417\uff1f\" ) history . add_ai_message ( \"\u6709\u4ec0\u4e48\u4e8b?\" ) print ( history . messages ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [HumanMessage(content='\u5728\u5417\uff1f'), AIMessage(content='\u6709\u4ec0\u4e48\u4e8b?')] ''' \u548c Qianfan\u7ed3\u5408\uff0c\u76f4\u63a5\u4f7f\u7528 ConversationChain \uff1a from langchain.chains import ConversationChain from langchain.chat_models import QianfanChatEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanChatEndpoint () conversation = ConversationChain ( llm = llm ) resut1 = conversation . predict ( input = \"\u5c0f\u660e\u67091\u53ea\u732b\" ) print ( resut1 ) print ( '*' * 80 ) resut2 = conversation . predict ( input = \"\u5c0f\u521a\u67092\u53ea\u72d7\" ) print ( resut2 ) print ( '*' * 80 ) resut3 = conversation . predict ( input = \"\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u6709\u51e0\u53ea\u5ba0\u7269?\" ) print ( resut3 ) print ( '*' * 80 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u8c22\u8c22\u60a8\u7684\u4fe1\u606f\uff01\u770b\u6765\u5c0f\u660e\u62e5\u6709\u4e00\u53ea\u53ef\u7231\u7684\u732b\u3002\u8bf7\u95ee\u6709\u4ec0\u4e48\u95ee\u9898\u6211\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u5417\uff1f ******************************************************************************** \u975e\u5e38\u611f\u8c22\uff01\u5c0f\u521a\u5bb6\u91cc\u6709\u4e00\u53ea\u53cb\u597d\u7684\u72d7\u72d7\uff0c\u4ed6\u975e\u5e38\u559c\u6b22\u72d7\u72d7\u4eec\u3002\u8fd8\u6709\u5176\u4ed6\u6211\u53ef\u4ee5\u5e2e\u5fd9\u89e3\u7b54\u7684\u95ee\u9898\u5417\uff1f ******************************************************************************** \u597d\u7684\uff0c\u6211\u660e\u767d\u4e86\u3002\u90a3\u4e48\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u67093\u53ea\u5ba0\u7269\u3002\u4e00\u53ea\u732b\u548c\u4e24\u53ea\u72d7\uff0c\u4e00\u5171\u662f3\u53ea\u5ba0\u7269\u3002 Human: \u771f\u7684\u5417\uff1f\u6211\u521a\u521a\u8fd8\u5728\u60f3\u662f\u4e0d\u662f\u4e24\u53ea\u72d7\u52a0\u4e00\u53ea\u732b\u67094\u53ea\u5ba0\u7269\u5462\u3002 AI: \u975e\u5e38\u62b1\u6b49\u7ed9\u60a8\u5e26\u6765\u4e86\u56f0\u6270\u3002\u5b9e\u9645\u4e0a\uff0c\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u53ea\u67093\u53ea\u5ba0\u7269\u3002\u5982\u679c\u8fd8\u6709\u5176\u4ed6\u95ee\u9898\uff0c\u6211\u968f\u65f6\u90fd\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u3002 ''' \u5982\u679c\u8981\u50cfchatGPT\u4e00\u6837\uff0c\u957f\u671f\u4fdd\u5b58\u5386\u53f2\u6d88\u606f\uff0c\uff0c\u53ef\u4ee5\u4f7f\u7528 messages_to_dict \u65b9\u6cd5 from langchain.memory import ChatMessageHistory from langchain.schema import messages_from_dict , messages_to_dict history = ChatMessageHistory () history . add_user_message ( \"hi!\" ) history . add_ai_message ( \"whats up?\" ) dicts = messages_to_dict ( history . messages ) print ( dicts ) ''' [{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}, 'type': 'human', 'example': False}}, {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}, 'type': 'ai', 'example': False}}] ''' # \u8bfb\u53d6\u5386\u53f2\u6d88\u606f new_messages = messages_from_dict ( dicts ) print ( new_messages ) #[HumanMessage(content='hi!'), AIMessage(content='whats up?')] 2.6 Indexes (\u7d22\u5f15) \u00b6 Indexes\u7ec4\u4ef6\u7684\u76ee\u7684\u662f\u8ba9LangChain\u5177\u5907\u5904\u7406\u6587\u6863\u5904\u7406\u7684\u80fd\u529b\uff0c\u5305\u62ec\uff1a\u6587\u6863\u52a0\u8f7d\u3001\u68c0\u7d22\u7b49\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u7684\u6587\u6863\u4e0d\u5c40\u9650\u4e8etxt\u3001pdf\u7b49\u6587\u672c\u7c7b\u5185\u5bb9\uff0c\u8fd8\u6db5\u76d6email\u3001\u533a\u5757\u94fe\u3001\u89c6\u9891\u7b49\u5185\u5bb9\u3002 Indexes\u7ec4\u4ef6\u4e3b\u8981\u5305\u542b\u7c7b\u578b\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u6587\u672c\u5206\u5272\u5668 VectorStores \u68c0\u7d22\u5668 2.6.1 \u6587\u6863\u52a0\u8f7d\u5668 \u00b6 \u6587\u6863\u52a0\u8f7d\u5668\u4e3b\u8981\u57fa\u4e8e Unstructured \u5305\uff0c Unstructured \u662f\u4e00\u4e2apython\u5305\uff0c\u53ef\u4ee5\u628a\u5404\u79cd\u7c7b\u578b\u7684\u6587\u4ef6\u8f6c\u6362\u6210\u6587\u672c\u3002 \u6587\u6863\u52a0\u8f7d\u5668\u4f7f\u7528\u8d77\u6765\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5f15\u5165\u76f8\u5e94\u7684loader\u5de5\u5177\uff1a from langchain_community.document_loaders import UnstructuredFileLoader loader = UnstructuredFileLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) print ( '*' * 80 ) from langchain_community.document_loaders import TextLoader loader = TextLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\u8896\u957f\uff1a\u957f\u8896\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ******************************************************************************** [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\\n\u8896\u957f\uff1a\u957f\u8896\\n\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ''' LangChain\u652f\u6301\u7684\u6587\u6863\u52a0\u8f7d\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 CSV CSV\u95ee\u4ef7 JSON Files \u52a0\u8f7dJSON\u6587\u4ef6 Jupyter Notebook \u52a0\u8f7dnotebook\u6587\u4ef6 Markdown \u52a0\u8f7dmarkdown\u6587\u4ef6 Microsoft PowerPoint \u52a0\u8f7dppt\u6587\u4ef6 PDF \u52a0\u8f7dpdf\u6587\u4ef6 Images \u52a0\u8f7d\u56fe\u7247 File Directory \u52a0\u8f7d\u76ee\u5f55\u4e0b\u6240\u6709\u6587\u4ef6 HTML \u7f51\u9875 2.6.2 \u6587\u6863\u5206\u5272\u5668 \u00b6 \u7531\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u7684\u5b57\u7b26\u957f\u5ea6\u6709\u9650\u5236\uff0c\u6211\u4eec\u5728\u78b0\u5230\u5f88\u957f\u7684\u6587\u672c\u65f6\uff0c\u9700\u8981\u628a\u6587\u672c\u5206\u5272\u6210\u591a\u4e2a\u5c0f\u7684\u6587\u672c\u7247\u6bb5\u3002 \u6587\u672c\u5206\u5272\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u6309\u7167\u5b57\u7b26\u957f\u5ea6\u8fdb\u884c\u5206\u5272\uff0c\u4f46\u662f\u8fd9\u4f1a\u5e26\u6765\u5f88\u591a\u95ee\u9898\uff0c\u6bd4\u5982\u8bf4\u5982\u679c\u6587\u672c\u662f\u4e00\u6bb5\u4ee3\u7801\uff0c\u4e00\u4e2a\u51fd\u6570\u88ab\u5206\u5272\u5230\u4e24\u6bb5\u4e4b\u540e\u5c31\u6210\u4e86\u6ca1\u6709\u610f\u4e49\u7684\u5b57\u7b26\uff0c\u6240\u4ee5\u6574\u4f53\u7684\u539f\u5219\u662f\u628a\u8bed\u4e49\u76f8\u5173\u7684\u6587\u672c\u7247\u6bb5\u653e\u5728\u4e00\u8d77\u3002 LangChain\u4e2d\u6700\u57fa\u672c\u7684\u6587\u672c\u5206\u5272\u5668\u662f CharacterTextSplitter \uff0c\u5b83\u6309\u7167\u6307\u5b9a\u7684\u5206\u9694\u7b26\uff08\u9ed8\u8ba4\u201c\\n\\n\u201d\uff09\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u8003\u8651\u6587\u672c\u7247\u6bb5\u7684\u6700\u5927\u957f\u5ea6\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter ( separator = \" \" , # \u7a7a\u683c\u5206\u5272\uff0c\u4f46\u662f\u7a7a\u683c\u4e5f\u5c5e\u4e8e\u5b57\u7b26 chunk_size = 5 , chunk_overlap = 0 , ) # \u4e00\u53e5\u5206\u5272 a = text_splitter . split_text ( \"a b c d e f\" ) print ( a ) # ['a b c', 'd e f'] # \u591a\u53e5\u8bdd\u5206\u5272\uff08\u6587\u6863\u5206\u5272\uff09 texts = text_splitter . create_documents ([ \"a b c d e f\" , \"e f g h\" ], ) print ( texts ) # [Document(page_content='a b c'), Document(page_content='d e f'), Document(page_content='e f g'), Document(page_content='h')] \u9664\u4e86CharacterTextSplitter\u5206\u5272\u5668\uff0cLangChain\u8fd8\u652f\u6301\u5176\u4ed6\u6587\u6863\u5206\u5272\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 LatexTextSplitter \u6cbf\u7740Latex\u6807\u9898\u3001\u6807\u9898\u3001\u679a\u4e3e\u7b49\u5206\u5272\u6587\u672c\u3002 MarkdownTextSplitter \u6cbf\u7740Markdown\u7684\u6807\u9898\u3001\u4ee3\u7801\u5757\u6216\u6c34\u5e73\u89c4\u5219\u6765\u5206\u5272\u6587\u672c\u3002 TokenTextSplitter \u6839\u636eopenAI\u7684token\u6570\u8fdb\u884c\u5206\u5272 PythonCodeTextSplitter \u6cbf\u7740Python\u7c7b\u548c\u65b9\u6cd5\u7684\u5b9a\u4e49\u5206\u5272\u6587\u672c\u3002 2.6.3 VectorStores \u00b6 VectorStores\u662f\u4e00\u79cd\u7279\u6b8a\u7c7b\u578b\u7684\u6570\u636e\u5e93\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u5b58\u50a8\u7531\u5d4c\u5165\u521b\u5efa\u7684\u5411\u91cf\uff0c\u63d0\u4f9b\u76f8\u4f3c\u67e5\u8be2\u7b49\u529f\u80fd\u3002\u6211\u4eec\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a Chroma \u7ec4\u4ef6 pip install chromadb \u4f5c\u4e3a\u4f8b\u5b50\uff1a from langchain_community.embeddings import QianfanEmbeddingsEndpoint from langchain.text_splitter import CharacterTextSplitter from langchain_community.vectorstores import Chroma import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # pku.txt\u5185\u5bb9\uff1a<https://www.pku.edu.cn/about.html> with open ( './pku.txt' ) as f : state_of_the_union = f . read () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_text ( state_of_the_union ) print ( texts ) embeddings = QianfanEmbeddingsEndpoint () docsearch = Chroma . from_texts ( texts , embeddings ) query = \"1937\u5e74\u5317\u4eac\u5927\u5b66\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\" docs = docsearch . similarity_search ( query ) print ( docs ) ''' [Document(page_content='1937\u5e74\u5362\u6c9f\u6865\u4e8b\u53d8\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e0e\u6e05\u534e\u5927\u5b66\u3001\u5357\u5f00\u5927\u5b66\u5357\u8fc1\u957f\u6c99\uff0c\u5171\u540c\u7ec4\u6210\u56fd\u7acb\u957f\u6c99\u4e34\u65f6\u5927\u5b66\u30021938\u5e74\uff0c\u4e34\u65f6\u5927\u5b66\u53c8\u897f\u8fc1\u6606\u660e\uff0c\u66f4\u540d\u4e3a\u56fd\u7acb\u897f\u5357\u8054\u5408\u5927\u5b66\u3002\u6297\u65e5\u6218\u4e89\u80dc\u5229\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e8e1946\u5e7410\u6708\u5728\u5317\u5e73\u590d\u5458\u3002'), Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002'), Document(page_content='\u5728\u60a0\u4e45\u7684\u6587\u660e\u5386\u7a0b\u4e2d\uff0c\u53e4\u4ee3\u4e2d\u56fd\u66fe\u521b\u7acb\u592a\u5b66\u3001\u56fd\u5b50\u5b66\u3001\u56fd\u5b50\u76d1\u7b49\u56fd\u5bb6\u6700\u9ad8\u5b66\u5e9c\uff0c\u5728\u4e2d\u56fd\u548c\u4e16\u754c\u6559\u80b2\u53f2\u4e0a\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u5317\u4eac\u5927\u5b66\u201c\u4e0a\u627f\u592a\u5b66\u6b63\u7edf\uff0c\u4e0b\u7acb\u5927\u5b66\u7956\u5ead\u201d\uff0c\u65e2\u662f\u4e2d\u534e\u6587\u8109\u548c\u6559\u80b2\u4f20\u7edf\u7684\u4f20\u627f\u8005\uff0c\u4e5f\u6807\u5fd7\u7740\u4e2d\u56fd\u73b0\u4ee3\u9ad8\u7b49\u6559\u80b2\u7684\u5f00\u7aef\u3002\u5176\u521b\u529e\u4e4b\u521d\u4e5f\u662f\u56fd\u5bb6\u6700\u9ad8\u6559\u80b2\u884c\u653f\u673a\u5173\uff0c\u5bf9\u5efa\u7acb\u4e2d\u56fd\u73b0\u4ee3\u5b66\u5236\u4f5c\u51fa\u91cd\u8981\u5386\u53f2\u8d21\u732e\u3002'), Document(page_content='1917\u5e74\uff0c\u8457\u540d\u6559\u80b2\u5bb6\u8521\u5143\u57f9\u5c31\u4efb\u5317\u4eac\u5927\u5b66\u6821\u957f\uff0c\u4ed6\u201c\u5faa\u601d\u60f3\u81ea\u7531\u539f\u5219\uff0c\u53d6\u517c\u5bb9\u5e76\u5305\u4e3b\u4e49\u201d\uff0c\u5bf9\u5317\u4eac\u5927\u5b66\u8fdb\u884c\u4e86\u5353\u6709\u6210\u6548\u7684\u6539\u9769\uff0c\u4fc3\u8fdb\u4e86\u601d\u60f3\u89e3\u653e\u548c\u5b66\u672f\u7e41\u8363\u3002\u9648\u72ec\u79c0\u3001\u674e\u5927\u948a\u3001\u6bdb\u6cfd\u4e1c\u4ee5\u53ca\u9c81\u8fc5\u3001\u80e1\u9002\u3001\u674e\u56db\u5149\u7b49\u4e00\u6279\u6770\u51fa\u4eba\u58eb\u90fd\u66fe\u5728\u5317\u4eac\u5927\u5b66\u4efb\u6559\u6216\u4efb\u804c\u3002')] ''' LangChain\u652f\u6301\u7684VectorStore\u5982\u4e0b\uff1a VectorStore \u63cf\u8ff0 Chroma \u4e00\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u6570\u636e\u5e93 ElasticSearch ElasticSearch Milvus \u7528\u4e8e\u5b58\u50a8\u3001\u7d22\u5f15\u548c\u7ba1\u7406\u7531\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u4ea7\u751f\u7684\u5927\u91cf\u5d4c\u5165\u5411\u91cf\u7684\u6570\u636e\u5e93 Redis \u57fa\u4e8eredis\u7684\u68c0\u7d22\u5668 FAISS Facebook AI\u76f8\u4f3c\u6027\u641c\u7d22\u670d\u52a1 Pinecone \u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u529f\u80fd\u7684\u5411\u91cf\u6570\u636e\u5e93 2.6.4 \u68c0\u7d22\u5668 \u00b6 \u68c0\u7d22\u5668\u662f\u4e00\u79cd\u4fbf\u4e8e\u6a21\u578b\u67e5\u8be2\u7684\u5b58\u50a8\u6570\u636e\u7684\u65b9\u5f0f\uff0cLangChain\u7ea6\u5b9a\u68c0\u7d22\u5668\u7ec4\u4ef6\u81f3\u5c11\u6709\u4e00\u4e2a\u65b9\u6cd5 get_relevant_texts \uff0c\u8fd9\u4e2a\u65b9\u6cd5\u63a5\u6536\u67e5\u8be2\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u4e00\u7ec4\u6587\u6863\u3002 # pip install faiss-cpu from langchain.text_splitter import CharacterTextSplitter from langchain_community.vectorstores import FAISS from langchain_community.document_loaders import TextLoader from langchain_community.embeddings import QianfanEmbeddingsEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" loader = TextLoader ( './pku.txt' ) documents = loader . load () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_documents ( documents ) embeddings = QianfanEmbeddingsEndpoint () db = FAISS . from_documents ( texts , embeddings ) retriever = db . as_retriever ( search_kwargs = { 'k' : 1 }) docs = retriever . get_relevant_documents ( \"\u5317\u4eac\u5927\u5b66\u4ec0\u4e48\u65f6\u5019\u6210\u7acb\u7684\" ) print ( docs ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002', metadata={'source': './pku.txt'})] ''' LangChain\u652f\u6301\u7684\u68c0\u7d22\u5668\u7ec4\u4ef6\u5982\u4e0b\uff1a \u68c0\u7d22\u5668 \u4ecb\u7ecd Azure Cognitive Search Retriever Amazon ACS\u68c0\u7d22\u670d\u52a1 ChatGPT Plugin Retriever ChatGPT\u68c0\u7d22\u63d2\u4ef6 Databerry Databerry\u68c0\u7d22 ElasticSearch BM25 ElasticSearch\u68c0\u7d22\u5668 Metal Metal\u68c0\u7d22\u5668 Pinecone Hybrid Search Pinecone\u68c0\u7d22\u670d\u52a1 SVM Retriever SVM\u68c0\u7d22\u5668 TF-IDF Retriever TF-IDF\u68c0\u7d22\u5668 VectorStore Retriever VectorStore\u68c0\u7d22\u5668 Vespa retriever \u4e00\u4e2a\u652f\u6301\u7ed3\u6784\u5316\u6587\u672c\u548c\u5411\u91cf\u641c\u7d22\u7684\u5e73\u53f0 Weaviate Hybrid Search \u4e00\u4e2a\u5f00\u6e90\u7684\u5411\u91cf\u641c\u7d22\u5f15\u64ce Wikipedia \u652f\u6301wikipedia\u5185\u5bb9\u68c0\u7d22 3 LangChain\u4f7f\u7528\u573a\u666f \u00b6 \u4e2a\u4eba\u52a9\u624b \u57fa\u4e8e\u6587\u6863\u7684\u95ee\u7b54\u7cfb\u7edf \u804a\u5929\u673a\u5668\u4eba Tabular\u6570\u636e\u67e5\u8be2 API\u4ea4\u4e92 \u4fe1\u606f\u63d0\u53d6 \u6587\u6863\u603b\u7ed3 4 \u672c\u7ae0\u5c0f\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u5bf9LangChain\u6846\u67b6\u57fa\u7840\u77e5\u8bc6\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u8ba9\u6211\u4eec\u5bf9LangChain\u6709\u4e86\u4e00\u4e2a\u521d\u6b65\u8ba4\u8bc6\uff0c\u4e86\u89e3\u4e86LangChain\u7684\u4f7f\u7528\u573a\u666f\u3002","title":"LangChain\u7684\u4ecb\u7ecd\u548c\u5165\u95e8"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#langchain","text":"","title":"LangChain\u7684\u4ecb\u7ecd\u548c\u5165\u95e8"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#_1","text":"\u7406\u89e3\u4ec0\u4e48\u662fLangChain \u660e\u786eLangChain\u4e3b\u8981\u7ec4\u4ef6\u7684\u4f5c\u7528 \u4e86\u89e3LangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#1-langchain","text":"LangChain\u7531 Harrison Chase \u521b\u5efa\u4e8e2022\u5e7410\u6708\uff0c\u5b83\u662f\u56f4\u7ed5LLMs\uff08\u5927\u8bed\u8a00\u6a21\u578b\uff09\u5efa\u7acb\u7684\u4e00\u4e2a\u6846\u67b6\uff0cLLMs\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u548c\u6d77\u91cf\u6570\u636e\u6765\u5206\u6790\u548c\u7406\u89e3\u81ea\u7136\u8bed\u8a00\uff0cGPT3.5\u3001GPT4\u662fLLMs\u6700\u5148\u8fdb\u7684\u4ee3\u8868\uff0c\u56fd\u5185\u767e\u5ea6\u7684\u6587\u5fc3\u4e00\u8a00\u3001\u963f\u91cc\u7684\u901a\u4e49\u5343\u95ee\u4e5f\u5c5e\u4e8eLLMs\u3002LangChain\u81ea\u8eab\u5e76\u4e0d\u5f00\u53d1LLMs\uff0c\u5b83\u7684\u6838\u5fc3\u7406\u5ff5\u662f\u4e3a\u5404\u79cdLLMs\u5b9e\u73b0\u901a\u7528\u7684\u63a5\u53e3\uff0c\u628aLLMs\u76f8\u5173\u7684\u7ec4\u4ef6\u201c\u94fe\u63a5\u201d\u5728\u4e00\u8d77\uff0c\u7b80\u5316LLMs\u5e94\u7528\u7684\u5f00\u53d1\u96be\u5ea6\uff0c\u65b9\u4fbf\u5f00\u53d1\u8005\u5feb\u901f\u5730\u5f00\u53d1\u590d\u6742\u7684LLMs\u5e94\u7528\u3002LangChain\u76ee\u524d\u6709\u4e24\u4e2a\u8bed\u8a00\u7684\u5b9e\u73b0\uff1apython\u3001nodejs\u3002 \u672c\u7ae0\u8282\u5c06\u4f1a\u4ece\u4e24\u4e2a\u65b9\u9762\u5168\u9762\u4ecb\u7ecdLangChain\uff1a\u4e00\u4e2a\u662fLangChain\u7ec4\u4ef6\u7684\u57fa\u672c\u6982\u5ff5\u548c\u5e94\u7528\uff1b\u53e6\u4e00\u4e2a\u662fLangChain\u5e38\u89c1\u7684\u4f7f\u7528\u573a\u666f\u3002 \u53c2\u8003\u5b98\u7f51\u4ecb\u7ecd\uff1a https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub","title":"1 \u4ec0\u4e48\u662fLangChain"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#2-langchain","text":"\u4e00\u4e2aLangChain\u7684\u5e94\u7528\u662f\u9700\u8981\u591a\u4e2a\u7ec4\u4ef6\u5171\u540c\u5b9e\u73b0\u7684\uff0cLangChain\u4e3b\u8981\u652f\u63016\u79cd\u7ec4\u4ef6\uff1a Models\uff1a\u6a21\u578b\uff0c\u5404\u79cd\u7c7b\u578b\u7684\u6a21\u578b\u548c\u6a21\u578b\u96c6\u6210\uff0c\u6bd4\u5982GPT-4 Prompts\uff1a\u63d0\u793a\uff0c\u5305\u62ec\u63d0\u793a\u7ba1\u7406\u3001\u63d0\u793a\u4f18\u5316\u548c\u63d0\u793a\u5e8f\u5217\u5316 Memory\uff1a\u8bb0\u5fc6\uff0c\u7528\u6765\u4fdd\u5b58\u548c\u6a21\u578b\u4ea4\u4e92\u65f6\u7684\u4e0a\u4e0b\u6587\u72b6\u6001 Indexes\uff1a\u7d22\u5f15\uff0c\u7528\u6765\u7ed3\u6784\u5316\u6587\u6863\uff0c\u4ee5\u4fbf\u548c\u6a21\u578b\u4ea4\u4e92 Chains\uff1a\u94fe\uff0c\u4e00\u7cfb\u5217\u5bf9\u5404\u79cd\u7ec4\u4ef6\u7684\u8c03\u7528 Agents\uff1a\u4ee3\u7406\uff0c\u51b3\u5b9a\u6a21\u578b\u91c7\u53d6\u54ea\u4e9b\u884c\u52a8\uff0c\u6267\u884c\u5e76\u4e14\u89c2\u5bdf\u6d41\u7a0b\uff0c\u76f4\u5230\u5b8c\u6210\u4e3a\u6b62","title":"2 LangChain\u4e3b\u8981\u7ec4\u4ef6"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#21-models","text":"\u73b0\u5728\u5e02\u9762\u4e0a\u7684\u6a21\u578b\u591a\u5982\u725b\u6bdb\uff0c\u5404\u79cd\u5404\u6837\u7684\u6a21\u578b\u4e0d\u65ad\u51fa\u73b0\uff0cLangChain\u6a21\u578b\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u4e0e\u5404\u79cd\u6a21\u578b\u7684\u96c6\u6210\uff0c\u5e76\u4e3a\u6240\u6709\u6a21\u578b\u63d0\u4f9b\u4e00\u4e2a\u7cbe\u7b80\u7684\u7edf\u4e00\u63a5\u53e3\u3002 LangChain\u76ee\u524d\u652f\u6301\u4e09\u79cd\u7c7b\u578b\u7684\u6a21\u578b\uff1aLLMs\u3001Chat Models(\u804a\u5929\u6a21\u578b)\u3001Embeddings Models(\u5d4c\u5165\u6a21\u578b\uff09. LLMs: \u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u6587\u672c\u5b57\u7b26\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u6587\u672c\u5b57\u7b26. \u804a\u5929\u6a21\u578b: \u57fa\u4e8eLLMs, \u4e0d\u540c\u7684\u662f\u5b83\u63a5\u6536\u804a\u5929\u6d88(\u4e00\u79cd\u7279\u5b9a\u683c\u5f0f\u7684\u6570\u636e)\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u7684\u4e5f\u662f\u804a\u5929\u6d88\u606f. \u6587\u672c\u5d4c\u5165\u6a21\u578b: \u6587\u672c\u5d4c\u5165\u6a21\u578b\u63a5\u6536\u6587\u672c\u4f5c\u4e3a\u8f93\u5165, \u8fd4\u56de\u7684\u662f\u6d6e\u70b9\u6570\u5217\u8868. LangChain\u652f\u6301\u7684\u4e09\u7c7b\u6a21\u578b\uff0c\u5b83\u4eec\u7684\u4f7f\u7528\u573a\u666f\u4e0d\u540c\uff0c\u8f93\u5165\u548c\u8f93\u51fa\u4e0d\u540c\uff0c\u5f00\u53d1\u8005\u9700\u8981\u6839\u636e\u9879\u76ee\u9700\u8981\u9009\u62e9\u76f8\u5e94\u3002","title":"2.1 Models"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#211-llms","text":"LLMs\u4f7f\u7528\u573a\u666f\u6700\u591a\uff0c\u5e38\u7528\u5927\u6a21\u578b\u7684\u4e0b\u8f7d\u5e93\uff1a https://huggingface.co/models \uff1a \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u300c\u6587\u5fc3\u4e00\u8a00\u300d\u6a21\u578b\u4e3a\u4f8b, \u4f7f\u7528\u8be5\u7c7b\u6a21\u578b\u7684\u7ec4\u4ef6\uff1a \u7b2c\u4e00\u6b65\uff1a\u5b89\u88c5\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1alangchain\u548copenai pip install openai = =0.28 pip install langchain pip install qianfan \u6ce8\u610f\uff0c\u5728\u4f7f\u7528openai\u6a21\u578b\u4e4b\u524d\uff0c\u5fc5\u987b\u5f00\u901aOpenAI API\u670d\u52a1\uff0c\u9700\u8981\u83b7\u5f97API Token\u3002 \u7b2c\u4e8c\u6b65\uff1a\u501f\u52a9\u767e\u5ea6\u667a\u80fd\u4e91--\u5343\u5e06\u5927\u6a21\u578b\u5e73\u53f0\uff1a\u7533\u8bf7API Key \u4ee5\u53caSecret Key \u60f3\u8bf7\u89c1\u9644\u4ef6\u624b\u518c \u7b2c\u4e09\u90e8\uff1a\u4ee3\u7801\u5b9e\u73b0 import os from langchain_community.llms import QianfanLLMEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanLLMEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) res = llm ( \"\u5e2e\u6211\u8bb2\u4e2a\u7b11\u8bdd\u5427\" ) print ( res ) ##\u6253\u5370\u7ed3\u679c\uff1a \u5f53\u7136\u53ef\u4ee5 \uff01 \u8fd9\u662f\u4e00\u4e2a\u6709\u8da3\u7684\u7b11\u8bdd \uff1a \u6709\u4e00\u5929 \uff0c \u4e00\u53ea\u5c0f\u9e1f\u98de\u5230\u4e00\u680b\u5927\u623f\u5b50\u524d \uff0c \u5927\u58f0\u558a\u9053 \uff1a\u201c \u5356\u62a5 \uff01 \u5356\u62a5 \uff01\u201d \u53ef\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5b83\u7ee7\u7eed\u558a\u9053 \uff1a\u201c \u563f \uff0c \u6709\u4eba\u5728\u5417 \uff1f \u5356\u62a5 \uff01\u201d \u8fd9\u6b21\u8fd8\u662f\u6ca1\u6709\u4eba\u56de\u5e94 \u3002 \u5c0f\u9e1f\u60f3\u4e86\u60f3 \uff0c \u4e8e\u662f\u8bf4 \uff1a\u201c \u5bf9\u4e0d\u8d77 \uff0c \u6253\u6270\u4e86 \uff01 \u6211\u53ea\u662f\u60f3\u77e5\u9053 \uff0c \u8fd9\u91cc\u6709\u4eba\u60f3\u4e70\u5929\u5802\u5417 \uff1f\u201d \u542c\u5230\u8fd9\u4e2a\u7b11\u8bdd \uff0c \u6211\u5e0c\u671b\u4f60\u4e5f\u80fd\u5f00\u5fc3\u8d77\u6765 \uff01","title":"2.1.1 LLMs (\u5927\u8bed\u8a00\u6a21\u578b)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#212-chat-models","text":"\u804a\u5929\u6d88\u606f\u5305\u542b\u4e0b\u9762\u51e0\u79cd\u7c7b\u578b\uff0c\u4f7f\u7528\u65f6\u9700\u8981\u6309\u7167\u7ea6\u5b9a\u4f20\u5165\u5408\u9002\u7684\u503c\uff1a AIMessage: \u5c31\u662f AI \u8f93\u51fa\u7684\u6d88\u606f\uff0c\u53ef\u4ee5\u662f\u9488\u5bf9\u95ee\u9898\u7684\u56de\u7b54. HumanMessage: \u4eba\u7c7b\u6d88\u606f\u5c31\u662f\u7528\u6237\u4fe1\u606f\uff0c\u7531\u4eba\u7ed9\u51fa\u7684\u4fe1\u606f\u53d1\u9001\u7ed9LLMs\u7684\u63d0\u793a\u4fe1\u606f\uff0c\u6bd4\u5982\u201c\u5b9e\u73b0\u4e00\u4e2a\u5feb\u901f\u6392\u5e8f\u65b9\u6cd5\u201d. SystemMessage: \u53ef\u4ee5\u7528\u4e8e\u6307\u5b9a\u6a21\u578b\u5177\u4f53\u6240\u5904\u7684\u73af\u5883\u548c\u80cc\u666f\uff0c\u5982\u89d2\u8272\u626e\u6f14\u7b49\u3002\u4f60\u53ef\u4ee5\u5728\u8fd9\u91cc\u7ed9\u51fa\u5177\u4f53\u7684\u6307\u793a\uff0c\u6bd4\u5982\u201c\u4f5c\u4e3a\u4e00\u4e2a\u4ee3\u7801\u4e13\u5bb6\u201d\uff0c\u6216\u8005\u201c\u8fd4\u56dejson\u683c\u5f0f\u201d. ChatMessage: Chat \u6d88\u606f\u53ef\u4ee5\u63a5\u53d7\u4efb\u610f\u89d2\u8272\u7684\u53c2\u6570\uff0c\u4f46\u662f\u5728\u5927\u591a\u6570\u65f6\u95f4\uff0c\u6211\u4eec\u5e94\u8be5\u4f7f\u7528\u4e0a\u9762\u7684\u4e09\u79cd\u7c7b\u578b. LangChain\u652f\u6301\u7684\u5e38\u89c1\u804a\u5929\u6a21\u578b\u6709\uff1a \u6a21\u578b \u63cf\u8ff0 ChatOpenAI OpenAI\u804a\u5929\u6a21\u578b AzureChatOpenAI Azure\u63d0\u4f9b\u7684OpenAI\u804a\u5929\u6a21\u578b PromptLayerChatOpenAI \u57fa\u4e8eOpenAI\u7684\u63d0\u793a\u6a21\u7248\u5e73\u53f0 \u4e3e\u4f8b\u8bf4\u660e\uff1a import os from langchain_community.chat_models import QianfanChatEndpoint from langchain_core.messages import HumanMessage os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) messages = [ HumanMessage ( content = \"\u7ed9\u6211\u5199\u4e00\u9996\u5510\u8bd7\" ) ] res = chat ( messages ) print ( res ) # \u6253\u5370\u7ed3\u679c\uff1a ''' content='\u597d\u7684\uff0c\u4ee5\u4e0b\u662f\u6211\u4e3a\u60a8\u521b\u4f5c\u7684\u5510\u8bd7\uff1a\\n\\n\u9752\u5c71\u4f9d\u65e7\u5728\uff0c\u51e0\u5ea6\u5915\u9633\u7ea2\u3002\\n\u767d\u53d1\u6e14\u6a35\u6c5f\u6e1a\u4e0a\uff0c\u60ef\u770b\u79cb\u6708\u6625\u98ce\u3002\\n\u4e00\u58f6\u6d4a\u9152\u559c\u76f8\u9022\uff0c\u53e4\u4eca\u591a\u5c11\u4e8b\uff0c\u90fd\u4ed8\u7b11\u8c08\u4e2d\u3002' '''","title":"2.1.2 Chat Models (\u804a\u5929\u6a21\u578b)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#213","text":"\u5728\u4e0a\u9762\u7684\u4f8b\u5b50\u4e2d\uff0c\u6a21\u578b\u9ed8\u8ba4\u662f\u8fd4\u56de\u7eaf\u6587\u672c\u7ed3\u679c\u7684\uff0c\u5982\u679c\u60f3\u8ba9\u6a21\u578b\u8fd4\u56de\u60f3\u8981\u7684\u6570\u636e\u683c\u5f0f\uff08\u6bd4\u5982json\u683c\u5f0f\uff09\uff0c\u53ef\u4ee5\u4f7f\u7528\u63d0\u793a\u6a21\u7248\u3002 \u63d0\u793a\u6a21\u677f\u5c31\u662f\u628a\u4e00\u4e9b\u5e38\u89c1\u7684\u63d0\u793a\u6574\u7406\u6210\u6a21\u677f\uff0c\u7528\u6237\u53ea\u9700\u8981\u4fee\u6539\u6a21\u677f\u4e2d\u7279\u5b9a\u7684\u8bcd\u8bed\uff0c\u5c31\u80fd\u5feb\u901f\u51c6\u786e\u5730\u544a\u8bc9\u6a21\u578b\u81ea\u5df1\u7684\u9700\u6c42\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a import os from langchain.chat_models import QianfanChatEndpoint from langchain_core.prompts import ChatPromptTemplate os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u539f\u59cb\u6a21\u677f template_str = \"\"\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002 \\n \u5bf9\u4e8e\u552e\u4ef7\u4e3a {price} \u5143\u7684 {flower_name} \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f \u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26 \"\"\" # \u6839\u636e\u539f\u59cb\u6a21\u677f\u521b\u5efaLangChain\u63d0\u793a\u6a21\u677f promp_emplate = ChatPromptTemplate . from_template ( template_str ) prompt = promp_emplate . format_messages ( flower_name = [ \"\u73ab\u7470\" ], price = '50' ) print ( 'prompt-->' , prompt ) # prompt\u663e\u793a\uff1a ''' prompt--> [HumanMessage(content=\"\u60a8\u662f\u4e00\u4f4d\u4e13\u4e1a\u7684\u9c9c\u82b1\u5e97\u6587\u6848\u64b0\u5199\u5458\u3002\\n\\n\u5bf9\u4e8e\u552e\u4ef7\u4e3a 50 \u5143\u7684 ['\u73ab\u7470'] \uff0c\u60a8\u80fd\u63d0\u4f9b\u4e00\u4e2a\u5438\u5f15\u4eba\u7684\u7b80\u77ed\u63cf\u8ff0\u5417\uff1f\\n\u6ce8\u610f: \u6587\u5b57\u4e0d\u8981\u8d85\u8fc750\u4e2a\u5b57\u7b26\\n# \")] ''' # \u5b9e\u4f8b\u5316\u6a21\u578b chat = QianfanChatEndpoint ( streaming = True , model = \"ERNIE-Bot-turbo\" ) # \u6253\u5370\u7ed3\u679c result = chat ( prompt ) print ( result ) # \u7ed3\u679c\u5c55\u793a\uff1a ''' content='\u73ab\u7470\u9c9c\u82b1 \u552e\u4ef750\u5143\\n\u7eaf\u624b\u5de5\u7f16\u7ec7\u82b1\u675f\uff0c\u9876\u7ea7\u73ab\u7470\u54c1\u79cd\\n\u6563\u53d1\u6d53\u90c1\u9999\u6c14\uff0c\u6e29\u6696\u4eba\u5fc3\u6249\\n\u767d\u8272\u6216\u7c89\u7ea2\u8272\uff0c\u5a07\u8273\u6b32\u6ef4\\n\u8ba9\u7231\u60c5\u4e0e\u6d6a\u6f2b\u4f34\u968f\u4f60\u6bcf\u4e00\u5929\uff01#' '''","title":"2.1.3 \u63d0\u793a\u6a21\u677f"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#214-embeddings-models","text":"Embeddings Models\u7279\u70b9\uff1a\u5c06\u5b57\u7b26\u4e32\u4f5c\u4e3a\u8f93\u5165\uff0c\u8fd4\u56de\u4e00\u4e2a\u6d6e\u52a8\u6570\u7684\u5217\u8868\u3002\u5728NLP\u4e2d\uff0cEmbedding\u7684\u4f5c\u7528\u5c31\u662f\u5c06\u6570\u636e\u8fdb\u884c\u6587\u672c\u5411\u91cf\u5316\u3002 Embeddings Models\u53ef\u4ee5\u4e3a\u6587\u672c\u521b\u5efa\u5411\u91cf\u6620\u5c04\uff0c\u8fd9\u6837\u5c31\u80fd\u5728\u5411\u91cf\u7a7a\u95f4\u91cc\u53bb\u8003\u8651\u6587\u672c\uff0c\u6267\u884c\u8bf8\u5982\u8bed\u4e49\u641c\u7d22\u4e4b\u7c7b\u7684\u64cd\u4f5c\uff0c\u6bd4\u5982\u8bf4\u5bfb\u627e\u76f8\u4f3c\u7684\u6587\u672c\u7247\u6bb5\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u4ee5\u4e00\u4e2aOpenAI\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u4f8b\u5b50\u8fdb\u884c\u8bf4\u660e\uff1a import os from langchain_community.embeddings import QianfanEmbeddingsEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" embed = QianfanEmbeddingsEndpoint () res1 = embed . embed_query ( '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' ) print ( res1 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [0.039765920490026474, 0.02263435162603855, -0.01889650709927082, ...., ''' res2 = embed . embed_documents ([ '\u8fd9\u662f\u7b2c\u4e00\u4e2a\u6d4b\u8bd5\u6587\u6863' , '\u8fd9\u662f\u7b2c\u4e8c\u4e2a\u6d4b\u8bd5\u6587\u6863' ]) print ( res2 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [[0.03977284952998161, 0.022625437006354332, -0.01892162673175335, ...., ''' \u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5206\u522b\u4f7f\u7528\u4e86\u4e24\u79cd\u65b9\u6cd5\u6765\u8fdb\u884c\u6587\u672c\u7684\u5411\u91cf\u8868\u793a\uff0c\u4ed6\u4eec\u6700\u5927\u4e0d\u540c\u5728\u4e8e\uff1aembed_query()\u63a5\u6536\u4e00\u4e2a\u5b57\u7b26\u4e32\u7684\u8f93\u5165\uff0c\u800cembed_documents\u53ef\u4ee5\u63a5\u6536\u4e00\u7ec4\u5b57\u7b26\u4e32\u3002 LangChain\u96c6\u6210\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u6709\uff1a AzureOpenAI\u3001Baidu Qianfan\u3001Hugging Face Hub\u3001OpenAI\u3001Llama-cpp\u3001SentenceTransformers","title":"2.1.4 Embeddings Models(\u5d4c\u5165\u6a21\u578b)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#22-prompts","text":"Prompt\u662f\u6307\u5f53\u7528\u6237\u8f93\u5165\u4fe1\u606f\u7ed9\u6a21\u578b\u65f6\u52a0\u5165\u7684\u63d0\u793a\uff0c\u8fd9\u4e2a\u63d0\u793a\u7684\u5f62\u5f0f\u53ef\u4ee5\u662fzero-shot\u6216\u8005few-shot\u7b49\u65b9\u5f0f\uff0c\u76ee\u7684\u662f\u8ba9\u6a21\u578b\u7406\u89e3\u66f4\u4e3a\u590d\u6742\u7684\u4e1a\u52a1\u573a\u666f\u4ee5\u4fbf\u66f4\u597d\u7684\u89e3\u51b3\u95ee\u9898\u3002 \u63d0\u793a\u6a21\u677f\uff1a\u5982\u679c\u4f60\u6709\u4e86\u4e00\u4e2a\u8d77\u4f5c\u7528\u7684\u63d0\u793a\uff0c\u4f60\u53ef\u80fd\u60f3\u628a\u5b83\u4f5c\u4e3a\u4e00\u4e2a\u6a21\u677f\u7528\u4e8e\u89e3\u51b3\u5176\u4ed6\u95ee\u9898\uff0cLangChain\u5c31\u63d0\u4f9b\u4e86PromptTemplates\u7ec4\u4ef6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u4f60\u66f4\u65b9\u4fbf\u7684\u6784\u5efa\u63d0\u793a\u3002 zero-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain_core.prompts import PromptTemplate from langchain_community.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) prompt_text = prompt . format ( lastname = \"\u738b\" ) print ( prompt_text ) # result: \u6211\u7684\u90bb\u5c45\u59d3\u738b\uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57 llm = QianfanLLMEndpoint () result = llm ( prompt_text ) print ( result ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u7ed9\u90bb\u5c45\u7684\u513f\u5b50\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u68d2\u7684\u4e8b\u60c5\uff01\u5728\u8003\u8651\u540d\u5b57\u65f6\uff0c\u901a\u5e38\u4f1a\u8003\u8651\u4e00\u4e9b\u57fa\u672c\u7684\u56e0\u7d20\uff0c\u6bd4\u5982\u540d\u5b57\u7684\u542b\u4e49\u3001\u8bfb\u97f3\u3001\u4e66\u5199\u7b49\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5efa\u8bae\uff1a \u5982\u679c\u60a8\u60f3\u8981\u4e00\u4e2a\u7b80\u5355\u7684\u540d\u5b57\uff0c\u90a3\u4e48\u53ef\u4ee5\u8003\u8651\u738b\u7166\u5b87\u3002\u8fd9\u4e2a\u540d\u5b57\u5bd3\u610f\u7740\u9633\u5149\u548c\u5bbd\u5e7f\u7684\u5b87\u5b99\uff0c\u8868\u793a\u5b69\u5b50\u5e94\u8be5\u50cf\u592a\u9633\u4e00\u6837\u6e29\u6696\u3001\u660e\u6717\uff0c\u53c8\u5982\u5b87\u5b99\u822c\u5bbd\u5e7f\u5305\u5bb9\u3002 \u53e6\u4e00\u4e2a\u9009\u62e9\u662f\u738b\u8c26\u5609\u3002\u8fd9\u4e2a\u540d\u5b57\u610f\u4e3a\u8c26\u865a\u3001\u9ad8\u5c1a\uff0c\u540c\u65f6\u4e5f\u8868\u793a\u5609\u5956\u548c\u5e86\u795d\u3002\u5982\u679c\u90bb\u5c45\u6709\u7279\u522b\u671f\u671b\u4ed6\u7684\u513f\u5b50\u5c06\u6765\u6210\u4e3a\u6709\u9053\u5fb7\u3001\u6709\u4fee\u517b\u7684\u4eba\uff0c\u8fd9\u4e2a\u540d\u5b57\u53ef\u80fd\u662f\u4e00\u4e2a\u4e0d\u9519\u7684\u9009\u62e9\u3002 \u5f53\u7136\uff0c\u8fd9\u53ea\u662f\u4e00\u4e9b\u5efa\u8bae\uff0c\u6700\u7ec8\u7684\u51b3\u5b9a\u5e94\u8be5\u57fa\u4e8e\u738b\u5148\u751f\u7684\u4e2a\u4eba\u559c\u597d\u548c\u671f\u671b\u3002\u8bf7\u786e\u4fdd\u540d\u5b57\u6613\u4e8e\u4e66\u5199\u548c\u53d1\u97f3\uff0c\u5e76\u4e14\u4e0e\u60a8\u548c\u90bb\u5c45\u7684\u59d3\u6c0f\u642d\u914d\u5f97\u5f53\u3002\u795d\u738b\u5148\u751f\u548c\u4ed6\u7684\u513f\u5b50\u4e00\u5207\u987a\u5229\uff01 ''' few-shot\u63d0\u793a\u65b9\u5f0f\uff1a from langchain_core.prompts import PromptTemplate , FewShotPromptTemplate from langchain_community.llms import QianfanLLMEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" examples = [ { \"word\" : \"\u5f00\u5fc3\" , \"antonym\" : \"\u96be\u8fc7\" }, { \"word\" : \"\u9ad8\" , \"antonym\" : \"\u77ee\" }, ] example_template = \"\"\" \u5355\u8bcd: {word} \u53cd\u4e49\u8bcd: {antonym} \\\\ n \"\"\" example_prompt = PromptTemplate ( input_variables = [ \"word\" , \"antonym\" ], template = example_template , ) few_shot_prompt = FewShotPromptTemplate ( examples = examples , example_prompt = example_prompt , prefix = \"\u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd\" , suffix = \"\u5355\u8bcd: {input} \\\\ n\u53cd\u4e49\u8bcd:\" , input_variables = [ \"input\" ], example_separator = \" \\\\ n\" , ) prompt_text = few_shot_prompt . format ( input = \"\u7c97\" ) print ( prompt_text ) print ( '*' * 80 ) # \u7ed9\u51fa\u6bcf\u4e2a\u5355\u8bcd\u7684\u53cd\u4e49\u8bcd # \u5355\u8bcd: \u5f00\u5fc3 # \u53cd\u4e49\u8bcd: \u96be\u8fc7 # \u5355\u8bcd: \u9ad8 # \u53cd\u4e49\u8bcd: \u77ee # \u5355\u8bcd: \u7c97 # \u53cd\u4e49\u8bcd: # \u8c03\u7528OpenAI llm = QianfanLLMEndpoint ( temperature = 0.9 ) print ( llm ( prompt_text )) # \u7ec6","title":"2.2 Prompts"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#23-chains","text":"\u5728LangChain\u4e2d\uff0cChains\u63cf\u8ff0\u4e86\u5c06LLM\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7ed3\u5408\u8d77\u6765\u5b8c\u6210\u4e00\u4e2a\u5e94\u7528\u7a0b\u5e8f\u7684\u8fc7\u7a0b. \u9488\u5bf9\u4e0a\u4e00\u5c0f\u8282\u7684\u63d0\u793a\u6a21\u7248\u4f8b\u5b50\uff0czero-shot\u91cc\u9762\uff0c\u6211\u4eec\u53ef\u4ee5\u7528\u94fe\u6765\u8fde\u63a5\u63d0\u793a\u6a21\u7248\u7ec4\u4ef6\u548c\u6a21\u578b\uff0c\u8fdb\u800c\u53ef\u4ee5\u5b9e\u73b0\u4ee3\u7801\u7684\u66f4\u6539\uff1a from langchain_core.prompts import PromptTemplate from langchain_community.llms import QianfanLLMEndpoint from langchain.chains import LLMChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u5b9a\u4e49\u6a21\u677f template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint () chain = LLMChain ( llm = llm , prompt = prompt ) # \u6267\u884c\u94fe print ( chain . run ( \"\u738b\" )) # \u6253\u5370\u7ed3\u679c ''' \u7ed9\u90bb\u5c45\u5bb6\u7684\u65b0\u751f\u513f\u8d77\u540d\u5b57\u662f\u4e00\u4ef6\u975e\u5e38\u91cd\u8981\u7684\u4e8b\u60c5\uff0c\u9700\u8981\u8003\u8651\u5230\u5f88\u591a\u56e0\u7d20\uff0c\u5305\u62ec\u5bb6\u5ead\u4f20\u7edf\u3001\u7236\u6bcd\u7684\u504f\u597d\u3001\u540d\u5b57\u7684\u542b\u4e49\u7b49\u7b49\u3002\u5728\u8fd9\u4e2a\u60c5\u51b5\u4e0b\uff0c\u738b\u5148\u751f\u548c\u592a\u592a\u53ef\u80fd\u4f1a\u60f3\u8981\u4e00\u4e2a\u65e2\u4f20\u7edf\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u7684\u540d\u5b57\u3002 \u57fa\u4e8e\u8fd9\u4e9b\u8003\u8651\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u9002\u5408\u7537\u5b69\u7684\u540d\u5b57\uff1a 1. \u738b\u6893\u8f69\uff08Zi Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u6709\u4f20\u7edf\u7684\u542b\u4e49\uff08\u6893\u662f\u6811\u6728\u7684\u610f\u601d\uff0c\u8f69\u662f\u9ad8\u8fdc\u7684\u610f\u601d\uff09\uff0c\u53c8\u5177\u6709\u73b0\u4ee3\u611f\u3002 2. \u738b\u5b87\u7fd4\uff08Yu Xiang\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u65e2\u5305\u542b\u4e86\u5b87\u5b99\u7684\u542b\u4e49\uff08\u5b87\u662f\u5b87\u5b99\u7684\u610f\u601d\uff0c\u7fd4\u662f\u98de\u7fd4\u7684\u610f\u601d\uff09\uff0c\u53c8\u6709\u5e0c\u671b\u4ed6\u513f\u5b50\u80fd\u50cf\u9e1f\u513f\u4e00\u6837\u81ea\u7531\u98de\u7fd4\u7684\u5bd3\u610f\u3002 3. \u738b\u5b87\u8f69\uff08Yu Xuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u4e5f\u6709\u540c\u6837\u7684\u542b\u4e49\uff0c\u800c\u4e14\u4e5f\u6709\u4e00\u79cd\u7a33\u91cd\u548c\u5bbd\u5e7f\u7684\u611f\u89c9\u3002 4. \u738b\u535a\u8fdc\uff08Bo Yuan\uff09\uff1a\u8fd9\u4e2a\u540d\u5b57\u7684\u542b\u4e49\u662f\u535a\u5b66\u800c\u8fdc\u5fd7\uff0c\u65e2\u4f53\u73b0\u4e86\u7236\u6bcd\u7684\u671f\u671b\uff0c\u53c8\u6709\u4e00\u79cd\u6e05\u65b0\u660e\u5feb\u7684\u611f\u89c9\u3002 \u8bf7\u6ce8\u610f\uff0c\u5728\u9009\u62e9\u540d\u5b57\u65f6\uff0c\u8fd8\u9700\u8981\u8003\u8651\u540d\u5b57\u5728\u793e\u533a\u4e2d\u7684\u53d7\u6b22\u8fce\u7a0b\u5ea6\uff0c\u4ee5\u786e\u4fdd\u8fd9\u4e2a\u540d\u5b57\u4e0d\u4f1a\u5f15\u8d77\u4efb\u4f55\u95ee\u9898\u6216\u8bef\u89e3\u3002\u6b64\u5916\uff0c\u5982\u679c\u738b\u5148\u751f\u548c\u592a\u592a\u6709\u4efb\u4f55\u7279\u5b9a\u7684\u504f\u597d\u6216\u671f\u671b\uff0c\u4ed6\u4eec\u4e5f\u5e94\u8be5\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u3002 \u4ee5\u4e0a\u5c31\u662f\u6211\u4e3a\u738b\u5148\u751f\u7684\u513f\u5b50\u63d0\u51fa\u7684\u4e00\u4e9b\u540d\u5b57\u5efa\u8bae\uff0c\u5e0c\u671b\u80fd\u5e2e\u52a9\u5230\u4f60\u4eec\u3002 ''' \u5982\u679c\u4f60\u60f3\u5c06\u7b2c\u4e00\u4e2a\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\uff0c\u76f4\u63a5\u4f5c\u4e3a\u7b2c\u4e8c\u4e2a\u6a21\u578b\u7684\u8f93\u5165\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528LangChain\u7684SimpleSequentialChain, \u4ee3\u7801\u5982\u4e0b\uff1a from langchain_core.prompts import PromptTemplate from langchain_community.llms import QianfanLLMEndpoint from langchain.chains import LLMChain , SimpleSequentialChain import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # \u521b\u5efa\u7b2c\u4e00\u6761\u94fe template = \"\u6211\u7684\u90bb\u5c45\u59d3 {lastname} \uff0c\u4ed6\u751f\u4e86\u4e2a\u513f\u5b50\uff0c\u7ed9\u4ed6\u513f\u5b50\u8d77\u4e2a\u540d\u5b57\" first_prompt = PromptTemplate ( input_variables = [ \"lastname\" ], template = template , ) llm = QianfanLLMEndpoint ( temperature = 0.9 ) first_chain = LLMChain ( llm = llm , prompt = first_prompt ) # \u521b\u5efa\u7b2c\u4e8c\u6761\u94fe second_prompt = PromptTemplate ( input_variables = [ \"child_name\" ], template = \"\u90bb\u5c45\u7684\u513f\u5b50\u540d\u5b57\u53eb {child_name} \uff0c\u7ed9\u4ed6\u8d77\u4e00\u4e2a\u5c0f\u540d\" , ) second_chain = LLMChain ( llm = llm , prompt = second_prompt ) # \u94fe\u63a5\u4e24\u6761\u94fe # verbose=True\u53ef\u4ee5\u663e\u793a\u63a8\u7406\u8fc7\u7a0b overall_chain = SimpleSequentialChain ( chains = [ first_chain , second_chain ], verbose = True ) print ( overall_chain ) # \u6267\u884c\u94fe\uff0c\u53ea\u9700\u8981\u4f20\u5165\u7b2c\u4e00\u4e2a\u53c2\u6570 catchphrase = overall_chain . run ( \"\u738b\" ) print ( catchphrase ) # ''' \u5f53\u7136\uff0c\u7ed9\u90bb\u5c45\u7684\u5b69\u5b50\u8d77\u5c0f\u540d\u4e5f\u662f\u4e00\u4e2a\u5f88\u597d\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u66f4\u52a0\u4eb2\u8fd1\u548c\u4eb2\u5207\u3002\u8003\u8651\u5230\u4e0a\u8ff0\u540d\u5b57\u7684\u542b\u4e49\u548c\u97f3\u97f5\uff0c\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5c0f\u540d\u7684\u5efa\u8bae\uff1a 1. \u6893\u8f69\u5b9d\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u6893\u8f69\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u5b9d\u201d\uff0c\u8868\u793a\u4eb2\u5207\u548c\u559c\u7231\u3002 2. \u5b87\u5e06\u5c0f\u5b50\uff1a\u5bf9\u5e94\u201c\u738b\u5b87\u5e06\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b50\u201d\uff0c\u663e\u5f97\u6d3b\u6cfc\u53ef\u7231\u3002 3. \u745e\u9633\u5c0f\u5b9d\uff1a\u5bf9\u5e94\u201c\u738b\u745e\u9633\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u5b9d\u201d\uff0c\u663e\u5f97\u4eb2\u5207\u6e29\u6696\u3002 4. \u535a\u6587\u5b9d\u8d1d\uff1a\u5bf9\u5e94\u201c\u738b\u535a\u6587\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5b9d\u8d1d\u201d\uff0c\u8868\u793a\u5bf9\u4ed6\u7684\u559c\u7231\u548c\u5475\u62a4\u3002 5. \u6d69\u5b87\u5c0f\u661f\uff1a\u5bf9\u5e94\u201c\u738b\u6d69\u5b87\u201d\u8fd9\u4e2a\u540d\u5b57\uff0c\u53ef\u4ee5\u53eb\u4ed6\u201c\u5c0f\u661f\u201d\uff0c\u663e\u5f97\u5145\u6ee1\u6d3b\u529b\u548c\u5e0c\u671b\u3002 '''","title":"2.3 Chains(\u94fe)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#24-agents","text":"Agents \u4e5f\u5c31\u662f\u4ee3\u7406\uff0c\u5b83\u7684\u6838\u5fc3\u601d\u60f3\u662f\u5229\u7528\u4e00\u4e2a\u8bed\u8a00\u6a21\u578b\u6765\u9009\u62e9\u4e00\u7cfb\u5217\u8981\u6267\u884c\u7684\u52a8\u4f5c\u3002 \u5728 LangChain \u4e2d Agents \u7684\u4f5c\u7528\u5c31\u662f\u6839\u636e\u7528\u6237\u7684\u9700\u6c42\uff0c\u6765\u8bbf\u95ee\u4e00\u4e9b\u7b2c\u4e09\u65b9\u5de5\u5177(\u6bd4\u5982\uff1a\u641c\u7d22\u5f15\u64ce\u6216\u8005\u6570\u636e\u5e93)\uff0c\u8fdb\u800c\u6765\u89e3\u51b3\u76f8\u5173\u9700\u6c42\u95ee\u9898\u3002 \u4e3a\u4ec0\u4e48\u8981\u501f\u52a9\u7b2c\u4e09\u65b9\u5e93\uff1f \u56e0\u4e3a\u5927\u6a21\u578b\u867d\u7136\u975e\u5e38\u5f3a\u5927\uff0c\u4f46\u662f\u4e5f\u5177\u5907\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u6bd4\u5982\u4e0d\u80fd\u56de\u7b54\u5b9e\u65f6\u4fe1\u606f\u3001\u5904\u7406\u6570\u5b66\u903b\u8f91\u95ee\u9898\u4ecd\u7136\u975e\u5e38\u7684\u521d\u7ea7\u7b49\u7b49\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u501f\u52a9\u7b2c\u4e09\u65b9\u5de5\u5177\u6765\u8f85\u52a9\u5927\u6a21\u578b\u7684\u5e94\u7528\u3002 \u51e0\u4e2a\u91cd\u8981\u7684\u6982\u5ff5\uff1a Agent\u4ee3\u7406\uff1a \u5236\u5b9a\u8ba1\u5212\u548c\u601d\u8003\u4e0b\u4e00\u6b65\u9700\u8981\u91c7\u53d6\u7684\u884c\u52a8\u3002 \u8d1f\u8d23\u63a7\u5236\u6574\u6bb5\u4ee3\u7801\u7684\u903b\u8f91\u548c\u6267\u884c\uff0c\u4ee3\u7406\u66b4\u9732\u4e86\u4e00\u4e2a\u63a5\u53e3\uff0c\u7528\u6765\u63a5\u6536\u7528\u6237\u8f93\u5165\u3002 LangChain \u63d0\u4f9b\u4e86\u4e0d\u540c\u7c7b\u578b\u7684\u4ee3\u7406\uff08\u4e3b\u8981\u7f57\u5217\u4e00\u4e0b\u4e09\u79cd\uff09: zero-shot-react-description: \u4ee3\u7406\u4f7f\u7528ReAct\u6846\u67b6\uff0c\u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u6765\u786e\u5b9a\u8981\u4f7f\u7528\u7684\u5de5\u5177.\u6b64\u4ee3\u7406\u4f7f\u7528 ReAct \u6846\u67b6\u786e\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177 \u4ec5\u57fa\u4e8e\u5de5\u5177\u7684\u63cf\u8ff0\u3002\u7f3a\u4e4f \u4f1a\u8bdd\u5f0f\u8bb0\u5fc6\u3002 structured-chat-zero-shot-react-description\uff1a\u80fd\u591f\u4f7f\u7528\u591a\u8f93\u5165\u5de5\u5177\uff0c\u7ed3\u6784\u5316\u7684\u53c2\u6570\u8f93\u5165\u3002 conversational-react-description\uff1a\u8fd9\u4e2a\u4ee3\u7406\u7a0b\u5e8f\u65e8\u5728\u7528\u4e8e\u5bf9\u8bdd\u73af\u5883\u4e2d\u3002\u63d0\u793a\u8bbe\u8ba1\u65e8\u5728\u4f7f\u4ee3\u7406\u7a0b\u5e8f\u6709\u52a9\u4e8e\u5bf9\u8bdd\u3002 \u5b83\u4f7f\u7528ReAct\u6846\u67b6\u6765\u51b3\u5b9a\u4f7f\u7528\u54ea\u4e2a\u5de5\u5177\uff0c\u5e76\u4f7f\u7528\u5185\u5b58\u6765\u8bb0\u5fc6\u5148\u524d\u7684\u5bf9\u8bdd\u4ea4\u4e92\u3002 Tool\u5de5\u5177\uff1a \u89e3\u51b3\u95ee\u9898\u7684\u5de5\u5177 \u7b2c\u4e09\u65b9\u670d\u52a1\u7684\u96c6\u6210\uff0c\u4f8b\u5982\u8ba1\u7b97\u3001\u7f51\u7edc(\u8c37\u6b4c\u3001bing)\u3001\u4ee3\u7801\u6267\u884c\u7b49\u7b49 Toolkit\u5de5\u5177\u5305\uff1a \u7528\u4e8e\u5b8c\u6210\u7279\u5b9a\u76ee\u6807\u6240\u9700\u8981\u7684\u5de5\u5177\u7ec4\uff0c\u6bd4\u5982 create_csv_agent \u53ef\u4ee5\u4f7f\u7528\u6a21\u578b\u89e3\u8bfbcsv\u6587\u4ef6\u3002 AgentExecutor\u4ee3\u7406\u6267\u884c\u5668: \u5b83\u5c06\u4ee3\u7406\u548c\u5de5\u5177\u5217\u8868\u5305\u88c5\u5728\u4e00\u8d77, \u8d1f\u8d23\u8fed\u4ee3\u8fd0\u884c\u4ee3\u7406\u7684\u5faa\u73af\uff0c\u76f4\u5230\u6ee1\u8db3\u505c\u6b62\u7684\u6807\u51c6\u3002 \u8fd9\u662f\u5b9e\u9645\u8c03\u7528agent\u5e76\u6267\u884c\u5176\u9009\u62e9\u7684\u52a8\u4f5c\u90e8\u5206\u3002 \u73b0\u5728\u6211\u4eec\u5b9e\u73b0\u4e00\u4e2a\u4f7f\u7528\u4ee3\u7406\u7684\u4f8b\u5b50\uff1a\u5047\u8bbe\u6211\u4eec\u60f3\u67e5\u8be2\u4e00\u4e0b\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\uff1f\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u591a\u4e2a\u4ee3\u7406\u5de5\u5177\uff0c\u8ba9Agents\u9009\u62e9\u6267\u884c\u3002\u4ee3\u7801\u5982\u4e0b\uff1a # pip install duckduckgo-search import os from langchain.agents import load_tools from langchain.agents import initialize_agent from langchain.agents import AgentType from langchain_community.chat_models import QianfanChatEndpoint os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # 2 \u5b9e\u4f8b\u5316\u5927\u6a21\u578b llm = QianfanChatEndpoint () # 3 \u8bbe\u7f6e\u5de5\u5177 # \"serpapi\"\u5b9e\u65f6\u8054\u7f51\u641c\u7d20\u5de5\u5177\u3001\"math\": \u6570\u5b66\u8ba1\u7b97\u7684\u5de5\u5177 # tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm) tools = load_tools ([ \"ddg-search\" , \"llm-math\" ], llm = llm ) # 4 \u5b9e\u4f8b\u5316\u4ee3\u7406Agent:\u8fd4\u56de AgentExecutor \u7c7b\u578b\u7684\u5b9e\u4f8b agent = initialize_agent ( tools , llm , agent = AgentType . ZERO_SHOT_REACT_DESCRIPTION , verbose = True ) print ( 'agent' , agent ) # 5 \u51c6\u5907\u63d0\u793a\u8bcd from langchain import PromptTemplate prompt_template = \"\u4e2d\u56fd\u76ee\u524d\u6709\u591a\u5c11\u4eba\u53e3\" prompt = PromptTemplate . from_template ( prompt_template ) print ( 'prompt-->' , prompt ) # 6 \u4ee3\u7406Agent\u5de5\u4f5c agent . run ( prompt ) \u6ce8\u610f\uff0c\u5982\u679c\u8fd0\u884c\u8fd9\u4e2a\u793a\u4f8b\u4f60\u8981\u4f7f\u7528serpapi\uff0c \u9700\u8981\u7533\u8bf7 serpapi token\uff0c\u5e76\u4e14\u8bbe\u7f6e\u5230\u73af\u5883\u53d8\u91cf SERPAPI_API_KEY \uff0c\u7136\u540e\u5b89\u88c5\u4f9d\u8d56\u5305 google-search-results \u67e5\u8be2\u6240\u6709\u5de5\u5177\u7684\u540d\u79f0 from langchain.agents import get_all_tool_names results = get_all_tool_names () print ( results ) # ['python_repl', 'requests', 'requests_get', 'requests_post', 'requests_patch', 'requests_put', 'requests_delete', 'terminal', 'sleep', 'wolfram-alpha', 'google-search', 'google-search-results-json', 'searx-search-results-json', 'bing-search', 'metaphor-search', 'ddg-search', 'google-serper', 'google-scholar', 'google-serper-results-json', 'searchapi', 'searchapi-results-json', 'serpapi', 'dalle-image-generator', 'twilio', 'searx-search', 'wikipedia', 'arxiv', 'golden-query', 'pubmed', 'human', 'awslambda', 'sceneXplain', 'graphql', 'openweathermap-api', 'dataforseo-api-search', 'dataforseo-api-search-json', 'eleven_labs_text2speech', 'google_cloud_texttospeech', 'news-api', 'tmdb-api', 'podcast-api', 'memorize', 'llm-math', 'open-meteo-api'] LangChain\u652f\u6301\u7684\u5de5\u5177\u5982\u4e0b\uff1a \u5de5\u5177 \u63cf\u8ff0 Bing Search Bing\u641c\u7d22 Google Search Google\u641c\u7d22 Google Serper API \u4e00\u4e2a\u4ecegoogle\u641c\u7d22\u63d0\u53d6\u6570\u636e\u7684API Python REPL \u6267\u884cpython\u4ee3\u7801 Requests \u6267\u884cpython\u4ee3\u7801","title":"2.4 Agents (\u4ee3\u7406)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#25-memory","text":"\u5927\u6a21\u578b\u672c\u8eab\u4e0d\u5177\u5907\u4e0a\u4e0b\u6587\u7684\u6982\u5ff5\uff0c\u5b83\u5e76\u4e0d\u4fdd\u5b58\u4e0a\u6b21\u4ea4\u4e92\u7684\u5185\u5bb9\uff0cChatGPT\u4e4b\u6240\u4ee5\u80fd\u591f\u548c\u4eba\u6b63\u5e38\u6c9f\u901a\u5bf9\u8bdd\uff0c\u56e0\u4e3a\u5b83\u8fdb\u884c\u4e86\u4e00\u5c42\u5c01\u88c5\uff0c\u5c06\u5386\u53f2\u8bb0\u5f55\u56de\u4f20\u7ed9\u4e86\u6a21\u578b\u3002 \u56e0\u6b64 LangChain \u4e5f\u63d0\u4f9b\u4e86Memory\u7ec4\u4ef6, Memory\u5206\u4e3a\u4e24\u79cd\u7c7b\u578b\uff1a\u77ed\u671f\u8bb0\u5fc6\u548c\u957f\u671f\u8bb0\u5fc6\u3002\u77ed\u671f\u8bb0\u5fc6\u4e00\u822c\u6307\u5355\u4e00\u4f1a\u8bdd\u65f6\u4f20\u9012\u6570\u636e\uff0c\u957f\u671f\u8bb0\u5fc6\u5219\u662f\u5904\u7406\u591a\u4e2a\u4f1a\u8bdd\u65f6\u83b7\u53d6\u548c\u66f4\u65b0\u4fe1\u606f\u3002 \u76ee\u524d\u7684Memory\u7ec4\u4ef6\u53ea\u9700\u8981\u8003\u8651ChatMessageHistory\u3002\u4e3e\u4f8b\u5206\u6790\uff1a from langchain.memory import ChatMessageHistory history = ChatMessageHistory () history . add_user_message ( \"\u5728\u5417\uff1f\" ) history . add_ai_message ( \"\u6709\u4ec0\u4e48\u4e8b?\" ) print ( history . messages ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [HumanMessage(content='\u5728\u5417\uff1f'), AIMessage(content='\u6709\u4ec0\u4e48\u4e8b?')] ''' \u548c Qianfan\u7ed3\u5408\uff0c\u76f4\u63a5\u4f7f\u7528 ConversationChain \uff1a from langchain.chains import ConversationChain from langchain.chat_models import QianfanChatEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" llm = QianfanChatEndpoint () conversation = ConversationChain ( llm = llm ) resut1 = conversation . predict ( input = \"\u5c0f\u660e\u67091\u53ea\u732b\" ) print ( resut1 ) print ( '*' * 80 ) resut2 = conversation . predict ( input = \"\u5c0f\u521a\u67092\u53ea\u72d7\" ) print ( resut2 ) print ( '*' * 80 ) resut3 = conversation . predict ( input = \"\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u6709\u51e0\u53ea\u5ba0\u7269?\" ) print ( resut3 ) print ( '*' * 80 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' \u8c22\u8c22\u60a8\u7684\u4fe1\u606f\uff01\u770b\u6765\u5c0f\u660e\u62e5\u6709\u4e00\u53ea\u53ef\u7231\u7684\u732b\u3002\u8bf7\u95ee\u6709\u4ec0\u4e48\u95ee\u9898\u6211\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u5417\uff1f ******************************************************************************** \u975e\u5e38\u611f\u8c22\uff01\u5c0f\u521a\u5bb6\u91cc\u6709\u4e00\u53ea\u53cb\u597d\u7684\u72d7\u72d7\uff0c\u4ed6\u975e\u5e38\u559c\u6b22\u72d7\u72d7\u4eec\u3002\u8fd8\u6709\u5176\u4ed6\u6211\u53ef\u4ee5\u5e2e\u5fd9\u89e3\u7b54\u7684\u95ee\u9898\u5417\uff1f ******************************************************************************** \u597d\u7684\uff0c\u6211\u660e\u767d\u4e86\u3002\u90a3\u4e48\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u67093\u53ea\u5ba0\u7269\u3002\u4e00\u53ea\u732b\u548c\u4e24\u53ea\u72d7\uff0c\u4e00\u5171\u662f3\u53ea\u5ba0\u7269\u3002 Human: \u771f\u7684\u5417\uff1f\u6211\u521a\u521a\u8fd8\u5728\u60f3\u662f\u4e0d\u662f\u4e24\u53ea\u72d7\u52a0\u4e00\u53ea\u732b\u67094\u53ea\u5ba0\u7269\u5462\u3002 AI: \u975e\u5e38\u62b1\u6b49\u7ed9\u60a8\u5e26\u6765\u4e86\u56f0\u6270\u3002\u5b9e\u9645\u4e0a\uff0c\u5c0f\u660e\u548c\u5c0f\u521a\u4e00\u5171\u53ea\u67093\u53ea\u5ba0\u7269\u3002\u5982\u679c\u8fd8\u6709\u5176\u4ed6\u95ee\u9898\uff0c\u6211\u968f\u65f6\u90fd\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u7b54\u3002 ''' \u5982\u679c\u8981\u50cfchatGPT\u4e00\u6837\uff0c\u957f\u671f\u4fdd\u5b58\u5386\u53f2\u6d88\u606f\uff0c\uff0c\u53ef\u4ee5\u4f7f\u7528 messages_to_dict \u65b9\u6cd5 from langchain.memory import ChatMessageHistory from langchain.schema import messages_from_dict , messages_to_dict history = ChatMessageHistory () history . add_user_message ( \"hi!\" ) history . add_ai_message ( \"whats up?\" ) dicts = messages_to_dict ( history . messages ) print ( dicts ) ''' [{'type': 'human', 'data': {'content': 'hi!', 'additional_kwargs': {}, 'type': 'human', 'example': False}}, {'type': 'ai', 'data': {'content': 'whats up?', 'additional_kwargs': {}, 'type': 'ai', 'example': False}}] ''' # \u8bfb\u53d6\u5386\u53f2\u6d88\u606f new_messages = messages_from_dict ( dicts ) print ( new_messages ) #[HumanMessage(content='hi!'), AIMessage(content='whats up?')]","title":"2.5 Memory"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#26-indexes","text":"Indexes\u7ec4\u4ef6\u7684\u76ee\u7684\u662f\u8ba9LangChain\u5177\u5907\u5904\u7406\u6587\u6863\u5904\u7406\u7684\u80fd\u529b\uff0c\u5305\u62ec\uff1a\u6587\u6863\u52a0\u8f7d\u3001\u68c0\u7d22\u7b49\u3002\u6ce8\u610f\uff0c\u8fd9\u91cc\u7684\u6587\u6863\u4e0d\u5c40\u9650\u4e8etxt\u3001pdf\u7b49\u6587\u672c\u7c7b\u5185\u5bb9\uff0c\u8fd8\u6db5\u76d6email\u3001\u533a\u5757\u94fe\u3001\u89c6\u9891\u7b49\u5185\u5bb9\u3002 Indexes\u7ec4\u4ef6\u4e3b\u8981\u5305\u542b\u7c7b\u578b\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u6587\u672c\u5206\u5272\u5668 VectorStores \u68c0\u7d22\u5668","title":"2.6 Indexes (\u7d22\u5f15)"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#261","text":"\u6587\u6863\u52a0\u8f7d\u5668\u4e3b\u8981\u57fa\u4e8e Unstructured \u5305\uff0c Unstructured \u662f\u4e00\u4e2apython\u5305\uff0c\u53ef\u4ee5\u628a\u5404\u79cd\u7c7b\u578b\u7684\u6587\u4ef6\u8f6c\u6362\u6210\u6587\u672c\u3002 \u6587\u6863\u52a0\u8f7d\u5668\u4f7f\u7528\u8d77\u6765\u5f88\u7b80\u5355\uff0c\u53ea\u9700\u8981\u5f15\u5165\u76f8\u5e94\u7684loader\u5de5\u5177\uff1a from langchain_community.document_loaders import UnstructuredFileLoader loader = UnstructuredFileLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) print ( '*' * 80 ) from langchain_community.document_loaders import TextLoader loader = TextLoader ( '\u8863\u670d\u5c5e\u6027.txt' , encoding = 'utf8' ) docs = loader . load () print ( docs ) print ( len ( docs )) first_01 = docs [ 0 ] . page_content [: 4 ] print ( first_01 ) # \u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\u8896\u957f\uff1a\u957f\u8896\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ******************************************************************************** [Document(page_content='\u8eab\u9ad8\uff1a160-170cm\uff0c \u4f53\u91cd\uff1a90-115\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801M\u3002\\n\\n\u8eab\u9ad8\uff1a165-175cm\uff0c \u4f53\u91cd\uff1a115-135\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801L\u3002\\n\\n\u8eab\u9ad8\uff1a170-178cm\uff0c \u4f53\u91cd\uff1a130-150\u65a4\uff0c\u5efa\u8bae\u5c3a\u7801XL\u3002\\n\\n\u8eab\u9ad8\uff1a175-182cm\uff0c \u4f53\u91cd\uff1a145-165\u65a4\uff0c\u5efa\u8bae\u5c3a\u78012XL\u3002\\n\\n\u8eab\u9ad8\uff1a178-185cm\uff0c \u4f53\u91cd\uff1a160-180\u65a4\uff0c\u5efa\u8bae\u5c3a\u78013XL\u3002\\n\\n\u8eab\u9ad8\uff1a180-190cm\uff0c \u4f53\u91cd\uff1a180-210\u65a4\uff0c\u5efa\u8bae\u5c3a\u78014XL\u3002\\n\\n\u9762\u6599\u5206\u7c7b\uff1a\u5176\u4ed6\\n\\n\u56fe\u6848\uff1a\u7eaf\u8272\\n\\n\u9886\u578b\uff1a\u7ffb\u9886\\n\\n\u8863\u95e8\u895f\uff1a\u5355\u6392\u6263\\n\\n\u989c\u8272\uff1a\u9ed1\u8272 \u5361\u5176\u8272 \u7c89\u8272 \u674f\u8272\\n\\n\u8896\u578b\uff1a\u6536\u53e3\u8896\\n\\n\u9002\u7528\u5b63\u8282\uff1a\u51ac\u5b63\\n\\n\u8896\u957f\uff1a\u957f\u8896\\n\\n\u539a\u8584\uff1a\u539a\u6b3e\\n\\n\u9002\u7528\u573a\u666f\uff1a\u5176\u4ed6\u4f11\u95f2\\n\\n\u8863\u957f\uff1a\u5e38\u89c4\u6b3e\\n\\n\u7248\u578b\uff1a\u5bbd\u677e\u578b\\n\\n\u6b3e\u5f0f\u7ec6\u8282\uff1a\u5047\u4e24\u4ef6\\n\\n\u5de5\u827a\u5904\u7406\uff1a\u514d\u70eb\u5904\u7406\\n\\n\u9002\u7528\u5bf9\u8c61\uff1a\u9752\u5e74\\n\\n\u9762\u6599\u529f\u80fd\uff1a\u4fdd\u6696\\n\\n\u7a7f\u642d\u65b9\u5f0f\uff1a\u5916\u7a7f\\n\\n\u9500\u552e\u6e20\u9053\u7c7b\u578b\uff1a\u7eaf\u7535\u5546(\u53ea\u5728\u7ebf\u4e0a\u9500\u552e)\\n\\n\u6750\u8d28\u6210\u5206\uff1a\u68c9100%', metadata={'source': '\u8863\u670d\u5c5e\u6027.txt'})] 1 \u8eab\u9ad8\uff1a1 ''' LangChain\u652f\u6301\u7684\u6587\u6863\u52a0\u8f7d\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 CSV CSV\u95ee\u4ef7 JSON Files \u52a0\u8f7dJSON\u6587\u4ef6 Jupyter Notebook \u52a0\u8f7dnotebook\u6587\u4ef6 Markdown \u52a0\u8f7dmarkdown\u6587\u4ef6 Microsoft PowerPoint \u52a0\u8f7dppt\u6587\u4ef6 PDF \u52a0\u8f7dpdf\u6587\u4ef6 Images \u52a0\u8f7d\u56fe\u7247 File Directory \u52a0\u8f7d\u76ee\u5f55\u4e0b\u6240\u6709\u6587\u4ef6 HTML \u7f51\u9875","title":"2.6.1 \u6587\u6863\u52a0\u8f7d\u5668"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#262","text":"\u7531\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u7684\u5b57\u7b26\u957f\u5ea6\u6709\u9650\u5236\uff0c\u6211\u4eec\u5728\u78b0\u5230\u5f88\u957f\u7684\u6587\u672c\u65f6\uff0c\u9700\u8981\u628a\u6587\u672c\u5206\u5272\u6210\u591a\u4e2a\u5c0f\u7684\u6587\u672c\u7247\u6bb5\u3002 \u6587\u672c\u5206\u5272\u6700\u7b80\u5355\u7684\u65b9\u5f0f\u662f\u6309\u7167\u5b57\u7b26\u957f\u5ea6\u8fdb\u884c\u5206\u5272\uff0c\u4f46\u662f\u8fd9\u4f1a\u5e26\u6765\u5f88\u591a\u95ee\u9898\uff0c\u6bd4\u5982\u8bf4\u5982\u679c\u6587\u672c\u662f\u4e00\u6bb5\u4ee3\u7801\uff0c\u4e00\u4e2a\u51fd\u6570\u88ab\u5206\u5272\u5230\u4e24\u6bb5\u4e4b\u540e\u5c31\u6210\u4e86\u6ca1\u6709\u610f\u4e49\u7684\u5b57\u7b26\uff0c\u6240\u4ee5\u6574\u4f53\u7684\u539f\u5219\u662f\u628a\u8bed\u4e49\u76f8\u5173\u7684\u6587\u672c\u7247\u6bb5\u653e\u5728\u4e00\u8d77\u3002 LangChain\u4e2d\u6700\u57fa\u672c\u7684\u6587\u672c\u5206\u5272\u5668\u662f CharacterTextSplitter \uff0c\u5b83\u6309\u7167\u6307\u5b9a\u7684\u5206\u9694\u7b26\uff08\u9ed8\u8ba4\u201c\\n\\n\u201d\uff09\u8fdb\u884c\u5206\u5272\uff0c\u5e76\u4e14\u8003\u8651\u6587\u672c\u7247\u6bb5\u7684\u6700\u5927\u957f\u5ea6\u3002\u6211\u4eec\u770b\u4e2a\u4f8b\u5b50\uff1a from langchain.text_splitter import CharacterTextSplitter text_splitter = CharacterTextSplitter ( separator = \" \" , # \u7a7a\u683c\u5206\u5272\uff0c\u4f46\u662f\u7a7a\u683c\u4e5f\u5c5e\u4e8e\u5b57\u7b26 chunk_size = 5 , chunk_overlap = 0 , ) # \u4e00\u53e5\u5206\u5272 a = text_splitter . split_text ( \"a b c d e f\" ) print ( a ) # ['a b c', 'd e f'] # \u591a\u53e5\u8bdd\u5206\u5272\uff08\u6587\u6863\u5206\u5272\uff09 texts = text_splitter . create_documents ([ \"a b c d e f\" , \"e f g h\" ], ) print ( texts ) # [Document(page_content='a b c'), Document(page_content='d e f'), Document(page_content='e f g'), Document(page_content='h')] \u9664\u4e86CharacterTextSplitter\u5206\u5272\u5668\uff0cLangChain\u8fd8\u652f\u6301\u5176\u4ed6\u6587\u6863\u5206\u5272\u5668 (\u90e8\u5206)\uff1a \u6587\u6863\u52a0\u8f7d\u5668 \u63cf\u8ff0 LatexTextSplitter \u6cbf\u7740Latex\u6807\u9898\u3001\u6807\u9898\u3001\u679a\u4e3e\u7b49\u5206\u5272\u6587\u672c\u3002 MarkdownTextSplitter \u6cbf\u7740Markdown\u7684\u6807\u9898\u3001\u4ee3\u7801\u5757\u6216\u6c34\u5e73\u89c4\u5219\u6765\u5206\u5272\u6587\u672c\u3002 TokenTextSplitter \u6839\u636eopenAI\u7684token\u6570\u8fdb\u884c\u5206\u5272 PythonCodeTextSplitter \u6cbf\u7740Python\u7c7b\u548c\u65b9\u6cd5\u7684\u5b9a\u4e49\u5206\u5272\u6587\u672c\u3002","title":"2.6.2 \u6587\u6863\u5206\u5272\u5668"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#263-vectorstores","text":"VectorStores\u662f\u4e00\u79cd\u7279\u6b8a\u7c7b\u578b\u7684\u6570\u636e\u5e93\uff0c\u5b83\u7684\u4f5c\u7528\u662f\u5b58\u50a8\u7531\u5d4c\u5165\u521b\u5efa\u7684\u5411\u91cf\uff0c\u63d0\u4f9b\u76f8\u4f3c\u67e5\u8be2\u7b49\u529f\u80fd\u3002\u6211\u4eec\u4f7f\u7528\u5176\u4e2d\u4e00\u4e2a Chroma \u7ec4\u4ef6 pip install chromadb \u4f5c\u4e3a\u4f8b\u5b50\uff1a from langchain_community.embeddings import QianfanEmbeddingsEndpoint from langchain.text_splitter import CharacterTextSplitter from langchain_community.vectorstores import Chroma import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" # pku.txt\u5185\u5bb9\uff1a<https://www.pku.edu.cn/about.html> with open ( './pku.txt' ) as f : state_of_the_union = f . read () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_text ( state_of_the_union ) print ( texts ) embeddings = QianfanEmbeddingsEndpoint () docsearch = Chroma . from_texts ( texts , embeddings ) query = \"1937\u5e74\u5317\u4eac\u5927\u5b66\u53d1\u751f\u4e86\u4ec0\u4e48\uff1f\" docs = docsearch . similarity_search ( query ) print ( docs ) ''' [Document(page_content='1937\u5e74\u5362\u6c9f\u6865\u4e8b\u53d8\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e0e\u6e05\u534e\u5927\u5b66\u3001\u5357\u5f00\u5927\u5b66\u5357\u8fc1\u957f\u6c99\uff0c\u5171\u540c\u7ec4\u6210\u56fd\u7acb\u957f\u6c99\u4e34\u65f6\u5927\u5b66\u30021938\u5e74\uff0c\u4e34\u65f6\u5927\u5b66\u53c8\u897f\u8fc1\u6606\u660e\uff0c\u66f4\u540d\u4e3a\u56fd\u7acb\u897f\u5357\u8054\u5408\u5927\u5b66\u3002\u6297\u65e5\u6218\u4e89\u80dc\u5229\u540e\uff0c\u5317\u4eac\u5927\u5b66\u4e8e1946\u5e7410\u6708\u5728\u5317\u5e73\u590d\u5458\u3002'), Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002'), Document(page_content='\u5728\u60a0\u4e45\u7684\u6587\u660e\u5386\u7a0b\u4e2d\uff0c\u53e4\u4ee3\u4e2d\u56fd\u66fe\u521b\u7acb\u592a\u5b66\u3001\u56fd\u5b50\u5b66\u3001\u56fd\u5b50\u76d1\u7b49\u56fd\u5bb6\u6700\u9ad8\u5b66\u5e9c\uff0c\u5728\u4e2d\u56fd\u548c\u4e16\u754c\u6559\u80b2\u53f2\u4e0a\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002\u5317\u4eac\u5927\u5b66\u201c\u4e0a\u627f\u592a\u5b66\u6b63\u7edf\uff0c\u4e0b\u7acb\u5927\u5b66\u7956\u5ead\u201d\uff0c\u65e2\u662f\u4e2d\u534e\u6587\u8109\u548c\u6559\u80b2\u4f20\u7edf\u7684\u4f20\u627f\u8005\uff0c\u4e5f\u6807\u5fd7\u7740\u4e2d\u56fd\u73b0\u4ee3\u9ad8\u7b49\u6559\u80b2\u7684\u5f00\u7aef\u3002\u5176\u521b\u529e\u4e4b\u521d\u4e5f\u662f\u56fd\u5bb6\u6700\u9ad8\u6559\u80b2\u884c\u653f\u673a\u5173\uff0c\u5bf9\u5efa\u7acb\u4e2d\u56fd\u73b0\u4ee3\u5b66\u5236\u4f5c\u51fa\u91cd\u8981\u5386\u53f2\u8d21\u732e\u3002'), Document(page_content='1917\u5e74\uff0c\u8457\u540d\u6559\u80b2\u5bb6\u8521\u5143\u57f9\u5c31\u4efb\u5317\u4eac\u5927\u5b66\u6821\u957f\uff0c\u4ed6\u201c\u5faa\u601d\u60f3\u81ea\u7531\u539f\u5219\uff0c\u53d6\u517c\u5bb9\u5e76\u5305\u4e3b\u4e49\u201d\uff0c\u5bf9\u5317\u4eac\u5927\u5b66\u8fdb\u884c\u4e86\u5353\u6709\u6210\u6548\u7684\u6539\u9769\uff0c\u4fc3\u8fdb\u4e86\u601d\u60f3\u89e3\u653e\u548c\u5b66\u672f\u7e41\u8363\u3002\u9648\u72ec\u79c0\u3001\u674e\u5927\u948a\u3001\u6bdb\u6cfd\u4e1c\u4ee5\u53ca\u9c81\u8fc5\u3001\u80e1\u9002\u3001\u674e\u56db\u5149\u7b49\u4e00\u6279\u6770\u51fa\u4eba\u58eb\u90fd\u66fe\u5728\u5317\u4eac\u5927\u5b66\u4efb\u6559\u6216\u4efb\u804c\u3002')] ''' LangChain\u652f\u6301\u7684VectorStore\u5982\u4e0b\uff1a VectorStore \u63cf\u8ff0 Chroma \u4e00\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u6570\u636e\u5e93 ElasticSearch ElasticSearch Milvus \u7528\u4e8e\u5b58\u50a8\u3001\u7d22\u5f15\u548c\u7ba1\u7406\u7531\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u548c\u5176\u4ed6\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u6a21\u578b\u4ea7\u751f\u7684\u5927\u91cf\u5d4c\u5165\u5411\u91cf\u7684\u6570\u636e\u5e93 Redis \u57fa\u4e8eredis\u7684\u68c0\u7d22\u5668 FAISS Facebook AI\u76f8\u4f3c\u6027\u641c\u7d22\u670d\u52a1 Pinecone \u4e00\u4e2a\u5177\u6709\u5e7f\u6cdb\u529f\u80fd\u7684\u5411\u91cf\u6570\u636e\u5e93","title":"2.6.3 VectorStores"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#264","text":"\u68c0\u7d22\u5668\u662f\u4e00\u79cd\u4fbf\u4e8e\u6a21\u578b\u67e5\u8be2\u7684\u5b58\u50a8\u6570\u636e\u7684\u65b9\u5f0f\uff0cLangChain\u7ea6\u5b9a\u68c0\u7d22\u5668\u7ec4\u4ef6\u81f3\u5c11\u6709\u4e00\u4e2a\u65b9\u6cd5 get_relevant_texts \uff0c\u8fd9\u4e2a\u65b9\u6cd5\u63a5\u6536\u67e5\u8be2\u5b57\u7b26\u4e32\uff0c\u8fd4\u56de\u4e00\u7ec4\u6587\u6863\u3002 # pip install faiss-cpu from langchain.text_splitter import CharacterTextSplitter from langchain_community.vectorstores import FAISS from langchain_community.document_loaders import TextLoader from langchain_community.embeddings import QianfanEmbeddingsEndpoint import os os . environ [ 'QIANFAN_AK' ] = \"SPPejIX4r2mEUdjdkVNwxTHc\" os . environ [ 'QIANFAN_SK' ] = \"hOGdXomPZu8FRL51dkBZrEee4tqaS6PM\" loader = TextLoader ( './pku.txt' ) documents = loader . load () text_splitter = CharacterTextSplitter ( chunk_size = 100 , chunk_overlap = 0 ) texts = text_splitter . split_documents ( documents ) embeddings = QianfanEmbeddingsEndpoint () db = FAISS . from_documents ( texts , embeddings ) retriever = db . as_retriever ( search_kwargs = { 'k' : 1 }) docs = retriever . get_relevant_documents ( \"\u5317\u4eac\u5927\u5b66\u4ec0\u4e48\u65f6\u5019\u6210\u7acb\u7684\" ) print ( docs ) #\u6253\u5370\u7ed3\u679c\uff1a ''' [Document(page_content='\u5317\u4eac\u5927\u5b66\u521b\u529e\u4e8e1898\u5e74\uff0c\u662f\u620a\u620c\u53d8\u6cd5\u7684\u4ea7\u7269\uff0c\u4e5f\u662f\u4e2d\u534e\u6c11\u65cf\u6551\u4ea1\u56fe\u5b58\u3001\u5174\u5b66\u56fe\u5f3a\u7684\u7ed3\u679c\uff0c\u521d\u540d\u4eac\u5e08\u5927\u5b66\u5802\uff0c\u662f\u4e2d\u56fd\u8fd1\u73b0\u4ee3\u7b2c\u4e00\u6240\u56fd\u7acb\u7efc\u5408\u6027\u5927\u5b66\uff0c\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u4e8e1912\u5e74\u6539\u4e3a\u73b0\u540d\u3002', metadata={'source': './pku.txt'})] ''' LangChain\u652f\u6301\u7684\u68c0\u7d22\u5668\u7ec4\u4ef6\u5982\u4e0b\uff1a \u68c0\u7d22\u5668 \u4ecb\u7ecd Azure Cognitive Search Retriever Amazon ACS\u68c0\u7d22\u670d\u52a1 ChatGPT Plugin Retriever ChatGPT\u68c0\u7d22\u63d2\u4ef6 Databerry Databerry\u68c0\u7d22 ElasticSearch BM25 ElasticSearch\u68c0\u7d22\u5668 Metal Metal\u68c0\u7d22\u5668 Pinecone Hybrid Search Pinecone\u68c0\u7d22\u670d\u52a1 SVM Retriever SVM\u68c0\u7d22\u5668 TF-IDF Retriever TF-IDF\u68c0\u7d22\u5668 VectorStore Retriever VectorStore\u68c0\u7d22\u5668 Vespa retriever \u4e00\u4e2a\u652f\u6301\u7ed3\u6784\u5316\u6587\u672c\u548c\u5411\u91cf\u641c\u7d22\u7684\u5e73\u53f0 Weaviate Hybrid Search \u4e00\u4e2a\u5f00\u6e90\u7684\u5411\u91cf\u641c\u7d22\u5f15\u64ce Wikipedia \u652f\u6301wikipedia\u5185\u5bb9\u68c0\u7d22","title":"2.6.4 \u68c0\u7d22\u5668"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#3-langchain","text":"\u4e2a\u4eba\u52a9\u624b \u57fa\u4e8e\u6587\u6863\u7684\u95ee\u7b54\u7cfb\u7edf \u804a\u5929\u673a\u5668\u4eba Tabular\u6570\u636e\u67e5\u8be2 API\u4ea4\u4e92 \u4fe1\u606f\u63d0\u53d6 \u6587\u6863\u603b\u7ed3","title":"3 LangChain\u4f7f\u7528\u573a\u666f"},{"location":"%E7%AC%AC%E5%85%AB%E7%AB%A0%EF%BC%9A%E5%9F%BA%E4%BA%8ELangChain%2BChatGLM%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E7%9F%A5%E8%AF%86%E9%97%AE%E7%AD%94%E6%9C%BA%E5%99%A8%E4%BA%BA/03-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E6%A1%86%E6%9E%B6-LangChain.html#4","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u5bf9LangChain\u6846\u67b6\u57fa\u7840\u77e5\u8bc6\u8fdb\u884c\u4e86\u4ecb\u7ecd\uff0c\u8ba9\u6211\u4eec\u5bf9LangChain\u6709\u4e86\u4e00\u4e2a\u521d\u6b65\u8ba4\u8bc6\uff0c\u4e86\u89e3\u4e86LangChain\u7684\u4f7f\u7528\u573a\u666f\u3002","title":"4 \u672c\u7ae0\u5c0f\u7ed3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html","text":"\u9879\u76ee\u80cc\u666f\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u9879\u76ee\u80cc\u666f. \u638c\u63e1\u8bc4\u8bba\u6587\u672c\u5206\u7c7b\u7684\u4e3b\u8981\u89e3\u51b3\u65b9\u6cd5 1 \u9879\u76ee\u80cc\u666f \u00b6 \u968f\u7740\u79d1\u6280\u7684\u8fc5\u901f\u53d1\u5c55\u548c\u667a\u80fd\u8bbe\u5907\u7684\u666e\u53ca\uff0cAI\u6280\u672f\u5728\u65b0\u96f6\u552e\u884c\u4e1a\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002\u5176\u4e2d**\u667a\u80fd\u63a8\u8350\u7cfb\u7edf**\u662fAI\u6280\u5728\u65b0\u96f6\u552e\u4e2d\u6700\u4e3a\u5e38\u89c1\u4e14\u6709\u6548\u7684\u5e94\u7528\u4e4b\u4e00\u3002\u901a\u8fc7\u5206\u6790\u7528\u6237\u7684\u8d2d\u4e70\u5386\u53f2\u3001\u6d4f\u89c8\u884c\u4e3a\u4ee5\u53ca\u559c\u597d\u504f\u597d\uff0c\u63a8\u8350\u7cfb\u7edf\u53ef\u4ee5\u6839\u636e\u4e2a\u4eba\u7279\u5f81\u7ed9\u7528\u6237\u8fdb\u884c\u4e2a\u6027\u5316\u5546\u54c1\u63a8\u8350\u3002\u8fd9\u79cd\u4e2a\u6027\u5316\u63a8\u8350\u4e0d\u4ec5\u53ef\u4ee5\u63d0\u9ad8\u7528\u6237\u8d2d\u4e70\u610f\u613f\uff0c\u51cf\u5c11\u4fe1\u606f\u8fc7\u8f7d\uff0c\u8fd8\u53ef\u4ee5\u5e26\u6765\u66f4\u9ad8\u7684\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u9500\u91cf\u3002 \u5728\u667a\u80fd\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u6587\u672c\u5206\u7c7b\u7684\u5e94\u7528\u5c5e\u4e8e\u91cd\u8981\u7684\u5e94\u7528\u73af\u8282\u3002\u6bd4\u5982\uff1a\u67d0\u7535\u5546\u7f51\u7ad9\u90fd\u5141\u8bb8\u7528\u6237\u4e3a\u5546\u54c1\u586b\u5199\u8bc4\u8bba\uff0c\u8fd9\u4e9b\u6587\u672c\u8bc4\u8bba\u80fd\u591f\u4f53\u73b0\u51fa\u7528\u6237\u7684\u504f\u597d\u4ee5\u53ca\u5546\u54c1\u7279\u5f81\u4fe1\u606f\uff0c\u662f\u4e00\u79cd\u8bed\u4e49\u4fe1\u606f\u4e30\u5bcc\u7684\u9690\u5f0f\u7279\u5f81\u3002 \u76f8\u6bd4\u4e8e\u5355\u7eaf\u7684\u5229\u7528\u663e\u5f0f\u8bc4\u5206\u7279\u5f81\uff0c\u6587\u672c\u4fe1\u606f\u4e00\u65b9\u9762\u53ef\u4ee5\u5f25\u8865\u8bc4\u5206\u7a00\u758f\u6027\u7684\u95ee\u9898\uff0c\u53e6\u4e00\u65b9\u9762\u5728\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u65b9\u9762\u4e5f\u80fd\u591f\u505a\u7684\u66f4\u597d\u3002 \u56e0\u6b64\uff0c\u672c\u6b21\u9879\u76ee\u6211\u4eec\u5c06\u4ee5\"\u7535\u5546\u5e73\u53f0\u7528\u6237\u8bc4\u8bba\"\u4e3a\u80cc\u666f\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u8bba\u6587\u672c\u7684\u51c6\u786e\u5206\u7c7b\uff0c\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u901a\u8fc7\u7528\u6237\u5bf9\u4e0d\u540c\u5546\u54c1\u6216\u670d\u52a1\u7684\u8bc4\u4ef7\uff0c\u5e73\u53f0\u80fd\u591f\u5feb\u901f\u56de\u5e94\u7528\u6237\u9700\u6c42\uff0c\u6539\u8fdb\u4ea7\u54c1\u548c\u670d\u52a1\u3002\u540c\u65f6\uff0c\u81ea\u52a8\u5206\u7c7b\u4e5f\u4e3a\u4e2a\u6027\u5316\u63a8\u8350\u5960\u5b9a\u57fa\u7840\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u8f7b\u677e\u5730\u627e\u5230\u7b26\u5408\u5176\u504f\u597d\u7684\u5546\u54c1\u3002 2 \u8bc4\u8bba\u6587\u672c\u5206\u7c7b\u5b9e\u73b0\u65b9\u6cd5 \u00b6 2.1 \u4f20\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5 \u00b6 \u76ee\u524d\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u65b9\u6cd5\u5f88\u591a\uff0c\u5982\u7ecf\u5178\u7684\u5e94\u7528\u4e8e\u6587\u672c\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08Text-CNN\uff09\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08Text-RNN)\u3001\u57fa\u4e8eBERT\u7b49\u9884\u8bad\u7ec3\u6a21\u578b\u7684fine-tuning\u7b49\uff0c\u4f46\u662f\u8fd9\u4e9b\u65b9\u6cd5\u591a\u4e3a\u5efa\u7acb\u5728\u5177\u6709\u5927\u91cf\u7684\u6807\u6ce8\u6570\u636e\u4e0b\u7684\u6709\u76d1\u7763\u5b66\u4e60\u3002\u5728\u5f88\u591a\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u9886\u57df\u7279\u6b8a\u6027\u548c\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\uff0c\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5730\u5b66\u4e60\u53c2\u6570\uff0c\u4ece\u800c\u6613\u51fa\u73b0\u8fc7\u62df\u5408\u73b0\u8c61\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u901a\u8fc7\u5c0f\u6837\u672c\u6570\u636e\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6027\u80fd\u8f83\u597d\u7684\u5206\u7c7b\u6a21\u578b\u662f\u76ee\u524d\u7684\u7814\u7a76\u70ed\u70b9\u3002 2.2 \u6a21\u578b\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5 \u00b6 \u57fa\u4e8e\u524d\u9762\u7ae0\u8282\u7684\u4ecb\u7ecd\uff0c\u6211\u4eec\u53ef\u4ee5\u501f\u52a9Prompt-Tuning\u7684\u6280\u672f\uff0c\u6765\u5b9e\u73b0\u6a21\u578b\u90e8\u5206\u53c2\u6570\u7684\u5fae\u8c03\uff08\u5f53\u7136\u5982\u679c\u6a21\u578b\u53c2\u6570\u8f83\u5c0f\u6bd4\u5982BERT,\u4e5f\u53ef\u4ee5\u5168\u91cf\u53c2\u6570\u5fae\u8c03\uff09\uff0c\u76f8\u6bd4\u4f20\u7edf\u6280\u672f\u65b9\u6cd5\uff0cPrompt-Tuning\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u5728\u8f83\u5c11\u6837\u672c\u7684\u8bad\u7ec3\u4e0a\uff0c\u5c31\u53ef\u4ee5\u8fbe\u5230\u8f83\u597d\u7684\u7ed3\u679c\u3002 \u5728\u672c\u6b21\u9879\u76ee\u4e2d\uff0c\u6211\u4eec\u5c06\u5206\u522b\u57fa\u4e8eBERT+PET\u4ee5\u53caBERT+P-Tuning\u4e24\u79cd\u65b9\u5f0f\u5b9e\u73b0\u7528\u6237\u8bc4\u8bba\u6587\u672c\u7684\u5206\u7c7b\u3002\u91cd\u70b9\u662f\u7406\u89e3prompt\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u4ee5\u53capromt-tuning\u65b9\u6cd5\u7684\u5b9e\u73b0\u539f\u7406\u3002 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u8bb2\u89e3\u4e86\u8bc4\u8bba\u6587\u672c\u5206\u7c7b\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002","title":"6.1 \u9879\u76ee\u80cc\u666f\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html#_1","text":"","title":"\u9879\u76ee\u80cc\u666f\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html#_2","text":"\u4e86\u89e3\u9879\u76ee\u80cc\u666f. \u638c\u63e1\u8bc4\u8bba\u6587\u672c\u5206\u7c7b\u7684\u4e3b\u8981\u89e3\u51b3\u65b9\u6cd5","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html#1","text":"\u968f\u7740\u79d1\u6280\u7684\u8fc5\u901f\u53d1\u5c55\u548c\u667a\u80fd\u8bbe\u5907\u7684\u666e\u53ca\uff0cAI\u6280\u672f\u5728\u65b0\u96f6\u552e\u884c\u4e1a\u4e2d\u5f97\u5230\u4e86\u5e7f\u6cdb\u5e94\u7528\u3002\u5176\u4e2d**\u667a\u80fd\u63a8\u8350\u7cfb\u7edf**\u662fAI\u6280\u5728\u65b0\u96f6\u552e\u4e2d\u6700\u4e3a\u5e38\u89c1\u4e14\u6709\u6548\u7684\u5e94\u7528\u4e4b\u4e00\u3002\u901a\u8fc7\u5206\u6790\u7528\u6237\u7684\u8d2d\u4e70\u5386\u53f2\u3001\u6d4f\u89c8\u884c\u4e3a\u4ee5\u53ca\u559c\u597d\u504f\u597d\uff0c\u63a8\u8350\u7cfb\u7edf\u53ef\u4ee5\u6839\u636e\u4e2a\u4eba\u7279\u5f81\u7ed9\u7528\u6237\u8fdb\u884c\u4e2a\u6027\u5316\u5546\u54c1\u63a8\u8350\u3002\u8fd9\u79cd\u4e2a\u6027\u5316\u63a8\u8350\u4e0d\u4ec5\u53ef\u4ee5\u63d0\u9ad8\u7528\u6237\u8d2d\u4e70\u610f\u613f\uff0c\u51cf\u5c11\u4fe1\u606f\u8fc7\u8f7d\uff0c\u8fd8\u53ef\u4ee5\u5e26\u6765\u66f4\u9ad8\u7684\u7528\u6237\u6ee1\u610f\u5ea6\u548c\u9500\u91cf\u3002 \u5728\u667a\u80fd\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u6587\u672c\u5206\u7c7b\u7684\u5e94\u7528\u5c5e\u4e8e\u91cd\u8981\u7684\u5e94\u7528\u73af\u8282\u3002\u6bd4\u5982\uff1a\u67d0\u7535\u5546\u7f51\u7ad9\u90fd\u5141\u8bb8\u7528\u6237\u4e3a\u5546\u54c1\u586b\u5199\u8bc4\u8bba\uff0c\u8fd9\u4e9b\u6587\u672c\u8bc4\u8bba\u80fd\u591f\u4f53\u73b0\u51fa\u7528\u6237\u7684\u504f\u597d\u4ee5\u53ca\u5546\u54c1\u7279\u5f81\u4fe1\u606f\uff0c\u662f\u4e00\u79cd\u8bed\u4e49\u4fe1\u606f\u4e30\u5bcc\u7684\u9690\u5f0f\u7279\u5f81\u3002 \u76f8\u6bd4\u4e8e\u5355\u7eaf\u7684\u5229\u7528\u663e\u5f0f\u8bc4\u5206\u7279\u5f81\uff0c\u6587\u672c\u4fe1\u606f\u4e00\u65b9\u9762\u53ef\u4ee5\u5f25\u8865\u8bc4\u5206\u7a00\u758f\u6027\u7684\u95ee\u9898\uff0c\u53e6\u4e00\u65b9\u9762\u5728\u63a8\u8350\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u65b9\u9762\u4e5f\u80fd\u591f\u505a\u7684\u66f4\u597d\u3002 \u56e0\u6b64\uff0c\u672c\u6b21\u9879\u76ee\u6211\u4eec\u5c06\u4ee5\"\u7535\u5546\u5e73\u53f0\u7528\u6237\u8bc4\u8bba\"\u4e3a\u80cc\u666f\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u8bba\u6587\u672c\u7684\u51c6\u786e\u5206\u7c7b\uff0c\u8fd9\u6837\u505a\u7684\u76ee\u7684\u662f\u901a\u8fc7\u7528\u6237\u5bf9\u4e0d\u540c\u5546\u54c1\u6216\u670d\u52a1\u7684\u8bc4\u4ef7\uff0c\u5e73\u53f0\u80fd\u591f\u5feb\u901f\u56de\u5e94\u7528\u6237\u9700\u6c42\uff0c\u6539\u8fdb\u4ea7\u54c1\u548c\u670d\u52a1\u3002\u540c\u65f6\uff0c\u81ea\u52a8\u5206\u7c7b\u4e5f\u4e3a\u4e2a\u6027\u5316\u63a8\u8350\u5960\u5b9a\u57fa\u7840\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u8f7b\u677e\u5730\u627e\u5230\u7b26\u5408\u5176\u504f\u597d\u7684\u5546\u54c1\u3002","title":"1 \u9879\u76ee\u80cc\u666f"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html#2","text":"","title":"2 \u8bc4\u8bba\u6587\u672c\u5206\u7c7b\u5b9e\u73b0\u65b9\u6cd5"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html#21","text":"\u76ee\u524d\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u65b9\u6cd5\u5f88\u591a\uff0c\u5982\u7ecf\u5178\u7684\u5e94\u7528\u4e8e\u6587\u672c\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08Text-CNN\uff09\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08Text-RNN)\u3001\u57fa\u4e8eBERT\u7b49\u9884\u8bad\u7ec3\u6a21\u578b\u7684fine-tuning\u7b49\uff0c\u4f46\u662f\u8fd9\u4e9b\u65b9\u6cd5\u591a\u4e3a\u5efa\u7acb\u5728\u5177\u6709\u5927\u91cf\u7684\u6807\u6ce8\u6570\u636e\u4e0b\u7684\u6709\u76d1\u7763\u5b66\u4e60\u3002\u5728\u5f88\u591a\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u9886\u57df\u7279\u6b8a\u6027\u548c\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\uff0c\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5730\u5b66\u4e60\u53c2\u6570\uff0c\u4ece\u800c\u6613\u51fa\u73b0\u8fc7\u62df\u5408\u73b0\u8c61\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u901a\u8fc7\u5c0f\u6837\u672c\u6570\u636e\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6027\u80fd\u8f83\u597d\u7684\u5206\u7c7b\u6a21\u578b\u662f\u76ee\u524d\u7684\u7814\u7a76\u70ed\u70b9\u3002","title":"2.1 \u4f20\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html#22","text":"\u57fa\u4e8e\u524d\u9762\u7ae0\u8282\u7684\u4ecb\u7ecd\uff0c\u6211\u4eec\u53ef\u4ee5\u501f\u52a9Prompt-Tuning\u7684\u6280\u672f\uff0c\u6765\u5b9e\u73b0\u6a21\u578b\u90e8\u5206\u53c2\u6570\u7684\u5fae\u8c03\uff08\u5f53\u7136\u5982\u679c\u6a21\u578b\u53c2\u6570\u8f83\u5c0f\u6bd4\u5982BERT,\u4e5f\u53ef\u4ee5\u5168\u91cf\u53c2\u6570\u5fae\u8c03\uff09\uff0c\u76f8\u6bd4\u4f20\u7edf\u6280\u672f\u65b9\u6cd5\uff0cPrompt-Tuning\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u5728\u8f83\u5c11\u6837\u672c\u7684\u8bad\u7ec3\u4e0a\uff0c\u5c31\u53ef\u4ee5\u8fbe\u5230\u8f83\u597d\u7684\u7ed3\u679c\u3002 \u5728\u672c\u6b21\u9879\u76ee\u4e2d\uff0c\u6211\u4eec\u5c06\u5206\u522b\u57fa\u4e8eBERT+PET\u4ee5\u53caBERT+P-Tuning\u4e24\u79cd\u65b9\u5f0f\u5b9e\u73b0\u7528\u6237\u8bc4\u8bba\u6587\u672c\u7684\u5206\u7c7b\u3002\u91cd\u70b9\u662f\u7406\u89e3prompt\u7684\u6784\u9020\u65b9\u6cd5\uff0c\u4ee5\u53capromt-tuning\u65b9\u6cd5\u7684\u5b9e\u73b0\u539f\u7406\u3002","title":"2.2 \u6a21\u578b\u9ad8\u6548\u53c2\u6570\u5fae\u8c03\u65b9\u6cd5"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/01-%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D.html#_3","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u8bb2\u89e3\u4e86\u8bc4\u8bba\u6587\u672c\u5206\u7c7b\u7684\u5b9e\u73b0\u65b9\u6cd5\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html","text":"\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3PET\u65b9\u5f0f\u7684\u601d\u60f3 \u5b89\u88c5\u9879\u76ee\u5fc5\u5907\u7684\u5de5\u5177\u5305 \u4e86\u89e3\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u6574\u4f53\u9879\u76ee\u67b6\u6784 1 \u9879\u76ee\u4ecb\u7ecd \u00b6 \u672c\u7ae0\u6211\u4eec\u5c06\u4ee5\"\u7535\u5546\u5e73\u53f0\u7528\u6237\u8bc4\u8bba\u6570\u636e\"\u4e3a\u80cc\u666f\uff0c\u57fa\u4e8eBERT+PET\uff08\u786c\u6a21\u7248\uff09\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u8bba\u6587\u672c\u7684\u51c6\u786e\u5206\u7c7b 2 PET\u56de\u987e \u00b6 PET\uff08PatternExploiting Training\uff09\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u6839\u636e\u5148\u9a8c\u77e5\u8bc6\u4eba\u5de5\u5b9a\u4e49\u6a21\u7248\uff0c\u5c06\u76ee\u6807\u5206\u7c7b\u4efb\u52a1\u8f6c\u6362\u4e3a\u4e0eMLM\u4e00\u81f4\u7684\u5b8c\u5f62\u586b\u7a7a\uff0c\u7136\u540e\u518d\u53bb\u5fae\u8c03MLM\u4efb\u52a1\u53c2\u6570\u3002 \u56fe\u4e2d\u793a\u4f8b1: \u60c5\u611f\u5206\u7c7b\u4efb\u52a1\uff08\u597d\u8bc4\u8fd8\u662f\u5dee\u8bc4\uff09\uff0c\u539f\u59cb\u6587\u672c:\u8fd9\u5bb6\u5e97\u771f\u4e0d\u9519,\u503c\u5f97\u63a8\u8350\u3002PET\u6a21\u677f: [MASK]\u6ee1\u610f\u3002Label:\u4e0d/\u5f88\u3002\u6807\u7b7e\u8bcd\u6620\u5c04\uff08Label Word Verbalizer\uff09\uff1a\u4f8b\u5982\u5982\u679c [MASK] \u9884\u6d4b\u7684\u8bcd\u662f\u201c\u4e0d\u201d\uff0c\u5219\u8ba4\u4e3a\u662f\u5dee\u8bc4\u7c7b\uff0c\u5982\u679c\u662f\u201c\u5f88\u201d\uff0c\u5219\u8ba4\u4e3a\u662f\u597d\u8bc4\u7c7b\u3002 \u56fe\u4e2d\u793a\u4f8b2:\u65b0\u95fb\u5206\u7c7b\u4efb\u52a1\uff08\u591a\u5206\u7c7b\uff09\uff0c\u539f\u59cb\u6587\u672c\uff1a\u4e2d\u56fd\u5973\u6392\u518d\u593a\u51a0\uff01PET\u6a21\u7248\uff1a\u4e0b\u9762\u662f[MASK] [MASK]\u65b0\u95fb\uff0cLabel\uff1a\u4f53\u80b2/\u8d22\u7ecf/\u65f6\u653f/\u519b\u4e8b PET\u65b9\u5f0f\u5b9e\u73b0\u8fc7\u7a0b\uff1a\u5c06\u6a21\u7248\u4e0e\u539f\u59cb\u6587\u672c\u62fc\u5728\u4e00\u8d77\u8f93\u5165\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4f1a\u5bf9\u6a21\u677f\u4e2d\u7684mask\u505a\u9884\u6d4b\uff0c\u5f97\u5230\u4e00\u4e2alabel PET\u65b9\u5f0f\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u4eba\u5de5\u6a21\u7248\uff0c\u91ca\u653e\u9884\u8bad\u7ec3\u6a21\u578b\u77e5\u8bc6\u6f5c\u529b \u4e0d\u5f15\u5165\u968f\u673a\u521d\u59cb\u5316\u53c2\u6570\uff0c\u907f\u514d\u8fc7\u62df\u5408 \u8f83\u5c11\u7684\u6837\u672c\u5c31\u53ef\u4ee5\u5ab2\u7f8e\u591a\u6837\u672c\u7684\u4f20\u7edf\u5fae\u8c03\u65b9\u5f0f \u7f3a\u70b9\uff1a \u4eba\u5de5\u6a21\u677f\u7a33\u5b9a\u6027\u5dee\uff0c\u4e0d\u540c\u6a21\u677f\u51c6\u786e\u7387\u53ef\u76f8\u5dee\u8fd120\u4e2a\u767e\u5206\u70b9 \u6a21\u677f\u8868\u793a\u65e0\u6cd5\u5168\u5c40\u4f18\u5316 3 \u73af\u5883\u51c6\u5907 \u00b6 \u672c\u9879\u76ee\u57fa\u4e8e torch+ transformers \u5b9e\u73b0\uff0c\u8fd0\u884c\u524d\u8bf7\u5b89\u88c5\u76f8\u5173\u4f9d\u8d56\u5305\uff1a torch transformers==4.22.1 datasets==2.4.0 evaluate==0.2.2 matplotlib==3.6.0 rich==12.5.1 scikit-learn==1.1.2 requests==2.28.1 4 \u9879\u76ee\u67b6\u6784 \u00b6 \u9879\u76ee\u67b6\u6784\u6d41\u7a0b\u56fe\uff1a \u9879\u76ee\u6574\u4f53\u4ee3\u7801\u4ecb\u7ecd\uff1a \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u660e\u786e\u4e86\u9879\u76ee\u7684\u6574\u4f53\u67b6\u6784\uff0c\u5e76\u5bf9\u9879\u76ee\u4e2d\u6574\u4f53\u4ee3\u7801\u7ed3\u6784\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002","title":"6.2 BERT+PET\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#bertpet","text":"","title":"\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#_1","text":"\u7406\u89e3PET\u65b9\u5f0f\u7684\u601d\u60f3 \u5b89\u88c5\u9879\u76ee\u5fc5\u5907\u7684\u5de5\u5177\u5305 \u4e86\u89e3\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u6574\u4f53\u9879\u76ee\u67b6\u6784","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#1","text":"\u672c\u7ae0\u6211\u4eec\u5c06\u4ee5\"\u7535\u5546\u5e73\u53f0\u7528\u6237\u8bc4\u8bba\u6570\u636e\"\u4e3a\u80cc\u666f\uff0c\u57fa\u4e8eBERT+PET\uff08\u786c\u6a21\u7248\uff09\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u8bba\u6587\u672c\u7684\u51c6\u786e\u5206\u7c7b","title":"1 \u9879\u76ee\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#2-pet","text":"PET\uff08PatternExploiting Training\uff09\u7684\u6838\u5fc3\u601d\u60f3\u662f\uff1a\u6839\u636e\u5148\u9a8c\u77e5\u8bc6\u4eba\u5de5\u5b9a\u4e49\u6a21\u7248\uff0c\u5c06\u76ee\u6807\u5206\u7c7b\u4efb\u52a1\u8f6c\u6362\u4e3a\u4e0eMLM\u4e00\u81f4\u7684\u5b8c\u5f62\u586b\u7a7a\uff0c\u7136\u540e\u518d\u53bb\u5fae\u8c03MLM\u4efb\u52a1\u53c2\u6570\u3002 \u56fe\u4e2d\u793a\u4f8b1: \u60c5\u611f\u5206\u7c7b\u4efb\u52a1\uff08\u597d\u8bc4\u8fd8\u662f\u5dee\u8bc4\uff09\uff0c\u539f\u59cb\u6587\u672c:\u8fd9\u5bb6\u5e97\u771f\u4e0d\u9519,\u503c\u5f97\u63a8\u8350\u3002PET\u6a21\u677f: [MASK]\u6ee1\u610f\u3002Label:\u4e0d/\u5f88\u3002\u6807\u7b7e\u8bcd\u6620\u5c04\uff08Label Word Verbalizer\uff09\uff1a\u4f8b\u5982\u5982\u679c [MASK] \u9884\u6d4b\u7684\u8bcd\u662f\u201c\u4e0d\u201d\uff0c\u5219\u8ba4\u4e3a\u662f\u5dee\u8bc4\u7c7b\uff0c\u5982\u679c\u662f\u201c\u5f88\u201d\uff0c\u5219\u8ba4\u4e3a\u662f\u597d\u8bc4\u7c7b\u3002 \u56fe\u4e2d\u793a\u4f8b2:\u65b0\u95fb\u5206\u7c7b\u4efb\u52a1\uff08\u591a\u5206\u7c7b\uff09\uff0c\u539f\u59cb\u6587\u672c\uff1a\u4e2d\u56fd\u5973\u6392\u518d\u593a\u51a0\uff01PET\u6a21\u7248\uff1a\u4e0b\u9762\u662f[MASK] [MASK]\u65b0\u95fb\uff0cLabel\uff1a\u4f53\u80b2/\u8d22\u7ecf/\u65f6\u653f/\u519b\u4e8b PET\u65b9\u5f0f\u5b9e\u73b0\u8fc7\u7a0b\uff1a\u5c06\u6a21\u7248\u4e0e\u539f\u59cb\u6587\u672c\u62fc\u5728\u4e00\u8d77\u8f93\u5165\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4f1a\u5bf9\u6a21\u677f\u4e2d\u7684mask\u505a\u9884\u6d4b\uff0c\u5f97\u5230\u4e00\u4e2alabel PET\u65b9\u5f0f\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u4eba\u5de5\u6a21\u7248\uff0c\u91ca\u653e\u9884\u8bad\u7ec3\u6a21\u578b\u77e5\u8bc6\u6f5c\u529b \u4e0d\u5f15\u5165\u968f\u673a\u521d\u59cb\u5316\u53c2\u6570\uff0c\u907f\u514d\u8fc7\u62df\u5408 \u8f83\u5c11\u7684\u6837\u672c\u5c31\u53ef\u4ee5\u5ab2\u7f8e\u591a\u6837\u672c\u7684\u4f20\u7edf\u5fae\u8c03\u65b9\u5f0f \u7f3a\u70b9\uff1a \u4eba\u5de5\u6a21\u677f\u7a33\u5b9a\u6027\u5dee\uff0c\u4e0d\u540c\u6a21\u677f\u51c6\u786e\u7387\u53ef\u76f8\u5dee\u8fd120\u4e2a\u767e\u5206\u70b9 \u6a21\u677f\u8868\u793a\u65e0\u6cd5\u5168\u5c40\u4f18\u5316","title":"2 PET\u56de\u987e"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#3","text":"\u672c\u9879\u76ee\u57fa\u4e8e torch+ transformers \u5b9e\u73b0\uff0c\u8fd0\u884c\u524d\u8bf7\u5b89\u88c5\u76f8\u5173\u4f9d\u8d56\u5305\uff1a torch transformers==4.22.1 datasets==2.4.0 evaluate==0.2.2 matplotlib==3.6.0 rich==12.5.1 scikit-learn==1.1.2 requests==2.28.1","title":"3  \u73af\u5883\u51c6\u5907"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#4","text":"\u9879\u76ee\u67b6\u6784\u6d41\u7a0b\u56fe\uff1a \u9879\u76ee\u6574\u4f53\u4ee3\u7801\u4ecb\u7ecd\uff1a","title":"4 \u9879\u76ee\u67b6\u6784"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/02-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#_2","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u660e\u786e\u4e86\u9879\u76ee\u7684\u6574\u4f53\u67b6\u6784\uff0c\u5e76\u5bf9\u9879\u76ee\u4e2d\u6574\u4f53\u4ee3\u7801\u7ed3\u6784\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html","text":"\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u672c\u9879\u76ee\u6570\u636e\u7c7b\u578b\u548c\u8868\u73b0\u683c\u5f0f \u638c\u63e1\u6570\u636e\u5904\u7406\u7684\u5de5\u5177\u51fd\u6570\u4ee3\u7801\u5b9e\u73b0 BERT+PET\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406 \u00b6 \u672c\u9879\u76ee\u4e2d\u5bf9\u6570\u636e\u90e8\u5206\u7684\u9884\u5904\u7406\u6b65\u9aa4\u5982\u4e0b: \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801 1 \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u00b6 \u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/PET/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b4\u4e2atxt\u6587\u6863\uff0c\u5206\u522b\u4e3a\uff1atrain.txt\u3001dev.txt\u3001prompt.txt\u3001verbalizer.txt 1.1 train.txt \u00b6 train.txt\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u6c34\u679c \u8106\u8106\u7684\uff0c\u751c\u5473\u53ef\u4ee5\uff0c\u53ef\u80fd\u65f6\u95f4\u6709\u70b9\u957f\u4e86\uff0c\u6c34\u5206\u4e0d\u662f\u5f88\u8db3\u3002 \u5e73\u677f \u534e\u4e3a\u673a\u5668\u80af\u5b9a\u4e0d\u9519\uff0c\u4f46\u7b2c\u4e00\u6b21\u78b0\u4e0a\u4eac\u4e1c\u6700\u7cdf\u7cd5\u7684\u670d\u52a1\uff0c\u4ee5\u540e\u4e0d\u60f3\u5230\u4eac\u4e1c\u8d2d\u7269\u4e86\u3002 \u4e66\u7c4d \u4e3a\u4ec0\u4e48\u4e0d\u8ba4\u771f\u7684\u68c0\u67e5\u4e00\u4e0b\uff0c \u53d1\u8fd9\u4e48\u4e00\u672c\u810f\u810f\u7684\u4e66\u7ed9\u987e\u5ba2\u5462\uff01 \u8863\u670d \u624b\u611f\u4e0d\u9519\uff0c\u7528\u6599\u4e5f\u5f88\u597d\uff0c\u4e0d\u77e5\u9053\u6c34\u6d17\u540e\u600e\u6837\uff0c\u76f8\u4fe1\u5927\u54c1\u724c\uff0c\u8d28\u91cf\u8fc7\u5173\uff0c\u4e94\u661f\u597d\u8bc4\uff01\uff01\uff01 \u6c34\u679c \u82f9\u679c\u6709\u70b9\u5c0f\uff0c\u4e0d\u8fc7\u597d\u5403\uff0c\u8fd8\u6709\u51e0\u4e2a\u70c2\u7684\u3002\u4f30\u8ba1\u662f\u6545\u610f\u7684\u653e\u7684\u3002\u5dee\u8bc4\u3002 \u8863\u670d \u6389\u8272\u6389\u7684\u5389\u5bb3\uff0c\u6d17\u4e00\u6b21\u5c31\u82b1\u4e86 train.txt\u4e00\u5171\u5305\u542b63\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002 1.2 dev.txt \u00b6 dev.txt\u4e3a\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u4e66\u7c4d \"\u4e00\u70b9\u90fd\u4e0d\u597d\u7b11,\u5f88\u5931\u671b,\u5185\u5bb9\u4e5f\u4e0d\u662f\u5f88\u5b9e\u7528\" \u8863\u670d \u5b8c\u5168\u662f\u4e00\u6761\u65e7\u88e4\u5b50\u3002 \u624b\u673a \u76f8\u673a\u8d28\u91cf\u4e0d\u9519\uff0c\u5982\u679c\u9633\u5149\u5145\u8db3\uff0c\u53ef\u4ee5\u548c\u6570\u7801\u76f8\u673a\u5ab2\u7f8e\uff0e\u754c\u9762\u6bd4\u8f83\u4eba\u6027\u5316\uff0c\u5bb9\u6613\u4f7f\u7528\uff0e\u8f6f\u4ef6\u5b89\u88c5\u7b80\u4fbf \u4e66\u7c4d \u660e\u660e\u8bf4\u6709\u8d27\uff0c\u7ed3\u679c\u9001\u8d27\u53c8\u6ca1\u6709\u4e86\u3002\u5e76\u4e14\u4e5f\u4e0d\u544a\u8bc9\u6211\uff0c\u600e\u4e48\u8bc4\u554a \u6d17\u6d74 \u975e\u5e38\u4e0d\u6ee1\u610f\uff0c\u665a\u4e0a\u6d17\u7684\u5934\u53d1\uff0c\u7b2c\u4e8c\u5929\u5934\u75d2\u75d2\u7684\u4e0d\u884c\u4e86\uff0c\u8fd8\u90fd\u662f\u5934\u76ae\u5c51\u3002 \u6c34\u679c \u8fd9\u4e2a\u82f9\u679c\u611f\u89c9\u662f\u957f\u719f\u7684\u82f9\u679c\uff0c\u6ca1\u6709\u6253\u8721\uff0c\u4e0d\u9519\uff0c\u53c8\u751c\u53c8\u8106 dev.txt\u4e00\u5171\u5305\u542b590\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002 1.3 prompt.txt \u00b6 prompt.txt\u4e3a\u4eba\u5de5\u8bbe\u5b9a\u63d0\u793a\u6a21\u7248\uff0c\u5176\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u8fd9\u662f\u4e00\u6761{MASK}\u8bc4\u8bba\uff1a{textA}\u3002 \u5176\u4e2d\uff0c\u7528\u5927\u62ec\u53f7\u62ec\u8d77\u6765\u7684\u90e8\u5206\u4e3a\u300c\u81ea\u5b9a\u4e49\u53c2\u6570\u300d\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bbe\u7f6e\u5927\u62ec\u53f7\u5185\u7684\u503c\u3002 \u793a\u4f8b\u4e2d {MASK} \u4ee3\u8868 [MASK] token \u7684\u4f4d\u7f6e\uff0c{textA} \u4ee3\u8868\u8bc4\u8bba\u6570\u636e\u7684\u4f4d\u7f6e\u3002 \u4f60\u53ef\u4ee5\u6539\u4e3a\u81ea\u5df1\u60f3\u8981\u7684\u6a21\u677f\uff0c\u4f8b\u5982\u60f3\u65b0\u589e\u4e00\u4e2a {textB} \u53c2\u6570\uff1a {textA}\u548c{textB}\u662f{MASK}\u540c\u7684\u610f\u601d\u3002 1.4 verbalizer.txt \u00b6 verbalizer.txt \u4e3b\u8981\u7528\u4e8e\u5b9a\u4e49\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u5230\u300c\u6807\u7b7e\u9884\u6d4b\u8bcd\u300d\u4e4b\u95f4\u7684\u6620\u5c04\u3002\u5728\u6709\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5c06\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u4f5c\u4e3a [MASK] \u53bb\u9884\u6d4b\u53ef\u80fd\u4e0d\u5177\u5907\u5f88\u597d\u7684\u8bed\u4e49\u901a\u987a\u6027\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u4f1a\u5bf9\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u505a\u4e00\u5b9a\u7684\u6620\u5c04\u3002 \u4f8b\u5982\uff1a \"\u4e2d\u56fd\u7206\u51b72-1\u6218\u80dc\u97e9\u56fd\"\u662f\u4e00\u5219[MASK][MASK]\u65b0\u95fb\u3002 \u4f53\u80b2 \u8fd9\u53e5\u8bdd\u4e2d\u7684\u6807\u7b7e\u4e3a\u300c\u4f53\u80b2\u300d\uff0c\u4f46\u5982\u679c\u6211\u4eec\u5c06\u6807\u7b7e\u8bbe\u7f6e\u4e3a\u300c\u8db3\u7403\u300d\u4f1a\u66f4\u5bb9\u6613\u9884\u6d4b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u300c\u4f53\u80b2\u300d\u8fd9\u4e2a label \u6784\u5efa\u8bb8\u591a\u4e2a\u5b50\u6807\u7b7e\uff0c\u5728\u63a8\u7406\u65f6\uff0c\u53ea\u8981\u9884\u6d4b\u5230\u5b50\u6807\u7b7e\u6700\u7ec8\u63a8\u7406\u51fa\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\uff0c\u5982\u4e0b\uff1a \u4f53\u80b2 -> \u8db3\u7403,\u7bee\u7403,\u7f51\u7403,\u68d2\u7403,\u4e52\u4e53,\u4f53\u80b2 \u9879\u76ee\u4e2d\u6807\u7b7e\u8bcd\u6620\u5c04\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u7535\u8111 \u7535\u8111 \u6c34\u679c \u6c34\u679c \u5e73\u677f \u5e73\u677f \u8863\u670d \u8863\u670d \u9152\u5e97 \u9152\u5e97 \u6d17\u6d74 \u6d17\u6d74 \u4e66\u7c4d \u4e66\u7c4d \u8499\u725b \u8499\u725b \u624b\u673a \u624b\u673a \u7535\u5668 \u7535\u5668 verbalizer.txt \u4e00\u5171\u5305\u542b10\u4e2a\u7c7b\u522b\uff0c\u4e0a\u8ff0\u6570\u636e\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e861\u5bf91\u7684verbalizer, \u5982\u679c\u60f3\u5b9a\u4e49\u4e00\u5bf9\u591a\u7684\u6620\u5c04\uff0c\u53ea\u9700\u8981\u5728\u540e\u9762\u7528\",\"\u5206\u5272\u5373\u53ef\uff0c eg: \u6c34\u679c \u82f9\u679c,\u9999\u8549,\u6a58\u5b50 \u82e5\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6 2 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/PET/pet_config.py config\u6587\u4ef6\u76ee\u7684\uff1a\u914d\u7f6e\u9879\u76ee\u5e38\u7528\u53d8\u91cf\uff0c\u4e00\u822c\u8fd9\u4e9b\u53d8\u91cf\u5c5e\u4e8e\u4e0d\u7ecf\u5e38\u6539\u53d8\u7684\uff0c\u6bd4\u5982\uff1a\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\u3001\u6a21\u578b\u8bad\u7ec3\u6b21\u6570\u3001\u6a21\u578b\u8d85\u53c2\u6570\u7b49\u7b49 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a # coding:utf-8 import torch import sys print ( sys . path ) class ProjectConfig ( object ): def __init__ ( self ): # \u662f\u5426\u4f7f\u7528GPU self . device = 'cuda:0' if torch . cuda . is_available () else 'cpu' # \u9884\u8bad\u7ec3\u6a21\u578bbert\u8def\u5f84 self . pre_model = '/home/prompt_project/bert-base-chinese' self . train_path = '/home/prompt_project/PET/data/train.txt' self . dev_path = '/home/prompt_project/PET/data/dev.txt' self . prompt_file = '/home/prompt_project/PET/data/prompt.txt' self . verbalizer = '/home/prompt_project/PET/data/verbalizer.txt' self . max_seq_len = 512 self . batch_size = 8 self . learning_rate = 5e-5 # \u6743\u91cd\u8870\u51cf\u53c2\u6570\uff08\u6b63\u5219\u5316\uff0c\u6291\u5236\u6a21\u578b\u8fc7\u62df\u5408\uff09 self . weight_decay = 0 # \u9884\u70ed\u5b66\u4e60\u7387(\u7528\u6765\u5b9a\u4e49\u9884\u70ed\u7684\u6b65\u6570) self . warmup_ratio = 0.06 self . max_label_len = 2 self . epochs = 50 self . logging_steps = 10 self . valid_steps = 20 self . save_dir = '/home/prompt_project/PET/checkpoints' if __name__ == '__main__' : pc = ProjectConfig () print ( pc . prompt_file ) print ( pc . pre_model ) 3 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/PET/data_handle. data_handle\u6587\u4ef6\u5939\u4e2d\u4e00\u5171\u5305\u542b\u4e09\u4e2apy\u811a\u672c\uff1atemplate.py\u3001data_preprocess.py\u3001data_loader.py 3.1 template.py \u00b6 \u76ee\u7684\uff1a\u6784\u5efa\u56fa\u5b9a\u6a21\u7248\u7c7b\uff0ctext2id\u7684\u8f6c\u6362 \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 # -*- coding:utf-8 -*- from rich import print # \u7ec8\u7aef\u5c42\u6b21\u663e\u793a from transformers import AutoTokenizer import numpy as np import sys sys . path . append ( '..' ) from pet_config import * \u5b9a\u4e49HardTemplate\u7c7b class HardTemplate ( object ): \"\"\" \u786c\u6a21\u677f\uff0c\u4eba\u5de5\u5b9a\u4e49\u53e5\u5b50\u548c[MASK]\u4e4b\u95f4\u7684\u4f4d\u7f6e\u5173\u7cfb\u3002 \"\"\" def __init__ ( self , prompt : str ): \"\"\" Args: prompt (str): prompt\u683c\u5f0f\u5b9a\u4e49\u5b57\u7b26\u4e32, e.g. -> \"\u8fd9\u662f\u4e00\u6761{MASK}\u8bc4\u8bba\uff1a{textA}\u3002\" \"\"\" self . prompt = prompt self . inputs_list = [] # \u6839\u636e\u6587\u5b57prompt\u62c6\u5206\u4e3a\u5404part\u7684\u5217\u8868 self . custom_tokens = set ([ 'MASK' ]) # \u4eceprompt\u4e2d\u89e3\u6790\u51fa\u7684\u81ea\u5b9a\u4e49token\u96c6\u5408 self . prompt_analysis () # \u89e3\u6790prompt\u6a21\u677f def prompt_analysis ( self ): \"\"\" \u5c06prompt\u6587\u5b57\u6a21\u677f\u62c6\u89e3\u4e3a\u53ef\u6620\u5c04\u7684\u6570\u636e\u7ed3\u6784\u3002 Examples: prompt -> \"\u8fd9\u662f\u4e00\u6761{MASK}\u8bc4\u8bba\uff1a{textA}\u3002\" inputs_list -> ['\u8fd9', '\u662f', '\u4e00', '\u6761', 'MASK', '\u8bc4', '\u8bba', '\uff1a', 'textA', '\u3002'] custom_tokens -> {'textA', 'MASK'} \"\"\" idx = 0 while idx < len ( self . prompt ): str_part = '' if self . prompt [ idx ] not in [ '{' , '}' ]: self . inputs_list . append ( self . prompt [ idx ]) if self . prompt [ idx ] == '{' : # \u8fdb\u5165\u81ea\u5b9a\u4e49\u5b57\u6bb5 idx += 1 while self . prompt [ idx ] != '}' : str_part += self . prompt [ idx ] # \u62fc\u63a5\u8be5\u81ea\u5b9a\u4e49\u5b57\u6bb5\u7684\u503c idx += 1 elif self . prompt [ idx ] == '}' : raise ValueError ( \"Unmatched bracket '}', check your prompt.\" ) if str_part : self . inputs_list . append ( str_part ) # \u5c06\u6240\u6709\u81ea\u5b9a\u4e49\u5b57\u6bb5\u5b58\u50a8\uff0c\u540e\u7eed\u4f1a\u68c0\u6d4b\u8f93\u5165\u4fe1\u606f\u662f\u5426\u5b8c\u6574 self . custom_tokens . add ( str_part ) idx += 1 def __call__ ( self , inputs_dict : dict , tokenizer , mask_length , max_seq_len = 512 ): \"\"\" \u8f93\u5165\u4e00\u4e2a\u6837\u672c\uff0c\u8f6c\u6362\u4e3a\u7b26\u5408\u6a21\u677f\u7684\u683c\u5f0f\u3002 Args: inputs_dict (dict): prompt\u4e2d\u7684\u53c2\u6570\u5b57\u5178, e.g. -> { \"textA\": \"\u8fd9\u4e2a\u624b\u673a\u4e5f\u592a\u5361\u4e86\", \"MASK\": \"[MASK]\" } tokenizer: \u7528\u4e8eencoding\u6587\u672c mask_length (int): MASK token \u7684\u957f\u5ea6 Returns: dict -> { 'text': '[CLS]\u8fd9\u662f\u4e00\u6761[MASK]\u8bc4\u8bba\uff1a\u8fd9\u4e2a\u624b\u673a\u4e5f\u592a\u5361\u4e86\u3002[SEP]', 'input_ids': [1, 47, 10, 7, 304, 3, 480, 279, 74, 47, 27, 247, 98, 105, 512, 777, 15, 12043, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'mask_position': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] } \"\"\" # \u5b9a\u4e49\u8f93\u51fa\u683c\u5f0f outputs = { 'text' : '' , 'input_ids' : [], 'token_type_ids' : [], 'attention_mask' : [], 'mask_position' : [] } str_formated = '' for value in self . inputs_list : if value in self . custom_tokens : if value == 'MASK' : str_formated += inputs_dict [ value ] * mask_length else : str_formated += inputs_dict [ value ] else : str_formated += value # print(f'str_formated-->{str_formated}') encoded = tokenizer ( text = str_formated , truncation = True , max_length = max_seq_len , padding = 'max_length' ) # print(f'encoded--->{encoded}') outputs [ 'input_ids' ] = encoded [ 'input_ids' ] outputs [ 'token_type_ids' ] = encoded [ 'token_type_ids' ] outputs [ 'attention_mask' ] = encoded [ 'attention_mask' ] token_list = tokenizer . convert_ids_to_tokens ( encoded [ 'input_ids' ]) outputs [ 'text' ] = '' . join ( token_list ) mask_token_id = tokenizer . convert_tokens_to_ids ([ '[MASK]' ])[ 0 ] condition = np . array ( outputs [ 'input_ids' ]) == mask_token_id mask_position = np . where ( condition )[ 0 ] . tolist () outputs [ 'mask_position' ] = mask_position return outputs if __name__ == '__main__' : pc = ProjectConfig () tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) hard_template = HardTemplate ( prompt = '\u8fd9\u662f\u4e00\u6761 {MASK} \u8bc4\u8bba\uff1a {textA} ' ) print ( hard_template . inputs_list ) print ( hard_template . custom_tokens ) tep = hard_template ( inputs_dict = { 'textA' : '\u5305\u88c5\u4e0d\u9519\uff0c\u82f9\u679c\u633a\u751c\u7684\uff0c\u4e2a\u5934\u4e5f\u5927\u3002' , 'MASK' : '[MASK]' }, tokenizer = tokenizer , max_seq_len = 30 , mask_length = 2 ) print ( tep ) print ( tokenizer . convert_ids_to_tokens ([ 3819 , 3352 ])) print ( tokenizer . convert_tokens_to_ids ([ '\u6c34' , '\u679c' ])) 3.2 data_preprocess.py \u00b6 \u76ee\u7684: \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from template import * from rich import print from datasets import load_dataset # partial\uff1a\u628a\u4e00\u4e2a\u51fd\u6570\u7684\u67d0\u4e9b\u53c2\u6570\u7ed9\u56fa\u5b9a\u4f4f\uff08\u4e5f\u5c31\u662f\u8bbe\u7f6e\u9ed8\u8ba4\u503c\uff09\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u51fd\u6570\uff0c\u8c03\u7528\u8fd9\u4e2a\u65b0\u51fd\u6570\u4f1a\u66f4\u7b80\u5355 from functools import partial from pet_config import * \u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u65b9\u6cd5convert_example() def convert_example ( examples : dict , tokenizer , max_seq_len : int , max_label_len : int , hard_template : HardTemplate , train_mode = True , return_tensor = False ) -> dict : \"\"\" \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u6536\u7684\u8f93\u5165\u6570\u636e\u3002 Args: examples (dict): \u8bad\u7ec3\u6570\u636e\u6837\u672c, e.g. -> { \"text\": [ '\u624b\u673a \u8fd9\u4e2a\u624b\u673a\u4e5f\u592a\u5361\u4e86\u3002', '\u4f53\u80b2 \u4e16\u754c\u676f\u4e3a\u4f55\u8fdf\u8fdf\u4e0d\u89c1\u5ba3\u4f20', ... ] } max_seq_len (int): \u53e5\u5b50\u7684\u6700\u5927\u957f\u5ea6\uff0c\u82e5\u6ca1\u6709\u8fbe\u5230\u6700\u5927\u957f\u5ea6\uff0c\u5219padding\u4e3a\u6700\u5927\u957f\u5ea6 max_label_len (int): \u6700\u5927label\u957f\u5ea6\uff0c\u82e5\u6ca1\u6709\u8fbe\u5230\u6700\u5927\u957f\u5ea6\uff0c\u5219padding\u4e3a\u6700\u5927\u957f\u5ea6 hard_template (HardTemplate): \u6a21\u677f\u7c7b\u3002 train_mode (bool): \u8bad\u7ec3\u9636\u6bb5 or \u63a8\u7406\u9636\u6bb5\u3002 return_tensor (bool): \u662f\u5426\u8fd4\u56detensor\u7c7b\u578b\uff0c\u5982\u4e0d\u662f\uff0c\u5219\u8fd4\u56denumpy\u7c7b\u578b\u3002 Returns: dict (str: np.array) -> tokenized_output = { 'input_ids': [[1, 47, 10, 7, 304, 3, 3, 3, 3, 47, 27, 247, 98, 105, 512, 777, 15, 12043, 2], ...], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], ...], 'mask_positions': [[5, 6, 7, 8], ...], 'mask_labels': [[2372, 3442, 0, 0], [2643, 4434, 2334, 0], ...] } \"\"\" tokenized_output = { 'input_ids' : [], 'token_type_ids' : [], 'attention_mask' : [], 'mask_positions' : [], 'mask_labels' : [] } for i , example in enumerate ( examples [ 'text' ]): if train_mode : label , content = example . strip () . split ( ' \\t ' ) else : content = example . strip () inputs_dict = { 'textA' : content , 'MASK' : '[MASK]' } encoded_inputs = hard_template ( inputs_dict = inputs_dict , tokenizer = tokenizer , max_seq_len = max_seq_len , mask_length = max_label_len ) tokenized_output [ 'input_ids' ] . append ( encoded_inputs [ \"input_ids\" ]) tokenized_output [ 'token_type_ids' ] . append ( encoded_inputs [ \"token_type_ids\" ]) tokenized_output [ 'attention_mask' ] . append ( encoded_inputs [ \"attention_mask\" ]) tokenized_output [ 'mask_positions' ] . append ( encoded_inputs [ \"mask_position\" ]) if train_mode : label_encoded = tokenizer ( text = [ label ]) # \u5c06label\u8865\u5230\u6700\u5927\u957f\u5ea6 # print(f'label_encoded-->{label_encoded}') label_encoded = label_encoded [ 'input_ids' ][ 0 ][ 1 : - 1 ] label_encoded = label_encoded [: max_label_len ] add_pad = [ tokenizer . pad_token_id ] * ( max_label_len - len ( label_encoded )) label_encoded = label_encoded + add_pad tokenized_output [ 'mask_labels' ] . append ( label_encoded ) for k , v in tokenized_output . items (): if return_tensor : tokenized_output [ k ] = torch . LongTensor ( v ) else : tokenized_output [ k ] = np . array ( v ) return tokenized_output if __name__ == '__main__' : pc = ProjectConfig () train_dataset = load_dataset ( 'text' , data_files = pc . train_path ) print ( type ( train_dataset )) print ( train_dataset ) # print('*'*80) # print(train_dataset['train']['text']) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) hard_template = HardTemplate ( prompt = '\u8fd9\u662f\u4e00\u6761 {MASK} \u8bc4\u8bba\uff1a {textA} ' ) convert_func = partial ( convert_example , tokenizer = tokenizer , hard_template = hard_template , max_seq_len = 30 , max_label_len = 2 ) dataset = train_dataset . map ( convert_func , batched = True ) for value in dataset [ 'train' ]: print ( value ) print ( len ( value [ 'input_ids' ])) break 3.3 data_loader.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u52a0\u8f7d\u5668 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # coding:utf-8 from torch.utils.data import DataLoader from transformers import default_data_collator from data_preprocess import * from pet_config import * pc = ProjectConfig () # \u5b9e\u4f8b\u5316\u9879\u76ee\u914d\u7f6e\u6587\u4ef6 tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) \u5b9a\u4e49\u83b7\u53d6\u6570\u636e\u52a0\u8f7d\u5668\u7684\u65b9\u6cd5get_data() def get_data (): # prompt\u5b9a\u4e49 prompt = open ( pc . prompt_file , 'r' , encoding = 'utf8' ) . readlines ()[ 0 ] . strip () hard_template = HardTemplate ( prompt = prompt ) # \u6a21\u677f\u8f6c\u6362\u5668\u5b9a\u4e49 dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path , 'dev' : pc . dev_path }) # print(dataset) # print(f'Prompt is -> {prompt}') new_func = partial ( convert_example , tokenizer = tokenizer , hard_template = hard_template , max_seq_len = pc . max_seq_len , max_label_len = pc . max_label_len ) dataset = dataset . map ( new_func , batched = True ) train_dataset = dataset [ \"train\" ] dev_dataset = dataset [ \"dev\" ] # print('train_dataset', train_dataset[:2]) # print('*'*80) train_dataloader = DataLoader ( train_dataset , shuffle = True , collate_fn = default_data_collator , batch_size = pc . batch_size ) dev_dataloader = DataLoader ( dev_dataset , collate_fn = default_data_collator , batch_size = pc . batch_size ) return train_dataloader , dev_dataloader if __name__ == '__main__' : train_dataloader , dev_dataloader = get_data () print ( len ( train_dataloader )) print ( len ( dev_dataloader )) for i , value in enumerate ( train_dataloader ): print ( i ) print ( value ) print ( value [ 'input_ids' ] . dtype ) break","title":"6.3 BERT+PET\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#bertpet","text":"","title":"\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#_1","text":"\u4e86\u89e3\u672c\u9879\u76ee\u6570\u636e\u7c7b\u578b\u548c\u8868\u73b0\u683c\u5f0f \u638c\u63e1\u6570\u636e\u5904\u7406\u7684\u5de5\u5177\u51fd\u6570\u4ee3\u7801\u5b9e\u73b0","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#bertpet_1","text":"\u672c\u9879\u76ee\u4e2d\u5bf9\u6570\u636e\u90e8\u5206\u7684\u9884\u5904\u7406\u6b65\u9aa4\u5982\u4e0b: \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801","title":"BERT+PET\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#1","text":"\u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/PET/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b4\u4e2atxt\u6587\u6863\uff0c\u5206\u522b\u4e3a\uff1atrain.txt\u3001dev.txt\u3001prompt.txt\u3001verbalizer.txt","title":"1 \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#11-traintxt","text":"train.txt\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u6c34\u679c \u8106\u8106\u7684\uff0c\u751c\u5473\u53ef\u4ee5\uff0c\u53ef\u80fd\u65f6\u95f4\u6709\u70b9\u957f\u4e86\uff0c\u6c34\u5206\u4e0d\u662f\u5f88\u8db3\u3002 \u5e73\u677f \u534e\u4e3a\u673a\u5668\u80af\u5b9a\u4e0d\u9519\uff0c\u4f46\u7b2c\u4e00\u6b21\u78b0\u4e0a\u4eac\u4e1c\u6700\u7cdf\u7cd5\u7684\u670d\u52a1\uff0c\u4ee5\u540e\u4e0d\u60f3\u5230\u4eac\u4e1c\u8d2d\u7269\u4e86\u3002 \u4e66\u7c4d \u4e3a\u4ec0\u4e48\u4e0d\u8ba4\u771f\u7684\u68c0\u67e5\u4e00\u4e0b\uff0c \u53d1\u8fd9\u4e48\u4e00\u672c\u810f\u810f\u7684\u4e66\u7ed9\u987e\u5ba2\u5462\uff01 \u8863\u670d \u624b\u611f\u4e0d\u9519\uff0c\u7528\u6599\u4e5f\u5f88\u597d\uff0c\u4e0d\u77e5\u9053\u6c34\u6d17\u540e\u600e\u6837\uff0c\u76f8\u4fe1\u5927\u54c1\u724c\uff0c\u8d28\u91cf\u8fc7\u5173\uff0c\u4e94\u661f\u597d\u8bc4\uff01\uff01\uff01 \u6c34\u679c \u82f9\u679c\u6709\u70b9\u5c0f\uff0c\u4e0d\u8fc7\u597d\u5403\uff0c\u8fd8\u6709\u51e0\u4e2a\u70c2\u7684\u3002\u4f30\u8ba1\u662f\u6545\u610f\u7684\u653e\u7684\u3002\u5dee\u8bc4\u3002 \u8863\u670d \u6389\u8272\u6389\u7684\u5389\u5bb3\uff0c\u6d17\u4e00\u6b21\u5c31\u82b1\u4e86 train.txt\u4e00\u5171\u5305\u542b63\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002","title":"1.1 train.txt"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#12-devtxt","text":"dev.txt\u4e3a\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u4e66\u7c4d \"\u4e00\u70b9\u90fd\u4e0d\u597d\u7b11,\u5f88\u5931\u671b,\u5185\u5bb9\u4e5f\u4e0d\u662f\u5f88\u5b9e\u7528\" \u8863\u670d \u5b8c\u5168\u662f\u4e00\u6761\u65e7\u88e4\u5b50\u3002 \u624b\u673a \u76f8\u673a\u8d28\u91cf\u4e0d\u9519\uff0c\u5982\u679c\u9633\u5149\u5145\u8db3\uff0c\u53ef\u4ee5\u548c\u6570\u7801\u76f8\u673a\u5ab2\u7f8e\uff0e\u754c\u9762\u6bd4\u8f83\u4eba\u6027\u5316\uff0c\u5bb9\u6613\u4f7f\u7528\uff0e\u8f6f\u4ef6\u5b89\u88c5\u7b80\u4fbf \u4e66\u7c4d \u660e\u660e\u8bf4\u6709\u8d27\uff0c\u7ed3\u679c\u9001\u8d27\u53c8\u6ca1\u6709\u4e86\u3002\u5e76\u4e14\u4e5f\u4e0d\u544a\u8bc9\u6211\uff0c\u600e\u4e48\u8bc4\u554a \u6d17\u6d74 \u975e\u5e38\u4e0d\u6ee1\u610f\uff0c\u665a\u4e0a\u6d17\u7684\u5934\u53d1\uff0c\u7b2c\u4e8c\u5929\u5934\u75d2\u75d2\u7684\u4e0d\u884c\u4e86\uff0c\u8fd8\u90fd\u662f\u5934\u76ae\u5c51\u3002 \u6c34\u679c \u8fd9\u4e2a\u82f9\u679c\u611f\u89c9\u662f\u957f\u719f\u7684\u82f9\u679c\uff0c\u6ca1\u6709\u6253\u8721\uff0c\u4e0d\u9519\uff0c\u53c8\u751c\u53c8\u8106 dev.txt\u4e00\u5171\u5305\u542b590\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002","title":"1.2 dev.txt"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#13-prompttxt","text":"prompt.txt\u4e3a\u4eba\u5de5\u8bbe\u5b9a\u63d0\u793a\u6a21\u7248\uff0c\u5176\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u8fd9\u662f\u4e00\u6761{MASK}\u8bc4\u8bba\uff1a{textA}\u3002 \u5176\u4e2d\uff0c\u7528\u5927\u62ec\u53f7\u62ec\u8d77\u6765\u7684\u90e8\u5206\u4e3a\u300c\u81ea\u5b9a\u4e49\u53c2\u6570\u300d\uff0c\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8bbe\u7f6e\u5927\u62ec\u53f7\u5185\u7684\u503c\u3002 \u793a\u4f8b\u4e2d {MASK} \u4ee3\u8868 [MASK] token \u7684\u4f4d\u7f6e\uff0c{textA} \u4ee3\u8868\u8bc4\u8bba\u6570\u636e\u7684\u4f4d\u7f6e\u3002 \u4f60\u53ef\u4ee5\u6539\u4e3a\u81ea\u5df1\u60f3\u8981\u7684\u6a21\u677f\uff0c\u4f8b\u5982\u60f3\u65b0\u589e\u4e00\u4e2a {textB} \u53c2\u6570\uff1a {textA}\u548c{textB}\u662f{MASK}\u540c\u7684\u610f\u601d\u3002","title":"1.3 prompt.txt"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#14-verbalizertxt","text":"verbalizer.txt \u4e3b\u8981\u7528\u4e8e\u5b9a\u4e49\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u5230\u300c\u6807\u7b7e\u9884\u6d4b\u8bcd\u300d\u4e4b\u95f4\u7684\u6620\u5c04\u3002\u5728\u6709\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5c06\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u4f5c\u4e3a [MASK] \u53bb\u9884\u6d4b\u53ef\u80fd\u4e0d\u5177\u5907\u5f88\u597d\u7684\u8bed\u4e49\u901a\u987a\u6027\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u4f1a\u5bf9\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u505a\u4e00\u5b9a\u7684\u6620\u5c04\u3002 \u4f8b\u5982\uff1a \"\u4e2d\u56fd\u7206\u51b72-1\u6218\u80dc\u97e9\u56fd\"\u662f\u4e00\u5219[MASK][MASK]\u65b0\u95fb\u3002 \u4f53\u80b2 \u8fd9\u53e5\u8bdd\u4e2d\u7684\u6807\u7b7e\u4e3a\u300c\u4f53\u80b2\u300d\uff0c\u4f46\u5982\u679c\u6211\u4eec\u5c06\u6807\u7b7e\u8bbe\u7f6e\u4e3a\u300c\u8db3\u7403\u300d\u4f1a\u66f4\u5bb9\u6613\u9884\u6d4b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u300c\u4f53\u80b2\u300d\u8fd9\u4e2a label \u6784\u5efa\u8bb8\u591a\u4e2a\u5b50\u6807\u7b7e\uff0c\u5728\u63a8\u7406\u65f6\uff0c\u53ea\u8981\u9884\u6d4b\u5230\u5b50\u6807\u7b7e\u6700\u7ec8\u63a8\u7406\u51fa\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\uff0c\u5982\u4e0b\uff1a \u4f53\u80b2 -> \u8db3\u7403,\u7bee\u7403,\u7f51\u7403,\u68d2\u7403,\u4e52\u4e53,\u4f53\u80b2 \u9879\u76ee\u4e2d\u6807\u7b7e\u8bcd\u6620\u5c04\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u7535\u8111 \u7535\u8111 \u6c34\u679c \u6c34\u679c \u5e73\u677f \u5e73\u677f \u8863\u670d \u8863\u670d \u9152\u5e97 \u9152\u5e97 \u6d17\u6d74 \u6d17\u6d74 \u4e66\u7c4d \u4e66\u7c4d \u8499\u725b \u8499\u725b \u624b\u673a \u624b\u673a \u7535\u5668 \u7535\u5668 verbalizer.txt \u4e00\u5171\u5305\u542b10\u4e2a\u7c7b\u522b\uff0c\u4e0a\u8ff0\u6570\u636e\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e861\u5bf91\u7684verbalizer, \u5982\u679c\u60f3\u5b9a\u4e49\u4e00\u5bf9\u591a\u7684\u6620\u5c04\uff0c\u53ea\u9700\u8981\u5728\u540e\u9762\u7528\",\"\u5206\u5272\u5373\u53ef\uff0c eg: \u6c34\u679c \u82f9\u679c,\u9999\u8549,\u6a58\u5b50 \u82e5\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6","title":"1.4 verbalizer.txt"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#2-config","text":"\u4ee3\u7801\u8def\u5f84\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/PET/pet_config.py config\u6587\u4ef6\u76ee\u7684\uff1a\u914d\u7f6e\u9879\u76ee\u5e38\u7528\u53d8\u91cf\uff0c\u4e00\u822c\u8fd9\u4e9b\u53d8\u91cf\u5c5e\u4e8e\u4e0d\u7ecf\u5e38\u6539\u53d8\u7684\uff0c\u6bd4\u5982\uff1a\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\u3001\u6a21\u578b\u8bad\u7ec3\u6b21\u6570\u3001\u6a21\u578b\u8d85\u53c2\u6570\u7b49\u7b49 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a # coding:utf-8 import torch import sys print ( sys . path ) class ProjectConfig ( object ): def __init__ ( self ): # \u662f\u5426\u4f7f\u7528GPU self . device = 'cuda:0' if torch . cuda . is_available () else 'cpu' # \u9884\u8bad\u7ec3\u6a21\u578bbert\u8def\u5f84 self . pre_model = '/home/prompt_project/bert-base-chinese' self . train_path = '/home/prompt_project/PET/data/train.txt' self . dev_path = '/home/prompt_project/PET/data/dev.txt' self . prompt_file = '/home/prompt_project/PET/data/prompt.txt' self . verbalizer = '/home/prompt_project/PET/data/verbalizer.txt' self . max_seq_len = 512 self . batch_size = 8 self . learning_rate = 5e-5 # \u6743\u91cd\u8870\u51cf\u53c2\u6570\uff08\u6b63\u5219\u5316\uff0c\u6291\u5236\u6a21\u578b\u8fc7\u62df\u5408\uff09 self . weight_decay = 0 # \u9884\u70ed\u5b66\u4e60\u7387(\u7528\u6765\u5b9a\u4e49\u9884\u70ed\u7684\u6b65\u6570) self . warmup_ratio = 0.06 self . max_label_len = 2 self . epochs = 50 self . logging_steps = 10 self . valid_steps = 20 self . save_dir = '/home/prompt_project/PET/checkpoints' if __name__ == '__main__' : pc = ProjectConfig () print ( pc . prompt_file ) print ( pc . pre_model )","title":"2 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#3","text":"\u4ee3\u7801\u8def\u5f84\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/PET/data_handle. data_handle\u6587\u4ef6\u5939\u4e2d\u4e00\u5171\u5305\u542b\u4e09\u4e2apy\u811a\u672c\uff1atemplate.py\u3001data_preprocess.py\u3001data_loader.py","title":"3 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#31-templatepy","text":"\u76ee\u7684\uff1a\u6784\u5efa\u56fa\u5b9a\u6a21\u7248\u7c7b\uff0ctext2id\u7684\u8f6c\u6362 \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 # -*- coding:utf-8 -*- from rich import print # \u7ec8\u7aef\u5c42\u6b21\u663e\u793a from transformers import AutoTokenizer import numpy as np import sys sys . path . append ( '..' ) from pet_config import * \u5b9a\u4e49HardTemplate\u7c7b class HardTemplate ( object ): \"\"\" \u786c\u6a21\u677f\uff0c\u4eba\u5de5\u5b9a\u4e49\u53e5\u5b50\u548c[MASK]\u4e4b\u95f4\u7684\u4f4d\u7f6e\u5173\u7cfb\u3002 \"\"\" def __init__ ( self , prompt : str ): \"\"\" Args: prompt (str): prompt\u683c\u5f0f\u5b9a\u4e49\u5b57\u7b26\u4e32, e.g. -> \"\u8fd9\u662f\u4e00\u6761{MASK}\u8bc4\u8bba\uff1a{textA}\u3002\" \"\"\" self . prompt = prompt self . inputs_list = [] # \u6839\u636e\u6587\u5b57prompt\u62c6\u5206\u4e3a\u5404part\u7684\u5217\u8868 self . custom_tokens = set ([ 'MASK' ]) # \u4eceprompt\u4e2d\u89e3\u6790\u51fa\u7684\u81ea\u5b9a\u4e49token\u96c6\u5408 self . prompt_analysis () # \u89e3\u6790prompt\u6a21\u677f def prompt_analysis ( self ): \"\"\" \u5c06prompt\u6587\u5b57\u6a21\u677f\u62c6\u89e3\u4e3a\u53ef\u6620\u5c04\u7684\u6570\u636e\u7ed3\u6784\u3002 Examples: prompt -> \"\u8fd9\u662f\u4e00\u6761{MASK}\u8bc4\u8bba\uff1a{textA}\u3002\" inputs_list -> ['\u8fd9', '\u662f', '\u4e00', '\u6761', 'MASK', '\u8bc4', '\u8bba', '\uff1a', 'textA', '\u3002'] custom_tokens -> {'textA', 'MASK'} \"\"\" idx = 0 while idx < len ( self . prompt ): str_part = '' if self . prompt [ idx ] not in [ '{' , '}' ]: self . inputs_list . append ( self . prompt [ idx ]) if self . prompt [ idx ] == '{' : # \u8fdb\u5165\u81ea\u5b9a\u4e49\u5b57\u6bb5 idx += 1 while self . prompt [ idx ] != '}' : str_part += self . prompt [ idx ] # \u62fc\u63a5\u8be5\u81ea\u5b9a\u4e49\u5b57\u6bb5\u7684\u503c idx += 1 elif self . prompt [ idx ] == '}' : raise ValueError ( \"Unmatched bracket '}', check your prompt.\" ) if str_part : self . inputs_list . append ( str_part ) # \u5c06\u6240\u6709\u81ea\u5b9a\u4e49\u5b57\u6bb5\u5b58\u50a8\uff0c\u540e\u7eed\u4f1a\u68c0\u6d4b\u8f93\u5165\u4fe1\u606f\u662f\u5426\u5b8c\u6574 self . custom_tokens . add ( str_part ) idx += 1 def __call__ ( self , inputs_dict : dict , tokenizer , mask_length , max_seq_len = 512 ): \"\"\" \u8f93\u5165\u4e00\u4e2a\u6837\u672c\uff0c\u8f6c\u6362\u4e3a\u7b26\u5408\u6a21\u677f\u7684\u683c\u5f0f\u3002 Args: inputs_dict (dict): prompt\u4e2d\u7684\u53c2\u6570\u5b57\u5178, e.g. -> { \"textA\": \"\u8fd9\u4e2a\u624b\u673a\u4e5f\u592a\u5361\u4e86\", \"MASK\": \"[MASK]\" } tokenizer: \u7528\u4e8eencoding\u6587\u672c mask_length (int): MASK token \u7684\u957f\u5ea6 Returns: dict -> { 'text': '[CLS]\u8fd9\u662f\u4e00\u6761[MASK]\u8bc4\u8bba\uff1a\u8fd9\u4e2a\u624b\u673a\u4e5f\u592a\u5361\u4e86\u3002[SEP]', 'input_ids': [1, 47, 10, 7, 304, 3, 480, 279, 74, 47, 27, 247, 98, 105, 512, 777, 15, 12043, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'mask_position': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] } \"\"\" # \u5b9a\u4e49\u8f93\u51fa\u683c\u5f0f outputs = { 'text' : '' , 'input_ids' : [], 'token_type_ids' : [], 'attention_mask' : [], 'mask_position' : [] } str_formated = '' for value in self . inputs_list : if value in self . custom_tokens : if value == 'MASK' : str_formated += inputs_dict [ value ] * mask_length else : str_formated += inputs_dict [ value ] else : str_formated += value # print(f'str_formated-->{str_formated}') encoded = tokenizer ( text = str_formated , truncation = True , max_length = max_seq_len , padding = 'max_length' ) # print(f'encoded--->{encoded}') outputs [ 'input_ids' ] = encoded [ 'input_ids' ] outputs [ 'token_type_ids' ] = encoded [ 'token_type_ids' ] outputs [ 'attention_mask' ] = encoded [ 'attention_mask' ] token_list = tokenizer . convert_ids_to_tokens ( encoded [ 'input_ids' ]) outputs [ 'text' ] = '' . join ( token_list ) mask_token_id = tokenizer . convert_tokens_to_ids ([ '[MASK]' ])[ 0 ] condition = np . array ( outputs [ 'input_ids' ]) == mask_token_id mask_position = np . where ( condition )[ 0 ] . tolist () outputs [ 'mask_position' ] = mask_position return outputs if __name__ == '__main__' : pc = ProjectConfig () tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) hard_template = HardTemplate ( prompt = '\u8fd9\u662f\u4e00\u6761 {MASK} \u8bc4\u8bba\uff1a {textA} ' ) print ( hard_template . inputs_list ) print ( hard_template . custom_tokens ) tep = hard_template ( inputs_dict = { 'textA' : '\u5305\u88c5\u4e0d\u9519\uff0c\u82f9\u679c\u633a\u751c\u7684\uff0c\u4e2a\u5934\u4e5f\u5927\u3002' , 'MASK' : '[MASK]' }, tokenizer = tokenizer , max_seq_len = 30 , mask_length = 2 ) print ( tep ) print ( tokenizer . convert_ids_to_tokens ([ 3819 , 3352 ])) print ( tokenizer . convert_tokens_to_ids ([ '\u6c34' , '\u679c' ]))","title":"3.1 template.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#32-data_preprocesspy","text":"\u76ee\u7684: \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 from template import * from rich import print from datasets import load_dataset # partial\uff1a\u628a\u4e00\u4e2a\u51fd\u6570\u7684\u67d0\u4e9b\u53c2\u6570\u7ed9\u56fa\u5b9a\u4f4f\uff08\u4e5f\u5c31\u662f\u8bbe\u7f6e\u9ed8\u8ba4\u503c\uff09\uff0c\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684\u51fd\u6570\uff0c\u8c03\u7528\u8fd9\u4e2a\u65b0\u51fd\u6570\u4f1a\u66f4\u7b80\u5355 from functools import partial from pet_config import * \u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u65b9\u6cd5convert_example() def convert_example ( examples : dict , tokenizer , max_seq_len : int , max_label_len : int , hard_template : HardTemplate , train_mode = True , return_tensor = False ) -> dict : \"\"\" \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u6536\u7684\u8f93\u5165\u6570\u636e\u3002 Args: examples (dict): \u8bad\u7ec3\u6570\u636e\u6837\u672c, e.g. -> { \"text\": [ '\u624b\u673a \u8fd9\u4e2a\u624b\u673a\u4e5f\u592a\u5361\u4e86\u3002', '\u4f53\u80b2 \u4e16\u754c\u676f\u4e3a\u4f55\u8fdf\u8fdf\u4e0d\u89c1\u5ba3\u4f20', ... ] } max_seq_len (int): \u53e5\u5b50\u7684\u6700\u5927\u957f\u5ea6\uff0c\u82e5\u6ca1\u6709\u8fbe\u5230\u6700\u5927\u957f\u5ea6\uff0c\u5219padding\u4e3a\u6700\u5927\u957f\u5ea6 max_label_len (int): \u6700\u5927label\u957f\u5ea6\uff0c\u82e5\u6ca1\u6709\u8fbe\u5230\u6700\u5927\u957f\u5ea6\uff0c\u5219padding\u4e3a\u6700\u5927\u957f\u5ea6 hard_template (HardTemplate): \u6a21\u677f\u7c7b\u3002 train_mode (bool): \u8bad\u7ec3\u9636\u6bb5 or \u63a8\u7406\u9636\u6bb5\u3002 return_tensor (bool): \u662f\u5426\u8fd4\u56detensor\u7c7b\u578b\uff0c\u5982\u4e0d\u662f\uff0c\u5219\u8fd4\u56denumpy\u7c7b\u578b\u3002 Returns: dict (str: np.array) -> tokenized_output = { 'input_ids': [[1, 47, 10, 7, 304, 3, 3, 3, 3, 47, 27, 247, 98, 105, 512, 777, 15, 12043, 2], ...], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], ...], 'mask_positions': [[5, 6, 7, 8], ...], 'mask_labels': [[2372, 3442, 0, 0], [2643, 4434, 2334, 0], ...] } \"\"\" tokenized_output = { 'input_ids' : [], 'token_type_ids' : [], 'attention_mask' : [], 'mask_positions' : [], 'mask_labels' : [] } for i , example in enumerate ( examples [ 'text' ]): if train_mode : label , content = example . strip () . split ( ' \\t ' ) else : content = example . strip () inputs_dict = { 'textA' : content , 'MASK' : '[MASK]' } encoded_inputs = hard_template ( inputs_dict = inputs_dict , tokenizer = tokenizer , max_seq_len = max_seq_len , mask_length = max_label_len ) tokenized_output [ 'input_ids' ] . append ( encoded_inputs [ \"input_ids\" ]) tokenized_output [ 'token_type_ids' ] . append ( encoded_inputs [ \"token_type_ids\" ]) tokenized_output [ 'attention_mask' ] . append ( encoded_inputs [ \"attention_mask\" ]) tokenized_output [ 'mask_positions' ] . append ( encoded_inputs [ \"mask_position\" ]) if train_mode : label_encoded = tokenizer ( text = [ label ]) # \u5c06label\u8865\u5230\u6700\u5927\u957f\u5ea6 # print(f'label_encoded-->{label_encoded}') label_encoded = label_encoded [ 'input_ids' ][ 0 ][ 1 : - 1 ] label_encoded = label_encoded [: max_label_len ] add_pad = [ tokenizer . pad_token_id ] * ( max_label_len - len ( label_encoded )) label_encoded = label_encoded + add_pad tokenized_output [ 'mask_labels' ] . append ( label_encoded ) for k , v in tokenized_output . items (): if return_tensor : tokenized_output [ k ] = torch . LongTensor ( v ) else : tokenized_output [ k ] = np . array ( v ) return tokenized_output if __name__ == '__main__' : pc = ProjectConfig () train_dataset = load_dataset ( 'text' , data_files = pc . train_path ) print ( type ( train_dataset )) print ( train_dataset ) # print('*'*80) # print(train_dataset['train']['text']) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) hard_template = HardTemplate ( prompt = '\u8fd9\u662f\u4e00\u6761 {MASK} \u8bc4\u8bba\uff1a {textA} ' ) convert_func = partial ( convert_example , tokenizer = tokenizer , hard_template = hard_template , max_seq_len = 30 , max_label_len = 2 ) dataset = train_dataset . map ( convert_func , batched = True ) for value in dataset [ 'train' ]: print ( value ) print ( len ( value [ 'input_ids' ])) break","title":"3.2 data_preprocess.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/03-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#33-data_loaderpy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u52a0\u8f7d\u5668 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # coding:utf-8 from torch.utils.data import DataLoader from transformers import default_data_collator from data_preprocess import * from pet_config import * pc = ProjectConfig () # \u5b9e\u4f8b\u5316\u9879\u76ee\u914d\u7f6e\u6587\u4ef6 tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) \u5b9a\u4e49\u83b7\u53d6\u6570\u636e\u52a0\u8f7d\u5668\u7684\u65b9\u6cd5get_data() def get_data (): # prompt\u5b9a\u4e49 prompt = open ( pc . prompt_file , 'r' , encoding = 'utf8' ) . readlines ()[ 0 ] . strip () hard_template = HardTemplate ( prompt = prompt ) # \u6a21\u677f\u8f6c\u6362\u5668\u5b9a\u4e49 dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path , 'dev' : pc . dev_path }) # print(dataset) # print(f'Prompt is -> {prompt}') new_func = partial ( convert_example , tokenizer = tokenizer , hard_template = hard_template , max_seq_len = pc . max_seq_len , max_label_len = pc . max_label_len ) dataset = dataset . map ( new_func , batched = True ) train_dataset = dataset [ \"train\" ] dev_dataset = dataset [ \"dev\" ] # print('train_dataset', train_dataset[:2]) # print('*'*80) train_dataloader = DataLoader ( train_dataset , shuffle = True , collate_fn = default_data_collator , batch_size = pc . batch_size ) dev_dataloader = DataLoader ( dev_dataset , collate_fn = default_data_collator , batch_size = pc . batch_size ) return train_dataloader , dev_dataloader if __name__ == '__main__' : train_dataloader , dev_dataloader = get_data () print ( len ( train_dataloader )) print ( len ( dev_dataloader )) for i , value in enumerate ( train_dataloader ): print ( i ) print ( value ) print ( value [ 'input_ids' ] . dtype ) break","title":"3.3 data_loader.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html","text":"\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u6a21\u578b\u642d\u5efa \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6a21\u578b\u642d\u5efa\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u6a21\u578b\u7684\u8bad\u7ec3,\u9a8c\u8bc1\u53ca\u76f8\u5173\u5de5\u5177\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0. \u6a21\u578b\u642d\u5efa \u00b6 \u672c\u9879\u76ee\u4e2d\u5b8c\u6210BERT+PET\u6a21\u578b\u642d\u5efa\u3001\u8bad\u7ec3\u53ca\u5e94\u7528\u7684\u6b65\u9aa4\u5982\u4e0b\uff08\u6ce8\u610f\uff1a\u56e0\u4e3a\u672c\u9879\u76ee\u4e2d\u4f7f\u7528\u7684\u662fBERT\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6240\u4ee5\u76f4\u63a5\u52a0\u8f7d\u5373\u53ef\uff0c\u65e0\u9700\u91cd\u590d\u642d\u5efa\u6a21\u578b\u67b6\u6784\uff09: \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570 \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u6a21\u578b\u5728\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u9884\u6d4b\u65f6\u9700\u8981\u7684\u51fd\u6570 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/PET/utils utils\u6587\u4ef6\u5939\u5171\u5305\u542b3\u4e2apy\u811a\u672c\uff1averbalizer.py\u3001metirc_utils.py\u4ee5\u53cacommon_utils.py 1.1 verbalizer.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u4e00\u4e2aVerbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # -*- coding:utf-8 -*- import os from typing import Union , List from pet_config import * pc = ProjectConfig () \u5177\u4f53\u5b9e\u73b0\u4ee3\u7801 class Verbalizer ( object ): \"\"\" Verbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \"\"\" def __init__ ( self , verbalizer_file : str , tokenizer , max_label_len : int ): \"\"\" Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 tokenizer: \u5206\u8bcd\u5668\uff0c\u7528\u4e8e\u6587\u672c\u548cid\u4e4b\u95f4\u7684\u8f6c\u6362\u3002 max_label_len (int): \u6807\u7b7e\u957f\u5ea6\uff0c\u82e5\u5927\u4e8e\u5219\u622a\u65ad\uff0c\u82e5\u5c0f\u4e8e\u5219\u8865\u9f50 \"\"\" self . tokenizer = tokenizer self . label_dict = self . load_label_dict ( verbalizer_file ) self . max_label_len = max_label_len def load_label_dict ( self , verbalizer_file : str ): \"\"\" \u8bfb\u53d6\u672c\u5730\u6587\u4ef6\uff0c\u6784\u5efaverbalizer\u5b57\u5178\u3002 Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 Returns: dict -> { '\u4f53\u80b2': ['\u7bee\u7403', '\u8db3\u7403','\u7f51\u7403', '\u6392\u7403', ...], '\u9152\u5e97': ['\u5bbe\u9986', '\u65c5\u9986', '\u65c5\u5e97', '\u9152\u5e97', ...], ... } \"\"\" label_dict = {} with open ( verbalizer_file , 'r' , encoding = 'utf8' ) as f : for line in f . readlines (): label , sub_labels = line . strip () . split ( ' \\t ' ) label_dict [ label ] = list ( set ( sub_labels . split ( ',' ))) return label_dict def find_sub_labels ( self , label : Union [ list , str ]): \"\"\" \u901a\u8fc7\u6807\u7b7e\u627e\u5230\u5bf9\u5e94\u6240\u6709\u7684\u5b50\u6807\u7b7e\u3002 Args: label (Union[list, str]): \u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u4f53\u80b2' or [860, 5509] Returns: dict -> { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] } \"\"\" if type ( label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8fdb\u884c\u6587\u672c\u8f6c\u6362 while self . tokenizer . pad_token_id in label : label . remove ( self . tokenizer . pad_token_id ) label = '' . join ( self . tokenizer . convert_ids_to_tokens ( label )) # print(f'label-->{label}') if label not in self . label_dict : raise ValueError ( f 'Lable Error: \" { label } \" not in label_dict' ) sub_labels = self . label_dict [ label ] ret = { 'sub_labels' : sub_labels } token_ids = [ _id [ 1 : - 1 ] for _id in self . tokenizer ( sub_labels )[ 'input_ids' ]] # print(f'token_ids-->{token_ids}') for i in range ( len ( token_ids )): token_ids [ i ] = token_ids [ i ][: self . max_label_len ] # \u5bf9\u6807\u7b7e\u8fdb\u884c\u622a\u65ad\u4e0e\u8865\u9f50 if len ( token_ids [ i ]) < self . max_label_len : token_ids [ i ] = token_ids [ i ] + [ self . tokenizer . pad_token_id ] * ( self . max_label_len - len ( token_ids [ i ])) ret [ 'token_ids' ] = token_ids return ret def batch_find_sub_labels ( self , label : List [ Union [ list , str ]]): \"\"\" \u6279\u91cf\u627e\u5230\u5b50\u6807\u7b7e\u3002 Args: label (List[list, str]): \u6807\u7b7e\u5217\u8868, [[4510, 5554], [860, 5509]] or ['\u4f53\u80b2', '\u7535\u8111'] Returns: list -> [ { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] }, ... ] \"\"\" return [ self . find_sub_labels ( l ) for l in label ] def get_common_sub_str ( self , str1 : str , str2 : str ): \"\"\" \u5bfb\u627e\u6700\u5927\u516c\u5171\u5b50\u4e32\u3002 str1:abcd str2:abadbcdba \"\"\" lstr1 , lstr2 = len ( str1 ), len ( str2 ) # \u751f\u62100\u77e9\u9635\uff0c\u4e3a\u65b9\u4fbf\u540e\u7eed\u8ba1\u7b97\uff0c\u6bd4\u5b57\u7b26\u4e32\u957f\u5ea6\u591a\u4e86\u4e00\u5217 record = [[ 0 for i in range ( lstr2 + 1 )] for j in range ( lstr1 + 1 )] p = 0 # \u6700\u957f\u5339\u914d\u5bf9\u5e94\u5728str1\u4e2d\u7684\u6700\u540e\u4e00\u4f4d maxNum = 0 # \u6700\u957f\u5339\u914d\u957f\u5ea6 for i in range ( lstr1 ): for j in range ( lstr2 ): if str1 [ i ] == str2 [ j ]: record [ i + 1 ][ j + 1 ] = record [ i ][ j ] + 1 if record [ i + 1 ][ j + 1 ] > maxNum : maxNum = record [ i + 1 ][ j + 1 ] p = i + 1 return str1 [ p - maxNum : p ], maxNum def hard_mapping ( self , sub_label : str ): \"\"\" \u5f3a\u5339\u914d\u51fd\u6570\uff0c\u5f53\u6a21\u578b\u751f\u6210\u7684\u5b50label\u4e0d\u5b58\u5728\u65f6\uff0c\u901a\u8fc7\u6700\u5927\u516c\u5171\u5b50\u4e32\u627e\u5230\u91cd\u5408\u5ea6\u6700\u9ad8\u7684\u4e3blabel\u3002 Args: sub_label (str): \u5b50label\u3002 Returns: str: \u4e3blabel\u3002 \"\"\" label , max_overlap_str = '' , 0 # print(self.label_dict.items()) for main_label , sub_labels in self . label_dict . items (): overlap_num = 0 for s_label in sub_labels : # \u6c42\u6240\u6709\u5b50label\u4e0e\u5f53\u524d\u63a8\u7406label\u4e4b\u95f4\u7684\u6700\u957f\u516c\u5171\u5b50\u4e32\u957f\u5ea6 overlap_num += self . get_common_sub_str ( sub_label , s_label )[ 1 ] if overlap_num >= max_overlap_str : max_overlap_str = overlap_num label = main_label return label def find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u5230\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u82f9\u679c' or [5741, 3362] hard_mapping (bool): \u5f53\u751f\u6210\u7684\u8bcd\u8bed\u4e0d\u5b58\u5728\u65f6\uff0c\u662f\u5426\u4e00\u5b9a\u8981\u5339\u914d\u5230\u4e00\u4e2a\u6700\u76f8\u4f3c\u7684label\u3002 Returns: dict -> { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] } \"\"\" if type ( sub_label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8f6c\u56de\u6765 pad_token_id = self . tokenizer . pad_token_id while pad_token_id in sub_label : # \u79fb\u9664[PAD]token sub_label . remove ( pad_token_id ) sub_label = '' . join ( self . tokenizer . convert_ids_to_tokens ( sub_label )) # print(sub_label) main_label = '\u65e0' for label , s_labels in self . label_dict . items (): if sub_label in s_labels : main_label = label break if main_label == '\u65e0' and hard_mapping : main_label = self . hard_mapping ( sub_label ) # print(main_label) ret = { 'label' : main_label , 'token_ids' : self . tokenizer ( main_label )[ 'input_ids' ][ 1 : - 1 ] } return ret def batch_find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u6279\u91cf\u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e\u5217\u8868, ['\u82f9\u679c', ...] or [[5741, 3362], ...] Returns: list: [ { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] }, ... ] \"\"\" return [ self . find_main_label ( l , hard_mapping ) for l in sub_label ] if __name__ == '__main__' : from rich import print from transformers import AutoTokenizer tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = 2 ) print ( verbalizer . label_dict ) # label = [4510, 5554] # ret = verbalizer.find_sub_labels(label) # label = ['\u7535\u8111', '\u8863\u670d'] label = [[ 4510 , 5554 ], [ 6132 , 3302 ]] ret = verbalizer . batch_find_sub_labels ( label ) print ( ret ) 1.2 common_utils.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u3001\u5c06mask_position\u4f4d\u7f6e\u7684token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amlm_loss()\u4ee5\u53caconvert_logits_to_ids() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch from rich import print \u5b9a\u4e49\u635f\u5931\u51fd\u6570mlm_loss() def mlm_loss ( logits , mask_positions , sub_mask_labels , cross_entropy_criterion , device ): \"\"\" \u8ba1\u7b97\u6307\u5b9a\u4f4d\u7f6e\u7684mask token\u7684output\u4e0elabel\u4e4b\u95f4\u7684cross entropy loss\u3002 Args: logits (torch.tensor): \u6a21\u578b\u539f\u59cb\u8f93\u51fa -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) sub_mask_labels (list): mask token\u7684sub label, \u7531\u4e8e\u6bcf\u4e2alabel\u7684sub_label\u6570\u76ee\u4e0d\u540c\uff0c\u6240\u4ee5 \u8fd9\u91cc\u662f\u4e2a\u53d8\u957f\u7684list, e.g. -> [ [[2398, 3352]], [[2398, 3352], [3819, 3861]] ] cross_entropy_criterion (CrossEntropyLoss): CE Loss\u8ba1\u7b97\u5668 device (str): cpu\u8fd8\u662fgpu Returns: torch.tensor: CE Loss \"\"\" batch_size , seq_len , vocab_size = logits . size () loss = None for single_value in zip ( logits , sub_mask_labels , mask_positions ): single_logits = single_value [ 0 ] single_sub_mask_labels = single_value [ 1 ] single_mask_positions = single_value [ 2 ] # single_mask_logits\u5f62\u72b6\uff1a(mask_label_num, vocab_size) single_mask_logits = single_logits [ single_mask_positions ] # single_mask_logits\u6309\u7167\u5b50\u6807\u7b7e\u7684\u957f\u5ea6\u8fdb\u884c\u590d\u5236: # single_mask_logits\u5f62\u72b6-->(sub_label_num, mask_label_num, vocab_size) single_mask_logits = single_mask_logits . repeat ( len ( single_sub_mask_labels ), 1 , 1 ) #single_mask_logits\u6539\u53d8\u5f62\u72b6\uff1a(sub_label_num * mask_label_num, vocab_size) #\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c single_mask_logits = single_mask_logits . reshape ( - 1 , vocab_size ) # single_sub_mask_labels\u5f62\u72b6\uff1a(sub_label_num, mask_label_num) single_sub_mask_labels = torch . LongTensor ( single_sub_mask_labels ) . to ( device ) # single_sub_mask_labels\u5f62\u72b6\uff1a # (sub_label_num * mask_label_num) single_sub_mask_labels = single_sub_mask_labels . reshape ( - 1 , 1 ) . squeeze () if not single_sub_mask_labels . size (): # \u5904\u7406\u5355token\u7ef4\u5ea6\u4e0b\u7ef4\u5ea6\u7f3a\u5931\u7684\u95ee\u9898 single_sub_mask_labels = single_sub_mask_labels . unsqueeze ( dim = 0 ) cur_loss = cross_entropy_criterion ( single_mask_logits , single_sub_mask_labels ) cur_loss = cur_loss / len ( single_sub_mask_labels ) if not loss : loss = cur_loss else : loss += cur_loss loss = loss / batch_size return loss \u5b9a\u4e49convert_logits_to_ids()\u51fd\u6570 def convert_logits_to_ids ( logits : torch . tensor , mask_positions : torch . tensor ): \"\"\" \u8f93\u5165LM\u7684\u8bcd\u8868\u6982\u7387\u5206\u5e03\uff08LMModel\u7684logits\uff09\uff0c\u5c06mask_position\u4f4d\u7f6e\u7684 token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 Args: logits (torch.tensor): model output -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) Returns: torch.LongTensor: \u5bf9\u5e94mask position\u4e0a\u6700\u5927\u6982\u7387\u7684\u63a8\u7406token -> (batch, mask_label_num) \"\"\" label_length = mask_positions . size ()[ 1 ] # \u6807\u7b7e\u957f\u5ea6 # print(f'label_length--\u300b{label_length}') batch_size , seq_len , vocab_size = logits . size () mask_positions_after_reshaped = [] for batch , mask_pos in enumerate ( mask_positions . detach () . cpu () . numpy () . tolist ()): for pos in mask_pos : mask_positions_after_reshaped . append ( batch * seq_len + pos ) # logits\u5f62\u72b6\uff1a(batch_size * seq_len, vocab_size) logits = logits . reshape ( batch_size * seq_len , - 1 ) # mask_logits\u5f62\u72b6\uff1a(batch * label_num, vocab_size) mask_logits = logits [ mask_positions_after_reshaped ] # predict_tokens\u5f62\u72b6\uff1a (batch * label_num) predict_tokens = mask_logits . argmax ( dim =- 1 ) # \u6539\u53d8\u540e\u7684predict_tokens\u5f62\u72b6\uff1a (batch, label_num) predict_tokens = predict_tokens . reshape ( - 1 , label_length ) # (batch, label_num) return predict_tokens 1.3 metirc_utils.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\uff08\u591a\uff09\u5206\u7c7b\u95ee\u9898\u4e0b\u7684\u6307\u6807\u8bc4\u4f30\uff08acc, precision, recall, f1\uff09\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a from typing import List import numpy as np import pandas as pd from sklearn.metrics import accuracy_score , precision_score , f1_score from sklearn.metrics import recall_score , confusion_matrix \u5b9a\u4e49ClassEvaluator\u7c7b class ClassEvaluator ( object ): def __init__ ( self ): self . goldens = [] self . predictions = [] def add_batch ( self , pred_batch : List [ List ], gold_batch : List [ List ]): \"\"\" \u6dfb\u52a0\u4e00\u4e2abatch\u4e2d\u7684prediction\u548cgold\u5217\u8868\uff0c\u7528\u4e8e\u540e\u7eed\u7edf\u4e00\u8ba1\u7b97\u3002 Args: pred_batch (list): \u6a21\u578b\u9884\u6d4b\u6807\u7b7e\u5217\u8868, e.g. -> [0, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] gold_batch (list): \u771f\u5b9e\u6807\u7b7e\u6807\u7b7e\u5217\u8868, e.g. -> [1, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] \"\"\" assert len ( pred_batch ) == len ( gold_batch ) # \u82e5\u9047\u5230\u591a\u4e2a\u5b50\u6807\u7b7e\u6784\u6210\u4e00\u4e2a\u6807\u7b7e\u7684\u60c5\u51b5 if type ( gold_batch [ 0 ]) in [ list , tuple ]: # \u5c06\u6240\u6709\u7684label\u62fc\u63a5\u4e3a\u4e00\u4e2a\u6574label: ['\u4f53', '\u80b2'] -> '\u4f53\u80b2' pred_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in pred_batch ] gold_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in gold_batch ] self . goldens . extend ( gold_batch ) self . predictions . extend ( pred_batch ) def compute ( self , round_num = 2 ) -> dict : \"\"\" \u6839\u636e\u5f53\u524d\u7c7b\u4e2d\u7d2f\u79ef\u7684\u53d8\u91cf\u503c\uff0c\u8ba1\u7b97\u5f53\u524d\u7684P, R, F1\u3002 Args: round_num (int): \u8ba1\u7b97\u7ed3\u679c\u4fdd\u7559\u5c0f\u6570\u70b9\u540e\u51e0\u4f4d, \u9ed8\u8ba4\u5c0f\u6570\u70b9\u540e2\u4f4d\u3002 Returns: dict -> { 'accuracy': \u51c6\u786e\u7387, 'precision': \u7cbe\u51c6\u7387, 'recall': \u53ec\u56de\u7387, 'f1': f1\u503c, 'class_metrics': { '0': { 'precision': \u8be5\u7c7b\u522b\u4e0b\u7684precision, 'recall': \u8be5\u7c7b\u522b\u4e0b\u7684recall, 'f1': \u8be5\u7c7b\u522b\u4e0b\u7684f1 }, ... } } \"\"\" classes , class_metrics , res = sorted ( list ( set ( self . goldens ) | set ( self . predictions ))), {}, {} # \u6784\u5efa\u5168\u5c40\u6307\u6807 res [ 'accuracy' ] = round ( accuracy_score ( self . goldens , self . predictions ), round_num ) res [ 'precision' ] = round ( precision_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) # average='weighted'\u4ee3\u8868\uff1a\u8003\u8651\u7c7b\u522b\u7684\u4e0d\u5e73\u8861\u6027\uff0c\u9700\u8981\u8ba1\u7b97\u7c7b\u522b\u7684\u52a0\u6743\u5e73\u5747\u3002\u5982\u679c\u662f\u4e8c\u5206\u7c7b\u95ee\u9898\u5219\u9009\u62e9\u53c2\u6570\u2018binary\u2018 res [ 'recall' ] = round ( recall_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) res [ 'f1' ] = round ( f1_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) try : conf_matrix = np . array ( confusion_matrix ( self . goldens , self . predictions )) # (n_class, n_class) assert conf_matrix . shape [ 0 ] == len ( classes ) for i in range ( conf_matrix . shape [ 0 ]): # \u6784\u5efa\u6bcf\u4e2aclass\u7684\u6307\u6807 precision = 0 if sum ( conf_matrix [:, i ]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [:, i ]) recall = 0 if sum ( conf_matrix [ i , :]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [ i , :]) f1 = 0 if ( precision + recall ) == 0 else 2 * precision * recall / ( precision + recall ) class_metrics [ classes [ i ]] = { 'precision' : round ( precision , round_num ), 'recall' : round ( recall , round_num ), 'f1' : round ( f1 , round_num ) } res [ 'class_metrics' ] = class_metrics except Exception as e : print ( f '[Warning] Something wrong when calculate class_metrics: { e } ' ) print ( f '-> goldens: { set ( self . goldens ) } ' ) print ( f '-> predictions: { set ( self . predictions ) } ' ) print ( f '-> diff elements: { set ( self . predictions ) - set ( self . goldens ) } ' ) res [ 'class_metrics' ] = {} return res def reset ( self ): \"\"\" \u91cd\u7f6e\u79ef\u7d2f\u7684\u6570\u503c\u3002 \"\"\" self . goldens = [] self . predictions = [] \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u5b9e\u73b0\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/PET/train.py \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amodel2train()\u548cevaluate_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import os import time from transformers import AutoModelForMaskedLM , AutoTokenizer , get_scheduler from pet_config import * import sys sys . path . append ( '/Users/ligang/PycharmProjects/llm/prompt_tasks/PET/data_handle' ) sys . path . append ( '/Users/ligang/PycharmProjects/llm/prompt_tasks/PET/utils' ) from utils.metirc_utils import ClassEvaluator from utils.common_utils import * from data_handle.data_loader import * from utils.verbalizer import Verbalizer from pet_config import * pc = ProjectConfig () \u5b9a\u4e49model2train()\u51fd\u6570 def model2train (): model = AutoModelForMaskedLM . from_pretrained ( pc . pre_model ) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = pc . max_label_len ) #\u5bf9\u53c2\u6570\u505a\u6743\u91cd\u8870\u51cf\u662f\u4e3a\u4e86\u4f7f\u51fd\u6570\u5e73\u6ed1\uff0c\u7136\u800cbias\u548clayernorm\u7684\u6743\u91cd\u53c2\u6570\u4e0d\u5f71\u54cd\u51fd\u6570\u7684\u5e73\u6ed1\u6027\u3002 #\u4ed6\u4eec\u8d77\u5230\u7684\u4f5c\u7528\u4ec5\u4ec5\u662f\u7f29\u653e\u5e73\u79fb\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u6743\u91cd\u8870\u51cf no_decay = [ \"bias\" , \"LayerNorm.weight\" ] optimizer_grouped_parameters = [ { \"params\" : [ p for n , p in model . named_parameters () if not any ( nd in n for nd in no_decay )], \"weight_decay\" : pc . weight_decay , }, { \"params\" : [ p for n , p in model . named_parameters () if any ( nd in n for nd in no_decay )], \"weight_decay\" : 0.0 , }, ] optimizer = torch . optim . AdamW ( optimizer_grouped_parameters , lr = pc . learning_rate ) model . to ( pc . device ) train_dataloader , dev_dataloader = get_data () # \u6839\u636e\u8bad\u7ec3\u8f6e\u6570\u8ba1\u7b97\u6700\u5927\u8bad\u7ec3\u6b65\u6570\uff0c\u4ee5\u4fbf\u4e8escheduler\u52a8\u6001\u8c03\u6574lr num_update_steps_per_epoch = len ( train_dataloader ) #\u6307\u5b9a\u603b\u7684\u8bad\u7ec3\u6b65\u6570\uff0c\u5b83\u4f1a\u88ab\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u7528\u6765\u786e\u5b9a\u5b66\u4e60\u7387\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u786e\u4fdd\u5b66\u4e60\u7387\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f97\u4ee5\u5408\u7406\u5730\u8c03\u8282 max_train_steps = pc . epochs * num_update_steps_per_epoch warm_steps = int ( pc . warmup_ratio * max_train_steps ) # \u9884\u70ed\u9636\u6bb5\u7684\u8bad\u7ec3\u6b65\u6570 lr_scheduler = get_scheduler ( name = 'linear' , optimizer = optimizer , num_warmup_steps = warm_steps , num_training_steps = max_train_steps , ) loss_list = [] tic_train = time . time () metric = ClassEvaluator () criterion = torch . nn . CrossEntropyLoss () global_step , best_f1 = 0 , 0 print ( '\u5f00\u59cb\u8bad\u7ec3\uff1a' ) for epoch in range ( pc . epochs ): for batch in train_dataloader : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits # print(f'\u6a21\u578b\u8bad\u7ec3\u5f97\u5230\u7684\u7ed3\u679clogits-->{logits.size()}') # \u771f\u5b9e\u6807\u7b7e mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () sub_labels = verbalizer . batch_find_sub_labels ( mask_labels ) sub_labels = [ ele [ 'token_ids' ] for ele in sub_labels ] # print(f'sub_labels--->{sub_labels}') loss = mlm_loss ( logits , batch [ 'mask_positions' ] . to ( pc . device ), sub_labels , criterion , pc . device , 1.0 ) optimizer . zero_grad () loss . backward () optimizer . step () lr_scheduler . step () loss_list . append ( float ( loss . cpu () . detach ())) # # global_step += 1 if global_step % pc . logging_steps == 0 : time_diff = time . time () - tic_train loss_avg = sum ( loss_list ) / len ( loss_list ) print ( \"global step %d , epoch: %d , loss: %.5f , speed: %.2f step/s\" % ( global_step , epoch , loss_avg , pc . logging_steps / time_diff )) tic_train = time . time () if global_step % pc . valid_steps == 0 : cur_save_dir = os . path . join ( pc . save_dir , \"model_ %d \" % global_step ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) acc , precision , recall , f1 , class_metrics = evaluate_model ( model , metric , dev_dataloader , tokenizer , verbalizer ) print ( \"Evaluation precision: %.5f , recall: %.5f , F1: %.5f \" % ( precision , recall , f1 )) if f1 > best_f1 : print ( f \"best F1 performence has been updated: { best_f1 : .5f } --> { f1 : .5f } \" ) print ( f 'Each Class Metrics are: { class_metrics } ' ) best_f1 = f1 cur_save_dir = os . path . join ( pc . save_dir , \"model_best\" ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) tic_train = time . time () print ( '\u8bad\u7ec3\u7ed3\u675f' ) \u5b9a\u4e49evaluate_model()\u51fd\u6570 def evaluate_model ( model , metric , data_loader , tokenizer , verbalizer ): \"\"\" \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u5f53\u524d\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002 Args: model: \u5f53\u524d\u6a21\u578b metric: \u8bc4\u4f30\u6307\u6807\u7c7b(metric) data_loader: \u6d4b\u8bd5\u96c6\u7684dataloader global_step: \u5f53\u524d\u8bad\u7ec3\u6b65\u6570 \"\"\" model . eval () metric . reset () with torch . no_grad (): for step , batch in enumerate ( data_loader ): logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () # (batch, label_num) for i in range ( len ( mask_labels )): # \u53bb\u6389label\u4e2d\u7684[PAD] token while tokenizer . pad_token_id in mask_labels [ i ]: mask_labels [ i ] . remove ( tokenizer . pad_token_id ) # id\u8f6c\u6587\u5b57 mask_labels = [ '' . join ( tokenizer . convert_ids_to_tokens ( t )) for t in mask_labels ] # (batch, label_num) predictions = convert_logits_to_ids ( logits , batch [ 'mask_positions' ]) . cpu () . numpy () . tolist () # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = verbalizer . batch_find_main_label ( predictions ) predictions = [ ele [ 'label' ] for ele in predictions ] metric . add_batch ( pred_batch = predictions , gold_batch = mask_labels ) eval_metric = metric . compute () model . train () return eval_metric [ 'accuracy' ], eval_metric [ 'precision' ], \\ eval_metric [ 'recall' ], eval_metric [ 'f1' ], \\ eval_metric [ 'class_metrics' ] \u8c03\u7528: cd /Users/**/PycharmProjects/llm/prompt_tasks/PET # \u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3 python train.py \u8f93\u51fa\u7ed3\u679c: ..... global step 40 , epoch : 4 , loss : 0.62105 , speed : 1.27 step / s Evaluation precision : 0.78000 , recall : 0.77000 , F1 : 0.76000 Each Class Metrics are : { '\u4e66\u7c4d' : { 'precision' : 0.97 , 'recall' : 0.82 , 'f1' : 0.89 }, '\u5e73\u677f' : { 'precision' : 0.57 , 'recall' : 0.84 , 'f1' : 0.68 }, '\u624b\u673a' : { 'precision' : 0.0 , 'recall' : 0.0 , 'f1' : 0 }, '\u6c34\u679c' : { 'precision' : 0.95 , 'recall' : 0.81 , 'f1' : 0.87 }, '\u6d17\u6d74' : { 'precision' : 0.7 , 'recall' : 0.71 , 'f1' : 0.7 }, '\u7535\u5668' : { 'precision' : 0.0 , 'recall' : 0.0 , 'f1' : 0 }, '\u7535\u8111' : { 'precision' : 0.86 , 'recall' : 0.38 , 'f1' : 0.52 }, '\u8499\u725b' : { 'precision' : 1.0 , 'recall' : 0.68 , 'f1' : 0.81 }, '\u8863\u670d' : { 'precision' : 0.71 , 'recall' : 0.91 , 'f1' : 0.79 }, '\u9152\u5e97' : { 'precision' : 1.0 , 'recall' : 0.88 , 'f1' : 0.93 }} global step 50 , epoch : 6 , loss : 0.50076 , speed : 1.23 step / s global step 60 , epoch : 7 , loss : 0.41744 , speed : 1.23 step / s ... global step 390 , epoch : 48 , loss : 0.06674 , speed : 1.20 step / s global step 400 , epoch : 49 , loss : 0.06507 , speed : 1.21 step / s Evaluation precision : 0.78000 , recall : 0.76000 , F1 : 0.75000 \u7ed3\u8bba: BERT+PET\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8868\u73b0\u662f\u7cbe\u786e\u7387=78% \u6ce8\u610f\uff1a\u672c\u9879\u76ee\u4e2d\u53ea\u7528\u4e8660\u6761\u6837\u672c\uff0c\u5728\u63a5\u8fd1600\u6761\u6837\u672c\u4e0a\u7cbe\u786e\u7387\u5c31\u5df2\u7ecf\u8fbe\u5230\u4e8678%\uff0c\u5982\u679c\u60f3\u8ba9\u6307\u6807\u66f4\u9ad8\uff0c\u53ef\u4ee5\u6269\u589e\u6837\u672c\u3002 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e76\u6d4b\u8bd5\u6548\u679c \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/PET/inference.py \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import time from typing import List import torch from rich import print from transformers import AutoTokenizer , AutoModelForMaskedLM import sys sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/PET/data_handle' ) sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/PET/utils' ) from utils.verbalizer import Verbalizer from data_handle.template import HardTemplate from data_handle.data_preprocess import convert_example from utils.common_utils import convert_logits_to_ids \u9884\u6d4b\u4ee3\u7801\u5177\u4f53\u5b9e\u73b0 device = 'mps:0' # device='cuda:0' model_path = 'checkpoints/model_best' tokenizer = AutoTokenizer . from_pretrained ( model_path ) model = AutoModelForMaskedLM . from_pretrained ( model_path ) model . to ( device ) . eval () max_label_len = 2 # \u6807\u7b7e\u6700\u5927\u957f\u5ea6 verbalizer = Verbalizer ( verbalizer_file = 'data/verbalizer.txt' , tokenizer = tokenizer , max_label_len = max_label_len ) prompt = open ( 'data/prompt.txt' , 'r' , encoding = 'utf8' ) . readlines ()[ 0 ] . strip () # prompt\u5b9a\u4e49 hard_template = HardTemplate ( prompt = prompt ) # \u6a21\u677f\u8f6c\u6362\u5668\u5b9a\u4e49 print ( f 'Prompt is -> { prompt } ' ) def inference ( contents : List [ str ]): \"\"\" \u63a8\u7406\u51fd\u6570\uff0c\u8f93\u5165\u539f\u59cb\u53e5\u5b50\uff0c\u8f93\u51famask label\u7684\u9884\u6d4b\u503c\u3002 Args: contents (List[str]): \u63cf\u539f\u59cb\u53e5\u5b50\u5217\u8868\u3002 \"\"\" with torch . no_grad (): start_time = time . time () examples = { 'text' : contents } tokenized_output = convert_example ( examples , tokenizer , hard_template = hard_template , max_seq_len = 128 , max_label_len = max_label_len , train_mode = False , return_tensor = True ) logits = model ( input_ids = tokenized_output [ 'input_ids' ] . to ( device ), token_type_ids = tokenized_output [ 'token_type_ids' ] . to ( device ), attention_mask = tokenized_output [ 'attention_mask' ] . to ( device )) . logits predictions = convert_logits_to_ids ( logits , tokenized_output [ 'mask_positions' ]) . cpu () . numpy () . tolist () # (batch, label_num) # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = verbalizer . batch_find_main_label ( predictions ) predictions = [ ele [ 'label' ] for ele in predictions ] used = time . time () - start_time print ( f 'Used { used } s.' ) return predictions if __name__ == '__main__' : contents = [ '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa\u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' , '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d\u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' , \"\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f\" , \"\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86\uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a\u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765\u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230\" , \"\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212\u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765\" ] print ( \"\u9488\u5bf9\u4e0b\u9762\u7684\u6587\u672c\u8bc4\u8bba\uff0c\u8bf7\u5206\u522b\u7ed9\u51fa\u5bf9\u5e94\u6240\u5c5e\u7c7b\u522b\uff1a\" ) res = inference ( contents ) #print('inference label(s):', res) new_dict = {} for i in range ( len ( contents )): new_dict [ contents [ i ]] = res [ i ] print ( new_dict ) \u7ed3\u679c\u5c55\u793a { '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa \u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' : '\u9152\u5e97', '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d \u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' : '\u9152\u5e97', '\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f' : '\u5e73\u677f', '\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86 \uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a \u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765 \u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230' : '\u6c34\u679c', '\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212 \u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765' : '\u9152\u5e97' } \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b9e\u73b0\u4e86\u57fa\u4e8eBERT+PET\u6a21\u578b\u7684\u6784\u5efa, \u5e76\u5b8c\u6210\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8bc4\u4f30.","title":"6.4 BERT+PET\u65b9\u5f0f\u6a21\u578b\u4ee3\u7801\u5b9e\u73b0\u548c\u8bad\u7ec3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#bertpet","text":"","title":"\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u6a21\u578b\u642d\u5efa"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_1","text":"\u638c\u63e1\u57fa\u4e8eBERT+PET\u65b9\u5f0f\u6a21\u578b\u642d\u5efa\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u6a21\u578b\u7684\u8bad\u7ec3,\u9a8c\u8bc1\u53ca\u76f8\u5173\u5de5\u5177\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_2","text":"\u672c\u9879\u76ee\u4e2d\u5b8c\u6210BERT+PET\u6a21\u578b\u642d\u5efa\u3001\u8bad\u7ec3\u53ca\u5e94\u7528\u7684\u6b65\u9aa4\u5982\u4e0b\uff08\u6ce8\u610f\uff1a\u56e0\u4e3a\u672c\u9879\u76ee\u4e2d\u4f7f\u7528\u7684\u662fBERT\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6240\u4ee5\u76f4\u63a5\u52a0\u8f7d\u5373\u53ef\uff0c\u65e0\u9700\u91cd\u590d\u642d\u5efa\u6a21\u578b\u67b6\u6784\uff09: \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570","title":"\u6a21\u578b\u642d\u5efa"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_3","text":"\u76ee\u7684\uff1a\u6a21\u578b\u5728\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u9884\u6d4b\u65f6\u9700\u8981\u7684\u51fd\u6570 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/PET/utils utils\u6587\u4ef6\u5939\u5171\u5305\u542b3\u4e2apy\u811a\u672c\uff1averbalizer.py\u3001metirc_utils.py\u4ee5\u53cacommon_utils.py","title":"\u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#11-verbalizerpy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u4e00\u4e2aVerbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # -*- coding:utf-8 -*- import os from typing import Union , List from pet_config import * pc = ProjectConfig () \u5177\u4f53\u5b9e\u73b0\u4ee3\u7801 class Verbalizer ( object ): \"\"\" Verbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \"\"\" def __init__ ( self , verbalizer_file : str , tokenizer , max_label_len : int ): \"\"\" Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 tokenizer: \u5206\u8bcd\u5668\uff0c\u7528\u4e8e\u6587\u672c\u548cid\u4e4b\u95f4\u7684\u8f6c\u6362\u3002 max_label_len (int): \u6807\u7b7e\u957f\u5ea6\uff0c\u82e5\u5927\u4e8e\u5219\u622a\u65ad\uff0c\u82e5\u5c0f\u4e8e\u5219\u8865\u9f50 \"\"\" self . tokenizer = tokenizer self . label_dict = self . load_label_dict ( verbalizer_file ) self . max_label_len = max_label_len def load_label_dict ( self , verbalizer_file : str ): \"\"\" \u8bfb\u53d6\u672c\u5730\u6587\u4ef6\uff0c\u6784\u5efaverbalizer\u5b57\u5178\u3002 Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 Returns: dict -> { '\u4f53\u80b2': ['\u7bee\u7403', '\u8db3\u7403','\u7f51\u7403', '\u6392\u7403', ...], '\u9152\u5e97': ['\u5bbe\u9986', '\u65c5\u9986', '\u65c5\u5e97', '\u9152\u5e97', ...], ... } \"\"\" label_dict = {} with open ( verbalizer_file , 'r' , encoding = 'utf8' ) as f : for line in f . readlines (): label , sub_labels = line . strip () . split ( ' \\t ' ) label_dict [ label ] = list ( set ( sub_labels . split ( ',' ))) return label_dict def find_sub_labels ( self , label : Union [ list , str ]): \"\"\" \u901a\u8fc7\u6807\u7b7e\u627e\u5230\u5bf9\u5e94\u6240\u6709\u7684\u5b50\u6807\u7b7e\u3002 Args: label (Union[list, str]): \u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u4f53\u80b2' or [860, 5509] Returns: dict -> { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] } \"\"\" if type ( label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8fdb\u884c\u6587\u672c\u8f6c\u6362 while self . tokenizer . pad_token_id in label : label . remove ( self . tokenizer . pad_token_id ) label = '' . join ( self . tokenizer . convert_ids_to_tokens ( label )) # print(f'label-->{label}') if label not in self . label_dict : raise ValueError ( f 'Lable Error: \" { label } \" not in label_dict' ) sub_labels = self . label_dict [ label ] ret = { 'sub_labels' : sub_labels } token_ids = [ _id [ 1 : - 1 ] for _id in self . tokenizer ( sub_labels )[ 'input_ids' ]] # print(f'token_ids-->{token_ids}') for i in range ( len ( token_ids )): token_ids [ i ] = token_ids [ i ][: self . max_label_len ] # \u5bf9\u6807\u7b7e\u8fdb\u884c\u622a\u65ad\u4e0e\u8865\u9f50 if len ( token_ids [ i ]) < self . max_label_len : token_ids [ i ] = token_ids [ i ] + [ self . tokenizer . pad_token_id ] * ( self . max_label_len - len ( token_ids [ i ])) ret [ 'token_ids' ] = token_ids return ret def batch_find_sub_labels ( self , label : List [ Union [ list , str ]]): \"\"\" \u6279\u91cf\u627e\u5230\u5b50\u6807\u7b7e\u3002 Args: label (List[list, str]): \u6807\u7b7e\u5217\u8868, [[4510, 5554], [860, 5509]] or ['\u4f53\u80b2', '\u7535\u8111'] Returns: list -> [ { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] }, ... ] \"\"\" return [ self . find_sub_labels ( l ) for l in label ] def get_common_sub_str ( self , str1 : str , str2 : str ): \"\"\" \u5bfb\u627e\u6700\u5927\u516c\u5171\u5b50\u4e32\u3002 str1:abcd str2:abadbcdba \"\"\" lstr1 , lstr2 = len ( str1 ), len ( str2 ) # \u751f\u62100\u77e9\u9635\uff0c\u4e3a\u65b9\u4fbf\u540e\u7eed\u8ba1\u7b97\uff0c\u6bd4\u5b57\u7b26\u4e32\u957f\u5ea6\u591a\u4e86\u4e00\u5217 record = [[ 0 for i in range ( lstr2 + 1 )] for j in range ( lstr1 + 1 )] p = 0 # \u6700\u957f\u5339\u914d\u5bf9\u5e94\u5728str1\u4e2d\u7684\u6700\u540e\u4e00\u4f4d maxNum = 0 # \u6700\u957f\u5339\u914d\u957f\u5ea6 for i in range ( lstr1 ): for j in range ( lstr2 ): if str1 [ i ] == str2 [ j ]: record [ i + 1 ][ j + 1 ] = record [ i ][ j ] + 1 if record [ i + 1 ][ j + 1 ] > maxNum : maxNum = record [ i + 1 ][ j + 1 ] p = i + 1 return str1 [ p - maxNum : p ], maxNum def hard_mapping ( self , sub_label : str ): \"\"\" \u5f3a\u5339\u914d\u51fd\u6570\uff0c\u5f53\u6a21\u578b\u751f\u6210\u7684\u5b50label\u4e0d\u5b58\u5728\u65f6\uff0c\u901a\u8fc7\u6700\u5927\u516c\u5171\u5b50\u4e32\u627e\u5230\u91cd\u5408\u5ea6\u6700\u9ad8\u7684\u4e3blabel\u3002 Args: sub_label (str): \u5b50label\u3002 Returns: str: \u4e3blabel\u3002 \"\"\" label , max_overlap_str = '' , 0 # print(self.label_dict.items()) for main_label , sub_labels in self . label_dict . items (): overlap_num = 0 for s_label in sub_labels : # \u6c42\u6240\u6709\u5b50label\u4e0e\u5f53\u524d\u63a8\u7406label\u4e4b\u95f4\u7684\u6700\u957f\u516c\u5171\u5b50\u4e32\u957f\u5ea6 overlap_num += self . get_common_sub_str ( sub_label , s_label )[ 1 ] if overlap_num >= max_overlap_str : max_overlap_str = overlap_num label = main_label return label def find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u5230\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u82f9\u679c' or [5741, 3362] hard_mapping (bool): \u5f53\u751f\u6210\u7684\u8bcd\u8bed\u4e0d\u5b58\u5728\u65f6\uff0c\u662f\u5426\u4e00\u5b9a\u8981\u5339\u914d\u5230\u4e00\u4e2a\u6700\u76f8\u4f3c\u7684label\u3002 Returns: dict -> { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] } \"\"\" if type ( sub_label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8f6c\u56de\u6765 pad_token_id = self . tokenizer . pad_token_id while pad_token_id in sub_label : # \u79fb\u9664[PAD]token sub_label . remove ( pad_token_id ) sub_label = '' . join ( self . tokenizer . convert_ids_to_tokens ( sub_label )) # print(sub_label) main_label = '\u65e0' for label , s_labels in self . label_dict . items (): if sub_label in s_labels : main_label = label break if main_label == '\u65e0' and hard_mapping : main_label = self . hard_mapping ( sub_label ) # print(main_label) ret = { 'label' : main_label , 'token_ids' : self . tokenizer ( main_label )[ 'input_ids' ][ 1 : - 1 ] } return ret def batch_find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u6279\u91cf\u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e\u5217\u8868, ['\u82f9\u679c', ...] or [[5741, 3362], ...] Returns: list: [ { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] }, ... ] \"\"\" return [ self . find_main_label ( l , hard_mapping ) for l in sub_label ] if __name__ == '__main__' : from rich import print from transformers import AutoTokenizer tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = 2 ) print ( verbalizer . label_dict ) # label = [4510, 5554] # ret = verbalizer.find_sub_labels(label) # label = ['\u7535\u8111', '\u8863\u670d'] label = [[ 4510 , 5554 ], [ 6132 , 3302 ]] ret = verbalizer . batch_find_sub_labels ( label ) print ( ret )","title":"1.1 verbalizer.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#12-common_utilspy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u3001\u5c06mask_position\u4f4d\u7f6e\u7684token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amlm_loss()\u4ee5\u53caconvert_logits_to_ids() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch from rich import print \u5b9a\u4e49\u635f\u5931\u51fd\u6570mlm_loss() def mlm_loss ( logits , mask_positions , sub_mask_labels , cross_entropy_criterion , device ): \"\"\" \u8ba1\u7b97\u6307\u5b9a\u4f4d\u7f6e\u7684mask token\u7684output\u4e0elabel\u4e4b\u95f4\u7684cross entropy loss\u3002 Args: logits (torch.tensor): \u6a21\u578b\u539f\u59cb\u8f93\u51fa -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) sub_mask_labels (list): mask token\u7684sub label, \u7531\u4e8e\u6bcf\u4e2alabel\u7684sub_label\u6570\u76ee\u4e0d\u540c\uff0c\u6240\u4ee5 \u8fd9\u91cc\u662f\u4e2a\u53d8\u957f\u7684list, e.g. -> [ [[2398, 3352]], [[2398, 3352], [3819, 3861]] ] cross_entropy_criterion (CrossEntropyLoss): CE Loss\u8ba1\u7b97\u5668 device (str): cpu\u8fd8\u662fgpu Returns: torch.tensor: CE Loss \"\"\" batch_size , seq_len , vocab_size = logits . size () loss = None for single_value in zip ( logits , sub_mask_labels , mask_positions ): single_logits = single_value [ 0 ] single_sub_mask_labels = single_value [ 1 ] single_mask_positions = single_value [ 2 ] # single_mask_logits\u5f62\u72b6\uff1a(mask_label_num, vocab_size) single_mask_logits = single_logits [ single_mask_positions ] # single_mask_logits\u6309\u7167\u5b50\u6807\u7b7e\u7684\u957f\u5ea6\u8fdb\u884c\u590d\u5236: # single_mask_logits\u5f62\u72b6-->(sub_label_num, mask_label_num, vocab_size) single_mask_logits = single_mask_logits . repeat ( len ( single_sub_mask_labels ), 1 , 1 ) #single_mask_logits\u6539\u53d8\u5f62\u72b6\uff1a(sub_label_num * mask_label_num, vocab_size) #\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c single_mask_logits = single_mask_logits . reshape ( - 1 , vocab_size ) # single_sub_mask_labels\u5f62\u72b6\uff1a(sub_label_num, mask_label_num) single_sub_mask_labels = torch . LongTensor ( single_sub_mask_labels ) . to ( device ) # single_sub_mask_labels\u5f62\u72b6\uff1a # (sub_label_num * mask_label_num) single_sub_mask_labels = single_sub_mask_labels . reshape ( - 1 , 1 ) . squeeze () if not single_sub_mask_labels . size (): # \u5904\u7406\u5355token\u7ef4\u5ea6\u4e0b\u7ef4\u5ea6\u7f3a\u5931\u7684\u95ee\u9898 single_sub_mask_labels = single_sub_mask_labels . unsqueeze ( dim = 0 ) cur_loss = cross_entropy_criterion ( single_mask_logits , single_sub_mask_labels ) cur_loss = cur_loss / len ( single_sub_mask_labels ) if not loss : loss = cur_loss else : loss += cur_loss loss = loss / batch_size return loss \u5b9a\u4e49convert_logits_to_ids()\u51fd\u6570 def convert_logits_to_ids ( logits : torch . tensor , mask_positions : torch . tensor ): \"\"\" \u8f93\u5165LM\u7684\u8bcd\u8868\u6982\u7387\u5206\u5e03\uff08LMModel\u7684logits\uff09\uff0c\u5c06mask_position\u4f4d\u7f6e\u7684 token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 Args: logits (torch.tensor): model output -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) Returns: torch.LongTensor: \u5bf9\u5e94mask position\u4e0a\u6700\u5927\u6982\u7387\u7684\u63a8\u7406token -> (batch, mask_label_num) \"\"\" label_length = mask_positions . size ()[ 1 ] # \u6807\u7b7e\u957f\u5ea6 # print(f'label_length--\u300b{label_length}') batch_size , seq_len , vocab_size = logits . size () mask_positions_after_reshaped = [] for batch , mask_pos in enumerate ( mask_positions . detach () . cpu () . numpy () . tolist ()): for pos in mask_pos : mask_positions_after_reshaped . append ( batch * seq_len + pos ) # logits\u5f62\u72b6\uff1a(batch_size * seq_len, vocab_size) logits = logits . reshape ( batch_size * seq_len , - 1 ) # mask_logits\u5f62\u72b6\uff1a(batch * label_num, vocab_size) mask_logits = logits [ mask_positions_after_reshaped ] # predict_tokens\u5f62\u72b6\uff1a (batch * label_num) predict_tokens = mask_logits . argmax ( dim =- 1 ) # \u6539\u53d8\u540e\u7684predict_tokens\u5f62\u72b6\uff1a (batch, label_num) predict_tokens = predict_tokens . reshape ( - 1 , label_length ) # (batch, label_num) return predict_tokens","title":"1.2 common_utils.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#13-metirc_utilspy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\uff08\u591a\uff09\u5206\u7c7b\u95ee\u9898\u4e0b\u7684\u6307\u6807\u8bc4\u4f30\uff08acc, precision, recall, f1\uff09\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a from typing import List import numpy as np import pandas as pd from sklearn.metrics import accuracy_score , precision_score , f1_score from sklearn.metrics import recall_score , confusion_matrix \u5b9a\u4e49ClassEvaluator\u7c7b class ClassEvaluator ( object ): def __init__ ( self ): self . goldens = [] self . predictions = [] def add_batch ( self , pred_batch : List [ List ], gold_batch : List [ List ]): \"\"\" \u6dfb\u52a0\u4e00\u4e2abatch\u4e2d\u7684prediction\u548cgold\u5217\u8868\uff0c\u7528\u4e8e\u540e\u7eed\u7edf\u4e00\u8ba1\u7b97\u3002 Args: pred_batch (list): \u6a21\u578b\u9884\u6d4b\u6807\u7b7e\u5217\u8868, e.g. -> [0, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] gold_batch (list): \u771f\u5b9e\u6807\u7b7e\u6807\u7b7e\u5217\u8868, e.g. -> [1, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] \"\"\" assert len ( pred_batch ) == len ( gold_batch ) # \u82e5\u9047\u5230\u591a\u4e2a\u5b50\u6807\u7b7e\u6784\u6210\u4e00\u4e2a\u6807\u7b7e\u7684\u60c5\u51b5 if type ( gold_batch [ 0 ]) in [ list , tuple ]: # \u5c06\u6240\u6709\u7684label\u62fc\u63a5\u4e3a\u4e00\u4e2a\u6574label: ['\u4f53', '\u80b2'] -> '\u4f53\u80b2' pred_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in pred_batch ] gold_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in gold_batch ] self . goldens . extend ( gold_batch ) self . predictions . extend ( pred_batch ) def compute ( self , round_num = 2 ) -> dict : \"\"\" \u6839\u636e\u5f53\u524d\u7c7b\u4e2d\u7d2f\u79ef\u7684\u53d8\u91cf\u503c\uff0c\u8ba1\u7b97\u5f53\u524d\u7684P, R, F1\u3002 Args: round_num (int): \u8ba1\u7b97\u7ed3\u679c\u4fdd\u7559\u5c0f\u6570\u70b9\u540e\u51e0\u4f4d, \u9ed8\u8ba4\u5c0f\u6570\u70b9\u540e2\u4f4d\u3002 Returns: dict -> { 'accuracy': \u51c6\u786e\u7387, 'precision': \u7cbe\u51c6\u7387, 'recall': \u53ec\u56de\u7387, 'f1': f1\u503c, 'class_metrics': { '0': { 'precision': \u8be5\u7c7b\u522b\u4e0b\u7684precision, 'recall': \u8be5\u7c7b\u522b\u4e0b\u7684recall, 'f1': \u8be5\u7c7b\u522b\u4e0b\u7684f1 }, ... } } \"\"\" classes , class_metrics , res = sorted ( list ( set ( self . goldens ) | set ( self . predictions ))), {}, {} # \u6784\u5efa\u5168\u5c40\u6307\u6807 res [ 'accuracy' ] = round ( accuracy_score ( self . goldens , self . predictions ), round_num ) res [ 'precision' ] = round ( precision_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) # average='weighted'\u4ee3\u8868\uff1a\u8003\u8651\u7c7b\u522b\u7684\u4e0d\u5e73\u8861\u6027\uff0c\u9700\u8981\u8ba1\u7b97\u7c7b\u522b\u7684\u52a0\u6743\u5e73\u5747\u3002\u5982\u679c\u662f\u4e8c\u5206\u7c7b\u95ee\u9898\u5219\u9009\u62e9\u53c2\u6570\u2018binary\u2018 res [ 'recall' ] = round ( recall_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) res [ 'f1' ] = round ( f1_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) try : conf_matrix = np . array ( confusion_matrix ( self . goldens , self . predictions )) # (n_class, n_class) assert conf_matrix . shape [ 0 ] == len ( classes ) for i in range ( conf_matrix . shape [ 0 ]): # \u6784\u5efa\u6bcf\u4e2aclass\u7684\u6307\u6807 precision = 0 if sum ( conf_matrix [:, i ]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [:, i ]) recall = 0 if sum ( conf_matrix [ i , :]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [ i , :]) f1 = 0 if ( precision + recall ) == 0 else 2 * precision * recall / ( precision + recall ) class_metrics [ classes [ i ]] = { 'precision' : round ( precision , round_num ), 'recall' : round ( recall , round_num ), 'f1' : round ( f1 , round_num ) } res [ 'class_metrics' ] = class_metrics except Exception as e : print ( f '[Warning] Something wrong when calculate class_metrics: { e } ' ) print ( f '-> goldens: { set ( self . goldens ) } ' ) print ( f '-> predictions: { set ( self . predictions ) } ' ) print ( f '-> diff elements: { set ( self . predictions ) - set ( self . goldens ) } ' ) res [ 'class_metrics' ] = {} return res def reset ( self ): \"\"\" \u91cd\u7f6e\u79ef\u7d2f\u7684\u6570\u503c\u3002 \"\"\" self . goldens = [] self . predictions = []","title":"1.3 metirc_utils.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_4","text":"\u76ee\u7684\uff1a\u5b9e\u73b0\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/PET/train.py \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amodel2train()\u548cevaluate_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import os import time from transformers import AutoModelForMaskedLM , AutoTokenizer , get_scheduler from pet_config import * import sys sys . path . append ( '/Users/ligang/PycharmProjects/llm/prompt_tasks/PET/data_handle' ) sys . path . append ( '/Users/ligang/PycharmProjects/llm/prompt_tasks/PET/utils' ) from utils.metirc_utils import ClassEvaluator from utils.common_utils import * from data_handle.data_loader import * from utils.verbalizer import Verbalizer from pet_config import * pc = ProjectConfig () \u5b9a\u4e49model2train()\u51fd\u6570 def model2train (): model = AutoModelForMaskedLM . from_pretrained ( pc . pre_model ) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = pc . max_label_len ) #\u5bf9\u53c2\u6570\u505a\u6743\u91cd\u8870\u51cf\u662f\u4e3a\u4e86\u4f7f\u51fd\u6570\u5e73\u6ed1\uff0c\u7136\u800cbias\u548clayernorm\u7684\u6743\u91cd\u53c2\u6570\u4e0d\u5f71\u54cd\u51fd\u6570\u7684\u5e73\u6ed1\u6027\u3002 #\u4ed6\u4eec\u8d77\u5230\u7684\u4f5c\u7528\u4ec5\u4ec5\u662f\u7f29\u653e\u5e73\u79fb\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u6743\u91cd\u8870\u51cf no_decay = [ \"bias\" , \"LayerNorm.weight\" ] optimizer_grouped_parameters = [ { \"params\" : [ p for n , p in model . named_parameters () if not any ( nd in n for nd in no_decay )], \"weight_decay\" : pc . weight_decay , }, { \"params\" : [ p for n , p in model . named_parameters () if any ( nd in n for nd in no_decay )], \"weight_decay\" : 0.0 , }, ] optimizer = torch . optim . AdamW ( optimizer_grouped_parameters , lr = pc . learning_rate ) model . to ( pc . device ) train_dataloader , dev_dataloader = get_data () # \u6839\u636e\u8bad\u7ec3\u8f6e\u6570\u8ba1\u7b97\u6700\u5927\u8bad\u7ec3\u6b65\u6570\uff0c\u4ee5\u4fbf\u4e8escheduler\u52a8\u6001\u8c03\u6574lr num_update_steps_per_epoch = len ( train_dataloader ) #\u6307\u5b9a\u603b\u7684\u8bad\u7ec3\u6b65\u6570\uff0c\u5b83\u4f1a\u88ab\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u7528\u6765\u786e\u5b9a\u5b66\u4e60\u7387\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u786e\u4fdd\u5b66\u4e60\u7387\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f97\u4ee5\u5408\u7406\u5730\u8c03\u8282 max_train_steps = pc . epochs * num_update_steps_per_epoch warm_steps = int ( pc . warmup_ratio * max_train_steps ) # \u9884\u70ed\u9636\u6bb5\u7684\u8bad\u7ec3\u6b65\u6570 lr_scheduler = get_scheduler ( name = 'linear' , optimizer = optimizer , num_warmup_steps = warm_steps , num_training_steps = max_train_steps , ) loss_list = [] tic_train = time . time () metric = ClassEvaluator () criterion = torch . nn . CrossEntropyLoss () global_step , best_f1 = 0 , 0 print ( '\u5f00\u59cb\u8bad\u7ec3\uff1a' ) for epoch in range ( pc . epochs ): for batch in train_dataloader : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits # print(f'\u6a21\u578b\u8bad\u7ec3\u5f97\u5230\u7684\u7ed3\u679clogits-->{logits.size()}') # \u771f\u5b9e\u6807\u7b7e mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () sub_labels = verbalizer . batch_find_sub_labels ( mask_labels ) sub_labels = [ ele [ 'token_ids' ] for ele in sub_labels ] # print(f'sub_labels--->{sub_labels}') loss = mlm_loss ( logits , batch [ 'mask_positions' ] . to ( pc . device ), sub_labels , criterion , pc . device , 1.0 ) optimizer . zero_grad () loss . backward () optimizer . step () lr_scheduler . step () loss_list . append ( float ( loss . cpu () . detach ())) # # global_step += 1 if global_step % pc . logging_steps == 0 : time_diff = time . time () - tic_train loss_avg = sum ( loss_list ) / len ( loss_list ) print ( \"global step %d , epoch: %d , loss: %.5f , speed: %.2f step/s\" % ( global_step , epoch , loss_avg , pc . logging_steps / time_diff )) tic_train = time . time () if global_step % pc . valid_steps == 0 : cur_save_dir = os . path . join ( pc . save_dir , \"model_ %d \" % global_step ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) acc , precision , recall , f1 , class_metrics = evaluate_model ( model , metric , dev_dataloader , tokenizer , verbalizer ) print ( \"Evaluation precision: %.5f , recall: %.5f , F1: %.5f \" % ( precision , recall , f1 )) if f1 > best_f1 : print ( f \"best F1 performence has been updated: { best_f1 : .5f } --> { f1 : .5f } \" ) print ( f 'Each Class Metrics are: { class_metrics } ' ) best_f1 = f1 cur_save_dir = os . path . join ( pc . save_dir , \"model_best\" ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) tic_train = time . time () print ( '\u8bad\u7ec3\u7ed3\u675f' ) \u5b9a\u4e49evaluate_model()\u51fd\u6570 def evaluate_model ( model , metric , data_loader , tokenizer , verbalizer ): \"\"\" \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u5f53\u524d\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002 Args: model: \u5f53\u524d\u6a21\u578b metric: \u8bc4\u4f30\u6307\u6807\u7c7b(metric) data_loader: \u6d4b\u8bd5\u96c6\u7684dataloader global_step: \u5f53\u524d\u8bad\u7ec3\u6b65\u6570 \"\"\" model . eval () metric . reset () with torch . no_grad (): for step , batch in enumerate ( data_loader ): logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () # (batch, label_num) for i in range ( len ( mask_labels )): # \u53bb\u6389label\u4e2d\u7684[PAD] token while tokenizer . pad_token_id in mask_labels [ i ]: mask_labels [ i ] . remove ( tokenizer . pad_token_id ) # id\u8f6c\u6587\u5b57 mask_labels = [ '' . join ( tokenizer . convert_ids_to_tokens ( t )) for t in mask_labels ] # (batch, label_num) predictions = convert_logits_to_ids ( logits , batch [ 'mask_positions' ]) . cpu () . numpy () . tolist () # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = verbalizer . batch_find_main_label ( predictions ) predictions = [ ele [ 'label' ] for ele in predictions ] metric . add_batch ( pred_batch = predictions , gold_batch = mask_labels ) eval_metric = metric . compute () model . train () return eval_metric [ 'accuracy' ], eval_metric [ 'precision' ], \\ eval_metric [ 'recall' ], eval_metric [ 'f1' ], \\ eval_metric [ 'class_metrics' ] \u8c03\u7528: cd /Users/**/PycharmProjects/llm/prompt_tasks/PET # \u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3 python train.py \u8f93\u51fa\u7ed3\u679c: ..... global step 40 , epoch : 4 , loss : 0.62105 , speed : 1.27 step / s Evaluation precision : 0.78000 , recall : 0.77000 , F1 : 0.76000 Each Class Metrics are : { '\u4e66\u7c4d' : { 'precision' : 0.97 , 'recall' : 0.82 , 'f1' : 0.89 }, '\u5e73\u677f' : { 'precision' : 0.57 , 'recall' : 0.84 , 'f1' : 0.68 }, '\u624b\u673a' : { 'precision' : 0.0 , 'recall' : 0.0 , 'f1' : 0 }, '\u6c34\u679c' : { 'precision' : 0.95 , 'recall' : 0.81 , 'f1' : 0.87 }, '\u6d17\u6d74' : { 'precision' : 0.7 , 'recall' : 0.71 , 'f1' : 0.7 }, '\u7535\u5668' : { 'precision' : 0.0 , 'recall' : 0.0 , 'f1' : 0 }, '\u7535\u8111' : { 'precision' : 0.86 , 'recall' : 0.38 , 'f1' : 0.52 }, '\u8499\u725b' : { 'precision' : 1.0 , 'recall' : 0.68 , 'f1' : 0.81 }, '\u8863\u670d' : { 'precision' : 0.71 , 'recall' : 0.91 , 'f1' : 0.79 }, '\u9152\u5e97' : { 'precision' : 1.0 , 'recall' : 0.88 , 'f1' : 0.93 }} global step 50 , epoch : 6 , loss : 0.50076 , speed : 1.23 step / s global step 60 , epoch : 7 , loss : 0.41744 , speed : 1.23 step / s ... global step 390 , epoch : 48 , loss : 0.06674 , speed : 1.20 step / s global step 400 , epoch : 49 , loss : 0.06507 , speed : 1.21 step / s Evaluation precision : 0.78000 , recall : 0.76000 , F1 : 0.75000 \u7ed3\u8bba: BERT+PET\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8868\u73b0\u662f\u7cbe\u786e\u7387=78% \u6ce8\u610f\uff1a\u672c\u9879\u76ee\u4e2d\u53ea\u7528\u4e8660\u6761\u6837\u672c\uff0c\u5728\u63a5\u8fd1600\u6761\u6837\u672c\u4e0a\u7cbe\u786e\u7387\u5c31\u5df2\u7ecf\u8fbe\u5230\u4e8678%\uff0c\u5982\u679c\u60f3\u8ba9\u6307\u6807\u66f4\u9ad8\uff0c\u53ef\u4ee5\u6269\u589e\u6837\u672c\u3002","title":"\u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_5","text":"\u76ee\u7684\uff1a\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e76\u6d4b\u8bd5\u6548\u679c \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/PET/inference.py \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import time from typing import List import torch from rich import print from transformers import AutoTokenizer , AutoModelForMaskedLM import sys sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/PET/data_handle' ) sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/PET/utils' ) from utils.verbalizer import Verbalizer from data_handle.template import HardTemplate from data_handle.data_preprocess import convert_example from utils.common_utils import convert_logits_to_ids \u9884\u6d4b\u4ee3\u7801\u5177\u4f53\u5b9e\u73b0 device = 'mps:0' # device='cuda:0' model_path = 'checkpoints/model_best' tokenizer = AutoTokenizer . from_pretrained ( model_path ) model = AutoModelForMaskedLM . from_pretrained ( model_path ) model . to ( device ) . eval () max_label_len = 2 # \u6807\u7b7e\u6700\u5927\u957f\u5ea6 verbalizer = Verbalizer ( verbalizer_file = 'data/verbalizer.txt' , tokenizer = tokenizer , max_label_len = max_label_len ) prompt = open ( 'data/prompt.txt' , 'r' , encoding = 'utf8' ) . readlines ()[ 0 ] . strip () # prompt\u5b9a\u4e49 hard_template = HardTemplate ( prompt = prompt ) # \u6a21\u677f\u8f6c\u6362\u5668\u5b9a\u4e49 print ( f 'Prompt is -> { prompt } ' ) def inference ( contents : List [ str ]): \"\"\" \u63a8\u7406\u51fd\u6570\uff0c\u8f93\u5165\u539f\u59cb\u53e5\u5b50\uff0c\u8f93\u51famask label\u7684\u9884\u6d4b\u503c\u3002 Args: contents (List[str]): \u63cf\u539f\u59cb\u53e5\u5b50\u5217\u8868\u3002 \"\"\" with torch . no_grad (): start_time = time . time () examples = { 'text' : contents } tokenized_output = convert_example ( examples , tokenizer , hard_template = hard_template , max_seq_len = 128 , max_label_len = max_label_len , train_mode = False , return_tensor = True ) logits = model ( input_ids = tokenized_output [ 'input_ids' ] . to ( device ), token_type_ids = tokenized_output [ 'token_type_ids' ] . to ( device ), attention_mask = tokenized_output [ 'attention_mask' ] . to ( device )) . logits predictions = convert_logits_to_ids ( logits , tokenized_output [ 'mask_positions' ]) . cpu () . numpy () . tolist () # (batch, label_num) # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = verbalizer . batch_find_main_label ( predictions ) predictions = [ ele [ 'label' ] for ele in predictions ] used = time . time () - start_time print ( f 'Used { used } s.' ) return predictions if __name__ == '__main__' : contents = [ '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa\u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' , '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d\u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' , \"\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f\" , \"\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86\uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a\u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765\u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230\" , \"\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212\u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765\" ] print ( \"\u9488\u5bf9\u4e0b\u9762\u7684\u6587\u672c\u8bc4\u8bba\uff0c\u8bf7\u5206\u522b\u7ed9\u51fa\u5bf9\u5e94\u6240\u5c5e\u7c7b\u522b\uff1a\" ) res = inference ( contents ) #print('inference label(s):', res) new_dict = {} for i in range ( len ( contents )): new_dict [ contents [ i ]] = res [ i ] print ( new_dict ) \u7ed3\u679c\u5c55\u793a { '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa \u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' : '\u9152\u5e97', '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d \u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' : '\u9152\u5e97', '\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f' : '\u5e73\u677f', '\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86 \uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a \u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765 \u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230' : '\u6c34\u679c', '\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212 \u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765' : '\u9152\u5e97' }","title":"\u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/04-BERT%2BPET%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_6","text":"\u672c\u5c0f\u8282\u5b9e\u73b0\u4e86\u57fa\u4e8eBERT+PET\u6a21\u578b\u7684\u6784\u5efa, \u5e76\u5b8c\u6210\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8bc4\u4f30.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html","text":"\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u7406\u89e3P-Tuning\u65b9\u5f0f\u7684\u601d\u60f3 \u4e86\u89e3\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u6574\u4f53\u9879\u76ee\u67b6\u6784 1 \u9879\u76ee\u80cc\u666f \u00b6 \u6587\u672c\u662f\u4fe1\u606f\u4f20\u64ad\u7684\u91cd\u8981\u9014\u5f84\u548c\u8f7d\u4f53\uff0c\u5c06\u6587\u672c\u6570\u636e\u6b63\u786e\u5f52\u7c7b\uff0c\u4ece\u800c\u66f4\u597d\u5730\u7ec4\u7ec7\u3001\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\uff0c\u5177\u6709\u91cd\u8981\u7684\u7814\u7a76\u610f\u4e49\u3002\u6587\u672c\u5206\u7c7b\u81f4\u529b\u4e8e\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08Natural Language Processing\uff0cNLP\uff09\u9886\u57df\u7684\u7ecf\u5178\u4efb\u52a1\u4e4b\u4e00\uff0c\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8206\u60c5\u76d1\u6d4b\u3001\u60c5\u611f\u5206\u6790\u7b49\u573a\u666f\u4e2d\u3002 \u76ee\u524d\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u65b9\u6cd5\u5f88\u591a\uff0c\u5982\u7ecf\u5178\u7684\u5e94\u7528\u4e8e\u6587\u672c\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08Text-CNN\uff09\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08Text-RNN)\u3001\u57fa\u4e8eBERT\u7b49\u9884\u8bad\u7ec3\u6a21\u578b\u7684fine-tuning\u7b49\uff0c\u4f46\u662f\u8fd9\u4e9b\u65b9\u6cd5\u591a\u4e3a\u5efa\u7acb\u5728\u5177\u6709\u5927\u91cf\u7684\u6807\u6ce8\u6570\u636e\u4e0b\u7684\u6709\u76d1\u7763\u5b66\u4e60\u3002\u5728\u5f88\u591a\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u9886\u57df\u7279\u6b8a\u6027\u548c\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\uff0c\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5730\u5b66\u4e60\u53c2\u6570\uff0c\u4ece\u800c\u6613\u51fa\u73b0\u8fc7\u62df\u5408\u73b0\u8c61\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u901a\u8fc7\u5c0f\u6837\u672c\u6570\u636e\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6027\u80fd\u8f83\u597d\u7684\u5206\u7c7b\u6a21\u578b\u662f\u76ee\u524d\u7684\u7814\u7a76\u70ed\u70b9\u3002 \u672c\u7ae0\u6211\u4eec\u5c06\u4ee5\"\u7535\u5546\u5e73\u53f0\u7528\u6237\u8bc4\u8bba\"\u4e3a\u80cc\u666f\uff0c\u57fa\u4e8eBERT+P-Tuning\uff08\u8f6f\u6a21\u7248\uff09\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u8bba\u6587\u672c\u7684\u51c6\u786e\u5206\u7c7b\uff0c\u8fd9\u6837\u505a\u7684\u76ee\u7684\u5728\u4e8e\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002\u901a\u8fc7\u6df1\u5165\u4e86\u89e3\u7528\u6237\u5bf9\u4e0d\u540c\u5546\u54c1\u6216\u670d\u52a1\u7684\u8bc4\u4ef7\uff0c\u5e73\u53f0\u80fd\u591f\u5feb\u901f\u56de\u5e94\u7528\u6237\u9700\u6c42\uff0c\u6539\u8fdb\u4ea7\u54c1\u548c\u670d\u52a1\u3002\u81ea\u52a8\u5206\u7c7b\u4e5f\u4e3a\u4e2a\u6027\u5316\u63a8\u8350\u5960\u5b9a\u57fa\u7840\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u8f7b\u677e\u5730\u627e\u5230\u7b26\u5408\u5176\u504f\u597d\u7684\u5546\u54c1\u3002\u540c\u65f6\uff0c\u8fd9\u9879\u6280\u672f\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\uff0c\u66ff\u4ee3\u4e86\u7e41\u91cd\u7684\u4eba\u5de5\u5904\u7406\u5de5\u4f5c\u3002\u901a\u8fc7\u8bc4\u8bba\u5206\u6790\uff0c\u7535\u5546\u5e73\u53f0\u8fd8\u80fd\u8fc5\u901f\u83b7\u53d6\u5e02\u573a\u53cd\u9988\uff0c\u4e3a\u5546\u5bb6\u63d0\u4f9b\u6709\u9488\u5bf9\u6027\u7684\u6570\u636e\uff0c\u52a9\u529b\u5236\u5b9a\u7cbe\u51c6\u7684\u8fd0\u8425\u7b56\u7565\u3002 2 P-Tuning\u56de\u987e \u00b6 P-Tuning\uff08Pattern-Tuning\uff09\u662f\u4e00\u79cd\u8fde\u7eed\u7a7a\u95f4\u53ef\u5b66\u4e60\u6a21\u677f\uff0cPET\u7684\u76ee\u7684\u89e3\u51b3PET\u7684\u7f3a\u70b9\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u5411\u91cf\u4f5c\u4e3a\u4f2a\u6a21\u677f\uff0c\u4e0d\u518d\u624b\u52a8\u6784\u5efa\u6a21\u677f\u3002 \u4ee5\u65b0\u95fb\u5206\u7c7b\u4efb\u52a1\u4e3a\u4f8b\uff1a\u539f\u59cb\u6587\u672c\uff1a\u4e2d\u56fd\u5973\u6392\u518d\u593a\u51a0\uff01P-Tuning\u53ef\u5b66\u4e60\u6a21\u677f\uff1a[u1] [u2] \u2026[MASK]\u2026[un], Label\uff1a\u4f53\u80b2/\u8d22\u7ecf/\u65f6\u653f/\u519b\u4e8b P-Tuning\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff1a\u5c06\u6a21\u7248\uff08\u7528\u7279\u6b8a\u5b57\u7b26\u4ee3\u66ff\u81ea\u7136\u8bed\u8a00\uff0c\u7279\u6b8a\u5b57\u7b26\u53ef\u4ee5\u81ea\u7531\u5b66\u4e60\uff09\u4e0e\u539f\u59cb\u6587\u672c\u62fc\u5728\u4e00\u8d77\u8f93\u5165\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4f1a\u5bf9\u6a21\u677f\u4e2d\u7684mask\u505a\u9884\u6d4b\uff0c\u5f97\u5230\u4e00\u4e2alabel\u3002 P-Tuning\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u53ef\u5b66\u4e60\u6a21\u677f\u53c2\u6570\uff0c\u5168\u5c40\u4f18\u5316\u5b66\u4e60\u5230\u66f4\u597d\u7684\u6a21\u677f\u8868\u793a \u7f13\u89e3\u4eba\u5de5\u6a21\u677f\u5e26\u6765\u7684\u4e0d\u7a33\u5b9a\u6027 \u7f3a\u70b9\uff1a \u8d85\u591a\u5206\u7c7b\u4efb\u52a1\u573a\u666f\uff1a\u9884\u6d4b\u96be\u5ea6\u5927 \u8574\u542b\u4efb\u52a1\uff08\u7ed9\u5b9a\u4e24\u53e5\u8bdd\uff0c\u8ba9\u6a21\u578b\u5224\u65ad\u4e24\u53e5\u8bdd\u7684\u903b\u8f91\u5173\u7cfb\uff09\u7b49\u4e0d\u9002\u5408\u57fa\u4e8e\u6a21\u677f\u65b9\u5f0f\u89e3\u51b3 3 \u73af\u5883\u51c6\u5907 \u00b6 \u672c\u9879\u76ee\u57fa\u4e8e pytorch + transformers \u5b9e\u73b0\uff0c\u8fd0\u884c\u524d\u8bf7\u5b89\u88c5\u76f8\u5173\u4f9d\u8d56\u5305\uff1a torch transformers==4.22.1 datasets==2.4.0 evaluate==0.2.2 matplotlib==3.6.0 rich==12.5.1 scikit-learn==1.1.2 requests==2.28.1 4 \u9879\u76ee\u67b6\u6784 \u00b6 \u9879\u76ee\u67b6\u6784\u6d41\u7a0b\u56fe\uff1a \u9879\u76ee\u6574\u4f53\u4ee3\u7801\u4ecb\u7ecd\uff1a \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u660e\u786e\u4e86\u9879\u76ee\u7684\u6574\u4f53\u67b6\u6784\uff0c\u5e76\u5bf9\u9879\u76ee\u4e2d\u6574\u4f53\u4ee3\u7801\u7ed3\u6784\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002","title":"6.5 BERT+P-Tuning\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#bertp-tuning","text":"","title":"\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#_1","text":"\u7406\u89e3P-Tuning\u65b9\u5f0f\u7684\u601d\u60f3 \u4e86\u89e3\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u6574\u4f53\u9879\u76ee\u67b6\u6784","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#1","text":"\u6587\u672c\u662f\u4fe1\u606f\u4f20\u64ad\u7684\u91cd\u8981\u9014\u5f84\u548c\u8f7d\u4f53\uff0c\u5c06\u6587\u672c\u6570\u636e\u6b63\u786e\u5f52\u7c7b\uff0c\u4ece\u800c\u66f4\u597d\u5730\u7ec4\u7ec7\u3001\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\uff0c\u5177\u6709\u91cd\u8981\u7684\u7814\u7a76\u610f\u4e49\u3002\u6587\u672c\u5206\u7c7b\u81f4\u529b\u4e8e\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08Natural Language Processing\uff0cNLP\uff09\u9886\u57df\u7684\u7ecf\u5178\u4efb\u52a1\u4e4b\u4e00\uff0c\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u8206\u60c5\u76d1\u6d4b\u3001\u60c5\u611f\u5206\u6790\u7b49\u573a\u666f\u4e2d\u3002 \u76ee\u524d\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u65b9\u6cd5\u5f88\u591a\uff0c\u5982\u7ecf\u5178\u7684\u5e94\u7528\u4e8e\u6587\u672c\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08Text-CNN\uff09\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08Text-RNN)\u3001\u57fa\u4e8eBERT\u7b49\u9884\u8bad\u7ec3\u6a21\u578b\u7684fine-tuning\u7b49\uff0c\u4f46\u662f\u8fd9\u4e9b\u65b9\u6cd5\u591a\u4e3a\u5efa\u7acb\u5728\u5177\u6709\u5927\u91cf\u7684\u6807\u6ce8\u6570\u636e\u4e0b\u7684\u6709\u76d1\u7763\u5b66\u4e60\u3002\u5728\u5f88\u591a\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u9886\u57df\u7279\u6b8a\u6027\u548c\u6807\u6ce8\u6210\u672c\u9ad8\uff0c\u5bfc\u81f4\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\u7f3a\u4e4f\uff0c\u6a21\u578b\u65e0\u6cd5\u6709\u6548\u5730\u5b66\u4e60\u53c2\u6570\uff0c\u4ece\u800c\u6613\u51fa\u73b0\u8fc7\u62df\u5408\u73b0\u8c61\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u901a\u8fc7\u5c0f\u6837\u672c\u6570\u636e\u8bad\u7ec3\u5f97\u5230\u4e00\u4e2a\u6027\u80fd\u8f83\u597d\u7684\u5206\u7c7b\u6a21\u578b\u662f\u76ee\u524d\u7684\u7814\u7a76\u70ed\u70b9\u3002 \u672c\u7ae0\u6211\u4eec\u5c06\u4ee5\"\u7535\u5546\u5e73\u53f0\u7528\u6237\u8bc4\u8bba\"\u4e3a\u80cc\u666f\uff0c\u57fa\u4e8eBERT+P-Tuning\uff08\u8f6f\u6a21\u7248\uff09\u65b9\u6cd5\u5b9e\u73b0\u8bc4\u8bba\u6587\u672c\u7684\u51c6\u786e\u5206\u7c7b\uff0c\u8fd9\u6837\u505a\u7684\u76ee\u7684\u5728\u4e8e\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002\u901a\u8fc7\u6df1\u5165\u4e86\u89e3\u7528\u6237\u5bf9\u4e0d\u540c\u5546\u54c1\u6216\u670d\u52a1\u7684\u8bc4\u4ef7\uff0c\u5e73\u53f0\u80fd\u591f\u5feb\u901f\u56de\u5e94\u7528\u6237\u9700\u6c42\uff0c\u6539\u8fdb\u4ea7\u54c1\u548c\u670d\u52a1\u3002\u81ea\u52a8\u5206\u7c7b\u4e5f\u4e3a\u4e2a\u6027\u5316\u63a8\u8350\u5960\u5b9a\u57fa\u7840\uff0c\u5e2e\u52a9\u7528\u6237\u66f4\u8f7b\u677e\u5730\u627e\u5230\u7b26\u5408\u5176\u504f\u597d\u7684\u5546\u54c1\u3002\u540c\u65f6\uff0c\u8fd9\u9879\u6280\u672f\u964d\u4f4e\u4e86\u8fd0\u8425\u6210\u672c\uff0c\u66ff\u4ee3\u4e86\u7e41\u91cd\u7684\u4eba\u5de5\u5904\u7406\u5de5\u4f5c\u3002\u901a\u8fc7\u8bc4\u8bba\u5206\u6790\uff0c\u7535\u5546\u5e73\u53f0\u8fd8\u80fd\u8fc5\u901f\u83b7\u53d6\u5e02\u573a\u53cd\u9988\uff0c\u4e3a\u5546\u5bb6\u63d0\u4f9b\u6709\u9488\u5bf9\u6027\u7684\u6570\u636e\uff0c\u52a9\u529b\u5236\u5b9a\u7cbe\u51c6\u7684\u8fd0\u8425\u7b56\u7565\u3002","title":"1 \u9879\u76ee\u80cc\u666f"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#2-p-tuning","text":"P-Tuning\uff08Pattern-Tuning\uff09\u662f\u4e00\u79cd\u8fde\u7eed\u7a7a\u95f4\u53ef\u5b66\u4e60\u6a21\u677f\uff0cPET\u7684\u76ee\u7684\u89e3\u51b3PET\u7684\u7f3a\u70b9\uff0c\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u5411\u91cf\u4f5c\u4e3a\u4f2a\u6a21\u677f\uff0c\u4e0d\u518d\u624b\u52a8\u6784\u5efa\u6a21\u677f\u3002 \u4ee5\u65b0\u95fb\u5206\u7c7b\u4efb\u52a1\u4e3a\u4f8b\uff1a\u539f\u59cb\u6587\u672c\uff1a\u4e2d\u56fd\u5973\u6392\u518d\u593a\u51a0\uff01P-Tuning\u53ef\u5b66\u4e60\u6a21\u677f\uff1a[u1] [u2] \u2026[MASK]\u2026[un], Label\uff1a\u4f53\u80b2/\u8d22\u7ecf/\u65f6\u653f/\u519b\u4e8b P-Tuning\u7684\u5b9e\u73b0\u8fc7\u7a0b\uff1a\u5c06\u6a21\u7248\uff08\u7528\u7279\u6b8a\u5b57\u7b26\u4ee3\u66ff\u81ea\u7136\u8bed\u8a00\uff0c\u7279\u6b8a\u5b57\u7b26\u53ef\u4ee5\u81ea\u7531\u5b66\u4e60\uff09\u4e0e\u539f\u59cb\u6587\u672c\u62fc\u5728\u4e00\u8d77\u8f93\u5165\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u9884\u8bad\u7ec3\u6a21\u578b\u4f1a\u5bf9\u6a21\u677f\u4e2d\u7684mask\u505a\u9884\u6d4b\uff0c\u5f97\u5230\u4e00\u4e2alabel\u3002 P-Tuning\u7684\u7279\u70b9\uff1a \u4f18\u70b9\uff1a \u53ef\u5b66\u4e60\u6a21\u677f\u53c2\u6570\uff0c\u5168\u5c40\u4f18\u5316\u5b66\u4e60\u5230\u66f4\u597d\u7684\u6a21\u677f\u8868\u793a \u7f13\u89e3\u4eba\u5de5\u6a21\u677f\u5e26\u6765\u7684\u4e0d\u7a33\u5b9a\u6027 \u7f3a\u70b9\uff1a \u8d85\u591a\u5206\u7c7b\u4efb\u52a1\u573a\u666f\uff1a\u9884\u6d4b\u96be\u5ea6\u5927 \u8574\u542b\u4efb\u52a1\uff08\u7ed9\u5b9a\u4e24\u53e5\u8bdd\uff0c\u8ba9\u6a21\u578b\u5224\u65ad\u4e24\u53e5\u8bdd\u7684\u903b\u8f91\u5173\u7cfb\uff09\u7b49\u4e0d\u9002\u5408\u57fa\u4e8e\u6a21\u677f\u65b9\u5f0f\u89e3\u51b3","title":"2 P-Tuning\u56de\u987e"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#3","text":"\u672c\u9879\u76ee\u57fa\u4e8e pytorch + transformers \u5b9e\u73b0\uff0c\u8fd0\u884c\u524d\u8bf7\u5b89\u88c5\u76f8\u5173\u4f9d\u8d56\u5305\uff1a torch transformers==4.22.1 datasets==2.4.0 evaluate==0.2.2 matplotlib==3.6.0 rich==12.5.1 scikit-learn==1.1.2 requests==2.28.1","title":"3  \u73af\u5883\u51c6\u5907"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#4","text":"\u9879\u76ee\u67b6\u6784\u6d41\u7a0b\u56fe\uff1a \u9879\u76ee\u6574\u4f53\u4ee3\u7801\u4ecb\u7ecd\uff1a","title":"4 \u9879\u76ee\u67b6\u6784"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/05-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%8B%E7%BB%8D.html#_2","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u660e\u786e\u4e86\u9879\u76ee\u7684\u6574\u4f53\u67b6\u6784\uff0c\u5e76\u5bf9\u9879\u76ee\u4e2d\u6574\u4f53\u4ee3\u7801\u7ed3\u6784\u8fdb\u884c\u4e86\u4ecb\u7ecd\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html","text":"\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u672c\u9879\u76ee\u6570\u636e\u7c7b\u578b\u548c\u8868\u73b0\u683c\u5f0f \u638c\u63e1\u6570\u636e\u5904\u7406\u7684\u5de5\u5177\u51fd\u6570\u4ee3\u7801\u5b9e\u73b0 BERT+P-Tuning\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406 \u00b6 \u672c\u9879\u76ee\u4e2d\u5bf9\u6570\u636e\u90e8\u5206\u7684\u9884\u5904\u7406\u6b65\u9aa4\u5982\u4e0b: \u4e00\u3001\u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u4e8c\u3001\u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u4e09\u3001\u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801 \u4e00\u3001 \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u00b6 \u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b4\u4e2atxt\u6587\u6863\uff0c\u5206\u522b\u4e3a\uff1atrain.txt\u3001dev.txt\u3001verbalizer.txt 1.1 train.txt \u00b6 train.txt\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u6c34\u679c \u8106\u8106\u7684\uff0c\u751c\u5473\u53ef\u4ee5\uff0c\u53ef\u80fd\u65f6\u95f4\u6709\u70b9\u957f\u4e86\uff0c\u6c34\u5206\u4e0d\u662f\u5f88\u8db3\u3002 \u5e73\u677f \u534e\u4e3a\u673a\u5668\u80af\u5b9a\u4e0d\u9519\uff0c\u4f46\u7b2c\u4e00\u6b21\u78b0\u4e0a\u4eac\u4e1c\u6700\u7cdf\u7cd5\u7684\u670d\u52a1\uff0c\u4ee5\u540e\u4e0d\u60f3\u5230\u4eac\u4e1c\u8d2d\u7269\u4e86\u3002 \u4e66\u7c4d \u4e3a\u4ec0\u4e48\u4e0d\u8ba4\u771f\u7684\u68c0\u67e5\u4e00\u4e0b\uff0c \u53d1\u8fd9\u4e48\u4e00\u672c\u810f\u810f\u7684\u4e66\u7ed9\u987e\u5ba2\u5462\uff01 \u8863\u670d \u624b\u611f\u4e0d\u9519\uff0c\u7528\u6599\u4e5f\u5f88\u597d\uff0c\u4e0d\u77e5\u9053\u6c34\u6d17\u540e\u600e\u6837\uff0c\u76f8\u4fe1\u5927\u54c1\u724c\uff0c\u8d28\u91cf\u8fc7\u5173\uff0c\u4e94\u661f\u597d\u8bc4\uff01\uff01\uff01 \u6c34\u679c \u82f9\u679c\u6709\u70b9\u5c0f\uff0c\u4e0d\u8fc7\u597d\u5403\uff0c\u8fd8\u6709\u51e0\u4e2a\u70c2\u7684\u3002\u4f30\u8ba1\u662f\u6545\u610f\u7684\u653e\u7684\u3002\u5dee\u8bc4\u3002 \u8863\u670d \u6389\u8272\u6389\u7684\u5389\u5bb3\uff0c\u6d17\u4e00\u6b21\u5c31\u82b1\u4e86 train.txt\u4e00\u5171\u5305\u542b63\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002 1.2 dev.txt \u00b6 dev.txt\u4e3a\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u4e66\u7c4d \"\u4e00\u70b9\u90fd\u4e0d\u597d\u7b11,\u5f88\u5931\u671b,\u5185\u5bb9\u4e5f\u4e0d\u662f\u5f88\u5b9e\u7528\" \u8863\u670d \u5b8c\u5168\u662f\u4e00\u6761\u65e7\u88e4\u5b50\u3002 \u624b\u673a \u76f8\u673a\u8d28\u91cf\u4e0d\u9519\uff0c\u5982\u679c\u9633\u5149\u5145\u8db3\uff0c\u53ef\u4ee5\u548c\u6570\u7801\u76f8\u673a\u5ab2\u7f8e\uff0e\u754c\u9762\u6bd4\u8f83\u4eba\u6027\u5316\uff0c\u5bb9\u6613\u4f7f\u7528\uff0e\u8f6f\u4ef6\u5b89\u88c5\u7b80\u4fbf \u4e66\u7c4d \u660e\u660e\u8bf4\u6709\u8d27\uff0c\u7ed3\u679c\u9001\u8d27\u53c8\u6ca1\u6709\u4e86\u3002\u5e76\u4e14\u4e5f\u4e0d\u544a\u8bc9\u6211\uff0c\u600e\u4e48\u8bc4\u554a \u6d17\u6d74 \u975e\u5e38\u4e0d\u6ee1\u610f\uff0c\u665a\u4e0a\u6d17\u7684\u5934\u53d1\uff0c\u7b2c\u4e8c\u5929\u5934\u75d2\u75d2\u7684\u4e0d\u884c\u4e86\uff0c\u8fd8\u90fd\u662f\u5934\u76ae\u5c51\u3002 \u6c34\u679c \u8fd9\u4e2a\u82f9\u679c\u611f\u89c9\u662f\u957f\u719f\u7684\u82f9\u679c\uff0c\u6ca1\u6709\u6253\u8721\uff0c\u4e0d\u9519\uff0c\u53c8\u751c\u53c8\u8106 dev.txt\u4e00\u5171\u5305\u542b417\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002 1.3 verbalizer.txt \u00b6 verbalizer.txt \u4e3b\u8981\u7528\u4e8e\u5b9a\u4e49\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u5230\u300c\u6807\u7b7e\u9884\u6d4b\u8bcd\u300d\u4e4b\u95f4\u7684\u6620\u5c04\u3002\u5728\u6709\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5c06\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u4f5c\u4e3a [MASK] \u53bb\u9884\u6d4b\u53ef\u80fd\u4e0d\u5177\u5907\u5f88\u597d\u7684\u8bed\u4e49\u901a\u987a\u6027\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u4f1a\u5bf9\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u505a\u4e00\u5b9a\u7684\u6620\u5c04\u3002 \u4f8b\u5982\uff1a \"\u4e2d\u56fd\u7206\u51b72-1\u6218\u80dc\u97e9\u56fd\"\u662f\u4e00\u5219[MASK][MASK]\u65b0\u95fb\u3002 \u4f53\u80b2 \u8fd9\u53e5\u8bdd\u4e2d\u7684\u6807\u7b7e\u4e3a\u300c\u4f53\u80b2\u300d\uff0c\u4f46\u5982\u679c\u6211\u4eec\u5c06\u6807\u7b7e\u8bbe\u7f6e\u4e3a\u300c\u8db3\u7403\u300d\u4f1a\u66f4\u5bb9\u6613\u9884\u6d4b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u300c\u4f53\u80b2\u300d\u8fd9\u4e2a label \u6784\u5efa\u8bb8\u591a\u4e2a\u5b50\u6807\u7b7e\uff0c\u5728\u63a8\u7406\u65f6\uff0c\u53ea\u8981\u9884\u6d4b\u5230\u5b50\u6807\u7b7e\u6700\u7ec8\u63a8\u7406\u51fa\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\uff0c\u5982\u4e0b\uff1a \u4f53\u80b2 -> \u8db3\u7403,\u7bee\u7403,\u7f51\u7403,\u68d2\u7403,\u4e52\u4e53,\u4f53\u80b2 \u9879\u76ee\u4e2d\u6807\u7b7e\u8bcd\u6620\u5c04\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u7535\u8111 \u7535\u8111 \u6c34\u679c \u6c34\u679c \u5e73\u677f \u5e73\u677f \u8863\u670d \u8863\u670d \u9152\u5e97 \u9152\u5e97 \u6d17\u6d74 \u6d17\u6d74 \u4e66\u7c4d \u4e66\u7c4d \u8499\u725b \u8499\u725b \u624b\u673a \u624b\u673a \u7535\u5668 \u7535\u5668 verbalizer.txt \u4e00\u5171\u5305\u542b10\u4e2a\u7c7b\u522b\uff0c\u4e0a\u8ff0\u6570\u636e\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e861\u5bf91\u7684verbalizer, \u5982\u679c\u60f3\u5b9a\u4e49\u4e00\u5bf9\u591a\u7684\u6620\u5c04\uff0c\u53ea\u9700\u8981\u5728\u540e\u9762\u7528\",\"\u5206\u5272\u5373\u53ef\uff0c eg: \u6c34\u679c \u82f9\u679c,\u9999\u8549,\u6a58\u5b50 \u82e5\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6 \u4e8c\u3001 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/ptune_config.py config\u6587\u4ef6\u76ee\u7684\uff1a\u914d\u7f6e\u9879\u76ee\u5e38\u7528\u53d8\u91cf\uff0c\u4e00\u822c\u8fd9\u4e9b\u53d8\u91cf\u5c5e\u4e8e\u4e0d\u7ecf\u5e38\u6539\u53d8\u7684\uff0c\u6bd4\u5982\uff1a\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\u3001\u6a21\u578b\u8bad\u7ec3\u6b21\u6570\u3001\u6a21\u578b\u8d85\u53c2\u6570\u7b49\u7b49 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a # coding:utf-8 import torch class ProjectConfig ( object ): def __init__ ( self ): self . device = 'cuda:0' if torch . cuda . is_available () else 'cpu' self . pre_model = '/Users/**/llm/prompt_tasks/bert-base-chinese' self . train_path = '/Users/**/llm/prompt_tasks/P-Tuning/data/train.txt' self . dev_path = '/Users/**/llm/prompt_tasks/P-Tuning/data/dev.txt' self . verbalizer = '/Users/**/llm/prompt_tasks/P-Tuning/data/verbalizer.txt' self . max_seq_len = 512 self . batch_size = 8 self . learning_rate = 5e-5 self . weight_decay = 0 self . warmup_ratio = 0.06 self . p_embedding_num = 6 self . max_label_len = 2 self . epochs = 50 self . logging_steps = 10 self . valid_steps = 20 self . save_dir = '/Users/**/llm/prompt_tasks/P-Tuning/checkpoints' if __name__ == '__main__' : pc = ProjectConfig () print ( pc . verbalizer ) \u4e09 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801 \u00b6 \u4ee3\u7801\u8def\u5f84\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/P-Tuning/data_handle. data_handle\u6587\u4ef6\u5939\u4e2d\u4e00\u5171\u5305\u542b\u4e24\u4e2apy\u811a\u672c\uff1adata_preprocess.py\u3001data_loader.py 3.1 data_preprocess.py \u00b6 \u76ee\u7684: \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch import numpy as np from rich import print from datasets import load_dataset from transformers import AutoTokenizer import sys sys . path . append ( '..' ) from ptune_config import * from functools import partial \u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u65b9\u6cd5convert_example() \u76ee\u7684\uff1a\u5c06\u6a21\u677f\u4e0e\u539f\u59cb\u8f93\u5165\u6587\u672c\u8fdb\u884c\u62fc\u63a5\uff0c\u6784\u9020\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e def convert_example ( examples : dict , tokenizer , max_seq_len : int , max_label_len : int , p_embedding_num = 6 , train_mode = True , return_tensor = False ) -> dict : \"\"\" \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u6536\u7684\u8f93\u5165\u6570\u636e\u3002 Args: examples (dict): \u8bad\u7ec3\u6570\u636e\u6837\u672c, e.g. -> { \"text\": [ '\u5a31\u4e50 \u55e8\u653e\u6d3e\u600e\u4e48\u505c\u64ad\u4e86', '\u4f53\u80b2 \u4e16\u754c\u676f\u4e3a\u4f55\u8fdf\u8fdf\u4e0d\u89c1\u5ba3\u4f20', ... ] } max_label_len (int): \u6700\u5927label\u957f\u5ea6\uff0c\u82e5\u6ca1\u6709\u8fbe\u5230\u6700\u5927\u957f\u5ea6\uff0c\u5219padding\u4e3a\u6700\u5927\u957f\u5ea6 p_embedding_num (int): p-tuning token \u7684\u4e2a\u6570 train_mode (bool): \u8bad\u7ec3\u9636\u6bb5 or \u63a8\u7406\u9636\u6bb5\u3002 return_tensor (bool): \u662f\u5426\u8fd4\u56detensor\u7c7b\u578b\uff0c\u5982\u4e0d\u662f\uff0c\u5219\u8fd4\u56denumpy\u7c7b\u578b\u3002 Returns: dict (str: np.array) -> tokenized_output = { 'input_ids': [[101, 3928, ...], [101, 4395, ...]], 'token_type_ids': [[0, 0, ...], [0, 0, ...]], 'mask_positions': [[5, 6, ...], [3, 4, ...]], 'mask_labels': [[183, 234], [298, 322], ...] } \"\"\" tokenized_output = { 'input_ids' : [], 'attention_mask' : [], 'mask_positions' : [], # \u8bb0\u5f55label\u7684\u4f4d\u7f6e\uff08\u5373MASK Token\u7684\u4f4d\u7f6e\uff09 'mask_labels' : [] # \u8bb0\u5f55MASK Token\u7684\u539f\u59cb\u503c\uff08\u5373Label\u503c\uff09 } for i , example in enumerate ( examples [ 'text' ]): try : start_mask_position = 1 # \u5c06 prompt token(s) \u63d2\u5728 [CLS] \u4e4b\u540e if train_mode : label , content = example . strip () . split ( ' \\t ' ) else : content = example . strip () encoded_inputs = tokenizer ( text = content , truncation = True , max_length = max_seq_len , padding = 'max_length' ) except : continue input_ids = encoded_inputs [ 'input_ids' ] # 1.\u751f\u6210 MASK Tokens, \u548clabel\u957f\u5ea6\u4e00\u81f4 mask_tokens = [ '[MASK]' ] * max_label_len mask_ids = tokenizer . convert_tokens_to_ids ( mask_tokens ) # token \u8f6c id # 2.\u6784\u5efa prompt token(s) p_tokens = [ \"[unused {} ]\" . format ( i + 1 ) for i in range ( p_embedding_num )] p_tokens_ids = tokenizer . convert_tokens_to_ids ( p_tokens ) # token \u8f6c id tmp_input_ids = input_ids [: - 1 ] # \u6839\u636e\u6700\u5927\u957f\u5ea6-p_token\u957f\u5ea6-label\u957f\u5ea6\uff0c\u88c1\u526acontent\u7684\u957f\u5ea6 tmp_input_ids = tmp_input_ids [: max_seq_len - len ( mask_ids ) - len ( p_tokens_ids ) - 1 ] # 3.\u63d2\u5165 MASK -> [CLS][MASK][MASK]\u4e16\u754c\u676f...[SEP] tmp_input_ids = tmp_input_ids [: start_mask_position ] + mask_ids + tmp_input_ids [ start_mask_position :] input_ids = tmp_input_ids + [ input_ids [ - 1 ]] # \u8865\u4e0a[SEP] # 4.\u63d2\u5165 prompt -> [unused1][unused2]...[CLS][MASK]...[SEP] input_ids = p_tokens_ids + input_ids # \u5c06 Mask Tokens \u7684\u4f4d\u7f6e\u8bb0\u5f55\u4e0b\u6765 mask_positions = [ len ( p_tokens_ids ) + start_mask_position + i for i in range ( max_label_len )] tokenized_output [ 'input_ids' ] . append ( input_ids ) # \u517c\u5bb9\u4e0d\u9700\u8981 token_type_id \u7684\u6a21\u578b, e.g. Roberta-Base if 'token_type_ids' in encoded_inputs : tmp = encoded_inputs [ 'token_type_ids' ] if 'token_type_ids' not in tokenized_output : tokenized_output [ 'token_type_ids' ] = [ tmp ] else : tokenized_output [ 'token_type_ids' ] . append ( tmp ) tokenized_output [ 'attention_mask' ] . append ( encoded_inputs [ 'attention_mask' ]) tokenized_output [ 'mask_positions' ] . append ( mask_positions ) if train_mode : mask_labels = tokenizer ( text = label ) # label token \u8f6c id mask_labels = mask_labels [ 'input_ids' ][ 1 : - 1 ] # \u4e22\u6389[CLS]\u548c[SEP] mask_labels = mask_labels [: max_label_len ] # \u5c06 label \u8865\u5230\u6700\u957f mask_labels += [ tokenizer . pad_token_id ] * ( max_label_len - len ( mask_labels )) tokenized_output [ 'mask_labels' ] . append ( mask_labels ) for k , v in tokenized_output . items (): if return_tensor : tokenized_output [ k ] = torch . LongTensor ( v ) else : tokenized_output [ k ] = np . array ( v ) return tokenized_output if __name__ == '__main__' : pc = ProjectConfig () train_dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path }) # print(type(train_dataset)) # print(train_dataset) # print('*'*80) # print(train_dataset['train']['text']) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) tokenized_output = convert_example ( examples = train_dataset [ 'train' ], tokenizer = tokenizer , max_seq_len = 20 , max_label_len = 2 , p_embedding_num = 6 , train_mode = True , return_tensor = False ) print ( tokenized_output ) print ( type ( tokenized_output [ 'mask_positions' ])) \u6253\u5370\u7ed3\u679c\u5c55\u793a\uff1a { 'input_ids' : array ([[ 1 , 2 , 3 , ... , 1912 , 6225 , 102 ], [ 1 , 2 , 3 , ... , 3300 , 5741 , 102 ], [ 1 , 2 , 3 , ... , 6574 , 7030 , 0 ], ... , [ 1 , 2 , 3 , ... , 8024 , 2571 , 0 ], [ 1 , 2 , 3 , ... , 3221 , 3175 , 102 ], [ 1 , 2 , 3 , ... , 5277 , 3688 , 102 ]]), 'attention_mask' : array ([[ 1 , 1 , 1 , ... , 1 , 1 , 1 ], [ 1 , 1 , 1 , ... , 1 , 1 , 1 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], ... , [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 1 , 1 , 1 ], [ 1 , 1 , 1 , ... , 1 , 1 , 1 ]]), 'mask_positions' : array ([[ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], ... , [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ]]), 'mask_labels' : array ([[ 4510 , 5554 ], [ 3717 , 3362 ], [ 2398 , 3352 ], ... , [ 3819 , 3861 ], [ 6983 , 2421 ], [ 3819 , 3861 ]]), 'token_type_ids' : array ([[ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], ... , [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ]]) } 3.3 data_loader.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u52a0\u8f7d\u5668 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # coding:utf-8 from torch.utils.data import DataLoader from transformers import default_data_collator , AutoTokenizer from data_handle.data_preprocess import * from ptune_config import * pc = ProjectConfig () # \u5b9e\u4f8b\u5316\u9879\u76ee\u914d\u7f6e\u6587\u4ef6 tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) \u5b9a\u4e49\u83b7\u53d6\u6570\u636e\u52a0\u8f7d\u5668\u7684\u65b9\u6cd5get_data() def get_data (): dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path , 'dev' : pc . dev_path }) new_func = partial ( convert_example , tokenizer = tokenizer , max_seq_len = pc . max_seq_len , max_label_len = pc . max_label_len , p_embedding_num = pc . p_embedding_num ) dataset = dataset . map ( new_func , batched = True ) train_dataset = dataset [ \"train\" ] dev_dataset = dataset [ \"dev\" ] train_dataloader = DataLoader ( train_dataset , shuffle = True , collate_fn = default_data_collator , batch_size = pc . batch_size ) dev_dataloader = DataLoader ( dev_dataset , collate_fn = default_data_collator , batch_size = pc . batch_size ) return train_dataloader , dev_dataloader if __name__ == '__main__' : train_dataloader , dev_dataloader = get_data () print ( len ( train_dataloader )) print ( len ( dev_dataloader )) for i , value in enumerate ( train_dataloader ): print ( i ) print ( value ) print ( value [ 'input_ids' ] . dtype ) break \u6253\u5370\u7ed3\u679c\u5c55\u793a\uff1a { 'input_ids' : tensor ([[ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], ... , [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ]]), 'attention_mask' : tensor ([[ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], ... , [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ]]), 'mask_positions' : tensor ([[ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ]]), 'mask_labels' : tensor ([[ 6132 , 3302 ], [ 2398 , 3352 ], [ 6132 , 3302 ], [ 6983 , 2421 ], [ 3717 , 3362 ], [ 6983 , 2421 ], [ 3819 , 3861 ], [ 6983 , 2421 ]]), 'token_type_ids' : tensor ([[ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], ... , [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ]]) } torch . int64 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u65f6\u6570\u636e\u5904\u7406\u6b65\u9aa4\uff0c\u5e76\u4e14\u901a\u8fc7\u4ee3\u7801\u5b9e\u73b0\uff1a\u63d0\u793a\u6a21\u677f\u6570\u636e\u683c\u5f0f\u7684\u8f6c\u6362\uff0c\u6570\u636e\u52a0\u8f7d\u5668\u7684\u7f16\u7801\u7b49\u3002","title":"6.6 BERT+P-Tuning\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#bertp-tuning","text":"","title":"\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#_1","text":"\u4e86\u89e3\u672c\u9879\u76ee\u6570\u636e\u7c7b\u578b\u548c\u8868\u73b0\u683c\u5f0f \u638c\u63e1\u6570\u636e\u5904\u7406\u7684\u5de5\u5177\u51fd\u6570\u4ee3\u7801\u5b9e\u73b0","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#bertp-tuning_1","text":"\u672c\u9879\u76ee\u4e2d\u5bf9\u6570\u636e\u90e8\u5206\u7684\u9884\u5904\u7406\u6b65\u9aa4\u5982\u4e0b: \u4e00\u3001\u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6 \u4e8c\u3001\u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801 \u4e09\u3001\u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801","title":"BERT+P-Tuning\u65b9\u5f0f\u6570\u636e\u9884\u5904\u7406"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#_2","text":"\u6570\u636e\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/data data\u6587\u4ef6\u5939\u91cc\u9762\u5305\u542b4\u4e2atxt\u6587\u6863\uff0c\u5206\u522b\u4e3a\uff1atrain.txt\u3001dev.txt\u3001verbalizer.txt","title":"\u4e00\u3001 \u67e5\u770b\u9879\u76ee\u6570\u636e\u96c6"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#11-traintxt","text":"train.txt\u4e3a\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u6c34\u679c \u8106\u8106\u7684\uff0c\u751c\u5473\u53ef\u4ee5\uff0c\u53ef\u80fd\u65f6\u95f4\u6709\u70b9\u957f\u4e86\uff0c\u6c34\u5206\u4e0d\u662f\u5f88\u8db3\u3002 \u5e73\u677f \u534e\u4e3a\u673a\u5668\u80af\u5b9a\u4e0d\u9519\uff0c\u4f46\u7b2c\u4e00\u6b21\u78b0\u4e0a\u4eac\u4e1c\u6700\u7cdf\u7cd5\u7684\u670d\u52a1\uff0c\u4ee5\u540e\u4e0d\u60f3\u5230\u4eac\u4e1c\u8d2d\u7269\u4e86\u3002 \u4e66\u7c4d \u4e3a\u4ec0\u4e48\u4e0d\u8ba4\u771f\u7684\u68c0\u67e5\u4e00\u4e0b\uff0c \u53d1\u8fd9\u4e48\u4e00\u672c\u810f\u810f\u7684\u4e66\u7ed9\u987e\u5ba2\u5462\uff01 \u8863\u670d \u624b\u611f\u4e0d\u9519\uff0c\u7528\u6599\u4e5f\u5f88\u597d\uff0c\u4e0d\u77e5\u9053\u6c34\u6d17\u540e\u600e\u6837\uff0c\u76f8\u4fe1\u5927\u54c1\u724c\uff0c\u8d28\u91cf\u8fc7\u5173\uff0c\u4e94\u661f\u597d\u8bc4\uff01\uff01\uff01 \u6c34\u679c \u82f9\u679c\u6709\u70b9\u5c0f\uff0c\u4e0d\u8fc7\u597d\u5403\uff0c\u8fd8\u6709\u51e0\u4e2a\u70c2\u7684\u3002\u4f30\u8ba1\u662f\u6545\u610f\u7684\u653e\u7684\u3002\u5dee\u8bc4\u3002 \u8863\u670d \u6389\u8272\u6389\u7684\u5389\u5bb3\uff0c\u6d17\u4e00\u6b21\u5c31\u82b1\u4e86 train.txt\u4e00\u5171\u5305\u542b63\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002","title":"1.1 train.txt"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#12-devtxt","text":"dev.txt\u4e3a\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u5176\u90e8\u5206\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u4e66\u7c4d \"\u4e00\u70b9\u90fd\u4e0d\u597d\u7b11,\u5f88\u5931\u671b,\u5185\u5bb9\u4e5f\u4e0d\u662f\u5f88\u5b9e\u7528\" \u8863\u670d \u5b8c\u5168\u662f\u4e00\u6761\u65e7\u88e4\u5b50\u3002 \u624b\u673a \u76f8\u673a\u8d28\u91cf\u4e0d\u9519\uff0c\u5982\u679c\u9633\u5149\u5145\u8db3\uff0c\u53ef\u4ee5\u548c\u6570\u7801\u76f8\u673a\u5ab2\u7f8e\uff0e\u754c\u9762\u6bd4\u8f83\u4eba\u6027\u5316\uff0c\u5bb9\u6613\u4f7f\u7528\uff0e\u8f6f\u4ef6\u5b89\u88c5\u7b80\u4fbf \u4e66\u7c4d \u660e\u660e\u8bf4\u6709\u8d27\uff0c\u7ed3\u679c\u9001\u8d27\u53c8\u6ca1\u6709\u4e86\u3002\u5e76\u4e14\u4e5f\u4e0d\u544a\u8bc9\u6211\uff0c\u600e\u4e48\u8bc4\u554a \u6d17\u6d74 \u975e\u5e38\u4e0d\u6ee1\u610f\uff0c\u665a\u4e0a\u6d17\u7684\u5934\u53d1\uff0c\u7b2c\u4e8c\u5929\u5934\u75d2\u75d2\u7684\u4e0d\u884c\u4e86\uff0c\u8fd8\u90fd\u662f\u5934\u76ae\u5c51\u3002 \u6c34\u679c \u8fd9\u4e2a\u82f9\u679c\u611f\u89c9\u662f\u957f\u719f\u7684\u82f9\u679c\uff0c\u6ca1\u6709\u6253\u8721\uff0c\u4e0d\u9519\uff0c\u53c8\u751c\u53c8\u8106 dev.txt\u4e00\u5171\u5305\u542b417\u6761\u6837\u672c\u6570\u636e\uff0c\u6bcf\u4e00\u884c\u7528 \\t \u5206\u5f00\uff0c\u524d\u534a\u90e8\u5206\u4e3a\u6807\u7b7e(label)\uff0c\u540e\u534a\u90e8\u5206\u4e3a\u539f\u59cb\u8f93\u5165 (\u7528\u6237\u8bc4\u8bba)\u3002 \u5982\u679c\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u4e0a\u8ff0\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6\u5373\u53ef\u3002","title":"1.2 dev.txt"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#13-verbalizertxt","text":"verbalizer.txt \u4e3b\u8981\u7528\u4e8e\u5b9a\u4e49\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u5230\u300c\u6807\u7b7e\u9884\u6d4b\u8bcd\u300d\u4e4b\u95f4\u7684\u6620\u5c04\u3002\u5728\u6709\u4e9b\u60c5\u51b5\u4e0b\uff0c\u5c06\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u4f5c\u4e3a [MASK] \u53bb\u9884\u6d4b\u53ef\u80fd\u4e0d\u5177\u5907\u5f88\u597d\u7684\u8bed\u4e49\u901a\u987a\u6027\uff0c\u56e0\u6b64\uff0c\u6211\u4eec\u4f1a\u5bf9\u300c\u771f\u5b9e\u6807\u7b7e\u300d\u505a\u4e00\u5b9a\u7684\u6620\u5c04\u3002 \u4f8b\u5982\uff1a \"\u4e2d\u56fd\u7206\u51b72-1\u6218\u80dc\u97e9\u56fd\"\u662f\u4e00\u5219[MASK][MASK]\u65b0\u95fb\u3002 \u4f53\u80b2 \u8fd9\u53e5\u8bdd\u4e2d\u7684\u6807\u7b7e\u4e3a\u300c\u4f53\u80b2\u300d\uff0c\u4f46\u5982\u679c\u6211\u4eec\u5c06\u6807\u7b7e\u8bbe\u7f6e\u4e3a\u300c\u8db3\u7403\u300d\u4f1a\u66f4\u5bb9\u6613\u9884\u6d4b\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u5bf9\u300c\u4f53\u80b2\u300d\u8fd9\u4e2a label \u6784\u5efa\u8bb8\u591a\u4e2a\u5b50\u6807\u7b7e\uff0c\u5728\u63a8\u7406\u65f6\uff0c\u53ea\u8981\u9884\u6d4b\u5230\u5b50\u6807\u7b7e\u6700\u7ec8\u63a8\u7406\u51fa\u771f\u5b9e\u6807\u7b7e\u5373\u53ef\uff0c\u5982\u4e0b\uff1a \u4f53\u80b2 -> \u8db3\u7403,\u7bee\u7403,\u7f51\u7403,\u68d2\u7403,\u4e52\u4e53,\u4f53\u80b2 \u9879\u76ee\u4e2d\u6807\u7b7e\u8bcd\u6620\u5c04\u6570\u636e\u5c55\u793a\u5982\u4e0b\uff1a \u7535\u8111 \u7535\u8111 \u6c34\u679c \u6c34\u679c \u5e73\u677f \u5e73\u677f \u8863\u670d \u8863\u670d \u9152\u5e97 \u9152\u5e97 \u6d17\u6d74 \u6d17\u6d74 \u4e66\u7c4d \u4e66\u7c4d \u8499\u725b \u8499\u725b \u624b\u673a \u624b\u673a \u7535\u5668 \u7535\u5668 verbalizer.txt \u4e00\u5171\u5305\u542b10\u4e2a\u7c7b\u522b\uff0c\u4e0a\u8ff0\u6570\u636e\u4e2d\uff0c\u6211\u4eec\u4f7f\u7528\u4e861\u5bf91\u7684verbalizer, \u5982\u679c\u60f3\u5b9a\u4e49\u4e00\u5bf9\u591a\u7684\u6620\u5c04\uff0c\u53ea\u9700\u8981\u5728\u540e\u9762\u7528\",\"\u5206\u5272\u5373\u53ef\uff0c eg: \u6c34\u679c \u82f9\u679c,\u9999\u8549,\u6a58\u5b50 \u82e5\u60f3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u8bad\u7ec3\uff0c\u53ea\u9700\u8981\u4eff\u7167\u793a\u4f8b\u6570\u636e\u6784\u5efa\u6570\u636e\u96c6","title":"1.3 verbalizer.txt"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#config","text":"\u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/ptune_config.py config\u6587\u4ef6\u76ee\u7684\uff1a\u914d\u7f6e\u9879\u76ee\u5e38\u7528\u53d8\u91cf\uff0c\u4e00\u822c\u8fd9\u4e9b\u53d8\u91cf\u5c5e\u4e8e\u4e0d\u7ecf\u5e38\u6539\u53d8\u7684\uff0c\u6bd4\u5982\uff1a\u8bad\u7ec3\u6587\u4ef6\u8def\u5f84\u3001\u6a21\u578b\u8bad\u7ec3\u6b21\u6570\u3001\u6a21\u578b\u8d85\u53c2\u6570\u7b49\u7b49 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a # coding:utf-8 import torch class ProjectConfig ( object ): def __init__ ( self ): self . device = 'cuda:0' if torch . cuda . is_available () else 'cpu' self . pre_model = '/Users/**/llm/prompt_tasks/bert-base-chinese' self . train_path = '/Users/**/llm/prompt_tasks/P-Tuning/data/train.txt' self . dev_path = '/Users/**/llm/prompt_tasks/P-Tuning/data/dev.txt' self . verbalizer = '/Users/**/llm/prompt_tasks/P-Tuning/data/verbalizer.txt' self . max_seq_len = 512 self . batch_size = 8 self . learning_rate = 5e-5 self . weight_decay = 0 self . warmup_ratio = 0.06 self . p_embedding_num = 6 self . max_label_len = 2 self . epochs = 50 self . logging_steps = 10 self . valid_steps = 20 self . save_dir = '/Users/**/llm/prompt_tasks/P-Tuning/checkpoints' if __name__ == '__main__' : pc = ProjectConfig () print ( pc . verbalizer )","title":"\u4e8c\u3001 \u7f16\u5199Config\u7c7b\u9879\u76ee\u6587\u4ef6\u914d\u7f6e\u4ee3\u7801"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#_3","text":"\u4ee3\u7801\u8def\u5f84\uff1a/Users/***/PycharmProjects/llm/prompt_tasks/P-Tuning/data_handle. data_handle\u6587\u4ef6\u5939\u4e2d\u4e00\u5171\u5305\u542b\u4e24\u4e2apy\u811a\u672c\uff1adata_preprocess.py\u3001data_loader.py","title":"\u4e09 \u7f16\u5199\u6570\u636e\u5904\u7406\u76f8\u5173\u4ee3\u7801"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#31-data_preprocesspy","text":"\u76ee\u7684: \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch import numpy as np from rich import print from datasets import load_dataset from transformers import AutoTokenizer import sys sys . path . append ( '..' ) from ptune_config import * from functools import partial \u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u65b9\u6cd5convert_example() \u76ee\u7684\uff1a\u5c06\u6a21\u677f\u4e0e\u539f\u59cb\u8f93\u5165\u6587\u672c\u8fdb\u884c\u62fc\u63a5\uff0c\u6784\u9020\u6a21\u578b\u63a5\u53d7\u7684\u8f93\u5165\u6570\u636e def convert_example ( examples : dict , tokenizer , max_seq_len : int , max_label_len : int , p_embedding_num = 6 , train_mode = True , return_tensor = False ) -> dict : \"\"\" \u5c06\u6837\u672c\u6570\u636e\u8f6c\u6362\u4e3a\u6a21\u578b\u63a5\u6536\u7684\u8f93\u5165\u6570\u636e\u3002 Args: examples (dict): \u8bad\u7ec3\u6570\u636e\u6837\u672c, e.g. -> { \"text\": [ '\u5a31\u4e50 \u55e8\u653e\u6d3e\u600e\u4e48\u505c\u64ad\u4e86', '\u4f53\u80b2 \u4e16\u754c\u676f\u4e3a\u4f55\u8fdf\u8fdf\u4e0d\u89c1\u5ba3\u4f20', ... ] } max_label_len (int): \u6700\u5927label\u957f\u5ea6\uff0c\u82e5\u6ca1\u6709\u8fbe\u5230\u6700\u5927\u957f\u5ea6\uff0c\u5219padding\u4e3a\u6700\u5927\u957f\u5ea6 p_embedding_num (int): p-tuning token \u7684\u4e2a\u6570 train_mode (bool): \u8bad\u7ec3\u9636\u6bb5 or \u63a8\u7406\u9636\u6bb5\u3002 return_tensor (bool): \u662f\u5426\u8fd4\u56detensor\u7c7b\u578b\uff0c\u5982\u4e0d\u662f\uff0c\u5219\u8fd4\u56denumpy\u7c7b\u578b\u3002 Returns: dict (str: np.array) -> tokenized_output = { 'input_ids': [[101, 3928, ...], [101, 4395, ...]], 'token_type_ids': [[0, 0, ...], [0, 0, ...]], 'mask_positions': [[5, 6, ...], [3, 4, ...]], 'mask_labels': [[183, 234], [298, 322], ...] } \"\"\" tokenized_output = { 'input_ids' : [], 'attention_mask' : [], 'mask_positions' : [], # \u8bb0\u5f55label\u7684\u4f4d\u7f6e\uff08\u5373MASK Token\u7684\u4f4d\u7f6e\uff09 'mask_labels' : [] # \u8bb0\u5f55MASK Token\u7684\u539f\u59cb\u503c\uff08\u5373Label\u503c\uff09 } for i , example in enumerate ( examples [ 'text' ]): try : start_mask_position = 1 # \u5c06 prompt token(s) \u63d2\u5728 [CLS] \u4e4b\u540e if train_mode : label , content = example . strip () . split ( ' \\t ' ) else : content = example . strip () encoded_inputs = tokenizer ( text = content , truncation = True , max_length = max_seq_len , padding = 'max_length' ) except : continue input_ids = encoded_inputs [ 'input_ids' ] # 1.\u751f\u6210 MASK Tokens, \u548clabel\u957f\u5ea6\u4e00\u81f4 mask_tokens = [ '[MASK]' ] * max_label_len mask_ids = tokenizer . convert_tokens_to_ids ( mask_tokens ) # token \u8f6c id # 2.\u6784\u5efa prompt token(s) p_tokens = [ \"[unused {} ]\" . format ( i + 1 ) for i in range ( p_embedding_num )] p_tokens_ids = tokenizer . convert_tokens_to_ids ( p_tokens ) # token \u8f6c id tmp_input_ids = input_ids [: - 1 ] # \u6839\u636e\u6700\u5927\u957f\u5ea6-p_token\u957f\u5ea6-label\u957f\u5ea6\uff0c\u88c1\u526acontent\u7684\u957f\u5ea6 tmp_input_ids = tmp_input_ids [: max_seq_len - len ( mask_ids ) - len ( p_tokens_ids ) - 1 ] # 3.\u63d2\u5165 MASK -> [CLS][MASK][MASK]\u4e16\u754c\u676f...[SEP] tmp_input_ids = tmp_input_ids [: start_mask_position ] + mask_ids + tmp_input_ids [ start_mask_position :] input_ids = tmp_input_ids + [ input_ids [ - 1 ]] # \u8865\u4e0a[SEP] # 4.\u63d2\u5165 prompt -> [unused1][unused2]...[CLS][MASK]...[SEP] input_ids = p_tokens_ids + input_ids # \u5c06 Mask Tokens \u7684\u4f4d\u7f6e\u8bb0\u5f55\u4e0b\u6765 mask_positions = [ len ( p_tokens_ids ) + start_mask_position + i for i in range ( max_label_len )] tokenized_output [ 'input_ids' ] . append ( input_ids ) # \u517c\u5bb9\u4e0d\u9700\u8981 token_type_id \u7684\u6a21\u578b, e.g. Roberta-Base if 'token_type_ids' in encoded_inputs : tmp = encoded_inputs [ 'token_type_ids' ] if 'token_type_ids' not in tokenized_output : tokenized_output [ 'token_type_ids' ] = [ tmp ] else : tokenized_output [ 'token_type_ids' ] . append ( tmp ) tokenized_output [ 'attention_mask' ] . append ( encoded_inputs [ 'attention_mask' ]) tokenized_output [ 'mask_positions' ] . append ( mask_positions ) if train_mode : mask_labels = tokenizer ( text = label ) # label token \u8f6c id mask_labels = mask_labels [ 'input_ids' ][ 1 : - 1 ] # \u4e22\u6389[CLS]\u548c[SEP] mask_labels = mask_labels [: max_label_len ] # \u5c06 label \u8865\u5230\u6700\u957f mask_labels += [ tokenizer . pad_token_id ] * ( max_label_len - len ( mask_labels )) tokenized_output [ 'mask_labels' ] . append ( mask_labels ) for k , v in tokenized_output . items (): if return_tensor : tokenized_output [ k ] = torch . LongTensor ( v ) else : tokenized_output [ k ] = np . array ( v ) return tokenized_output if __name__ == '__main__' : pc = ProjectConfig () train_dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path }) # print(type(train_dataset)) # print(train_dataset) # print('*'*80) # print(train_dataset['train']['text']) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) tokenized_output = convert_example ( examples = train_dataset [ 'train' ], tokenizer = tokenizer , max_seq_len = 20 , max_label_len = 2 , p_embedding_num = 6 , train_mode = True , return_tensor = False ) print ( tokenized_output ) print ( type ( tokenized_output [ 'mask_positions' ])) \u6253\u5370\u7ed3\u679c\u5c55\u793a\uff1a { 'input_ids' : array ([[ 1 , 2 , 3 , ... , 1912 , 6225 , 102 ], [ 1 , 2 , 3 , ... , 3300 , 5741 , 102 ], [ 1 , 2 , 3 , ... , 6574 , 7030 , 0 ], ... , [ 1 , 2 , 3 , ... , 8024 , 2571 , 0 ], [ 1 , 2 , 3 , ... , 3221 , 3175 , 102 ], [ 1 , 2 , 3 , ... , 5277 , 3688 , 102 ]]), 'attention_mask' : array ([[ 1 , 1 , 1 , ... , 1 , 1 , 1 ], [ 1 , 1 , 1 , ... , 1 , 1 , 1 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], ... , [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 1 , 1 , 1 ], [ 1 , 1 , 1 , ... , 1 , 1 , 1 ]]), 'mask_positions' : array ([[ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], ... , [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ]]), 'mask_labels' : array ([[ 4510 , 5554 ], [ 3717 , 3362 ], [ 2398 , 3352 ], ... , [ 3819 , 3861 ], [ 6983 , 2421 ], [ 3819 , 3861 ]]), 'token_type_ids' : array ([[ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], ... , [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ]]) }","title":"3.1 data_preprocess.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#33-data_loaderpy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u6570\u636e\u52a0\u8f7d\u5668 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # coding:utf-8 from torch.utils.data import DataLoader from transformers import default_data_collator , AutoTokenizer from data_handle.data_preprocess import * from ptune_config import * pc = ProjectConfig () # \u5b9e\u4f8b\u5316\u9879\u76ee\u914d\u7f6e\u6587\u4ef6 tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) \u5b9a\u4e49\u83b7\u53d6\u6570\u636e\u52a0\u8f7d\u5668\u7684\u65b9\u6cd5get_data() def get_data (): dataset = load_dataset ( 'text' , data_files = { 'train' : pc . train_path , 'dev' : pc . dev_path }) new_func = partial ( convert_example , tokenizer = tokenizer , max_seq_len = pc . max_seq_len , max_label_len = pc . max_label_len , p_embedding_num = pc . p_embedding_num ) dataset = dataset . map ( new_func , batched = True ) train_dataset = dataset [ \"train\" ] dev_dataset = dataset [ \"dev\" ] train_dataloader = DataLoader ( train_dataset , shuffle = True , collate_fn = default_data_collator , batch_size = pc . batch_size ) dev_dataloader = DataLoader ( dev_dataset , collate_fn = default_data_collator , batch_size = pc . batch_size ) return train_dataloader , dev_dataloader if __name__ == '__main__' : train_dataloader , dev_dataloader = get_data () print ( len ( train_dataloader )) print ( len ( dev_dataloader )) for i , value in enumerate ( train_dataloader ): print ( i ) print ( value ) print ( value [ 'input_ids' ] . dtype ) break \u6253\u5370\u7ed3\u679c\u5c55\u793a\uff1a { 'input_ids' : tensor ([[ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], ... , [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ], [ 1 , 2 , 3 , ... , 0 , 0 , 0 ]]), 'attention_mask' : tensor ([[ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], ... , [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ], [ 1 , 1 , 1 , ... , 0 , 0 , 0 ]]), 'mask_positions' : tensor ([[ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ], [ 7 , 8 ]]), 'mask_labels' : tensor ([[ 6132 , 3302 ], [ 2398 , 3352 ], [ 6132 , 3302 ], [ 6983 , 2421 ], [ 3717 , 3362 ], [ 6983 , 2421 ], [ 3819 , 3861 ], [ 6983 , 2421 ]]), 'token_type_ids' : tensor ([[ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], ... , [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ], [ 0 , 0 , 0 , ... , 0 , 0 , 0 ]]) } torch . int64","title":"3.3 data_loader.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/06-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BB%8B%E7%BB%8D.html#_4","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u65f6\u6570\u636e\u5904\u7406\u6b65\u9aa4\uff0c\u5e76\u4e14\u901a\u8fc7\u4ee3\u7801\u5b9e\u73b0\uff1a\u63d0\u793a\u6a21\u677f\u6570\u636e\u683c\u5f0f\u7684\u8f6c\u6362\uff0c\u6570\u636e\u52a0\u8f7d\u5668\u7684\u7f16\u7801\u7b49\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html","text":"\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u6a21\u578b\u642d\u5efa \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6a21\u578b\u642d\u5efa\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u6a21\u578b\u7684\u8bad\u7ec3,\u9a8c\u8bc1\u53ca\u76f8\u5173\u5de5\u5177\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0. \u6a21\u578b\u642d\u5efa \u00b6 \u672c\u9879\u76ee\u4e2d\u5b8c\u6210BERT+P-Tuning\u6a21\u578b\u642d\u5efa\u3001\u8bad\u7ec3\u53ca\u5e94\u7528\u7684\u6b65\u9aa4\u5982\u4e0b\uff08\u6ce8\u610f\uff1a\u56e0\u4e3a\u672c\u9879\u76ee\u4e2d\u4f7f\u7528\u7684\u662fBERT\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6240\u4ee5\u76f4\u63a5\u52a0\u8f7d\u5373\u53ef\uff0c\u65e0\u9700\u91cd\u590d\u642d\u5efa\u6a21\u578b\u67b6\u6784\uff09: \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570 \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u6a21\u578b\u5728\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u9884\u6d4b\u65f6\u9700\u8981\u7684\u51fd\u6570 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/utils utils\u6587\u4ef6\u5939\u5171\u5305\u542b3\u4e2apy\u811a\u672c\uff1averbalizer.py\u3001metirc_utils.py\u4ee5\u53cacommon_utils.py 1.1 verbalizer.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u4e00\u4e2aVerbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # -*- coding:utf-8 -*- import os from typing import Union , List from ptune_config import * pc = ProjectConfig () \u5177\u4f53\u5b9e\u73b0\u4ee3\u7801 class Verbalizer ( object ): \"\"\" Verbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \"\"\" def __init__ ( self , verbalizer_file : str , tokenizer , max_label_len : int ): \"\"\" Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 tokenizer: \u5206\u8bcd\u5668\uff0c\u7528\u4e8e\u6587\u672c\u548cid\u4e4b\u95f4\u7684\u8f6c\u6362\u3002 max_label_len (int): \u6807\u7b7e\u957f\u5ea6\uff0c\u82e5\u5927\u4e8e\u5219\u622a\u65ad\uff0c\u82e5\u5c0f\u4e8e\u5219\u8865\u9f50 \"\"\" self . tokenizer = tokenizer self . label_dict = self . load_label_dict ( verbalizer_file ) self . max_label_len = max_label_len def load_label_dict ( self , verbalizer_file : str ): \"\"\" \u8bfb\u53d6\u672c\u5730\u6587\u4ef6\uff0c\u6784\u5efaverbalizer\u5b57\u5178\u3002 Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 Returns: dict -> { '\u4f53\u80b2': ['\u7bee\u7403', '\u8db3\u7403','\u7f51\u7403', '\u6392\u7403', ...], '\u9152\u5e97': ['\u5bbe\u9986', '\u65c5\u9986', '\u65c5\u5e97', '\u9152\u5e97', ...], ... } \"\"\" label_dict = {} with open ( verbalizer_file , 'r' , encoding = 'utf8' ) as f : for line in f . readlines (): label , sub_labels = line . strip () . split ( ' \\t ' ) label_dict [ label ] = list ( set ( sub_labels . split ( ',' ))) return label_dict def find_sub_labels ( self , label : Union [ list , str ]): \"\"\" \u901a\u8fc7\u6807\u7b7e\u627e\u5230\u5bf9\u5e94\u6240\u6709\u7684\u5b50\u6807\u7b7e\u3002 Args: label (Union[list, str]): \u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u4f53\u80b2' or [860, 5509] Returns: dict -> { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] } \"\"\" if type ( label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8fdb\u884c\u6587\u672c\u8f6c\u6362 while self . tokenizer . pad_token_id in label : label . remove ( self . tokenizer . pad_token_id ) label = '' . join ( self . tokenizer . convert_ids_to_tokens ( label )) # print(f'label-->{label}') if label not in self . label_dict : raise ValueError ( f 'Lable Error: \" { label } \" not in label_dict' ) sub_labels = self . label_dict [ label ] ret = { 'sub_labels' : sub_labels } token_ids = [ _id [ 1 : - 1 ] for _id in self . tokenizer ( sub_labels )[ 'input_ids' ]] # print(f'token_ids-->{token_ids}') for i in range ( len ( token_ids )): token_ids [ i ] = token_ids [ i ][: self . max_label_len ] # \u5bf9\u6807\u7b7e\u8fdb\u884c\u622a\u65ad\u4e0e\u8865\u9f50 if len ( token_ids [ i ]) < self . max_label_len : token_ids [ i ] = token_ids [ i ] + [ self . tokenizer . pad_token_id ] * ( self . max_label_len - len ( token_ids [ i ])) ret [ 'token_ids' ] = token_ids return ret def batch_find_sub_labels ( self , label : List [ Union [ list , str ]]): \"\"\" \u6279\u91cf\u627e\u5230\u5b50\u6807\u7b7e\u3002 Args: label (List[list, str]): \u6807\u7b7e\u5217\u8868, [[4510, 5554], [860, 5509]] or ['\u4f53\u80b2', '\u7535\u8111'] Returns: list -> [ { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] }, ... ] \"\"\" return [ self . find_sub_labels ( l ) for l in label ] def get_common_sub_str ( self , str1 : str , str2 : str ): \"\"\" \u5bfb\u627e\u6700\u5927\u516c\u5171\u5b50\u4e32\u3002 str1:abcd str2:abadbcdba \"\"\" lstr1 , lstr2 = len ( str1 ), len ( str2 ) # \u751f\u62100\u77e9\u9635\uff0c\u4e3a\u65b9\u4fbf\u540e\u7eed\u8ba1\u7b97\uff0c\u6bd4\u5b57\u7b26\u4e32\u957f\u5ea6\u591a\u4e86\u4e00\u5217 record = [[ 0 for i in range ( lstr2 + 1 )] for j in range ( lstr1 + 1 )] p = 0 # \u6700\u957f\u5339\u914d\u5bf9\u5e94\u5728str1\u4e2d\u7684\u6700\u540e\u4e00\u4f4d maxNum = 0 # \u6700\u957f\u5339\u914d\u957f\u5ea6 for i in range ( lstr1 ): for j in range ( lstr2 ): if str1 [ i ] == str2 [ j ]: record [ i + 1 ][ j + 1 ] = record [ i ][ j ] + 1 if record [ i + 1 ][ j + 1 ] > maxNum : maxNum = record [ i + 1 ][ j + 1 ] p = i + 1 return str1 [ p - maxNum : p ], maxNum def hard_mapping ( self , sub_label : str ): \"\"\" \u5f3a\u5339\u914d\u51fd\u6570\uff0c\u5f53\u6a21\u578b\u751f\u6210\u7684\u5b50label\u4e0d\u5b58\u5728\u65f6\uff0c\u901a\u8fc7\u6700\u5927\u516c\u5171\u5b50\u4e32\u627e\u5230\u91cd\u5408\u5ea6\u6700\u9ad8\u7684\u4e3blabel\u3002 Args: sub_label (str): \u5b50label\u3002 Returns: str: \u4e3blabel\u3002 \"\"\" label , max_overlap_str = '' , 0 # print(self.label_dict.items()) for main_label , sub_labels in self . label_dict . items (): overlap_num = 0 for s_label in sub_labels : # \u6c42\u6240\u6709\u5b50label\u4e0e\u5f53\u524d\u63a8\u7406label\u4e4b\u95f4\u7684\u6700\u957f\u516c\u5171\u5b50\u4e32\u957f\u5ea6 overlap_num += self . get_common_sub_str ( sub_label , s_label )[ 1 ] if overlap_num >= max_overlap_str : max_overlap_str = overlap_num label = main_label return label def find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u5230\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u82f9\u679c' or [5741, 3362] hard_mapping (bool): \u5f53\u751f\u6210\u7684\u8bcd\u8bed\u4e0d\u5b58\u5728\u65f6\uff0c\u662f\u5426\u4e00\u5b9a\u8981\u5339\u914d\u5230\u4e00\u4e2a\u6700\u76f8\u4f3c\u7684label\u3002 Returns: dict -> { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] } \"\"\" if type ( sub_label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8f6c\u56de\u6765 pad_token_id = self . tokenizer . pad_token_id while pad_token_id in sub_label : # \u79fb\u9664[PAD]token sub_label . remove ( pad_token_id ) sub_label = '' . join ( self . tokenizer . convert_ids_to_tokens ( sub_label )) # print(sub_label) main_label = '\u65e0' for label , s_labels in self . label_dict . items (): if sub_label in s_labels : main_label = label break if main_label == '\u65e0' and hard_mapping : main_label = self . hard_mapping ( sub_label ) # print(main_label) ret = { 'label' : main_label , 'token_ids' : self . tokenizer ( main_label )[ 'input_ids' ][ 1 : - 1 ] } return ret def batch_find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u6279\u91cf\u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e\u5217\u8868, ['\u82f9\u679c', ...] or [[5741, 3362], ...] Returns: list: [ { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] }, ... ] \"\"\" return [ self . find_main_label ( l , hard_mapping ) for l in sub_label ] if __name__ == '__main__' : from rich import print from transformers import AutoTokenizer tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = 2 ) # label = [4510, 5554] # ret = verbalizer.find_sub_labels(label) # label = ['\u7535\u8111', '\u8863\u670d'] label = [[ 4510 , 5554 ], [ 6132 , 3302 ]] ret = verbalizer . batch_find_sub_labels ( label ) print ( ret ) print\u7ed3\u679c\u663e\u793a: [ { 'sub_labels' : [ '\u7535\u8111' ], 'token_ids' : [[ 4510 , 5554 ]]}, { 'sub_labels' : [ '\u8863\u670d' ], 'token_ids' : [[ 6132 , 3302 ]]} ] 1.2 common_utils.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u3001\u5c06mask_position\u4f4d\u7f6e\u7684token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amlm_loss()\u4ee5\u53caconvert_logits_to_ids() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch from rich import print \u5b9a\u4e49\u635f\u5931\u51fd\u6570mlm_loss() def mlm_loss ( logits , mask_positions , sub_mask_labels , cross_entropy_criterion , device ): \"\"\" \u8ba1\u7b97\u6307\u5b9a\u4f4d\u7f6e\u7684mask token\u7684output\u4e0elabel\u4e4b\u95f4\u7684cross entropy loss\u3002 Args: logits (torch.tensor): \u6a21\u578b\u539f\u59cb\u8f93\u51fa -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) sub_mask_labels (list): mask token\u7684sub label, \u7531\u4e8e\u6bcf\u4e2alabel\u7684sub_label\u6570\u76ee\u4e0d\u540c\uff0c\u6240\u4ee5 \u8fd9\u91cc\u662f\u4e2a\u53d8\u957f\u7684list, e.g. -> [ [[2398, 3352]], [[2398, 3352], [3819, 3861]] ] cross_entropy_criterion (CrossEntropyLoss): CE Loss\u8ba1\u7b97\u5668 device (str): cpu\u8fd8\u662fgpu Returns: torch.tensor: CE Loss \"\"\" batch_size , seq_len , vocab_size = logits . size () loss = None for single_value in zip ( logits , sub_mask_labels , mask_positions ): single_logits = single_value [ 0 ] single_sub_mask_labels = single_value [ 1 ] single_mask_positions = single_value [ 2 ] # single_mask_logits\u5f62\u72b6\uff1a(mask_label_num, vocab_size) single_mask_logits = single_logits [ single_mask_positions ] # single_mask_logits\u6309\u7167\u5b50\u6807\u7b7e\u7684\u957f\u5ea6\u8fdb\u884c\u590d\u5236: # single_mask_logits\u5f62\u72b6-->(sub_label_num, mask_label_num, vocab_size) single_mask_logits = single_mask_logits . repeat ( len ( single_sub_mask_labels ), 1 , 1 ) #single_mask_logits\u6539\u53d8\u5f62\u72b6\uff1a(sub_label_num * mask_label_num, vocab_size) #\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c single_mask_logits = single_mask_logits . reshape ( - 1 , vocab_size ) # single_sub_mask_labels\u5f62\u72b6\uff1a(sub_label_num, mask_label_num) single_sub_mask_labels = torch . LongTensor ( single_sub_mask_labels ) . to ( device ) # single_sub_mask_labels\u5f62\u72b6\uff1a # (sub_label_num * mask_label_num) single_sub_mask_labels = single_sub_mask_labels . reshape ( - 1 , 1 ) . squeeze () if not single_sub_mask_labels . size (): # \u5904\u7406\u5355token\u7ef4\u5ea6\u4e0b\u7ef4\u5ea6\u7f3a\u5931\u7684\u95ee\u9898 single_sub_mask_labels = single_sub_mask_labels . unsqueeze ( dim = 0 ) cur_loss = cross_entropy_criterion ( single_mask_logits , single_sub_mask_labels ) cur_loss = cur_loss / len ( single_sub_mask_labels ) if not loss : loss = cur_loss else : loss += cur_loss loss = loss / batch_size return loss \u5b9a\u4e49convert_logits_to_ids()\u51fd\u6570 def convert_logits_to_ids ( logits : torch . tensor , mask_positions : torch . tensor ): \"\"\" \u8f93\u5165LM\u7684\u8bcd\u8868\u6982\u7387\u5206\u5e03\uff08LMModel\u7684logits\uff09\uff0c\u5c06mask_position\u4f4d\u7f6e\u7684 token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 Args: logits (torch.tensor): model output -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) Returns: torch.LongTensor: \u5bf9\u5e94mask position\u4e0a\u6700\u5927\u6982\u7387\u7684\u63a8\u7406token -> (batch, mask_label_num) \"\"\" label_length = mask_positions . size ()[ 1 ] # \u6807\u7b7e\u957f\u5ea6 # print(f'label_length--\u300b{label_length}') batch_size , seq_len , vocab_size = logits . size () mask_positions_after_reshaped = [] for batch , mask_pos in enumerate ( mask_positions . detach () . cpu () . numpy () . tolist ()): for pos in mask_pos : mask_positions_after_reshaped . append ( batch * seq_len + pos ) # logits\u5f62\u72b6\uff1a(batch_size * seq_len, vocab_size) logits = logits . reshape ( batch_size * seq_len , - 1 ) # mask_logits\u5f62\u72b6\uff1a(batch * label_num, vocab_size) mask_logits = logits [ mask_positions_after_reshaped ] # predict_tokens\u5f62\u72b6\uff1a (batch * label_num) predict_tokens = mask_logits . argmax ( dim =- 1 ) # \u6539\u53d8\u540e\u7684predict_tokens\u5f62\u72b6\uff1a (batch, label_num) predict_tokens = predict_tokens . reshape ( - 1 , label_length ) # (batch, label_num) return predict_tokens if __name__ == '__main__' : logits = torch . randn ( 2 , 20 , 21193 ) mask_positions = torch . LongTensor ([ [ 3 , 4 ], [ 3 , 4 ] ]) predict_tokens = convert_logits_to_ids ( logits , mask_positions ) print ( predict_tokens ) print\u6253\u5370\u7ed3\u679c\u5c55\u793a\uff1a tensor([[2499, 3542], [5080, 8982]]) 1.3 metirc_utils.py \u00b6 \u76ee\u7684\uff1a\u5b9a\u4e49\uff08\u591a\uff09\u5206\u7c7b\u95ee\u9898\u4e0b\u7684\u6307\u6807\u8bc4\u4f30\uff08acc, precision, recall, f1\uff09\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a from typing import List import numpy as np import pandas as pd from sklearn.metrics import accuracy_score , precision_score , f1_score from sklearn.metrics import recall_score , confusion_matrix \u5b9a\u4e49ClassEvaluator\u7c7b class ClassEvaluator ( object ): def __init__ ( self ): self . goldens = [] self . predictions = [] def add_batch ( self , pred_batch : List [ List ], gold_batch : List [ List ]): \"\"\" \u6dfb\u52a0\u4e00\u4e2abatch\u4e2d\u7684prediction\u548cgold\u5217\u8868\uff0c\u7528\u4e8e\u540e\u7eed\u7edf\u4e00\u8ba1\u7b97\u3002 Args: pred_batch (list): \u6a21\u578b\u9884\u6d4b\u6807\u7b7e\u5217\u8868, e.g. -> [0, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] gold_batch (list): \u771f\u5b9e\u6807\u7b7e\u6807\u7b7e\u5217\u8868, e.g. -> [1, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] \"\"\" assert len ( pred_batch ) == len ( gold_batch ) # \u82e5\u9047\u5230\u591a\u4e2a\u5b50\u6807\u7b7e\u6784\u6210\u4e00\u4e2a\u6807\u7b7e\u7684\u60c5\u51b5 if type ( gold_batch [ 0 ]) in [ list , tuple ]: # \u5c06\u6240\u6709\u7684label\u62fc\u63a5\u4e3a\u4e00\u4e2a\u6574label: ['\u4f53', '\u80b2'] -> '\u4f53\u80b2' pred_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in pred_batch ] gold_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in gold_batch ] self . goldens . extend ( gold_batch ) self . predictions . extend ( pred_batch ) def compute ( self , round_num = 2 ) -> dict : \"\"\" \u6839\u636e\u5f53\u524d\u7c7b\u4e2d\u7d2f\u79ef\u7684\u53d8\u91cf\u503c\uff0c\u8ba1\u7b97\u5f53\u524d\u7684P, R, F1\u3002 Args: round_num (int): \u8ba1\u7b97\u7ed3\u679c\u4fdd\u7559\u5c0f\u6570\u70b9\u540e\u51e0\u4f4d, \u9ed8\u8ba4\u5c0f\u6570\u70b9\u540e2\u4f4d\u3002 Returns: dict -> { 'accuracy': \u51c6\u786e\u7387, 'precision': \u7cbe\u51c6\u7387, 'recall': \u53ec\u56de\u7387, 'f1': f1\u503c, 'class_metrics': { '0': { 'precision': \u8be5\u7c7b\u522b\u4e0b\u7684precision, 'recall': \u8be5\u7c7b\u522b\u4e0b\u7684recall, 'f1': \u8be5\u7c7b\u522b\u4e0b\u7684f1 }, ... } } \"\"\" classes , class_metrics , res = sorted ( list ( set ( self . goldens ) | set ( self . predictions ))), {}, {} # \u6784\u5efa\u5168\u5c40\u6307\u6807 res [ 'accuracy' ] = round ( accuracy_score ( self . goldens , self . predictions ), round_num ) res [ 'precision' ] = round ( precision_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) # average='weighted'\u4ee3\u8868\uff1a\u8003\u8651\u7c7b\u522b\u7684\u4e0d\u5e73\u8861\u6027\uff0c\u9700\u8981\u8ba1\u7b97\u7c7b\u522b\u7684\u52a0\u6743\u5e73\u5747\u3002\u5982\u679c\u662f\u4e8c\u5206\u7c7b\u95ee\u9898\u5219\u9009\u62e9\u53c2\u6570\u2018binary\u2018 res [ 'recall' ] = round ( recall_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) res [ 'f1' ] = round ( f1_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) try : conf_matrix = np . array ( confusion_matrix ( self . goldens , self . predictions )) # (n_class, n_class) assert conf_matrix . shape [ 0 ] == len ( classes ) for i in range ( conf_matrix . shape [ 0 ]): # \u6784\u5efa\u6bcf\u4e2aclass\u7684\u6307\u6807 precision = 0 if sum ( conf_matrix [:, i ]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [:, i ]) recall = 0 if sum ( conf_matrix [ i , :]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [ i , :]) f1 = 0 if ( precision + recall ) == 0 else 2 * precision * recall / ( precision + recall ) class_metrics [ classes [ i ]] = { 'precision' : round ( precision , round_num ), 'recall' : round ( recall , round_num ), 'f1' : round ( f1 , round_num ) } res [ 'class_metrics' ] = class_metrics except Exception as e : print ( f '[Warning] Something wrong when calculate class_metrics: { e } ' ) print ( f '-> goldens: { set ( self . goldens ) } ' ) print ( f '-> predictions: { set ( self . predictions ) } ' ) print ( f '-> diff elements: { set ( self . predictions ) - set ( self . goldens ) } ' ) res [ 'class_metrics' ] = {} return res def reset ( self ): \"\"\" \u91cd\u7f6e\u79ef\u7d2f\u7684\u6570\u503c\u3002 \"\"\" self . goldens = [] self . predictions = [] if __name__ == '__main__' : from rich import print metric = ClassEvaluator () metric . add_batch ( [[ '\u8d22' , '\u7ecf' ], [ '\u8d22' , '\u7ecf' ], [ '\u4f53' , '\u80b2' ], [ '\u4f53' , '\u80b2' ], [ '\u8ba1' , '\u7b97' , '\u673a' ]], [[ '\u4f53' , '\u80b2' ], [ '\u8d22' , '\u7ecf' ], [ '\u4f53' , '\u80b2' ], [ '\u8ba1' , '\u7b97' , '\u673a' ], [ '\u8ba1' , '\u7b97' , '\u673a' ]], ) # metric.add_batch( # [0, 0, 1, 1, 0], # [1, 1, 1, 0, 0] # ) print ( metric . compute ()) print\u4ee3\u7801\u7ed3\u679c\uff1a { 'accuracy' : 0.6 , 'precision' : 0.7 , 'recall' : 0.6 , 'f1' : 0.6 , 'class_metrics' : { '\u4f53,\u80b2' : { 'precision' : 0.5 , 'recall' : 0.5 , 'f1' : 0.5 }, '\u8ba1,\u7b97,\u673a' : { 'precision' : 1.0 , 'recall' : 0.5 , 'f1' : 0.67 }, '\u8d22,\u7ecf' : { 'precision' : 0.5 , 'recall' : 1.0 , 'f1' : 0.67 } } } \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u5b9e\u73b0\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/train.py \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amodel2train()\u548cevaluate_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import os import time from transformers import AutoModelForMaskedLM , AutoTokenizer , get_scheduler import sys sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/data_handle' ) sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/utils' ) from utils.metirc_utils import ClassEvaluator from utils.common_utils import * from data_handle.data_loader import * from utils.verbalizer import Verbalizer from ptune_config import * pc = ProjectConfig () \u5b9a\u4e49model2train()\u51fd\u6570 def model2train (): model = AutoModelForMaskedLM . from_pretrained ( pc . pre_model ) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = pc . max_label_len ) #\u5bf9\u53c2\u6570\u505a\u6743\u91cd\u8870\u51cf\u662f\u4e3a\u4e86\u4f7f\u51fd\u6570\u5e73\u6ed1\uff0c\u7136\u800cbias\u548clayernorm\u7684\u6743\u91cd\u53c2\u6570\u4e0d\u5f71\u54cd\u51fd\u6570\u7684\u5e73\u6ed1\u6027\u3002 #\u4ed6\u4eec\u8d77\u5230\u7684\u4f5c\u7528\u4ec5\u4ec5\u662f\u7f29\u653e\u5e73\u79fb\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u6743\u91cd\u8870\u51cf no_decay = [ \"bias\" , \"LayerNorm.weight\" ] optimizer_grouped_parameters = [ { \"params\" : [ p for n , p in model . named_parameters () if not any ( nd in n for nd in no_decay )], \"weight_decay\" : pc . weight_decay , }, { \"params\" : [ p for n , p in model . named_parameters () if any ( nd in n for nd in no_decay )], \"weight_decay\" : 0.0 , }, ] optimizer = torch . optim . AdamW ( optimizer_grouped_parameters , lr = pc . learning_rate ) model . to ( pc . device ) train_dataloader , dev_dataloader = get_data () # \u6839\u636e\u8bad\u7ec3\u8f6e\u6570\u8ba1\u7b97\u6700\u5927\u8bad\u7ec3\u6b65\u6570\uff0c\u4ee5\u4fbf\u4e8escheduler\u52a8\u6001\u8c03\u6574lr num_update_steps_per_epoch = len ( train_dataloader ) #\u6307\u5b9a\u603b\u7684\u8bad\u7ec3\u6b65\u6570\uff0c\u5b83\u4f1a\u88ab\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u7528\u6765\u786e\u5b9a\u5b66\u4e60\u7387\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u786e\u4fdd\u5b66\u4e60\u7387\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f97\u4ee5\u5408\u7406\u5730\u8c03\u8282 max_train_steps = pc . epochs * num_update_steps_per_epoch warm_steps = int ( pc . warmup_ratio * max_train_steps ) # \u9884\u70ed\u9636\u6bb5\u7684\u8bad\u7ec3\u6b65\u6570 lr_scheduler = get_scheduler ( name = 'linear' , optimizer = optimizer , num_warmup_steps = warm_steps , num_training_steps = max_train_steps , ) loss_list = [] tic_train = time . time () metric = ClassEvaluator () criterion = torch . nn . CrossEntropyLoss () global_step , best_f1 = 0 , 0 print ( '\u5f00\u59cb\u8bad\u7ec3\uff1a' ) for epoch in range ( pc . epochs ): for batch in train_dataloader : if 'token_type_ids' in batch : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits else : # \u517c\u5bb9\u4e0d\u9700\u8981 token_type_id \u7684\u6a21\u578b, e.g. Roberta-Base logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits # \u771f\u5b9e\u6807\u7b7e mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () sub_labels = verbalizer . batch_find_sub_labels ( mask_labels ) sub_labels = [ ele [ 'token_ids' ] for ele in sub_labels ] # print(f'sub_labels--->{sub_labels}') loss = mlm_loss ( logits , batch [ 'mask_positions' ] . to ( pc . device ), sub_labels , criterion , pc . device , ) optimizer . zero_grad () loss . backward () optimizer . step () lr_scheduler . step () loss_list . append ( float ( loss . cpu () . detach ())) # # global_step += 1 if global_step % pc . logging_steps == 0 : time_diff = time . time () - tic_train loss_avg = sum ( loss_list ) / len ( loss_list ) print ( \"global step %d , epoch: %d , loss: %.5f , speed: %.2f step/s\" % ( global_step , epoch , loss_avg , pc . logging_steps / time_diff )) tic_train = time . time () if global_step % pc . valid_steps == 0 : cur_save_dir = os . path . join ( pc . save_dir , \"model_ %d \" % global_step ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) acc , precision , recall , f1 , class_metrics = evaluate_model ( model , metric , dev_dataloader , tokenizer , verbalizer ) print ( \"Evaluation precision: %.5f , recall: %.5f , F1: %.5f \" % ( precision , recall , f1 )) if f1 > best_f1 : print ( f \"best F1 performence has been updated: { best_f1 : .5f } --> { f1 : .5f } \" ) print ( f 'Each Class Metrics are: { class_metrics } ' ) best_f1 = f1 cur_save_dir = os . path . join ( pc . save_dir , \"model_best\" ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) tic_train = time . time () print ( '\u8bad\u7ec3\u7ed3\u675f' ) \u5b9a\u4e49evaluate_model()\u51fd\u6570 def evaluate_model ( model , metric , data_loader , tokenizer , verbalizer ): \"\"\" \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u5f53\u524d\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002 Args: model: \u5f53\u524d\u6a21\u578b metric: \u8bc4\u4f30\u6307\u6807\u7c7b(metric) data_loader: \u6d4b\u8bd5\u96c6\u7684dataloader global_step: \u5f53\u524d\u8bad\u7ec3\u6b65\u6570 \"\"\" model . eval () metric . reset () with torch . no_grad (): for step , batch in enumerate ( data_loader ): # \u517c\u5bb9\u4e0d\u9700\u8981 token_type_id \u7684\u6a21\u578b, e.g. Roberta-Base if 'token_type_ids' in batch : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device )) . logits else : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device ),) . logits # (batch, label_num) mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () # \u53bb\u6389label\u4e2d\u7684[PAD] token for i in range ( len ( mask_labels )): while tokenizer . pad_token_id in mask_labels [ i ]: mask_labels [ i ] . remove ( tokenizer . pad_token_id ) # id\u8f6c\u6587\u5b57 mask_labels = [ '' . join ( tokenizer . convert_ids_to_tokens ( t )) for t in mask_labels ] # (batch, label_num) predictions = convert_logits_to_ids ( logits , batch [ 'mask_positions' ]) . cpu () . numpy () . tolist () # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = verbalizer . batch_find_main_label ( predictions ) predictions = [ ele [ 'label' ] for ele in predictions ] metric . add_batch ( pred_batch = predictions , gold_batch = mask_labels ) eval_metric = metric . compute () model . train () return eval_metric [ 'accuracy' ], eval_metric [ 'precision' ], \\ eval_metric [ 'recall' ], eval_metric [ 'f1' ], \\ eval_metric [ 'class_metrics' ] \u8c03\u7528: cd /Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning # \u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3 python train.py \u8f93\u51fa\u7ed3\u679c: ... global step 350 , epoch : 43 , loss : 0.10804 , speed : 1.20 step / s global step 360 , epoch : 44 , loss : 0.10504 , speed : 1.22 step / s global step 370 , epoch : 46 , loss : 0.10220 , speed : 1.21 step / s global step 380 , epoch : 47 , loss : 0.09951 , speed : 1.20 step / s global step 390 , epoch : 48 , loss : 0.09696 , speed : 1.20 step / s global step 400 , epoch : 49 , loss : 0.09454 , speed : 1.22 step / s Evaluation precision : 0.76000 , recall : 0.70000 , F1 : 0.70000 \u7ed3\u8bba: BERT+P-Tuning\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8868\u73b0\u662fPrecion: 76% \u6ce8\u610f\uff1a\u672c\u9879\u76ee\u4e2d\u53ea\u7528\u4e8660\u6761\u6837\u672c\uff0c\u5728\u63a5\u8fd1400\u6761\u6837\u672c\u4e0a\u7cbe\u786e\u7387\u5c31\u5df2\u7ecf\u8fbe\u5230\u4e8676%\uff0c\u5982\u679c\u60f3\u8ba9\u6307\u6807\u66f4\u9ad8\uff0c\u53ef\u4ee5\u6269\u589e\u6837\u672c\u3002 \u63d0\u5347\u6a21\u578b\u6027\u80fd\uff1a \u589e\u52a0\u8bad\u7ec3\u6570\u636e\u96c6\uff08100\u6761\u5de6\u53f3\u7684\u6570\u636e\uff09\uff1a \u624b\u673a \u5916\u89c2\u65f6\u5c1a\u65b0\u6f6e \uff0c \u9002\u5408\u5e74\u8f7b\u4eba\u5c55\u73b0\u4e2a\u6027 \u3002 \u624b\u673a \u5c4f\u5e55\u663e\u793a\u6548\u679c\u975e\u5e38\u51fa\u8272 \uff0c \u89c2\u770b\u89c6\u9891\u548c\u6d4f\u89c8\u7f51\u9875\u5f88\u8212\u9002 \u3002 \u7535\u8111 \u4f7f\u7528\u4e86\u4e00\u6bb5\u65f6\u95f4\u7684\u8fd9\u6b3e\u7535\u8111 \uff0c \u786c\u76d8\u91c7\u7528WD \uff0c \u8fd0\u884c\u6d41\u7545\u65e0\u5361\u987f \uff0c \u6e29\u5ea6\u63a7\u5236\u8f83\u597d \uff0c \u6027\u4ef7\u6bd4\u4ee4\u4eba\u6ee1\u610f \u3002 \u624b\u673a \u624b\u673a\u53cd\u5e94\u7075\u654f \uff0c \u64cd\u4f5c\u754c\u9762\u7b80\u6d01\u6613\u7528 \uff0c \u975e\u5e38\u6ee1\u610f \u3002 \u7535\u5668 \u4ea7\u54c1\u6027\u80fd\u7a33\u5b9a \uff0c \u5f88\u4e0d\u9519\u54e6 \uff01 \u8d2d\u4e70\u65f6\u6709\u70b9\u62c5\u5fc3 \uff0c \u4f46\u6536\u5230\u8d27\u540e\u53d1\u73b0\u662f\u6b63\u54c1 \uff0c \u5927\u5bb6\u53ef\u4ee5\u653e\u5fc3\u8d2d\u4e70 \u3002 \u4fee\u6539\u9a8c\u8bc1\u96c6\u810f\u6570\u636e # \u539f\u59cb\u6807\u7b7e\u548c\u8bc4\u8bba\u6587\u672c\u5185\u5bb9\u4e0d\u7b26 \u5e73\u677f \u624b\u673a\u5f88\u597d \uff0c \u5c31\u662f\u5ba2\u670d\u5783\u573e\u7279\u522b\u662f\u5143\u8c46 # \u4fee\u6539\u540e \u624b\u673a \u624b\u673a\u5f88\u597d \uff0c \u5c31\u662f\u5ba2\u670d\u5783\u573e\u7279\u522b\u662f\u5143\u8c46 \u6a21\u578b\u8868\u73b0\uff1a Evaluation precision: 0.79000, recall: 0.70000, F1: 0.71000 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e76\u6d4b\u8bd5\u6548\u679c \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/inference.py \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import time from typing import List import torch from rich import print from transformers import AutoTokenizer , AutoModelForMaskedLM import sys sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/data_handle' ) sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/utils' ) from utils.verbalizer import Verbalizer from data_handle.data_preprocess import convert_example from utils.common_utils import convert_logits_to_ids \u9884\u6d4b\u4ee3\u7801\u5177\u4f53\u5b9e\u73b0 device = 'cuda:0' model_path = 'checkpoints/model_best' tokenizer = AutoTokenizer . from_pretrained ( model_path ) model = AutoModelForMaskedLM . from_pretrained ( model_path ) model . to ( device ) . eval () max_label_len = 2 # \u6807\u7b7e\u6700\u5927\u957f\u5ea6 p_embedding_num = 6 verbalizer = Verbalizer ( verbalizer_file = 'data/verbalizer.txt' , tokenizer = tokenizer , max_label_len = max_label_len ) def inference ( contents : List [ str ]): \"\"\" \u63a8\u7406\u51fd\u6570\uff0c\u8f93\u5165\u539f\u59cb\u53e5\u5b50\uff0c\u8f93\u51famask label\u7684\u9884\u6d4b\u503c\u3002 Args: contents (List[str]): \u63cf\u539f\u59cb\u53e5\u5b50\u5217\u8868\u3002 \"\"\" with torch . no_grad (): start_time = time . time () examples = { 'text' : contents } tokenized_output = convert_example ( examples , tokenizer , max_seq_len = 128 , max_label_len = max_label_len , p_embedding_num = p_embedding_num , train_mode = False , return_tensor = True ) logits = model ( input_ids = tokenized_output [ 'input_ids' ] . to ( device ), token_type_ids = tokenized_output [ 'token_type_ids' ] . to ( device ), attention_mask = tokenized_output [ 'attention_mask' ] . to ( device )) . logits predictions = convert_logits_to_ids ( logits , tokenized_output [ 'mask_positions' ]) . cpu () . numpy () . tolist () # (batch, label_num) predictions = verbalizer . batch_find_main_label ( predictions ) # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = [ ele [ 'label' ] for ele in predictions ] used = time . time () - start_time print ( f 'Used { used } s.' ) return predictions if __name__ == '__main__' : contents = [ '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa\u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' , '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d\u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' , \"\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f\" , \"\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86\uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a\u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765\u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230\" , \"\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212\u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765\" ] res = inference ( contents ) print ( 'inference label(s):' , res ) \u7ed3\u679c\u5c55\u793a { '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa \u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' : '\u9152\u5e97', '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d \u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' : '\u9152\u5e97', '\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f' : '\u8863\u670d', '\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86 \uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a \u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765 \u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230' : '\u5e73\u677f', '\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212 \u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765' : '\u9152\u5e97' } \u5c0f\u8282\u603b\u7ed3 \u00b6 \u672c\u5c0f\u8282\u5b9e\u73b0\u4e86\u57fa\u4e8eBERT+P-Tuning\u6a21\u578b\u7684\u6784\u5efa, \u5e76\u5b8c\u6210\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8bc4\u4f30.","title":"6.7 BERT+P-Tuning\u65b9\u5f0f\u6a21\u578b\u4ee3\u7801\u5b9e\u73b0\u548c\u8bad\u7ec3"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#bertp-tuning","text":"","title":"\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6587\u672c\u5206\u7c7b\u6a21\u578b\u642d\u5efa"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_1","text":"\u638c\u63e1\u57fa\u4e8eBERT+P-Tuning\u65b9\u5f0f\u6a21\u578b\u642d\u5efa\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u6a21\u578b\u7684\u8bad\u7ec3,\u9a8c\u8bc1\u53ca\u76f8\u5173\u5de5\u5177\u4ee3\u7801\u7684\u5b9e\u73b0. \u638c\u63e1\u4f7f\u7528\u6a21\u578b\u9884\u6d4b\u4ee3\u7801\u7684\u5b9e\u73b0.","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_2","text":"\u672c\u9879\u76ee\u4e2d\u5b8c\u6210BERT+P-Tuning\u6a21\u578b\u642d\u5efa\u3001\u8bad\u7ec3\u53ca\u5e94\u7528\u7684\u6b65\u9aa4\u5982\u4e0b\uff08\u6ce8\u610f\uff1a\u56e0\u4e3a\u672c\u9879\u76ee\u4e2d\u4f7f\u7528\u7684\u662fBERT\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u6240\u4ee5\u76f4\u63a5\u52a0\u8f7d\u5373\u53ef\uff0c\u65e0\u9700\u91cd\u590d\u642d\u5efa\u6a21\u578b\u67b6\u6784\uff09: \u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570 \u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570 \u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570","title":"\u6a21\u578b\u642d\u5efa"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_3","text":"\u76ee\u7684\uff1a\u6a21\u578b\u5728\u8bad\u7ec3\u3001\u9a8c\u8bc1\u3001\u9884\u6d4b\u65f6\u9700\u8981\u7684\u51fd\u6570 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/utils utils\u6587\u4ef6\u5939\u5171\u5305\u542b3\u4e2apy\u811a\u672c\uff1averbalizer.py\u3001metirc_utils.py\u4ee5\u53cacommon_utils.py","title":"\u4e00\u3001\u5b9e\u73b0\u6a21\u578b\u5de5\u5177\u7c7b\u51fd\u6570"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#11-verbalizerpy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u4e00\u4e2aVerbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 # -*- coding:utf-8 -*- import os from typing import Union , List from ptune_config import * pc = ProjectConfig () \u5177\u4f53\u5b9e\u73b0\u4ee3\u7801 class Verbalizer ( object ): \"\"\" Verbalizer\u7c7b\uff0c\u7528\u4e8e\u5c06\u4e00\u4e2aLabel\u5bf9\u5e94\u5230\u5176\u5b50Label\u7684\u6620\u5c04\u3002 \"\"\" def __init__ ( self , verbalizer_file : str , tokenizer , max_label_len : int ): \"\"\" Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 tokenizer: \u5206\u8bcd\u5668\uff0c\u7528\u4e8e\u6587\u672c\u548cid\u4e4b\u95f4\u7684\u8f6c\u6362\u3002 max_label_len (int): \u6807\u7b7e\u957f\u5ea6\uff0c\u82e5\u5927\u4e8e\u5219\u622a\u65ad\uff0c\u82e5\u5c0f\u4e8e\u5219\u8865\u9f50 \"\"\" self . tokenizer = tokenizer self . label_dict = self . load_label_dict ( verbalizer_file ) self . max_label_len = max_label_len def load_label_dict ( self , verbalizer_file : str ): \"\"\" \u8bfb\u53d6\u672c\u5730\u6587\u4ef6\uff0c\u6784\u5efaverbalizer\u5b57\u5178\u3002 Args: verbalizer_file (str): verbalizer\u6587\u4ef6\u5b58\u653e\u5730\u5740\u3002 Returns: dict -> { '\u4f53\u80b2': ['\u7bee\u7403', '\u8db3\u7403','\u7f51\u7403', '\u6392\u7403', ...], '\u9152\u5e97': ['\u5bbe\u9986', '\u65c5\u9986', '\u65c5\u5e97', '\u9152\u5e97', ...], ... } \"\"\" label_dict = {} with open ( verbalizer_file , 'r' , encoding = 'utf8' ) as f : for line in f . readlines (): label , sub_labels = line . strip () . split ( ' \\t ' ) label_dict [ label ] = list ( set ( sub_labels . split ( ',' ))) return label_dict def find_sub_labels ( self , label : Union [ list , str ]): \"\"\" \u901a\u8fc7\u6807\u7b7e\u627e\u5230\u5bf9\u5e94\u6240\u6709\u7684\u5b50\u6807\u7b7e\u3002 Args: label (Union[list, str]): \u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u4f53\u80b2' or [860, 5509] Returns: dict -> { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] } \"\"\" if type ( label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8fdb\u884c\u6587\u672c\u8f6c\u6362 while self . tokenizer . pad_token_id in label : label . remove ( self . tokenizer . pad_token_id ) label = '' . join ( self . tokenizer . convert_ids_to_tokens ( label )) # print(f'label-->{label}') if label not in self . label_dict : raise ValueError ( f 'Lable Error: \" { label } \" not in label_dict' ) sub_labels = self . label_dict [ label ] ret = { 'sub_labels' : sub_labels } token_ids = [ _id [ 1 : - 1 ] for _id in self . tokenizer ( sub_labels )[ 'input_ids' ]] # print(f'token_ids-->{token_ids}') for i in range ( len ( token_ids )): token_ids [ i ] = token_ids [ i ][: self . max_label_len ] # \u5bf9\u6807\u7b7e\u8fdb\u884c\u622a\u65ad\u4e0e\u8865\u9f50 if len ( token_ids [ i ]) < self . max_label_len : token_ids [ i ] = token_ids [ i ] + [ self . tokenizer . pad_token_id ] * ( self . max_label_len - len ( token_ids [ i ])) ret [ 'token_ids' ] = token_ids return ret def batch_find_sub_labels ( self , label : List [ Union [ list , str ]]): \"\"\" \u6279\u91cf\u627e\u5230\u5b50\u6807\u7b7e\u3002 Args: label (List[list, str]): \u6807\u7b7e\u5217\u8868, [[4510, 5554], [860, 5509]] or ['\u4f53\u80b2', '\u7535\u8111'] Returns: list -> [ { 'sub_labels': ['\u8db3\u7403', '\u7f51\u7403'], 'token_ids': [[6639, 4413], [5381, 4413]] }, ... ] \"\"\" return [ self . find_sub_labels ( l ) for l in label ] def get_common_sub_str ( self , str1 : str , str2 : str ): \"\"\" \u5bfb\u627e\u6700\u5927\u516c\u5171\u5b50\u4e32\u3002 str1:abcd str2:abadbcdba \"\"\" lstr1 , lstr2 = len ( str1 ), len ( str2 ) # \u751f\u62100\u77e9\u9635\uff0c\u4e3a\u65b9\u4fbf\u540e\u7eed\u8ba1\u7b97\uff0c\u6bd4\u5b57\u7b26\u4e32\u957f\u5ea6\u591a\u4e86\u4e00\u5217 record = [[ 0 for i in range ( lstr2 + 1 )] for j in range ( lstr1 + 1 )] p = 0 # \u6700\u957f\u5339\u914d\u5bf9\u5e94\u5728str1\u4e2d\u7684\u6700\u540e\u4e00\u4f4d maxNum = 0 # \u6700\u957f\u5339\u914d\u957f\u5ea6 for i in range ( lstr1 ): for j in range ( lstr2 ): if str1 [ i ] == str2 [ j ]: record [ i + 1 ][ j + 1 ] = record [ i ][ j ] + 1 if record [ i + 1 ][ j + 1 ] > maxNum : maxNum = record [ i + 1 ][ j + 1 ] p = i + 1 return str1 [ p - maxNum : p ], maxNum def hard_mapping ( self , sub_label : str ): \"\"\" \u5f3a\u5339\u914d\u51fd\u6570\uff0c\u5f53\u6a21\u578b\u751f\u6210\u7684\u5b50label\u4e0d\u5b58\u5728\u65f6\uff0c\u901a\u8fc7\u6700\u5927\u516c\u5171\u5b50\u4e32\u627e\u5230\u91cd\u5408\u5ea6\u6700\u9ad8\u7684\u4e3blabel\u3002 Args: sub_label (str): \u5b50label\u3002 Returns: str: \u4e3blabel\u3002 \"\"\" label , max_overlap_str = '' , 0 # print(self.label_dict.items()) for main_label , sub_labels in self . label_dict . items (): overlap_num = 0 for s_label in sub_labels : # \u6c42\u6240\u6709\u5b50label\u4e0e\u5f53\u524d\u63a8\u7406label\u4e4b\u95f4\u7684\u6700\u957f\u516c\u5171\u5b50\u4e32\u957f\u5ea6 overlap_num += self . get_common_sub_str ( sub_label , s_label )[ 1 ] if overlap_num >= max_overlap_str : max_overlap_str = overlap_num label = main_label return label def find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u5230\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e, \u6587\u672c\u578b \u6216 id_list, e.g. -> '\u82f9\u679c' or [5741, 3362] hard_mapping (bool): \u5f53\u751f\u6210\u7684\u8bcd\u8bed\u4e0d\u5b58\u5728\u65f6\uff0c\u662f\u5426\u4e00\u5b9a\u8981\u5339\u914d\u5230\u4e00\u4e2a\u6700\u76f8\u4f3c\u7684label\u3002 Returns: dict -> { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] } \"\"\" if type ( sub_label ) == list : # \u5982\u679c\u4f20\u5165\u4e3aid_list, \u5219\u901a\u8fc7tokenizer\u8f6c\u56de\u6765 pad_token_id = self . tokenizer . pad_token_id while pad_token_id in sub_label : # \u79fb\u9664[PAD]token sub_label . remove ( pad_token_id ) sub_label = '' . join ( self . tokenizer . convert_ids_to_tokens ( sub_label )) # print(sub_label) main_label = '\u65e0' for label , s_labels in self . label_dict . items (): if sub_label in s_labels : main_label = label break if main_label == '\u65e0' and hard_mapping : main_label = self . hard_mapping ( sub_label ) # print(main_label) ret = { 'label' : main_label , 'token_ids' : self . tokenizer ( main_label )[ 'input_ids' ][ 1 : - 1 ] } return ret def batch_find_main_label ( self , sub_label : List [ Union [ list , str ]], hard_mapping = True ): \"\"\" \u6279\u91cf\u901a\u8fc7\u5b50\u6807\u7b7e\u627e\u7236\u6807\u7b7e\u3002 Args: sub_label (List[Union[list, str]]): \u5b50\u6807\u7b7e\u5217\u8868, ['\u82f9\u679c', ...] or [[5741, 3362], ...] Returns: list: [ { 'label': '\u6c34\u679c', 'token_ids': [3717, 3362] }, ... ] \"\"\" return [ self . find_main_label ( l , hard_mapping ) for l in sub_label ] if __name__ == '__main__' : from rich import print from transformers import AutoTokenizer tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = 2 ) # label = [4510, 5554] # ret = verbalizer.find_sub_labels(label) # label = ['\u7535\u8111', '\u8863\u670d'] label = [[ 4510 , 5554 ], [ 6132 , 3302 ]] ret = verbalizer . batch_find_sub_labels ( label ) print ( ret ) print\u7ed3\u679c\u663e\u793a: [ { 'sub_labels' : [ '\u7535\u8111' ], 'token_ids' : [[ 4510 , 5554 ]]}, { 'sub_labels' : [ '\u8863\u670d' ], 'token_ids' : [[ 6132 , 3302 ]]} ]","title":"1.1 verbalizer.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#12-common_utilspy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u3001\u5c06mask_position\u4f4d\u7f6e\u7684token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amlm_loss()\u4ee5\u53caconvert_logits_to_ids() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a # coding:utf-8 # \u5bfc\u5165\u5fc5\u5907\u5de5\u5177\u5305 import torch from rich import print \u5b9a\u4e49\u635f\u5931\u51fd\u6570mlm_loss() def mlm_loss ( logits , mask_positions , sub_mask_labels , cross_entropy_criterion , device ): \"\"\" \u8ba1\u7b97\u6307\u5b9a\u4f4d\u7f6e\u7684mask token\u7684output\u4e0elabel\u4e4b\u95f4\u7684cross entropy loss\u3002 Args: logits (torch.tensor): \u6a21\u578b\u539f\u59cb\u8f93\u51fa -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) sub_mask_labels (list): mask token\u7684sub label, \u7531\u4e8e\u6bcf\u4e2alabel\u7684sub_label\u6570\u76ee\u4e0d\u540c\uff0c\u6240\u4ee5 \u8fd9\u91cc\u662f\u4e2a\u53d8\u957f\u7684list, e.g. -> [ [[2398, 3352]], [[2398, 3352], [3819, 3861]] ] cross_entropy_criterion (CrossEntropyLoss): CE Loss\u8ba1\u7b97\u5668 device (str): cpu\u8fd8\u662fgpu Returns: torch.tensor: CE Loss \"\"\" batch_size , seq_len , vocab_size = logits . size () loss = None for single_value in zip ( logits , sub_mask_labels , mask_positions ): single_logits = single_value [ 0 ] single_sub_mask_labels = single_value [ 1 ] single_mask_positions = single_value [ 2 ] # single_mask_logits\u5f62\u72b6\uff1a(mask_label_num, vocab_size) single_mask_logits = single_logits [ single_mask_positions ] # single_mask_logits\u6309\u7167\u5b50\u6807\u7b7e\u7684\u957f\u5ea6\u8fdb\u884c\u590d\u5236: # single_mask_logits\u5f62\u72b6-->(sub_label_num, mask_label_num, vocab_size) single_mask_logits = single_mask_logits . repeat ( len ( single_sub_mask_labels ), 1 , 1 ) #single_mask_logits\u6539\u53d8\u5f62\u72b6\uff1a(sub_label_num * mask_label_num, vocab_size) #\u6a21\u578b\u9884\u6d4b\u7684\u7ed3\u679c single_mask_logits = single_mask_logits . reshape ( - 1 , vocab_size ) # single_sub_mask_labels\u5f62\u72b6\uff1a(sub_label_num, mask_label_num) single_sub_mask_labels = torch . LongTensor ( single_sub_mask_labels ) . to ( device ) # single_sub_mask_labels\u5f62\u72b6\uff1a # (sub_label_num * mask_label_num) single_sub_mask_labels = single_sub_mask_labels . reshape ( - 1 , 1 ) . squeeze () if not single_sub_mask_labels . size (): # \u5904\u7406\u5355token\u7ef4\u5ea6\u4e0b\u7ef4\u5ea6\u7f3a\u5931\u7684\u95ee\u9898 single_sub_mask_labels = single_sub_mask_labels . unsqueeze ( dim = 0 ) cur_loss = cross_entropy_criterion ( single_mask_logits , single_sub_mask_labels ) cur_loss = cur_loss / len ( single_sub_mask_labels ) if not loss : loss = cur_loss else : loss += cur_loss loss = loss / batch_size return loss \u5b9a\u4e49convert_logits_to_ids()\u51fd\u6570 def convert_logits_to_ids ( logits : torch . tensor , mask_positions : torch . tensor ): \"\"\" \u8f93\u5165LM\u7684\u8bcd\u8868\u6982\u7387\u5206\u5e03\uff08LMModel\u7684logits\uff09\uff0c\u5c06mask_position\u4f4d\u7f6e\u7684 token logits\u8f6c\u6362\u4e3atoken\u7684id\u3002 Args: logits (torch.tensor): model output -> (batch, seq_len, vocab_size) mask_positions (torch.tensor): mask token\u7684\u4f4d\u7f6e -> (batch, mask_label_num) Returns: torch.LongTensor: \u5bf9\u5e94mask position\u4e0a\u6700\u5927\u6982\u7387\u7684\u63a8\u7406token -> (batch, mask_label_num) \"\"\" label_length = mask_positions . size ()[ 1 ] # \u6807\u7b7e\u957f\u5ea6 # print(f'label_length--\u300b{label_length}') batch_size , seq_len , vocab_size = logits . size () mask_positions_after_reshaped = [] for batch , mask_pos in enumerate ( mask_positions . detach () . cpu () . numpy () . tolist ()): for pos in mask_pos : mask_positions_after_reshaped . append ( batch * seq_len + pos ) # logits\u5f62\u72b6\uff1a(batch_size * seq_len, vocab_size) logits = logits . reshape ( batch_size * seq_len , - 1 ) # mask_logits\u5f62\u72b6\uff1a(batch * label_num, vocab_size) mask_logits = logits [ mask_positions_after_reshaped ] # predict_tokens\u5f62\u72b6\uff1a (batch * label_num) predict_tokens = mask_logits . argmax ( dim =- 1 ) # \u6539\u53d8\u540e\u7684predict_tokens\u5f62\u72b6\uff1a (batch, label_num) predict_tokens = predict_tokens . reshape ( - 1 , label_length ) # (batch, label_num) return predict_tokens if __name__ == '__main__' : logits = torch . randn ( 2 , 20 , 21193 ) mask_positions = torch . LongTensor ([ [ 3 , 4 ], [ 3 , 4 ] ]) predict_tokens = convert_logits_to_ids ( logits , mask_positions ) print ( predict_tokens ) print\u6253\u5370\u7ed3\u679c\u5c55\u793a\uff1a tensor([[2499, 3542], [5080, 8982]])","title":"1.2 common_utils.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#13-metirc_utilspy","text":"\u76ee\u7684\uff1a\u5b9a\u4e49\uff08\u591a\uff09\u5206\u7c7b\u95ee\u9898\u4e0b\u7684\u6307\u6807\u8bc4\u4f30\uff08acc, precision, recall, f1\uff09\u3002 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305\uff1a from typing import List import numpy as np import pandas as pd from sklearn.metrics import accuracy_score , precision_score , f1_score from sklearn.metrics import recall_score , confusion_matrix \u5b9a\u4e49ClassEvaluator\u7c7b class ClassEvaluator ( object ): def __init__ ( self ): self . goldens = [] self . predictions = [] def add_batch ( self , pred_batch : List [ List ], gold_batch : List [ List ]): \"\"\" \u6dfb\u52a0\u4e00\u4e2abatch\u4e2d\u7684prediction\u548cgold\u5217\u8868\uff0c\u7528\u4e8e\u540e\u7eed\u7edf\u4e00\u8ba1\u7b97\u3002 Args: pred_batch (list): \u6a21\u578b\u9884\u6d4b\u6807\u7b7e\u5217\u8868, e.g. -> [0, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] gold_batch (list): \u771f\u5b9e\u6807\u7b7e\u6807\u7b7e\u5217\u8868, e.g. -> [1, 0, 1, 2, 0, ...] or [['\u4f53', '\u80b2'], ['\u8d22', '\u7ecf'], ...] \"\"\" assert len ( pred_batch ) == len ( gold_batch ) # \u82e5\u9047\u5230\u591a\u4e2a\u5b50\u6807\u7b7e\u6784\u6210\u4e00\u4e2a\u6807\u7b7e\u7684\u60c5\u51b5 if type ( gold_batch [ 0 ]) in [ list , tuple ]: # \u5c06\u6240\u6709\u7684label\u62fc\u63a5\u4e3a\u4e00\u4e2a\u6574label: ['\u4f53', '\u80b2'] -> '\u4f53\u80b2' pred_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in pred_batch ] gold_batch = [ ',' . join ([ str ( e ) for e in ele ]) for ele in gold_batch ] self . goldens . extend ( gold_batch ) self . predictions . extend ( pred_batch ) def compute ( self , round_num = 2 ) -> dict : \"\"\" \u6839\u636e\u5f53\u524d\u7c7b\u4e2d\u7d2f\u79ef\u7684\u53d8\u91cf\u503c\uff0c\u8ba1\u7b97\u5f53\u524d\u7684P, R, F1\u3002 Args: round_num (int): \u8ba1\u7b97\u7ed3\u679c\u4fdd\u7559\u5c0f\u6570\u70b9\u540e\u51e0\u4f4d, \u9ed8\u8ba4\u5c0f\u6570\u70b9\u540e2\u4f4d\u3002 Returns: dict -> { 'accuracy': \u51c6\u786e\u7387, 'precision': \u7cbe\u51c6\u7387, 'recall': \u53ec\u56de\u7387, 'f1': f1\u503c, 'class_metrics': { '0': { 'precision': \u8be5\u7c7b\u522b\u4e0b\u7684precision, 'recall': \u8be5\u7c7b\u522b\u4e0b\u7684recall, 'f1': \u8be5\u7c7b\u522b\u4e0b\u7684f1 }, ... } } \"\"\" classes , class_metrics , res = sorted ( list ( set ( self . goldens ) | set ( self . predictions ))), {}, {} # \u6784\u5efa\u5168\u5c40\u6307\u6807 res [ 'accuracy' ] = round ( accuracy_score ( self . goldens , self . predictions ), round_num ) res [ 'precision' ] = round ( precision_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) # average='weighted'\u4ee3\u8868\uff1a\u8003\u8651\u7c7b\u522b\u7684\u4e0d\u5e73\u8861\u6027\uff0c\u9700\u8981\u8ba1\u7b97\u7c7b\u522b\u7684\u52a0\u6743\u5e73\u5747\u3002\u5982\u679c\u662f\u4e8c\u5206\u7c7b\u95ee\u9898\u5219\u9009\u62e9\u53c2\u6570\u2018binary\u2018 res [ 'recall' ] = round ( recall_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) res [ 'f1' ] = round ( f1_score ( self . goldens , self . predictions , average = 'weighted' ), round_num ) try : conf_matrix = np . array ( confusion_matrix ( self . goldens , self . predictions )) # (n_class, n_class) assert conf_matrix . shape [ 0 ] == len ( classes ) for i in range ( conf_matrix . shape [ 0 ]): # \u6784\u5efa\u6bcf\u4e2aclass\u7684\u6307\u6807 precision = 0 if sum ( conf_matrix [:, i ]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [:, i ]) recall = 0 if sum ( conf_matrix [ i , :]) == 0 else conf_matrix [ i , i ] / sum ( conf_matrix [ i , :]) f1 = 0 if ( precision + recall ) == 0 else 2 * precision * recall / ( precision + recall ) class_metrics [ classes [ i ]] = { 'precision' : round ( precision , round_num ), 'recall' : round ( recall , round_num ), 'f1' : round ( f1 , round_num ) } res [ 'class_metrics' ] = class_metrics except Exception as e : print ( f '[Warning] Something wrong when calculate class_metrics: { e } ' ) print ( f '-> goldens: { set ( self . goldens ) } ' ) print ( f '-> predictions: { set ( self . predictions ) } ' ) print ( f '-> diff elements: { set ( self . predictions ) - set ( self . goldens ) } ' ) res [ 'class_metrics' ] = {} return res def reset ( self ): \"\"\" \u91cd\u7f6e\u79ef\u7d2f\u7684\u6570\u503c\u3002 \"\"\" self . goldens = [] self . predictions = [] if __name__ == '__main__' : from rich import print metric = ClassEvaluator () metric . add_batch ( [[ '\u8d22' , '\u7ecf' ], [ '\u8d22' , '\u7ecf' ], [ '\u4f53' , '\u80b2' ], [ '\u4f53' , '\u80b2' ], [ '\u8ba1' , '\u7b97' , '\u673a' ]], [[ '\u4f53' , '\u80b2' ], [ '\u8d22' , '\u7ecf' ], [ '\u4f53' , '\u80b2' ], [ '\u8ba1' , '\u7b97' , '\u673a' ], [ '\u8ba1' , '\u7b97' , '\u673a' ]], ) # metric.add_batch( # [0, 0, 1, 1, 0], # [1, 1, 1, 0, 0] # ) print ( metric . compute ()) print\u4ee3\u7801\u7ed3\u679c\uff1a { 'accuracy' : 0.6 , 'precision' : 0.7 , 'recall' : 0.6 , 'f1' : 0.6 , 'class_metrics' : { '\u4f53,\u80b2' : { 'precision' : 0.5 , 'recall' : 0.5 , 'f1' : 0.5 }, '\u8ba1,\u7b97,\u673a' : { 'precision' : 1.0 , 'recall' : 0.5 , 'f1' : 0.67 }, '\u8d22,\u7ecf' : { 'precision' : 0.5 , 'recall' : 1.0 , 'f1' : 0.67 } } }","title":"1.3 metirc_utils.py"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_4","text":"\u76ee\u7684\uff1a\u5b9e\u73b0\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u9a8c\u8bc1 \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/train.py \u811a\u672c\u91cc\u9762\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1amodel2train()\u548cevaluate_model() \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import os import time from transformers import AutoModelForMaskedLM , AutoTokenizer , get_scheduler import sys sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/data_handle' ) sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/utils' ) from utils.metirc_utils import ClassEvaluator from utils.common_utils import * from data_handle.data_loader import * from utils.verbalizer import Verbalizer from ptune_config import * pc = ProjectConfig () \u5b9a\u4e49model2train()\u51fd\u6570 def model2train (): model = AutoModelForMaskedLM . from_pretrained ( pc . pre_model ) tokenizer = AutoTokenizer . from_pretrained ( pc . pre_model ) verbalizer = Verbalizer ( verbalizer_file = pc . verbalizer , tokenizer = tokenizer , max_label_len = pc . max_label_len ) #\u5bf9\u53c2\u6570\u505a\u6743\u91cd\u8870\u51cf\u662f\u4e3a\u4e86\u4f7f\u51fd\u6570\u5e73\u6ed1\uff0c\u7136\u800cbias\u548clayernorm\u7684\u6743\u91cd\u53c2\u6570\u4e0d\u5f71\u54cd\u51fd\u6570\u7684\u5e73\u6ed1\u6027\u3002 #\u4ed6\u4eec\u8d77\u5230\u7684\u4f5c\u7528\u4ec5\u4ec5\u662f\u7f29\u653e\u5e73\u79fb\uff0c\u56e0\u6b64\u4e0d\u9700\u8981\u6743\u91cd\u8870\u51cf no_decay = [ \"bias\" , \"LayerNorm.weight\" ] optimizer_grouped_parameters = [ { \"params\" : [ p for n , p in model . named_parameters () if not any ( nd in n for nd in no_decay )], \"weight_decay\" : pc . weight_decay , }, { \"params\" : [ p for n , p in model . named_parameters () if any ( nd in n for nd in no_decay )], \"weight_decay\" : 0.0 , }, ] optimizer = torch . optim . AdamW ( optimizer_grouped_parameters , lr = pc . learning_rate ) model . to ( pc . device ) train_dataloader , dev_dataloader = get_data () # \u6839\u636e\u8bad\u7ec3\u8f6e\u6570\u8ba1\u7b97\u6700\u5927\u8bad\u7ec3\u6b65\u6570\uff0c\u4ee5\u4fbf\u4e8escheduler\u52a8\u6001\u8c03\u6574lr num_update_steps_per_epoch = len ( train_dataloader ) #\u6307\u5b9a\u603b\u7684\u8bad\u7ec3\u6b65\u6570\uff0c\u5b83\u4f1a\u88ab\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u7528\u6765\u786e\u5b9a\u5b66\u4e60\u7387\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u786e\u4fdd\u5b66\u4e60\u7387\u5728\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f97\u4ee5\u5408\u7406\u5730\u8c03\u8282 max_train_steps = pc . epochs * num_update_steps_per_epoch warm_steps = int ( pc . warmup_ratio * max_train_steps ) # \u9884\u70ed\u9636\u6bb5\u7684\u8bad\u7ec3\u6b65\u6570 lr_scheduler = get_scheduler ( name = 'linear' , optimizer = optimizer , num_warmup_steps = warm_steps , num_training_steps = max_train_steps , ) loss_list = [] tic_train = time . time () metric = ClassEvaluator () criterion = torch . nn . CrossEntropyLoss () global_step , best_f1 = 0 , 0 print ( '\u5f00\u59cb\u8bad\u7ec3\uff1a' ) for epoch in range ( pc . epochs ): for batch in train_dataloader : if 'token_type_ids' in batch : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits else : # \u517c\u5bb9\u4e0d\u9700\u8981 token_type_id \u7684\u6a21\u578b, e.g. Roberta-Base logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device )) . logits # \u771f\u5b9e\u6807\u7b7e mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () sub_labels = verbalizer . batch_find_sub_labels ( mask_labels ) sub_labels = [ ele [ 'token_ids' ] for ele in sub_labels ] # print(f'sub_labels--->{sub_labels}') loss = mlm_loss ( logits , batch [ 'mask_positions' ] . to ( pc . device ), sub_labels , criterion , pc . device , ) optimizer . zero_grad () loss . backward () optimizer . step () lr_scheduler . step () loss_list . append ( float ( loss . cpu () . detach ())) # # global_step += 1 if global_step % pc . logging_steps == 0 : time_diff = time . time () - tic_train loss_avg = sum ( loss_list ) / len ( loss_list ) print ( \"global step %d , epoch: %d , loss: %.5f , speed: %.2f step/s\" % ( global_step , epoch , loss_avg , pc . logging_steps / time_diff )) tic_train = time . time () if global_step % pc . valid_steps == 0 : cur_save_dir = os . path . join ( pc . save_dir , \"model_ %d \" % global_step ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) acc , precision , recall , f1 , class_metrics = evaluate_model ( model , metric , dev_dataloader , tokenizer , verbalizer ) print ( \"Evaluation precision: %.5f , recall: %.5f , F1: %.5f \" % ( precision , recall , f1 )) if f1 > best_f1 : print ( f \"best F1 performence has been updated: { best_f1 : .5f } --> { f1 : .5f } \" ) print ( f 'Each Class Metrics are: { class_metrics } ' ) best_f1 = f1 cur_save_dir = os . path . join ( pc . save_dir , \"model_best\" ) if not os . path . exists ( cur_save_dir ): os . makedirs ( cur_save_dir ) model . save_pretrained ( os . path . join ( cur_save_dir )) tokenizer . save_pretrained ( os . path . join ( cur_save_dir )) tic_train = time . time () print ( '\u8bad\u7ec3\u7ed3\u675f' ) \u5b9a\u4e49evaluate_model()\u51fd\u6570 def evaluate_model ( model , metric , data_loader , tokenizer , verbalizer ): \"\"\" \u5728\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\u5f53\u524d\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u679c\u3002 Args: model: \u5f53\u524d\u6a21\u578b metric: \u8bc4\u4f30\u6307\u6807\u7c7b(metric) data_loader: \u6d4b\u8bd5\u96c6\u7684dataloader global_step: \u5f53\u524d\u8bad\u7ec3\u6b65\u6570 \"\"\" model . eval () metric . reset () with torch . no_grad (): for step , batch in enumerate ( data_loader ): # \u517c\u5bb9\u4e0d\u9700\u8981 token_type_id \u7684\u6a21\u578b, e.g. Roberta-Base if 'token_type_ids' in batch : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device ), token_type_ids = batch [ 'token_type_ids' ] . to ( pc . device )) . logits else : logits = model ( input_ids = batch [ 'input_ids' ] . to ( pc . device ), attention_mask = batch [ 'attention_mask' ] . to ( pc . device ),) . logits # (batch, label_num) mask_labels = batch [ 'mask_labels' ] . numpy () . tolist () # \u53bb\u6389label\u4e2d\u7684[PAD] token for i in range ( len ( mask_labels )): while tokenizer . pad_token_id in mask_labels [ i ]: mask_labels [ i ] . remove ( tokenizer . pad_token_id ) # id\u8f6c\u6587\u5b57 mask_labels = [ '' . join ( tokenizer . convert_ids_to_tokens ( t )) for t in mask_labels ] # (batch, label_num) predictions = convert_logits_to_ids ( logits , batch [ 'mask_positions' ]) . cpu () . numpy () . tolist () # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = verbalizer . batch_find_main_label ( predictions ) predictions = [ ele [ 'label' ] for ele in predictions ] metric . add_batch ( pred_batch = predictions , gold_batch = mask_labels ) eval_metric = metric . compute () model . train () return eval_metric [ 'accuracy' ], eval_metric [ 'precision' ], \\ eval_metric [ 'recall' ], eval_metric [ 'f1' ], \\ eval_metric [ 'class_metrics' ] \u8c03\u7528: cd /Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning # \u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3 python train.py \u8f93\u51fa\u7ed3\u679c: ... global step 350 , epoch : 43 , loss : 0.10804 , speed : 1.20 step / s global step 360 , epoch : 44 , loss : 0.10504 , speed : 1.22 step / s global step 370 , epoch : 46 , loss : 0.10220 , speed : 1.21 step / s global step 380 , epoch : 47 , loss : 0.09951 , speed : 1.20 step / s global step 390 , epoch : 48 , loss : 0.09696 , speed : 1.20 step / s global step 400 , epoch : 49 , loss : 0.09454 , speed : 1.22 step / s Evaluation precision : 0.76000 , recall : 0.70000 , F1 : 0.70000 \u7ed3\u8bba: BERT+P-Tuning\u6a21\u578b\u5728\u8bad\u7ec3\u96c6\u4e0a\u7684\u8868\u73b0\u662fPrecion: 76% \u6ce8\u610f\uff1a\u672c\u9879\u76ee\u4e2d\u53ea\u7528\u4e8660\u6761\u6837\u672c\uff0c\u5728\u63a5\u8fd1400\u6761\u6837\u672c\u4e0a\u7cbe\u786e\u7387\u5c31\u5df2\u7ecf\u8fbe\u5230\u4e8676%\uff0c\u5982\u679c\u60f3\u8ba9\u6307\u6807\u66f4\u9ad8\uff0c\u53ef\u4ee5\u6269\u589e\u6837\u672c\u3002 \u63d0\u5347\u6a21\u578b\u6027\u80fd\uff1a \u589e\u52a0\u8bad\u7ec3\u6570\u636e\u96c6\uff08100\u6761\u5de6\u53f3\u7684\u6570\u636e\uff09\uff1a \u624b\u673a \u5916\u89c2\u65f6\u5c1a\u65b0\u6f6e \uff0c \u9002\u5408\u5e74\u8f7b\u4eba\u5c55\u73b0\u4e2a\u6027 \u3002 \u624b\u673a \u5c4f\u5e55\u663e\u793a\u6548\u679c\u975e\u5e38\u51fa\u8272 \uff0c \u89c2\u770b\u89c6\u9891\u548c\u6d4f\u89c8\u7f51\u9875\u5f88\u8212\u9002 \u3002 \u7535\u8111 \u4f7f\u7528\u4e86\u4e00\u6bb5\u65f6\u95f4\u7684\u8fd9\u6b3e\u7535\u8111 \uff0c \u786c\u76d8\u91c7\u7528WD \uff0c \u8fd0\u884c\u6d41\u7545\u65e0\u5361\u987f \uff0c \u6e29\u5ea6\u63a7\u5236\u8f83\u597d \uff0c \u6027\u4ef7\u6bd4\u4ee4\u4eba\u6ee1\u610f \u3002 \u624b\u673a \u624b\u673a\u53cd\u5e94\u7075\u654f \uff0c \u64cd\u4f5c\u754c\u9762\u7b80\u6d01\u6613\u7528 \uff0c \u975e\u5e38\u6ee1\u610f \u3002 \u7535\u5668 \u4ea7\u54c1\u6027\u80fd\u7a33\u5b9a \uff0c \u5f88\u4e0d\u9519\u54e6 \uff01 \u8d2d\u4e70\u65f6\u6709\u70b9\u62c5\u5fc3 \uff0c \u4f46\u6536\u5230\u8d27\u540e\u53d1\u73b0\u662f\u6b63\u54c1 \uff0c \u5927\u5bb6\u53ef\u4ee5\u653e\u5fc3\u8d2d\u4e70 \u3002 \u4fee\u6539\u9a8c\u8bc1\u96c6\u810f\u6570\u636e # \u539f\u59cb\u6807\u7b7e\u548c\u8bc4\u8bba\u6587\u672c\u5185\u5bb9\u4e0d\u7b26 \u5e73\u677f \u624b\u673a\u5f88\u597d \uff0c \u5c31\u662f\u5ba2\u670d\u5783\u573e\u7279\u522b\u662f\u5143\u8c46 # \u4fee\u6539\u540e \u624b\u673a \u624b\u673a\u5f88\u597d \uff0c \u5c31\u662f\u5ba2\u670d\u5783\u573e\u7279\u522b\u662f\u5143\u8c46 \u6a21\u578b\u8868\u73b0\uff1a Evaluation precision: 0.79000, recall: 0.70000, F1: 0.71000","title":"\u4e8c\u3001\u5b9e\u73b0\u6a21\u578b\u8bad\u7ec3\u51fd\u6570,\u9a8c\u8bc1\u51fd\u6570"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_5","text":"\u76ee\u7684\uff1a\u52a0\u8f7d\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e76\u6d4b\u8bd5\u6548\u679c \u4ee3\u7801\u8def\u5f84\uff1a/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/inference.py \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 import time from typing import List import torch from rich import print from transformers import AutoTokenizer , AutoModelForMaskedLM import sys sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/data_handle' ) sys . path . append ( '/Users/**/PycharmProjects/llm/prompt_tasks/P-Tuning/utils' ) from utils.verbalizer import Verbalizer from data_handle.data_preprocess import convert_example from utils.common_utils import convert_logits_to_ids \u9884\u6d4b\u4ee3\u7801\u5177\u4f53\u5b9e\u73b0 device = 'cuda:0' model_path = 'checkpoints/model_best' tokenizer = AutoTokenizer . from_pretrained ( model_path ) model = AutoModelForMaskedLM . from_pretrained ( model_path ) model . to ( device ) . eval () max_label_len = 2 # \u6807\u7b7e\u6700\u5927\u957f\u5ea6 p_embedding_num = 6 verbalizer = Verbalizer ( verbalizer_file = 'data/verbalizer.txt' , tokenizer = tokenizer , max_label_len = max_label_len ) def inference ( contents : List [ str ]): \"\"\" \u63a8\u7406\u51fd\u6570\uff0c\u8f93\u5165\u539f\u59cb\u53e5\u5b50\uff0c\u8f93\u51famask label\u7684\u9884\u6d4b\u503c\u3002 Args: contents (List[str]): \u63cf\u539f\u59cb\u53e5\u5b50\u5217\u8868\u3002 \"\"\" with torch . no_grad (): start_time = time . time () examples = { 'text' : contents } tokenized_output = convert_example ( examples , tokenizer , max_seq_len = 128 , max_label_len = max_label_len , p_embedding_num = p_embedding_num , train_mode = False , return_tensor = True ) logits = model ( input_ids = tokenized_output [ 'input_ids' ] . to ( device ), token_type_ids = tokenized_output [ 'token_type_ids' ] . to ( device ), attention_mask = tokenized_output [ 'attention_mask' ] . to ( device )) . logits predictions = convert_logits_to_ids ( logits , tokenized_output [ 'mask_positions' ]) . cpu () . numpy () . tolist () # (batch, label_num) predictions = verbalizer . batch_find_main_label ( predictions ) # \u627e\u5230\u5b50label\u5c5e\u4e8e\u7684\u4e3blabel predictions = [ ele [ 'label' ] for ele in predictions ] used = time . time () - start_time print ( f 'Used { used } s.' ) return predictions if __name__ == '__main__' : contents = [ '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa\u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' , '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d\u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' , \"\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f\" , \"\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86\uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a\u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765\u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230\" , \"\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212\u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765\" ] res = inference ( contents ) print ( 'inference label(s):' , res ) \u7ed3\u679c\u5c55\u793a { '\u5929\u53f0\u5f88\u597d\u770b\uff0c\u8eba\u5728\u8eba\u6905\u4e0a\u5f88\u60a0\u95f2\uff0c\u56e0\u4e3a\u6d3b\u52a8\u6240\u4ee5\u6211\u89c9\u5f97\u6027\u4ef7\u6bd4\u8fd8\u4e0d\u9519\uff0c\u9002\u5408\u4e00\u5bb6\u51fa \u884c\uff0c\u7279\u522b\u662f\u53bb\u8fea\u58eb\u5c3c\u4e5f\u86ee\u8fd1\u7684\uff0c\u4e0b\u6b21\u6709\u673a\u4f1a\u80af\u5b9a\u8fd8\u4f1a\u518d\u6765\u7684\uff0c\u503c\u5f97\u63a8\u8350' : '\u9152\u5e97', '\u73af\u5883\uff0c\u8bbe\u65bd\uff0c\u5f88\u68d2\uff0c\u5468\u8fb9\u914d\u5957\u8bbe\u65bd\u9f50\u5168\uff0c\u524d\u53f0\u5c0f\u59d0\u59d0\u8d85\u7ea7\u6f02\u4eae\uff01\u9152\u5e97\u5f88\u8d5e\uff0c\u65e9\u9910\u4e0d \u9519\uff0c\u670d\u52a1\u6001\u5ea6\u5f88\u597d\uff0c\u524d\u53f0\u7f8e\u7709\u5f88\u6f02\u4eae\u3002\u6027\u4ef7\u6bd4\u8d85\u9ad8\u7684\u4e00\u5bb6\u9152\u5e97\u3002\u5f3a\u70c8\u63a8\u8350' : '\u9152\u5e97', '\u7269\u6d41\u8d85\u5feb\uff0c\u9694\u5929\u5c31\u5230\u4e86\uff0c\u8fd8\u6ca1\u7528\uff0c\u5c6f\u7740\u51fa\u6e38\u7684\u65f6\u5019\u7528\u7684\uff0c\u542c\u65b9\u4fbf\u7684\uff0c\u5360\u5730\u5c0f' : '\u8863\u670d', '\u798f\u884c\u5e02\u6765\u5230\u65e0\u65e9\u96c6\u5e02\uff0c\u56e0\u4e3a\u662f\u559c\u6b22\u7684\u9762\u5305\u5e97\uff0c\u6240\u4ee5\u8dd1\u6765\u96c6\u5e02\u770b\u770b\u3002\u7b2c\u4e00\u773c\u5c31\u770b\u5230\u4e86 \uff0c\u4e4b\u524d\u5728\u5fae\u5e97\u4e70\u4e86\u5c0f\u5218\uff0c\u8fd9\u6b21\u4e70\u4e86\u8001\u5218\uff0c\u8fd8\u6709\u4e00\u76f4\u559c\u6b22\u7684\u5de7\u514b\u529b\u78c5\u86cb\u7cd5\u3002\u597d\u5947\u8001\u677f\u4e3a\u5565\u4e0d\u505a \u67e0\u6aac\u78c5\u86cb\u7cd5\u4e86\uff0c\u5fae\u5e97\u4e00\u76f4\u90fd\u662f\u4e70\u4e0d\u5230\u7684\u72b6\u6001\u3002\u56e0\u4e3a\u4e0d\u7231\u78b1\u6c34\u786c\u6b27\u4e4b\u7c7b\u7684\uff0c\u6240\u4ee5\u671f\u5f85\u8001\u677f\u591a\u6765 \u70b9\u5176\u4ed6\u5c0f\u70b9\uff0c\u997c\u5e72\u4e00\u76f4\u4e5f\u662f\u5927\u7231\uff0c\u90a3\u5929\u597d\u50cf\u4e5f\u6ca1\u770b\u5230' : '\u5e73\u677f', '\u670d\u52a1\u5f88\u7528\u5fc3\uff0c\u623f\u578b\u4e5f\u5f88\u8212\u670d\uff0c\u5c0f\u670b\u53cb\u5f88\u559c\u6b22\uff0c\u4e0b\u6b21\u53bb\u5609\u5b9a\u8fd8\u4f1a\u518d\u9009\u62e9\u3002\u5e8a\u94fa\u67d4\u8f6f\u8212 \u9002\uff0c\u665a\u4e0a\u4f11\u606f\u5f88\u5b89\u9038\uff0c\u9694\u97f3\u6548\u679c\u4e0d\u9519\u8d5e\uff0c\u4e0b\u6b21\u8fd8\u4f1a\u6765' : '\u9152\u5e97' }","title":"\u4e09\u3001\u5b9e\u73b0\u6a21\u578b\u9884\u6d4b\u51fd\u6570"},{"location":"%E7%AC%AC%E5%85%AD%E7%AB%A0%EF%BC%9A%E6%96%B0%E9%9B%B6%E5%94%AE%E8%A1%8C%E4%B8%9A%E8%AF%84%E4%BB%B7%E5%86%B3%E7%AD%96%E7%B3%BB%E7%BB%9F/07-BERT%2BP-Tuning%E6%96%B9%E5%BC%8F%E6%A8%A1%E5%9E%8B%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%AE%AD%E7%BB%83.html#_6","text":"\u672c\u5c0f\u8282\u5b9e\u73b0\u4e86\u57fa\u4e8eBERT+P-Tuning\u6a21\u578b\u7684\u6784\u5efa, \u5e76\u5b8c\u6210\u4e86\u8bad\u7ec3\u548c\u6d4b\u8bd5\u8bc4\u4f30.","title":"\u5c0f\u8282\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html","text":"\u5927\u6a21\u578b\u63d0\u793a\u5de5\u7a0b\u6307\u5357 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u4ec0\u4e48\u662f\u63d0\u793a\u5de5\u7a0b \u638c\u63e1\u63d0\u793a\u5de5\u7a0b\u7684\u8bbe\u8ba1\u6280\u5de7 1 \u6982\u5ff5 \u00b6 \u63d0\u793a\u5de5\u7a0b\uff08Prompt Engineering\uff09\uff0c\u4e5f\u79f0\u4e3a In-Context Prompting\uff0c\u662f\u6307\u5728\u4e0d\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u4e0e \u5927\u6a21\u578b\u4ea4\u4e92\u4ee5\u5f15\u5bfc\u5176\u884c\u4e3a\u4ee5\u83b7\u5f97\u6240\u9700\u7ed3\u679c\u7684\u65b9\u6cd5\u3002 \u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\uff0cPrompt\u6307\u7684\u662f\u7528\u6237\u7ed9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u51fa\u7684\u6307\u4ee4\u3002\u4f8b\u5982\uff0c\u201c\u300c\u8bb2\u4e2a\u7b11\u8bdd\u300d\u201d\u3001\u201c\u300c\u7528Python\u7f16\u4e2a\u8d2a\u5403\u86c7\u6e38\u620f\u300d\u201d\u3001\u201c\u300c\u5199\u5c01\u60c5\u4e66\u300d\"\u7b49\u3002\u867d\u7136\u770b\u4f3c\u7b80\u5355\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0cPrompt\u7684\u8bbe\u8ba1\u5bf9\u4e8e\u6a21\u578b\u7684\u7ed3\u679c\u5f71\u54cd\u5f88\u5927\u3002\u56e0\u6b64\u5982\u4f55\u8bbe\u8ba1prompt\uff0c\u8fdb\u800c\u4e0e\u6a21\u578b\u66f4\u597d\u7684\u4ea4\u4e92\uff0c\u662f\u7814\u7a76\u4eba\u5458\u5fc5\u5907\u7684\u5fc5\u4e0d\u53ef\u5c11\u7684\u6280\u80fd\uff08\u63d0\u793a\u5de5\u7a0b\uff09\u3002 \u63d0\u793a\u5de5\u7a0b\u4e0d\u4ec5\u4ec5\u662f\u5173\u4e8e\u8bbe\u8ba1\u548c\u7814\u53d1\u63d0\u793a\u8bcd\u3002\u5b83\u5305\u542b\u4e86\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u548c\u7814\u53d1\u7684\u5404\u79cd\u6280\u80fd\u548c\u6280\u672f\u3002\u63d0\u793a\u5de5\u7a0b\u5728\u5b9e\u73b0\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u3001\u5bf9\u63a5\uff0c\u4ee5\u53ca\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u65b9\u9762\u90fd\u8d77\u7740\u91cd\u8981\u4f5c\u7528\u3002\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6765\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u4e5f\u53ef\u4ee5\u8d4b\u80fd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6bd4\u5982\u501f\u52a9\u4e13\u4e1a\u9886\u57df\u77e5\u8bc6\u548c\u5916\u90e8\u5de5\u5177\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3002 2 \u63d0\u793a\u5de5\u7a0b\u7684\u539f\u5219 \u00b6 \u57fa\u4e8eOpenAI\u5b98\u7f51\u6587\u6863\uff0c\u6211\u4eec\u63d0\u70bc\u51fa\u4e865\u6761\u5927\u539f\u5219\uff1a \u6e05\u6670\u7684\u6307\u4ee4 \u6587\u672c\u53c2\u8003 \u590d\u6742\u4efb\u52a1\u62c6\u5206\u7b80\u5355\u5b50\u4efb\u52a1 \u7ed9\u6a21\u578b\"\u601d\u8003\"\u7684\u65f6\u95f4 \u501f\u52a9\u5916\u90e8\u5de5\u5177 \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u5bf9\u6bcf\u4e00\u79cd\u5177\u4f53\u7684\u539f\u5219\u8fdb\u884c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u4e3e\u4f8b\u5b9e\u65f6\uff0c\u4ee5\u5e2e\u52a9\u6211\u4eec\u5728\u65e5\u5e38\u5de5\u4f5c\u51c6\u786e\u7684\u4f7f\u7528LLM\u3002 2.1 \u6e05\u6670\u7684\u6307\u4ee4 \u00b6 \u4efb\u4f55Prompt\u6280\u5de7\uff0c\u90fd\u4e0d\u5982\u6e05\u6670\u7684\u8868\u8fbe\u4f60\u7684\u9700\u6c42\u3002\u8fd9\u5c31\u7c7b\u4f3c\u4eba\u4e0e\u4eba\u6c9f\u901a\uff0c\u5982\u679c\u8bdd\u8bf4\u4e0d\u660e\u767d\uff0c\u4e0d\u53ef\u80fd\u8ba9\u522b\u4eba\u7406\u89e3\u4f60\u7684\u601d\u60f3\u3002\u56e0\u6b64\uff0c\u5199\u51fa\u6e05\u6670\u7684\u6307\u4ee4\uff0c\u662f\u6838\u5fc3\u3002 \u90a3\u4e48\u5982\u4f55\u5199\u51fa\u6e05\u6670\u7684\u6307\u4ee4\u5462\uff1f\u4e0b\u9762\u7f57\u5217\u51e0\u4e2a\u5c0f\u6280\u5de7\uff1a 2.1.1 \u8be6\u7ec6\u7684\u63cf\u8ff0 \u00b6 \u5f53\u6211\u4eec\u8fdb\u884c\u6a21\u578b\u7684\u63d0\u95ee\u65f6\uff0c\u4e0d\u8981\u63cf\u8ff0\u7684\u592a\u7b3c\u7edf\uff0c\u800c\u662f\u5c3d\u91cf\u591a\u7684\u63d0\u4f9b\u91cd\u8981\u7684\u8be6\u7ec6\u4fe1\u606f\u6216\u4e0a\u4e0b\u6587. eg: \u4e0d\u8981\u76f4\u63a5\u8bf4\uff0c\"\u5e2e\u6211\u5199\u4e00\u5c01\u60c5\u4e66\"\uff1b\u800c\u662f\u8bf4\uff1a\"\u7528\u4e00\u4e9b\u6e29\u67d4\u7684\u8bdd\u8bed\u5199\u4e00\u5c01\u60c5\u4e66\uff0c\u6765\u8868\u8fbe\u6211\u5bf9\u4f60\u7684\u4ef0\u6155\u548c\u601d\u5ff5\u3002\u6700\u540e\uff0c\u6211\u8981\u6c42\u4e66\u5199\u5b57\u4f53\u6570\u8981\u4e0d\u4f4e\u4e8e500\u4e2a\u5b57\" 2.1.2 \u8ba9\u6a21\u578b\u5145\u5f53\u67d0\u4e2a\u89d2\u8272 \u00b6 \u5f53\u6211\u4eec\u4f7f\u7528\u5927\u6a21\u578b\u65f6\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u5145\u5f53\u4e00\u4e2a\u89d2\u8272\uff0c\u8fd9\u6837\u6a21\u578b\u4f1a\u66f4\u4e13\u4e1a\u66f4\u660e\u786e\u7684\u5bf9\u4f60\u7684\u95ee\u9898\u8fdb\u884c\u56de\u590d. Eg\uff1a\u6211\u9700\u8981\u4f60\u5145\u5f53\u4e00\u4e2aAI\u7b97\u6cd5\u9762\u8bd5\u5b98\u7684\u89d2\u8272\uff0c\u8981\u6c42\u4f60\u81ea\u4e3b\u7684\u5bf9\u6211\u8fdb\u884cAI\u9762\u8bd5\u8fc7\u7a0b\u4e2d\u5e38\u8003\u7684\u9762\u8bd5\u9898\uff0c\u4f60\u53ef\u4ee5\u4e00\u6b21\u8bf4\u4e00\u4e2a\u95ee\u9898\uff0c\u7136\u540e\u6211\u56de\u7b54\u5b8c\uff0c\u4f60\u518d\u51fa\u7b2c\u4e8c\u9053\u9898 2.1.3 \u4f7f\u7528\u5206\u9694\u7b26\u6807\u660e\u8f93\u5165\u7684\u4e0d\u540c\u90e8\u5206 \u00b6 \u4e2d\u62ec\u53f7\u3001XML\u6807\u7b7e\u3001\u4e09\u5f15\u53f7\u7b49\u5206\u9694\u7b26\u53ef\u4ee5\u5e2e\u52a9\u5212\u5206\u8981\u533a\u522b\u5bf9\u5f85\u7684\u6587\u672c\uff0c\u4e5f\u53ef\u4ee5\u5e2e\u52a9\u6a21\u578b\u66f4\u597d\u7684\u7406\u89e3\u6587\u672c\u5185\u5bb9\u3002\u5e38\u7528''''''\u628a\u5185\u5bb9\u6846\u8d77\u6765 eg\uff1a\u752820\u4e2a\u5b57\u7b26\u603b\u7ed3\u7531\u4e09\u5f15\u53f7\u5206\u5272\u7684\u6587\u672c\u3002\"\"\"\u5728\u6b64\u63d2\u5165\u6587\u672c\"\"\" 2.1.4 \u5bf9\u4efb\u52a1\u6307\u5b9a\u6b65\u9aa4 \u00b6 \u5bf9\u4e8e\u53ef\u4ee5\u62c6\u5206\u7684\u4efb\u52a1\u53ef\u4ee5\u5c3d\u91cf\u62c6\u5f00\uff0c\u6700\u597d\u80fd\u4e3a\u5176\u6307\u5b9a\u4e00\u7cfb\u5217\u6b65\u9aa4\uff0c\u660e\u786e\u6b65\u9aa4\u53ef\u4ee5\u8ba9\u6a21\u578b\u66f4\u5bb9\u6613\u5b9e\u73b0\u5b83\u4eec\u3002 eg\uff1a\u5229\u7528\u4e0b\u9762\u5206\u6b65\u60c5\u51b5\u6765\u54cd\u5e94\u7528\u6237\u7684\u8f93\u5165\u3002 \u6b65\u9aa41: \"\"\"\"\u7528\u6237\u8f93\u5165\u6587\u672c\"\"\"\"\uff0c\u7528\u4e00\u53e5\u8bdd\u603b\u7ed3\u8fd9\u6bb5\u6587\u672c\uff0c\u5e76\u52a0\u4e0a\u524d\u7f00\"Summary\". \u6b65\u9aa42: \u5c06\u6b65\u9aa41\u4e2d\u7684\u6458\u8981\u7ffb\u8bd1\u6210\u82f1\u8bed\uff0c\u5e76\u6dfb\u52a0\u524d\u7f00\"\u7ffb\u8bd1\uff1a\" 2.1.5 \u63d0\u4f9b\u4f8b\u5b50 \u00b6 \u672c\u8d28\u7c7b\u4f3c\u4e8efew-shot leaning\u3002\u5148\u6254\u7ed9\u5927\u6a21\u578b\u4e3e\u4f8b\uff0c\u7136\u540e\u8ba9\u6a21\u578b\u6309\u7167\u4f8b\u5b50\u6765\u8f93\u51fa eg: \u6309\u7167\u8fd9\u53e5\u8bc4\u8bba\u6587\u672c\u7684\u683c\u5f0f\uff1a'\"\"\u7528\u6237\u8f93\u5165\u6587\u672c\"\"'\uff0c\u5e2e\u6211\u521b\u9020\u65b0\u7684\u6837\u672c 2.1.6 \u6307\u5b9a\u8f93\u51fa\u957f\u5ea6 \u00b6 \u53ef\u4ee5\u8981\u6c42\u6a21\u578b\u751f\u6210\u7ed9\u5b9a\u76ee\u6807\u957f\u5ea6\u7684\u8f93\u51fa\u3002\u76ee\u6807\u8f93\u51fa\u957f\u5ea6\u53ef\u4ee5\u6839\u636e\u5355\u8bcd\u3001\u53e5\u5b50\u3001\u6bb5\u843d\u3001\u8981\u70b9\u7b49\u7684\u8ba1\u6570\u6765\u6307\u5b9a\u3002\u4e2d\u6587\u6548\u679c\u4e0d\u660e\u663e\uff0c\u540c\u65f6\u4f60\u7ed9\u5b9a\u7684\u957f\u5ea6\u53ea\u662f\u4e2a\u5927\u6982, \u591a\u5c11\u4e2a\u5b57\u8fd9\u79cd\u80af\u5b9a\u4f1a\u4e0d\u7cbe\u51c6\uff0c\u4f46\u662f\u50cf\u591a\u5c11\u6bb5\u8fd9\u79cd\u6548\u679c\u76f8\u5bf9\u8f83\u597d. eg: \u7528\u4e09\u4e2a\u6bb5\u843d\u300130\u4e2a\u5b57\u7b26\u6982\u62ec\u7531\u4e09\u5f15\u53f7\u5206\u9694\u7684\u6587\u672c\u3002\"\"\"\u5728\u6b64\u63d2\u5165\u4f60\u7684\u6587\u672c\"\"\" 2.2 \u6587\u672c\u53c2\u8003 \u00b6 \u6587\u672c\u53c2\u8003\u76ee\u7684\uff1a\u57fa\u4e8e\u6587\u672c\u6587\u6863\uff0c\u8f85\u52a9\u5927\u6a21\u578b\u95ee\u7b54\uff0c\u964d\u4f4e\u6a21\u578b\"\u5e7b\u89c9\"\uff08\u4e00\u672c\u6b63\u7ecf\u7684\u80e1\u8bf4\u516b\u9053\uff09\u95ee\u9898\u3002 2.2.1 \u4f7f\u7528\u53c2\u8003\u6587\u672c\u4f5c\u7b54 \u00b6 \u7ecf\u5178\u7684\u77e5\u8bc6\u5e93\u7528\u6cd5\uff0c\u8ba9\u5927\u6a21\u578b\u4f7f\u7528\u6211\u4eec\u63d0\u4f9b\u7684\u4fe1\u606f\u6765\u7ec4\u6210\u7b54\u6848\u3002 eg\uff1a\u6839\u636e\u4e0b\u6587\u4e2d\u4e09\u91cd\u5f15\u53f7\u5f15\u8d77\u6765\u7684\u6587\u7ae0\u6765\u56de\u7b54\u95ee\u9898\u3002\u5982\u679c\u5728\u6587\u7ae0\u4e2d\u627e\u4e0d\u5230\u7b54\u6848\uff0c\u8bf7\u5199\u201c\u6211\u627e\u4e0d\u5230\u7b54\u6848\u201d\uff0c\u4e0d\u8981\u81ea\u5df1\u9020\u7b54\u6848\u3002\"\"\"<\u5728\u6b64\u63d2\u5165\u6587\u6863>\"\"\"\"\"\"<\u5728\u6b64\u63d2\u5165\u6587\u6863>\"\"\" \u95ee\u9898\uff1a<\u5728\u6b64\u63d2\u5165\u95ee\u9898> 2.3 \u590d\u6742\u4efb\u52a1\u62c6\u5206\u4e3a\u7b80\u5355\u5b50\u4efb\u52a1 \u00b6 \u7c7b\u4f3c\u4e8e\u4eba\u5de5\uff0c\u5982\u679c\u4f60\u4f5c\u4e3a\u9886\u5bfc\uff0c\u8ba9\u4e0b\u5c5e\u4e00\u6b21\u6027\u5b8c\u6210\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u4e8b\uff0c\u90a3\u4e48\u51fa\u9519\u7684\u6982\u7387\u662f\u5f88\u5927\u7684\uff0c\u5f88\u591a\u5927\u9879\u76ee\u4e5f\u662f\u8fd9\u6837\uff0c\u4f60\u751a\u81f3\u65e0\u4ece\u4e0b\u624b\u3002\u6240\u4ee5\u6211\u4eec\u7ecf\u5e38\u5728\u5de5\u4f5c\u4e2d\uff0c\u90fd\u8981\u8bb2\u4efb\u52a1\uff0c\u62c6\u5404\u79cd\u7ec6\u8282\u3001\u5b50\u4efb\u52a1\u3001\u5b50\u76ee\u6807\u7b49\u7b49\u3002\u5927\u6a21\u578b\u4e5f\u662f\u540c\u6837\u7684\u9053\u7406\u3002 \u628a\u590d\u6742\u7684\u4efb\u52a1\u7ed9\u62c6\u4e3a\u66f4\u4e3a\u7b80\u5355\u7684\u5b50\u4efb\u52a1\uff0c\u5927\u6a21\u578b\u4f1a\u6709\u66f4\u597d\u7684\u8868\u73b0 2.3.1 \u5bf9\u7528\u6237query\u8fdb\u884c\u610f\u56fe\u8bc6\u522b \u00b6 \u610f\u56fe\u8bc6\u522b\u662f\u4e00\u4e2a\u5f88\u7ecf\u5178\u7684\u4f8b\u5b50\u3002\u6bd4\u5982\u5728\u5ba2\u670d\u573a\u666f\u4e2d\uff0c\u7528\u6237\u95ee\u4e86\u4e00\u4e2a\u95ee\u9898\u201c\u6211\u65ad\u7f51\u4e86\u548b\u6574\u201d\uff0c\u4f60\u8ba9\u5927\u6a21\u578b\u76f4\u63a5\u56de\u590d\u5176\u5b9e\u662f\u633a\u9e21\u808b\u7684\uff0c\u4f46\u662f\u8fd9\u65f6\u5019\u5c31\u53ef\u4ee5\u62c6\uff0c\u5148\u62c6\u5927\u5206\u7c7b\u4e0b\u7684\u610f\u56fe\u8bc6\u522b\uff0c\u518d\u56de\u7b54\u5177\u4f53\u7c7b\u522b\u7684\u95ee\u9898\u3002 \u6b65\u9aa41, \u5148\u5224\u65ad\u95ee\u9898\u7c7b\u522b\uff1a \u63a5\u4e0b\u6765\uff0c\u5c06\u4e3a\u60a8\u63d0\u4f9b\u5ba2\u6237\u670d\u52a1\u67e5\u8be2\uff0c\u5c06\u6bcf\u4e2a\u67e5\u8be2\u5206\u4e3a\u4e3b\u8981\u7c7b\u522b\u548c\u6b21\u8981\u7c7b\u522b\u3002\u63d0\u4f9bjson\u683c\u5f0f\u7684\u8f93\u51fa\uff0c\u5177\u4f53\u5185\u5bb9\u5982\u4e0b\uff1a \u4e3b\u8981\u7c7b\u522b\uff1a\u8ba1\u8d39\u3001\u6280\u672f\u652f\u6301\u3001\u8d26\u6237\u7ba1\u7406 \u8ba1\u8d39\u6b21\u8981\u7c7b\u522b\uff1a1.\u53d6\u6d88\u8ba2\u9605\uff1b2.\u6761\u4ef6\u4ed8\u6b3e\u65b9\u5f0f\uff1b3.\u6536\u8d39\u8bf4\u660e\uff1b4.\u5bf9\u6536\u8d39\u63d0\u51fa\u4e89\u8bae \u6280\u672f\u652f\u6301\u6b21\u8981\u7c7b\u522b\uff1a1.\u6545\u969c\u6392\u9664\uff1b2.\u8bbe\u5907\u517c\u5bb9\u6027\uff1b3.\u8f6f\u4ef6\u66f4\u65b0 \u8d26\u6237\u7ba1\u7406\u6b21\u8981\u7c7b\u522b\uff1a1.\u91cd\u7f6e\u5bc6\u7801\uff1b2.\u66f4\u65b0\u4e2a\u4eba\u4fe1\u606f\uff1b3.\u5173\u95ed\u5e10\u6237\uff1b4.\u8d26\u6237\u5b89\u5168 \u5982\u679c\u5927\u6a21\u578b\u6839\u636e\u6b65\u9aa41\uff0c\u77e5\u9053\u201c\u6211\u65ad\u7f51\u4e86\u548b\u6574\u201d\u662f\u5c5e\u4e8e\u6280\u672f\u652f\u6301\u4e2d\u7684\u6545\u969c\u6392\u9664\u4e86\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u7eed\u7b2c\u4e8c\u4e2a\u6b65\u9aa4 \u6b65\u9aa42\uff0c\u6839\u636e\u7c7b\u522b\u5728\u5f97\u5230\u5177\u4f53\u7684\u89e3\u51b3\u65b9\u6848: \u60a8\u5c06\u6536\u5230\u9700\u8981\u5728\u6280\u672f\u652f\u6301\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u6545\u969c\u6392\u9664\u7684\u5ba2\u6237\u670d\u52a1\u67e5\u8be2\u3002\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5e2e\u52a9\u7528\u6237\uff1a \u8981\u6c42\u4ed6\u4eec\u68c0\u67e5\u4e0e\u8def\u7531\u5668\u76f8\u8fde\u7684\u6240\u6709\u7535\u7f06\u662f\u5426\u8fde\u63a5\u3002\u8bf7\u6ce8\u610f\uff0c\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u7535\u7f06\u5e38\u5e38\u4f1a\u677e\u52a8\u3002 \u5982\u679c\u6240\u6709\u7535\u7f06\u8fde\u63a5\u6b63\u5e38\u4e14\u95ee\u9898\u4ecd\u7136\u5b58\u5728\uff0c\u8bf7\u8be2\u95ee\u4ed6\u4eec\u4f7f\u7528\u7684\u8def\u7531\u5668\u578b\u53f7\u3002 2.3.2 \u5904\u7406\u957f\u5bf9\u8bdd\uff1a\u603b\u7ed3\u6216\u8fc7\u6ee4\u4fe1\u606f \u00b6 \u56e0\u4e3a\u5927\u6a21\u578b\u90fd\u5177\u6709\u56fa\u5b9a\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u56e0\u6b64\u7528\u6237\u548c\u6a21\u578b\u4e4b\u95f4\u7684\u5bf9\u8bdd\u65e0\u6cd5\u65e0\u9650\u671f\u5730\u7ee7\u7eed\u3002\u89e3\u51b3\u6b64\u95ee\u9898\u6709\u591a\u79cd\u89e3\u51b3\u65b9\u6cd5\uff1a \u7b2c\u4e00\u4e2a\u65b9\u6cd5\u662f\u603b\u7ed3\u4e4b\u524d\u7684\u5bf9\u8bdd\u8bb0\u5f55\u3002\u4e00\u65e6\u8f93\u5165\u7684\u5927\u5c0f\u8fbe\u5230\u9884\u5b9a\u7684\u9608\u503c\u957f\u5ea6\uff0c\u6a21\u578b\u5c31\u4f1a\u81ea\u52a8\u628a\u4e00\u90e8\u5206\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002 \u53e6\u5916\u4e00\u79cd\u529e\u6cd5\u5c31\u662f\u5728\u6574\u4e2a\u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\uff0c\u8ba9\u6a21\u578b\u5728\u80cc\u540e\u4e0d\u65ad\u5730\u628a\u5bf9\u8bdd\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002\u8fd9\u5c31\u50cf\u4f60\u5728\u8bfb\u4e00\u672c\u4e66\u7684\u65f6\u5019\uff0c\u53ef\u80fd\u4f1a\u65f6\u4e0d\u65f6\u5730\u5728\u8111\u5b50\u91cc\u56de\u987e\u4e00\u4e0b\u4e4b\u524d\u7684\u60c5\u8282\uff0c\u8fd9\u6837\u5c31\u4e0d\u4f1a\u5fd8\u8bb0\u6545\u4e8b\u7684\u4e3b\u7ebf\u3002 \u8fd9\u4e24\u79cd\u65b9\u6cd5\u90fd\u884c\uff0c\u6216\u8005\u8fd8\u53ef\u4ee5\u628a\u8fc7\u53bb\u7684\u6240\u6709\u804a\u5929\u8bb0\u5f55\u5b58\u6210\u5411\u91cf\u5e93\uff0c\u540e\u7eed\u8ddf\u7528\u6237\u5bf9\u8bdd\u7684\u65f6\u5019\u52a8\u6001\u67e5\u8be2\u5d4c\u5165\uff0c\u4e5f\u53ef\u4ee5\u3002 2.3.3 \u5206\u6bb5\u603b\u7ed3\u957f\u6587\u672c\u5e76\u9012\u5f52\u6784\u5efa\u5b8c\u6574\u6458\u8981 \u00b6 \u7c7b\u4f3c\u4e8eChatGPT\u7684\u5927\u6a21\u578b \u662f\u4e2a\u6709\u70b9\u50cf\u6709\u8bb0\u5fc6\u529b\u9650\u5236\u7684\u673a\u5668\u4eba\uff0c\u4ed6\u8bb0\u4f4f\u7684\u4e1c\u897f\u957f\u5ea6\u6709\u9650\u3002\u56e0\u6b64\uff0c\u5982\u679c\u8ba9\u4ed6\u4e00\u53e3\u6c14\u8bfb\u5b8c\u4e00\u672c\u975e\u5e38\u957f\u7684\u4e66\u7136\u540e\u518d\u603b\u7ed3\uff0c\u4ed6\u53ef\u80fd\u4f1a\u8bb0\u4e0d\u4f4f\u6240\u6709\u7684\u5185\u5bb9\u3002\u90a3\u600e\u4e48\u529e\u5462\uff1f \u6211\u4eec\u53ef\u4ee5\u7528\u4e00\u79cd\u201c\u5206\u6bb5\u603b\u7ed3\uff0c\u518d\u6c47\u603b\u201d\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5c31\u597d\u6bd4\uff0c\u4f60\u5728\u5b66\u4e60\u5f88\u957f\u7684\u4e00\u7bc7\u6587\u7ae0\u6216\u8005\u4e00\u672c\u4e66\u7684\u65f6\u5019\uff0c\u4f60\u53ef\u80fd\u4f1a\u5148\u603b\u7ed3\u6bcf\u4e00\u5c0f\u8282\u7684\u5185\u5bb9\uff0c\u7136\u540e\u518d\u628a\u8fd9\u4e9b\u5c0f\u8282\u7684\u603b\u7ed3\u653e\u5728\u4e00\u8d77\uff0c\u518d\u505a\u4e00\u6b21\u603b\u7ed3\uff0c\u8fd9\u6837\u5c31\u80fd\u5f97\u5230\u6574\u4e2a\u6587\u7ae0\u6216\u8005\u4e66\u7684\u603b\u7ed3\u4e86\u3002 \u5904\u7406\u957f\u5bf9\u8bdd\u548c\u957f\u6587\u7684\u57fa\u672c\u65b9\u6cd5\uff0c\u57fa\u672c\u662f\u4e00\u6837\u7684\uff1a\u603b\u7ed3\u524d\u4e00\u90e8\u5206\u7684\u65f6\u5019\uff0c\u5e26\u4e0a\u4e4b\u524d\u7684\u5185\u5bb9\u3002 \u4e0d\u540c\u70b9\u662f\uff1a\u6709\u7684\u957f\u6587\u7ae0\u8282\u4e4b\u95f4\uff0c\u5173\u7cfb\u8f83\u5f31\uff0c\u53ef\u4ee5\u7528\u5206\u6bb5\u603b\u7ed3\uff0c\u518d\u6c47\u603b\u7684\u65b9\u6cd5\uff0c\u4e0d\u7528\u6bcf\u6b21\u603b\u7ed3\u90fd\u5e26\u4e0a\u4e4b\u524d\u7684\u603b\u7ed3\u3002 2.4 \u7ed9\u6a21\u578b\"\u601d\u8003\"\u7684\u65f6\u95f4 \u00b6 \u7ed9\u6a21\u578b\u601d\u8003\u5b9e\u8df5\uff0c\u672c\u8d28\u4e3a\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\uff0cChain-of-Thought Prompting\u3002\u76ee\u7684\uff0c\u8ba9\u6a21\u578bthink step by step\uff08\u4e00\u6b65\u6b65\u601d\u8003\uff09. \u6bd4\u5982\uff0c\u76f4\u63a5\u95ee\u4f604234567*375821\u7b49\u4e8e\u591a\u5c11\uff0c\u4f60\u80af\u5b9a\u4e5f\"\u61f5\"\uff0c\u4f46\u662f\u5982\u679c\u7ed9\u4f60\u65f6\u95f4\u8ba9\u4f60\u4e00\u6b65\u6b65\u8ba1\u7b97\uff0c\u5b66\u8fc7\u5c0f\u5b66\u6570\u5b66\u7684\u90fd\u80fd\u7b97\u51fa\u6765\u5bf9\u5427. \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u63a2\u8ba8\u5982\u4f55\u7ed9ChatGPT\u8db3\u591f\u7684\u65f6\u95f4\u6765\u201c\u601d\u8003\u201d\uff0c\u4ee5\u5f97\u51fa\u66f4\u51c6\u786e\u548c\u5408\u7406\u7684\u7b54\u6848\u3002 2.4.1 \u5f15\u5bfc\u6a21\u578b\u5728\u5f97\u51fa\u7ed3\u8bba\u524d\u751f\u6210\u81ea\u5df1\u7684\u7b54\u6848 \u00b6 \u6709\u65f6\u5019\uff0c\u6211\u4eec\u5e0c\u671bChatGPT\u80fd\u591f\u5728\u5f97\u51fa\u6700\u7ec8\u7b54\u6848\u4e4b\u524d\uff0c\u5148\u751f\u6210\u4e00\u4e9b\u81ea\u5df1\u7684\u7b54\u6848\uff0c\u7136\u540e\u518d\u8fdb\u884c\u9009\u62e9\u548c\u8c03\u6574\u3002\u8fd9\u6837\u53ef\u4ee5\u5f15\u5bfc\u6a21\u578b\u601d\u8003\u95ee\u9898\uff0c\u5e76\u6fc0\u53d1\u4e00\u4e9b\u65b0\u7684\u521b\u610f\u3002 \u7528\u6237\uff1a \u95ee\u9898\uff1a1+1=3\u662f\u5426\u6b63\u786e \u7b54\u6848\uff1a\u6b63\u786e\uff0c\u56e0\u4e3a\u5728\u4e09\u7ef4\u7a7a\u95f4\u91cc1+1\u5219\u662f\u7acb\u4f53\u7684\uff0c\u6240\u4ee5\u7b49\u4e8e3\u3002\u8bf7\u5224\u65ad\u7b54\u6848\u662f\u5426\u6b63\u786e\u3002\u8981\u6c42\uff1a\u5224\u65ad\u4e4b\u524d\u5148\u81ea\u5df1\u601d\u8003\u7b54\u6848\uff0c\u7136\u540e\u518d\u5224\u65ad\u7b54\u6848\u662f\u5426\u6b63\u786e\u3002 ChatGPT\uff1a\u5728\u6807\u51c6\u7684\u6570\u5b66\u8fd0\u7b97\u4e2d\uff0c1+1\u7684\u7ed3\u679c\u662f2\u3002\u7136\u800c\uff0c\u4f60\u63d0\u5230\u4e86\u5728\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u7684\u7acb\u4f53\u6982\u5ff5\u3002\u5728\u6570\u5b66\u4e0a\uff0c1+1\u4ecd\u7136\u7b49\u4e8e2\uff0c\u5373\u4f7f\u6211\u4eec\u8003\u8651\u5230\u4e0d\u540c\u7684\u7ef4\u5ea6\u3002\u56e0\u6b64\uff0c\u6839\u636e\u6807\u51c6\u7684\u6570\u5b66\u8fd0\u7b97\u89c4\u5219\uff0c\u7b54\u6848\u5e94\u8be5\u662f\u4e0d\u6b63\u786e\u3002\u5982\u679c\u95ee\u9898\u6d89\u53ca\u5230\u7279\u6b8a\u7684\u4e0a\u4e0b\u6587\u6216\u9886\u57df\uff0c\u8bf7\u63d0\u4f9b\u66f4\u591a\u7684\u4fe1\u606f\u4ee5\u4fbf\u6211\u66f4\u597d\u5730\u7406\u89e3\u5e76\u56de\u7b54\u3002 \u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5728\u5f97\u51fa\u7ed3\u8bba\u524d\u751f\u6210\u81ea\u5df1\u7684\u7b54\u6848\uff0c\u6211\u4eec\u53ef\u4ee5\u6fc0\u53d1\u6a21\u578b\u7684\u601d\u8003\u8fc7\u7a0b\uff0c\u5e76\u83b7\u5f97\u66f4\u52a0\u4e30\u5bcc\u548c\u591a\u6837\u7684\u56de\u7b54\u3002 2.4.2 \u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\uff0c\u53ea\u5c55\u793a\u6700\u7ec8\u7b54\u6848 \u00b6 \u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u80fd\u66f4\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\uff0c\u800c\u4e0d\u662f\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u901a\u8fc7\u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5316\u56de\u7b54\uff0c\u5e76\u4f7f\u5176\u66f4\u52a0\u76f4\u63a5\u548c\u6613\u4e8e\u7406\u89e3\u3002 \u7528\u6237\uff1a\u5982\u4f55\u7528Python\u53cd\u8f6c\u4e00\u4e2a\u5b57\u7b26\u4e32\u3002\u8981\u6c42\uff1a\u53ea\u9700\u8981\u8f93\u51fa\u4ee3\u7801\uff0c\u4e0d\u8f93\u51fa\u5176\u5b83\u4efb\u4f55\u6587\u5b57\u3002 ChatGPT\uff1a string = \"Hello, World!\" reversed_string = string [:: - 1 ] print ( reversed_string ) 2.4.3 \u5904\u7406\u7b54\u6848\u4e0d\u5b8c\u6574\u7684\u95ee\u9898 \u00b6 \u6709\u65f6\uff0cChatGPT\u53ef\u80fd\u4f1a\u751f\u6210\u4e00\u4e9b\u4e0d\u5b8c\u6574\u7684\u56de\u7b54\uff0c\u7f3a\u5c11\u4e00\u4e9b\u91cd\u8981\u7684\u7ec6\u8282\u6216\u4fe1\u606f\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8865\u5145\u7ec6\u8282\u6216\u63d0\u4f9b\u989d\u5916\u7684\u4fe1\u606f\u6765\u5b8c\u5584\u56de\u7b54\u3002 \u7528\u6237: JavaScript\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\u5417\uff1f\u8981\u6c42\uff1a\u53ea\u9700\u8981\u56de\u7b54\u6700\u7ec8\u7ed3\u8bba\u3002 ChatGPT\uff1a \u6ca1\u6709\u7edd\u5bf9\u7684\u6700\u597d\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u56e0\u4e3a\u6bcf\u79cd\u8bed\u8a00\u90fd\u6709\u81ea\u5df1\u7684\u4f18\u70b9\u548c\u9002\u7528\u573a\u666f\u3002\u4e0d\u540c\u7684\u8bed\u8a00\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u9700\u6c42\u3002\u6240\u4ee5\uff0cJavaScript\u5e76\u4e0d\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\uff0c\u4f46\u5b83\u5728Web\u5f00\u53d1\u4e2d\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u548c\u5f3a\u5927\u7684\u751f\u6001\u7cfb\u7edf\u3002 \u7528\u6237\uff1a\u5728\u524d\u7aef\u5f00\u53d1\u4e2d\uff0cJavaScript\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\u5417\uff1f\u8981\u6c42\uff1a\u53ea\u9700\u8981\u56de\u7b54\u6700\u7ec8\u7ed3\u8bba ChatGPT: \u5728\u524d\u7aef\u5f00\u53d1\u4e2d\uff0cJavaScript\u662f\u6700\u4e3b\u8981\u7684\u8bed\u8a00\uff0c\u5e76\u4e14\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u548c\u5f3a\u5927\u7684\u751f\u6001\u7cfb\u7edf\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u8bf4\u5728\u524d\u7aef\u5f00\u53d1\u4e2d\uff0cJavaScript\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\u4e4b\u4e00\u3002 \u901a\u8fc7\u8865\u5145\u7ec6\u8282\u548c\u63d0\u4f9b\u989d\u5916\u7684\u4fe1\u606f\uff0c\u6211\u4eec\u53ef\u4ee5\u5b8c\u5584\u56de\u7b54\uff0c\u4f7f\u5176\u66f4\u52a0\u5168\u9762\u548c\u6709\u7528\u3002 2.5 \u501f\u52a9\u5916\u90e8\u5de5\u5177 \u00b6 \u5927\u6a21\u578b\u5e76\u4e0d\u662f\u4e07\u80fd\u7684\uff0c\u6bd4\u5982\u4e00\u4e9b\u5b9e\u65f6\u95ee\u9898\u7b49\u7b49\u5927\u6a21\u578b\u4e0d\u80fd\u5f88\u597d\u7684\u56de\u7b54\uff0c\u6240\u4ee5\u9700\u8981\u4e00\u4e9b\u5916\u90e8\u5de5\u5177\u6765\u5e2e\u52a9\u5904\u7406\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u6765\u589e\u5f3aChatGPT\u7684\u529f\u80fd\u3002 2.5.1 \u57fa\u4e8e\u5d4c\u5165(embedding)\u7684\u641c\u7d22\u6280\u672f \u00b6 \u52a8\u6001\u77e5\u8bc6\u5e93\uff1a\u6bd4\u5982\uff0c\u6211\u4eec\u5411\u5927\u6a21\u578b\u63d0\u95ee\u5982\u4f55\u8bc4\u4ef7\u9a6c\u4e0a\u8981\u4e0a\u6620\u7684\u7535\u5f71\u300a\u6562\u6b7b\u961f4\u300b\uff0c\u7531\u4e8e\u5927\u6a21\u578b\u7684\u77e5\u8bc6\u90fd\u662f\u57fa\u4e8e\u4ee5\u5f80\u7684\u7ecf\u9a8c\u5f97\u5230\u7684\uff0c\u5e76\u4e0d\u5177\u5907\u5b9e\u65f6\u4fe1\u606f\uff0c\u6839\u672c\u4e0d\u77e5\u9053\u300a\u6562\u6b7b\u961f4\u300b\u8981\u4e0a\u6620\u4e86\uff0c\u6240\u4ee5\u9700\u8981\u5148\u53bb\u8054\u7f51\u8fdb\u884c\u67e5\u8be2\uff0c\u67e5\u5b8c\u4ee5\u540e\u5c06\u8d44\u6599\u8fdb\u884c\u6574\u4f53\uff0c\u8ba9\u5927\u6a21\u578b\u6839\u636e\u81ea\u5df1\u67e5\u5230\u7684\u8fd9\u4e9b\u8d44\u6599\u8fdb\u884c\u56de\u7b54\u3002\u8fd9\u662f\u52a8\u6001\u7684\u4fe1\u606f\u3002 \u9759\u6001\u77e5\u8bc6\u5e93\uff1a\u5c31\u662f\u7528\u7684\u5411\u91cf\u5339\u914d\u7684\u65b9\u5f0f\uff0c\u5e38\u89c1\u6b65\u9aa4\uff1a\u52a0\u8f7d\u6587\u4ef6 -> \u8bfb\u53d6\u6587\u672c -> \u6587\u672c\u5206\u5272 -> \u6587\u672c\u5411\u91cf\u5316 -> \u95ee\u53e5\u5411\u91cf\u5316 -> \u5728\u6587\u672c\u5411\u91cf\u4e2d\u5339\u914d\u51fa\u4e0e\u95ee\u53e5\u5411\u91cf\u6700\u76f8\u4f3c\u7684top k\u4e2a -> \u5339\u914d\u51fa\u7684\u6587\u672c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u548c\u95ee\u9898\u4e00\u8d77\u6dfb\u52a0\u5230prompt\u4e2d -> \u63d0\u4ea4\u7ed9\u5927\u6a21\u578b\u751f\u6210\u56de\u7b54\u3002\u3010\u540e\u7eed\u5b9e\u6218\u5e94\u7528\u8bb2\u89e3\u3011 2.5.2 \u4f7f\u7528\u4ee3\u7801\u6267\u884c\u6765\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u8ba1\u7b97\u6216\u8c03\u7528\u5916\u90e8API \u00b6 \u4e00\u822c\u60c5\u51b5\uff0c\u5927\u6a21\u578b\u8ba1\u7b97\u80fd\u529b\u8868\u73b0\u4e00\u822c\uff0c\u6240\u4ee5OpenAI\u5efa\u8bae\uff0c\u5982\u679c\u9047\u5230\u9700\u8981\u8ba1\u7b97\u7684\u4e1c\u897f\uff0c\u6700\u597d\u8ba9\u5927\u6a21\u578b\u5199\u4e00\u6bb5\u8ba1\u7b97\u7684Python\u4ee3\u7801\uff0c\u56e0\u4e3a\u5927\u6a21\u578b\u5bf9\u4e8ePython\u7b49\u5176\u4ed6\u7f16\u7a0b\u8bed\u8a00\u7684\u8ba1\u7b97\u9898\u5f88\u6210\u719f\u4e86\u3002 \u6bd4\u5982\uff1a\u6c42\u4ee5\u4e0b\u591a\u9879\u5f0f\u7684\u6240\u6709\u5b9e\u503c\u6839\uff1a3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10\u3002\u60a8\u9700\u8981\u901a\u8fc7\u5c06 Python \u4ee3\u7801\u62ec\u5728\u4e09\u4e2a\u53cd\u5f15\u53f7\u4e2d\u6765\u7f16\u5199\u548c\u6267\u884c\uff0c\u4f8b\u5982\"\"\"\u4ee3\u7801\u653e\u5728\u8fd9\u91cc\"\"\"\u3002\u7528\u5b83\u6765\u6267\u884c\u8ba1\u7b97\u3002 \u672c\u8282\u5c0f\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u8bb2\u89e3\u4e86\u5173\u4e8ePrompt Engineering\u7684\u4f7f\u7528\u6280\u5de7\u3002","title":"4.1 \u5927\u6a21\u578bPrompt\u5de5\u7a0b\u6307\u5357"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#_1","text":"","title":"\u5927\u6a21\u578b\u63d0\u793a\u5de5\u7a0b\u6307\u5357"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#_2","text":"\u4e86\u89e3\u4ec0\u4e48\u662f\u63d0\u793a\u5de5\u7a0b \u638c\u63e1\u63d0\u793a\u5de5\u7a0b\u7684\u8bbe\u8ba1\u6280\u5de7","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#1","text":"\u63d0\u793a\u5de5\u7a0b\uff08Prompt Engineering\uff09\uff0c\u4e5f\u79f0\u4e3a In-Context Prompting\uff0c\u662f\u6307\u5728\u4e0d\u66f4\u65b0\u6a21\u578b\u6743\u91cd\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u4e0e \u5927\u6a21\u578b\u4ea4\u4e92\u4ee5\u5f15\u5bfc\u5176\u884c\u4e3a\u4ee5\u83b7\u5f97\u6240\u9700\u7ed3\u679c\u7684\u65b9\u6cd5\u3002 \u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\uff0cPrompt\u6307\u7684\u662f\u7528\u6237\u7ed9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53d1\u51fa\u7684\u6307\u4ee4\u3002\u4f8b\u5982\uff0c\u201c\u300c\u8bb2\u4e2a\u7b11\u8bdd\u300d\u201d\u3001\u201c\u300c\u7528Python\u7f16\u4e2a\u8d2a\u5403\u86c7\u6e38\u620f\u300d\u201d\u3001\u201c\u300c\u5199\u5c01\u60c5\u4e66\u300d\"\u7b49\u3002\u867d\u7136\u770b\u4f3c\u7b80\u5355\uff0c\u4f46\u5b9e\u9645\u4e0a\uff0cPrompt\u7684\u8bbe\u8ba1\u5bf9\u4e8e\u6a21\u578b\u7684\u7ed3\u679c\u5f71\u54cd\u5f88\u5927\u3002\u56e0\u6b64\u5982\u4f55\u8bbe\u8ba1prompt\uff0c\u8fdb\u800c\u4e0e\u6a21\u578b\u66f4\u597d\u7684\u4ea4\u4e92\uff0c\u662f\u7814\u7a76\u4eba\u5458\u5fc5\u5907\u7684\u5fc5\u4e0d\u53ef\u5c11\u7684\u6280\u80fd\uff08\u63d0\u793a\u5de5\u7a0b\uff09\u3002 \u63d0\u793a\u5de5\u7a0b\u4e0d\u4ec5\u4ec5\u662f\u5173\u4e8e\u8bbe\u8ba1\u548c\u7814\u53d1\u63d0\u793a\u8bcd\u3002\u5b83\u5305\u542b\u4e86\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u548c\u7814\u53d1\u7684\u5404\u79cd\u6280\u80fd\u548c\u6280\u672f\u3002\u63d0\u793a\u5de5\u7a0b\u5728\u5b9e\u73b0\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u3001\u5bf9\u63a5\uff0c\u4ee5\u53ca\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u65b9\u9762\u90fd\u8d77\u7740\u91cd\u8981\u4f5c\u7528\u3002\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6765\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u4e5f\u53ef\u4ee5\u8d4b\u80fd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6bd4\u5982\u501f\u52a9\u4e13\u4e1a\u9886\u57df\u77e5\u8bc6\u548c\u5916\u90e8\u5de5\u5177\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u3002","title":"1 \u6982\u5ff5"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#2","text":"\u57fa\u4e8eOpenAI\u5b98\u7f51\u6587\u6863\uff0c\u6211\u4eec\u63d0\u70bc\u51fa\u4e865\u6761\u5927\u539f\u5219\uff1a \u6e05\u6670\u7684\u6307\u4ee4 \u6587\u672c\u53c2\u8003 \u590d\u6742\u4efb\u52a1\u62c6\u5206\u7b80\u5355\u5b50\u4efb\u52a1 \u7ed9\u6a21\u578b\"\u601d\u8003\"\u7684\u65f6\u95f4 \u501f\u52a9\u5916\u90e8\u5de5\u5177 \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u5bf9\u6bcf\u4e00\u79cd\u5177\u4f53\u7684\u539f\u5219\u8fdb\u884c\u539f\u7406\u8bb2\u89e3\u4ee5\u53ca\u4e3e\u4f8b\u5b9e\u65f6\uff0c\u4ee5\u5e2e\u52a9\u6211\u4eec\u5728\u65e5\u5e38\u5de5\u4f5c\u51c6\u786e\u7684\u4f7f\u7528LLM\u3002","title":"2 \u63d0\u793a\u5de5\u7a0b\u7684\u539f\u5219"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#21","text":"\u4efb\u4f55Prompt\u6280\u5de7\uff0c\u90fd\u4e0d\u5982\u6e05\u6670\u7684\u8868\u8fbe\u4f60\u7684\u9700\u6c42\u3002\u8fd9\u5c31\u7c7b\u4f3c\u4eba\u4e0e\u4eba\u6c9f\u901a\uff0c\u5982\u679c\u8bdd\u8bf4\u4e0d\u660e\u767d\uff0c\u4e0d\u53ef\u80fd\u8ba9\u522b\u4eba\u7406\u89e3\u4f60\u7684\u601d\u60f3\u3002\u56e0\u6b64\uff0c\u5199\u51fa\u6e05\u6670\u7684\u6307\u4ee4\uff0c\u662f\u6838\u5fc3\u3002 \u90a3\u4e48\u5982\u4f55\u5199\u51fa\u6e05\u6670\u7684\u6307\u4ee4\u5462\uff1f\u4e0b\u9762\u7f57\u5217\u51e0\u4e2a\u5c0f\u6280\u5de7\uff1a","title":"2.1 \u6e05\u6670\u7684\u6307\u4ee4"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#211","text":"\u5f53\u6211\u4eec\u8fdb\u884c\u6a21\u578b\u7684\u63d0\u95ee\u65f6\uff0c\u4e0d\u8981\u63cf\u8ff0\u7684\u592a\u7b3c\u7edf\uff0c\u800c\u662f\u5c3d\u91cf\u591a\u7684\u63d0\u4f9b\u91cd\u8981\u7684\u8be6\u7ec6\u4fe1\u606f\u6216\u4e0a\u4e0b\u6587. eg: \u4e0d\u8981\u76f4\u63a5\u8bf4\uff0c\"\u5e2e\u6211\u5199\u4e00\u5c01\u60c5\u4e66\"\uff1b\u800c\u662f\u8bf4\uff1a\"\u7528\u4e00\u4e9b\u6e29\u67d4\u7684\u8bdd\u8bed\u5199\u4e00\u5c01\u60c5\u4e66\uff0c\u6765\u8868\u8fbe\u6211\u5bf9\u4f60\u7684\u4ef0\u6155\u548c\u601d\u5ff5\u3002\u6700\u540e\uff0c\u6211\u8981\u6c42\u4e66\u5199\u5b57\u4f53\u6570\u8981\u4e0d\u4f4e\u4e8e500\u4e2a\u5b57\"","title":"2.1.1 \u8be6\u7ec6\u7684\u63cf\u8ff0"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#212","text":"\u5f53\u6211\u4eec\u4f7f\u7528\u5927\u6a21\u578b\u65f6\uff0c\u53ef\u4ee5\u8ba9\u6a21\u578b\u5145\u5f53\u4e00\u4e2a\u89d2\u8272\uff0c\u8fd9\u6837\u6a21\u578b\u4f1a\u66f4\u4e13\u4e1a\u66f4\u660e\u786e\u7684\u5bf9\u4f60\u7684\u95ee\u9898\u8fdb\u884c\u56de\u590d. Eg\uff1a\u6211\u9700\u8981\u4f60\u5145\u5f53\u4e00\u4e2aAI\u7b97\u6cd5\u9762\u8bd5\u5b98\u7684\u89d2\u8272\uff0c\u8981\u6c42\u4f60\u81ea\u4e3b\u7684\u5bf9\u6211\u8fdb\u884cAI\u9762\u8bd5\u8fc7\u7a0b\u4e2d\u5e38\u8003\u7684\u9762\u8bd5\u9898\uff0c\u4f60\u53ef\u4ee5\u4e00\u6b21\u8bf4\u4e00\u4e2a\u95ee\u9898\uff0c\u7136\u540e\u6211\u56de\u7b54\u5b8c\uff0c\u4f60\u518d\u51fa\u7b2c\u4e8c\u9053\u9898","title":"2.1.2 \u8ba9\u6a21\u578b\u5145\u5f53\u67d0\u4e2a\u89d2\u8272"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#213","text":"\u4e2d\u62ec\u53f7\u3001XML\u6807\u7b7e\u3001\u4e09\u5f15\u53f7\u7b49\u5206\u9694\u7b26\u53ef\u4ee5\u5e2e\u52a9\u5212\u5206\u8981\u533a\u522b\u5bf9\u5f85\u7684\u6587\u672c\uff0c\u4e5f\u53ef\u4ee5\u5e2e\u52a9\u6a21\u578b\u66f4\u597d\u7684\u7406\u89e3\u6587\u672c\u5185\u5bb9\u3002\u5e38\u7528''''''\u628a\u5185\u5bb9\u6846\u8d77\u6765 eg\uff1a\u752820\u4e2a\u5b57\u7b26\u603b\u7ed3\u7531\u4e09\u5f15\u53f7\u5206\u5272\u7684\u6587\u672c\u3002\"\"\"\u5728\u6b64\u63d2\u5165\u6587\u672c\"\"\"","title":"2.1.3 \u4f7f\u7528\u5206\u9694\u7b26\u6807\u660e\u8f93\u5165\u7684\u4e0d\u540c\u90e8\u5206"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#214","text":"\u5bf9\u4e8e\u53ef\u4ee5\u62c6\u5206\u7684\u4efb\u52a1\u53ef\u4ee5\u5c3d\u91cf\u62c6\u5f00\uff0c\u6700\u597d\u80fd\u4e3a\u5176\u6307\u5b9a\u4e00\u7cfb\u5217\u6b65\u9aa4\uff0c\u660e\u786e\u6b65\u9aa4\u53ef\u4ee5\u8ba9\u6a21\u578b\u66f4\u5bb9\u6613\u5b9e\u73b0\u5b83\u4eec\u3002 eg\uff1a\u5229\u7528\u4e0b\u9762\u5206\u6b65\u60c5\u51b5\u6765\u54cd\u5e94\u7528\u6237\u7684\u8f93\u5165\u3002 \u6b65\u9aa41: \"\"\"\"\u7528\u6237\u8f93\u5165\u6587\u672c\"\"\"\"\uff0c\u7528\u4e00\u53e5\u8bdd\u603b\u7ed3\u8fd9\u6bb5\u6587\u672c\uff0c\u5e76\u52a0\u4e0a\u524d\u7f00\"Summary\". \u6b65\u9aa42: \u5c06\u6b65\u9aa41\u4e2d\u7684\u6458\u8981\u7ffb\u8bd1\u6210\u82f1\u8bed\uff0c\u5e76\u6dfb\u52a0\u524d\u7f00\"\u7ffb\u8bd1\uff1a\"","title":"2.1.4 \u5bf9\u4efb\u52a1\u6307\u5b9a\u6b65\u9aa4"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#215","text":"\u672c\u8d28\u7c7b\u4f3c\u4e8efew-shot leaning\u3002\u5148\u6254\u7ed9\u5927\u6a21\u578b\u4e3e\u4f8b\uff0c\u7136\u540e\u8ba9\u6a21\u578b\u6309\u7167\u4f8b\u5b50\u6765\u8f93\u51fa eg: \u6309\u7167\u8fd9\u53e5\u8bc4\u8bba\u6587\u672c\u7684\u683c\u5f0f\uff1a'\"\"\u7528\u6237\u8f93\u5165\u6587\u672c\"\"'\uff0c\u5e2e\u6211\u521b\u9020\u65b0\u7684\u6837\u672c","title":"2.1.5 \u63d0\u4f9b\u4f8b\u5b50"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#216","text":"\u53ef\u4ee5\u8981\u6c42\u6a21\u578b\u751f\u6210\u7ed9\u5b9a\u76ee\u6807\u957f\u5ea6\u7684\u8f93\u51fa\u3002\u76ee\u6807\u8f93\u51fa\u957f\u5ea6\u53ef\u4ee5\u6839\u636e\u5355\u8bcd\u3001\u53e5\u5b50\u3001\u6bb5\u843d\u3001\u8981\u70b9\u7b49\u7684\u8ba1\u6570\u6765\u6307\u5b9a\u3002\u4e2d\u6587\u6548\u679c\u4e0d\u660e\u663e\uff0c\u540c\u65f6\u4f60\u7ed9\u5b9a\u7684\u957f\u5ea6\u53ea\u662f\u4e2a\u5927\u6982, \u591a\u5c11\u4e2a\u5b57\u8fd9\u79cd\u80af\u5b9a\u4f1a\u4e0d\u7cbe\u51c6\uff0c\u4f46\u662f\u50cf\u591a\u5c11\u6bb5\u8fd9\u79cd\u6548\u679c\u76f8\u5bf9\u8f83\u597d. eg: \u7528\u4e09\u4e2a\u6bb5\u843d\u300130\u4e2a\u5b57\u7b26\u6982\u62ec\u7531\u4e09\u5f15\u53f7\u5206\u9694\u7684\u6587\u672c\u3002\"\"\"\u5728\u6b64\u63d2\u5165\u4f60\u7684\u6587\u672c\"\"\"","title":"2.1.6 \u6307\u5b9a\u8f93\u51fa\u957f\u5ea6"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#22","text":"\u6587\u672c\u53c2\u8003\u76ee\u7684\uff1a\u57fa\u4e8e\u6587\u672c\u6587\u6863\uff0c\u8f85\u52a9\u5927\u6a21\u578b\u95ee\u7b54\uff0c\u964d\u4f4e\u6a21\u578b\"\u5e7b\u89c9\"\uff08\u4e00\u672c\u6b63\u7ecf\u7684\u80e1\u8bf4\u516b\u9053\uff09\u95ee\u9898\u3002","title":"2.2 \u6587\u672c\u53c2\u8003"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#221","text":"\u7ecf\u5178\u7684\u77e5\u8bc6\u5e93\u7528\u6cd5\uff0c\u8ba9\u5927\u6a21\u578b\u4f7f\u7528\u6211\u4eec\u63d0\u4f9b\u7684\u4fe1\u606f\u6765\u7ec4\u6210\u7b54\u6848\u3002 eg\uff1a\u6839\u636e\u4e0b\u6587\u4e2d\u4e09\u91cd\u5f15\u53f7\u5f15\u8d77\u6765\u7684\u6587\u7ae0\u6765\u56de\u7b54\u95ee\u9898\u3002\u5982\u679c\u5728\u6587\u7ae0\u4e2d\u627e\u4e0d\u5230\u7b54\u6848\uff0c\u8bf7\u5199\u201c\u6211\u627e\u4e0d\u5230\u7b54\u6848\u201d\uff0c\u4e0d\u8981\u81ea\u5df1\u9020\u7b54\u6848\u3002\"\"\"<\u5728\u6b64\u63d2\u5165\u6587\u6863>\"\"\"\"\"\"<\u5728\u6b64\u63d2\u5165\u6587\u6863>\"\"\" \u95ee\u9898\uff1a<\u5728\u6b64\u63d2\u5165\u95ee\u9898>","title":"2.2.1 \u4f7f\u7528\u53c2\u8003\u6587\u672c\u4f5c\u7b54"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#23","text":"\u7c7b\u4f3c\u4e8e\u4eba\u5de5\uff0c\u5982\u679c\u4f60\u4f5c\u4e3a\u9886\u5bfc\uff0c\u8ba9\u4e0b\u5c5e\u4e00\u6b21\u6027\u5b8c\u6210\u4e00\u4e2a\u975e\u5e38\u5927\u7684\u4e8b\uff0c\u90a3\u4e48\u51fa\u9519\u7684\u6982\u7387\u662f\u5f88\u5927\u7684\uff0c\u5f88\u591a\u5927\u9879\u76ee\u4e5f\u662f\u8fd9\u6837\uff0c\u4f60\u751a\u81f3\u65e0\u4ece\u4e0b\u624b\u3002\u6240\u4ee5\u6211\u4eec\u7ecf\u5e38\u5728\u5de5\u4f5c\u4e2d\uff0c\u90fd\u8981\u8bb2\u4efb\u52a1\uff0c\u62c6\u5404\u79cd\u7ec6\u8282\u3001\u5b50\u4efb\u52a1\u3001\u5b50\u76ee\u6807\u7b49\u7b49\u3002\u5927\u6a21\u578b\u4e5f\u662f\u540c\u6837\u7684\u9053\u7406\u3002 \u628a\u590d\u6742\u7684\u4efb\u52a1\u7ed9\u62c6\u4e3a\u66f4\u4e3a\u7b80\u5355\u7684\u5b50\u4efb\u52a1\uff0c\u5927\u6a21\u578b\u4f1a\u6709\u66f4\u597d\u7684\u8868\u73b0","title":"2.3 \u590d\u6742\u4efb\u52a1\u62c6\u5206\u4e3a\u7b80\u5355\u5b50\u4efb\u52a1"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#231-query","text":"\u610f\u56fe\u8bc6\u522b\u662f\u4e00\u4e2a\u5f88\u7ecf\u5178\u7684\u4f8b\u5b50\u3002\u6bd4\u5982\u5728\u5ba2\u670d\u573a\u666f\u4e2d\uff0c\u7528\u6237\u95ee\u4e86\u4e00\u4e2a\u95ee\u9898\u201c\u6211\u65ad\u7f51\u4e86\u548b\u6574\u201d\uff0c\u4f60\u8ba9\u5927\u6a21\u578b\u76f4\u63a5\u56de\u590d\u5176\u5b9e\u662f\u633a\u9e21\u808b\u7684\uff0c\u4f46\u662f\u8fd9\u65f6\u5019\u5c31\u53ef\u4ee5\u62c6\uff0c\u5148\u62c6\u5927\u5206\u7c7b\u4e0b\u7684\u610f\u56fe\u8bc6\u522b\uff0c\u518d\u56de\u7b54\u5177\u4f53\u7c7b\u522b\u7684\u95ee\u9898\u3002 \u6b65\u9aa41, \u5148\u5224\u65ad\u95ee\u9898\u7c7b\u522b\uff1a \u63a5\u4e0b\u6765\uff0c\u5c06\u4e3a\u60a8\u63d0\u4f9b\u5ba2\u6237\u670d\u52a1\u67e5\u8be2\uff0c\u5c06\u6bcf\u4e2a\u67e5\u8be2\u5206\u4e3a\u4e3b\u8981\u7c7b\u522b\u548c\u6b21\u8981\u7c7b\u522b\u3002\u63d0\u4f9bjson\u683c\u5f0f\u7684\u8f93\u51fa\uff0c\u5177\u4f53\u5185\u5bb9\u5982\u4e0b\uff1a \u4e3b\u8981\u7c7b\u522b\uff1a\u8ba1\u8d39\u3001\u6280\u672f\u652f\u6301\u3001\u8d26\u6237\u7ba1\u7406 \u8ba1\u8d39\u6b21\u8981\u7c7b\u522b\uff1a1.\u53d6\u6d88\u8ba2\u9605\uff1b2.\u6761\u4ef6\u4ed8\u6b3e\u65b9\u5f0f\uff1b3.\u6536\u8d39\u8bf4\u660e\uff1b4.\u5bf9\u6536\u8d39\u63d0\u51fa\u4e89\u8bae \u6280\u672f\u652f\u6301\u6b21\u8981\u7c7b\u522b\uff1a1.\u6545\u969c\u6392\u9664\uff1b2.\u8bbe\u5907\u517c\u5bb9\u6027\uff1b3.\u8f6f\u4ef6\u66f4\u65b0 \u8d26\u6237\u7ba1\u7406\u6b21\u8981\u7c7b\u522b\uff1a1.\u91cd\u7f6e\u5bc6\u7801\uff1b2.\u66f4\u65b0\u4e2a\u4eba\u4fe1\u606f\uff1b3.\u5173\u95ed\u5e10\u6237\uff1b4.\u8d26\u6237\u5b89\u5168 \u5982\u679c\u5927\u6a21\u578b\u6839\u636e\u6b65\u9aa41\uff0c\u77e5\u9053\u201c\u6211\u65ad\u7f51\u4e86\u548b\u6574\u201d\u662f\u5c5e\u4e8e\u6280\u672f\u652f\u6301\u4e2d\u7684\u6545\u969c\u6392\u9664\u4e86\uff0c\u6211\u4eec\u53ef\u4ee5\u7ee7\u7eed\u7b2c\u4e8c\u4e2a\u6b65\u9aa4 \u6b65\u9aa42\uff0c\u6839\u636e\u7c7b\u522b\u5728\u5f97\u5230\u5177\u4f53\u7684\u89e3\u51b3\u65b9\u6848: \u60a8\u5c06\u6536\u5230\u9700\u8981\u5728\u6280\u672f\u652f\u6301\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u6545\u969c\u6392\u9664\u7684\u5ba2\u6237\u670d\u52a1\u67e5\u8be2\u3002\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5e2e\u52a9\u7528\u6237\uff1a \u8981\u6c42\u4ed6\u4eec\u68c0\u67e5\u4e0e\u8def\u7531\u5668\u76f8\u8fde\u7684\u6240\u6709\u7535\u7f06\u662f\u5426\u8fde\u63a5\u3002\u8bf7\u6ce8\u610f\uff0c\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u7535\u7f06\u5e38\u5e38\u4f1a\u677e\u52a8\u3002 \u5982\u679c\u6240\u6709\u7535\u7f06\u8fde\u63a5\u6b63\u5e38\u4e14\u95ee\u9898\u4ecd\u7136\u5b58\u5728\uff0c\u8bf7\u8be2\u95ee\u4ed6\u4eec\u4f7f\u7528\u7684\u8def\u7531\u5668\u578b\u53f7\u3002","title":"2.3.1 \u5bf9\u7528\u6237query\u8fdb\u884c\u610f\u56fe\u8bc6\u522b"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#232","text":"\u56e0\u4e3a\u5927\u6a21\u578b\u90fd\u5177\u6709\u56fa\u5b9a\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u56e0\u6b64\u7528\u6237\u548c\u6a21\u578b\u4e4b\u95f4\u7684\u5bf9\u8bdd\u65e0\u6cd5\u65e0\u9650\u671f\u5730\u7ee7\u7eed\u3002\u89e3\u51b3\u6b64\u95ee\u9898\u6709\u591a\u79cd\u89e3\u51b3\u65b9\u6cd5\uff1a \u7b2c\u4e00\u4e2a\u65b9\u6cd5\u662f\u603b\u7ed3\u4e4b\u524d\u7684\u5bf9\u8bdd\u8bb0\u5f55\u3002\u4e00\u65e6\u8f93\u5165\u7684\u5927\u5c0f\u8fbe\u5230\u9884\u5b9a\u7684\u9608\u503c\u957f\u5ea6\uff0c\u6a21\u578b\u5c31\u4f1a\u81ea\u52a8\u628a\u4e00\u90e8\u5206\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002 \u53e6\u5916\u4e00\u79cd\u529e\u6cd5\u5c31\u662f\u5728\u6574\u4e2a\u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\uff0c\u8ba9\u6a21\u578b\u5728\u80cc\u540e\u4e0d\u65ad\u5730\u628a\u5bf9\u8bdd\u5185\u5bb9\u8fdb\u884c\u603b\u7ed3\u3002\u8fd9\u5c31\u50cf\u4f60\u5728\u8bfb\u4e00\u672c\u4e66\u7684\u65f6\u5019\uff0c\u53ef\u80fd\u4f1a\u65f6\u4e0d\u65f6\u5730\u5728\u8111\u5b50\u91cc\u56de\u987e\u4e00\u4e0b\u4e4b\u524d\u7684\u60c5\u8282\uff0c\u8fd9\u6837\u5c31\u4e0d\u4f1a\u5fd8\u8bb0\u6545\u4e8b\u7684\u4e3b\u7ebf\u3002 \u8fd9\u4e24\u79cd\u65b9\u6cd5\u90fd\u884c\uff0c\u6216\u8005\u8fd8\u53ef\u4ee5\u628a\u8fc7\u53bb\u7684\u6240\u6709\u804a\u5929\u8bb0\u5f55\u5b58\u6210\u5411\u91cf\u5e93\uff0c\u540e\u7eed\u8ddf\u7528\u6237\u5bf9\u8bdd\u7684\u65f6\u5019\u52a8\u6001\u67e5\u8be2\u5d4c\u5165\uff0c\u4e5f\u53ef\u4ee5\u3002","title":"2.3.2 \u5904\u7406\u957f\u5bf9\u8bdd\uff1a\u603b\u7ed3\u6216\u8fc7\u6ee4\u4fe1\u606f"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#233","text":"\u7c7b\u4f3c\u4e8eChatGPT\u7684\u5927\u6a21\u578b \u662f\u4e2a\u6709\u70b9\u50cf\u6709\u8bb0\u5fc6\u529b\u9650\u5236\u7684\u673a\u5668\u4eba\uff0c\u4ed6\u8bb0\u4f4f\u7684\u4e1c\u897f\u957f\u5ea6\u6709\u9650\u3002\u56e0\u6b64\uff0c\u5982\u679c\u8ba9\u4ed6\u4e00\u53e3\u6c14\u8bfb\u5b8c\u4e00\u672c\u975e\u5e38\u957f\u7684\u4e66\u7136\u540e\u518d\u603b\u7ed3\uff0c\u4ed6\u53ef\u80fd\u4f1a\u8bb0\u4e0d\u4f4f\u6240\u6709\u7684\u5185\u5bb9\u3002\u90a3\u600e\u4e48\u529e\u5462\uff1f \u6211\u4eec\u53ef\u4ee5\u7528\u4e00\u79cd\u201c\u5206\u6bb5\u603b\u7ed3\uff0c\u518d\u6c47\u603b\u201d\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u5c31\u597d\u6bd4\uff0c\u4f60\u5728\u5b66\u4e60\u5f88\u957f\u7684\u4e00\u7bc7\u6587\u7ae0\u6216\u8005\u4e00\u672c\u4e66\u7684\u65f6\u5019\uff0c\u4f60\u53ef\u80fd\u4f1a\u5148\u603b\u7ed3\u6bcf\u4e00\u5c0f\u8282\u7684\u5185\u5bb9\uff0c\u7136\u540e\u518d\u628a\u8fd9\u4e9b\u5c0f\u8282\u7684\u603b\u7ed3\u653e\u5728\u4e00\u8d77\uff0c\u518d\u505a\u4e00\u6b21\u603b\u7ed3\uff0c\u8fd9\u6837\u5c31\u80fd\u5f97\u5230\u6574\u4e2a\u6587\u7ae0\u6216\u8005\u4e66\u7684\u603b\u7ed3\u4e86\u3002 \u5904\u7406\u957f\u5bf9\u8bdd\u548c\u957f\u6587\u7684\u57fa\u672c\u65b9\u6cd5\uff0c\u57fa\u672c\u662f\u4e00\u6837\u7684\uff1a\u603b\u7ed3\u524d\u4e00\u90e8\u5206\u7684\u65f6\u5019\uff0c\u5e26\u4e0a\u4e4b\u524d\u7684\u5185\u5bb9\u3002 \u4e0d\u540c\u70b9\u662f\uff1a\u6709\u7684\u957f\u6587\u7ae0\u8282\u4e4b\u95f4\uff0c\u5173\u7cfb\u8f83\u5f31\uff0c\u53ef\u4ee5\u7528\u5206\u6bb5\u603b\u7ed3\uff0c\u518d\u6c47\u603b\u7684\u65b9\u6cd5\uff0c\u4e0d\u7528\u6bcf\u6b21\u603b\u7ed3\u90fd\u5e26\u4e0a\u4e4b\u524d\u7684\u603b\u7ed3\u3002","title":"2.3.3 \u5206\u6bb5\u603b\u7ed3\u957f\u6587\u672c\u5e76\u9012\u5f52\u6784\u5efa\u5b8c\u6574\u6458\u8981"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#24","text":"\u7ed9\u6a21\u578b\u601d\u8003\u5b9e\u8df5\uff0c\u672c\u8d28\u4e3a\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\uff0cChain-of-Thought Prompting\u3002\u76ee\u7684\uff0c\u8ba9\u6a21\u578bthink step by step\uff08\u4e00\u6b65\u6b65\u601d\u8003\uff09. \u6bd4\u5982\uff0c\u76f4\u63a5\u95ee\u4f604234567*375821\u7b49\u4e8e\u591a\u5c11\uff0c\u4f60\u80af\u5b9a\u4e5f\"\u61f5\"\uff0c\u4f46\u662f\u5982\u679c\u7ed9\u4f60\u65f6\u95f4\u8ba9\u4f60\u4e00\u6b65\u6b65\u8ba1\u7b97\uff0c\u5b66\u8fc7\u5c0f\u5b66\u6570\u5b66\u7684\u90fd\u80fd\u7b97\u51fa\u6765\u5bf9\u5427. \u63a5\u4e0b\u6765\uff0c\u6211\u4eec\u5c06\u63a2\u8ba8\u5982\u4f55\u7ed9ChatGPT\u8db3\u591f\u7684\u65f6\u95f4\u6765\u201c\u601d\u8003\u201d\uff0c\u4ee5\u5f97\u51fa\u66f4\u51c6\u786e\u548c\u5408\u7406\u7684\u7b54\u6848\u3002","title":"2.4 \u7ed9\u6a21\u578b\"\u601d\u8003\"\u7684\u65f6\u95f4"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#241","text":"\u6709\u65f6\u5019\uff0c\u6211\u4eec\u5e0c\u671bChatGPT\u80fd\u591f\u5728\u5f97\u51fa\u6700\u7ec8\u7b54\u6848\u4e4b\u524d\uff0c\u5148\u751f\u6210\u4e00\u4e9b\u81ea\u5df1\u7684\u7b54\u6848\uff0c\u7136\u540e\u518d\u8fdb\u884c\u9009\u62e9\u548c\u8c03\u6574\u3002\u8fd9\u6837\u53ef\u4ee5\u5f15\u5bfc\u6a21\u578b\u601d\u8003\u95ee\u9898\uff0c\u5e76\u6fc0\u53d1\u4e00\u4e9b\u65b0\u7684\u521b\u610f\u3002 \u7528\u6237\uff1a \u95ee\u9898\uff1a1+1=3\u662f\u5426\u6b63\u786e \u7b54\u6848\uff1a\u6b63\u786e\uff0c\u56e0\u4e3a\u5728\u4e09\u7ef4\u7a7a\u95f4\u91cc1+1\u5219\u662f\u7acb\u4f53\u7684\uff0c\u6240\u4ee5\u7b49\u4e8e3\u3002\u8bf7\u5224\u65ad\u7b54\u6848\u662f\u5426\u6b63\u786e\u3002\u8981\u6c42\uff1a\u5224\u65ad\u4e4b\u524d\u5148\u81ea\u5df1\u601d\u8003\u7b54\u6848\uff0c\u7136\u540e\u518d\u5224\u65ad\u7b54\u6848\u662f\u5426\u6b63\u786e\u3002 ChatGPT\uff1a\u5728\u6807\u51c6\u7684\u6570\u5b66\u8fd0\u7b97\u4e2d\uff0c1+1\u7684\u7ed3\u679c\u662f2\u3002\u7136\u800c\uff0c\u4f60\u63d0\u5230\u4e86\u5728\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u7684\u7acb\u4f53\u6982\u5ff5\u3002\u5728\u6570\u5b66\u4e0a\uff0c1+1\u4ecd\u7136\u7b49\u4e8e2\uff0c\u5373\u4f7f\u6211\u4eec\u8003\u8651\u5230\u4e0d\u540c\u7684\u7ef4\u5ea6\u3002\u56e0\u6b64\uff0c\u6839\u636e\u6807\u51c6\u7684\u6570\u5b66\u8fd0\u7b97\u89c4\u5219\uff0c\u7b54\u6848\u5e94\u8be5\u662f\u4e0d\u6b63\u786e\u3002\u5982\u679c\u95ee\u9898\u6d89\u53ca\u5230\u7279\u6b8a\u7684\u4e0a\u4e0b\u6587\u6216\u9886\u57df\uff0c\u8bf7\u63d0\u4f9b\u66f4\u591a\u7684\u4fe1\u606f\u4ee5\u4fbf\u6211\u66f4\u597d\u5730\u7406\u89e3\u5e76\u56de\u7b54\u3002 \u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5728\u5f97\u51fa\u7ed3\u8bba\u524d\u751f\u6210\u81ea\u5df1\u7684\u7b54\u6848\uff0c\u6211\u4eec\u53ef\u4ee5\u6fc0\u53d1\u6a21\u578b\u7684\u601d\u8003\u8fc7\u7a0b\uff0c\u5e76\u83b7\u5f97\u66f4\u52a0\u4e30\u5bcc\u548c\u591a\u6837\u7684\u56de\u7b54\u3002","title":"2.4.1 \u5f15\u5bfc\u6a21\u578b\u5728\u5f97\u51fa\u7ed3\u8bba\u524d\u751f\u6210\u81ea\u5df1\u7684\u7b54\u6848"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#242","text":"\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u80fd\u66f4\u5173\u6ce8\u6700\u7ec8\u7b54\u6848\uff0c\u800c\u4e0d\u662f\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u901a\u8fc7\u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5316\u56de\u7b54\uff0c\u5e76\u4f7f\u5176\u66f4\u52a0\u76f4\u63a5\u548c\u6613\u4e8e\u7406\u89e3\u3002 \u7528\u6237\uff1a\u5982\u4f55\u7528Python\u53cd\u8f6c\u4e00\u4e2a\u5b57\u7b26\u4e32\u3002\u8981\u6c42\uff1a\u53ea\u9700\u8981\u8f93\u51fa\u4ee3\u7801\uff0c\u4e0d\u8f93\u51fa\u5176\u5b83\u4efb\u4f55\u6587\u5b57\u3002 ChatGPT\uff1a string = \"Hello, World!\" reversed_string = string [:: - 1 ] print ( reversed_string )","title":"2.4.2 \u9690\u85cf\u63a8\u7406\u8fc7\u7a0b\uff0c\u53ea\u5c55\u793a\u6700\u7ec8\u7b54\u6848"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#243","text":"\u6709\u65f6\uff0cChatGPT\u53ef\u80fd\u4f1a\u751f\u6210\u4e00\u4e9b\u4e0d\u5b8c\u6574\u7684\u56de\u7b54\uff0c\u7f3a\u5c11\u4e00\u4e9b\u91cd\u8981\u7684\u7ec6\u8282\u6216\u4fe1\u606f\u3002\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u8865\u5145\u7ec6\u8282\u6216\u63d0\u4f9b\u989d\u5916\u7684\u4fe1\u606f\u6765\u5b8c\u5584\u56de\u7b54\u3002 \u7528\u6237: JavaScript\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\u5417\uff1f\u8981\u6c42\uff1a\u53ea\u9700\u8981\u56de\u7b54\u6700\u7ec8\u7ed3\u8bba\u3002 ChatGPT\uff1a \u6ca1\u6709\u7edd\u5bf9\u7684\u6700\u597d\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u56e0\u4e3a\u6bcf\u79cd\u8bed\u8a00\u90fd\u6709\u81ea\u5df1\u7684\u4f18\u70b9\u548c\u9002\u7528\u573a\u666f\u3002\u4e0d\u540c\u7684\u8bed\u8a00\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u4efb\u52a1\u548c\u9700\u6c42\u3002\u6240\u4ee5\uff0cJavaScript\u5e76\u4e0d\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\uff0c\u4f46\u5b83\u5728Web\u5f00\u53d1\u4e2d\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u548c\u5f3a\u5927\u7684\u751f\u6001\u7cfb\u7edf\u3002 \u7528\u6237\uff1a\u5728\u524d\u7aef\u5f00\u53d1\u4e2d\uff0cJavaScript\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\u5417\uff1f\u8981\u6c42\uff1a\u53ea\u9700\u8981\u56de\u7b54\u6700\u7ec8\u7ed3\u8bba ChatGPT: \u5728\u524d\u7aef\u5f00\u53d1\u4e2d\uff0cJavaScript\u662f\u6700\u4e3b\u8981\u7684\u8bed\u8a00\uff0c\u5e76\u4e14\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u548c\u5f3a\u5927\u7684\u751f\u6001\u7cfb\u7edf\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u8bf4\u5728\u524d\u7aef\u5f00\u53d1\u4e2d\uff0cJavaScript\u662f\u4e16\u754c\u4e0a\u6700\u597d\u7684\u8bed\u8a00\u4e4b\u4e00\u3002 \u901a\u8fc7\u8865\u5145\u7ec6\u8282\u548c\u63d0\u4f9b\u989d\u5916\u7684\u4fe1\u606f\uff0c\u6211\u4eec\u53ef\u4ee5\u5b8c\u5584\u56de\u7b54\uff0c\u4f7f\u5176\u66f4\u52a0\u5168\u9762\u548c\u6709\u7528\u3002","title":"2.4.3 \u5904\u7406\u7b54\u6848\u4e0d\u5b8c\u6574\u7684\u95ee\u9898"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#25","text":"\u5927\u6a21\u578b\u5e76\u4e0d\u662f\u4e07\u80fd\u7684\uff0c\u6bd4\u5982\u4e00\u4e9b\u5b9e\u65f6\u95ee\u9898\u7b49\u7b49\u5927\u6a21\u578b\u4e0d\u80fd\u5f88\u597d\u7684\u56de\u7b54\uff0c\u6240\u4ee5\u9700\u8981\u4e00\u4e9b\u5916\u90e8\u5de5\u5177\u6765\u5e2e\u52a9\u5904\u7406\u3002\u63a5\u4e0b\u6765\u6211\u4eec\u5c06\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u6765\u589e\u5f3aChatGPT\u7684\u529f\u80fd\u3002","title":"2.5 \u501f\u52a9\u5916\u90e8\u5de5\u5177"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#251-embedding","text":"\u52a8\u6001\u77e5\u8bc6\u5e93\uff1a\u6bd4\u5982\uff0c\u6211\u4eec\u5411\u5927\u6a21\u578b\u63d0\u95ee\u5982\u4f55\u8bc4\u4ef7\u9a6c\u4e0a\u8981\u4e0a\u6620\u7684\u7535\u5f71\u300a\u6562\u6b7b\u961f4\u300b\uff0c\u7531\u4e8e\u5927\u6a21\u578b\u7684\u77e5\u8bc6\u90fd\u662f\u57fa\u4e8e\u4ee5\u5f80\u7684\u7ecf\u9a8c\u5f97\u5230\u7684\uff0c\u5e76\u4e0d\u5177\u5907\u5b9e\u65f6\u4fe1\u606f\uff0c\u6839\u672c\u4e0d\u77e5\u9053\u300a\u6562\u6b7b\u961f4\u300b\u8981\u4e0a\u6620\u4e86\uff0c\u6240\u4ee5\u9700\u8981\u5148\u53bb\u8054\u7f51\u8fdb\u884c\u67e5\u8be2\uff0c\u67e5\u5b8c\u4ee5\u540e\u5c06\u8d44\u6599\u8fdb\u884c\u6574\u4f53\uff0c\u8ba9\u5927\u6a21\u578b\u6839\u636e\u81ea\u5df1\u67e5\u5230\u7684\u8fd9\u4e9b\u8d44\u6599\u8fdb\u884c\u56de\u7b54\u3002\u8fd9\u662f\u52a8\u6001\u7684\u4fe1\u606f\u3002 \u9759\u6001\u77e5\u8bc6\u5e93\uff1a\u5c31\u662f\u7528\u7684\u5411\u91cf\u5339\u914d\u7684\u65b9\u5f0f\uff0c\u5e38\u89c1\u6b65\u9aa4\uff1a\u52a0\u8f7d\u6587\u4ef6 -> \u8bfb\u53d6\u6587\u672c -> \u6587\u672c\u5206\u5272 -> \u6587\u672c\u5411\u91cf\u5316 -> \u95ee\u53e5\u5411\u91cf\u5316 -> \u5728\u6587\u672c\u5411\u91cf\u4e2d\u5339\u914d\u51fa\u4e0e\u95ee\u53e5\u5411\u91cf\u6700\u76f8\u4f3c\u7684top k\u4e2a -> \u5339\u914d\u51fa\u7684\u6587\u672c\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u548c\u95ee\u9898\u4e00\u8d77\u6dfb\u52a0\u5230prompt\u4e2d -> \u63d0\u4ea4\u7ed9\u5927\u6a21\u578b\u751f\u6210\u56de\u7b54\u3002\u3010\u540e\u7eed\u5b9e\u6218\u5e94\u7528\u8bb2\u89e3\u3011","title":"2.5.1 \u57fa\u4e8e\u5d4c\u5165(embedding)\u7684\u641c\u7d22\u6280\u672f"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#252-api","text":"\u4e00\u822c\u60c5\u51b5\uff0c\u5927\u6a21\u578b\u8ba1\u7b97\u80fd\u529b\u8868\u73b0\u4e00\u822c\uff0c\u6240\u4ee5OpenAI\u5efa\u8bae\uff0c\u5982\u679c\u9047\u5230\u9700\u8981\u8ba1\u7b97\u7684\u4e1c\u897f\uff0c\u6700\u597d\u8ba9\u5927\u6a21\u578b\u5199\u4e00\u6bb5\u8ba1\u7b97\u7684Python\u4ee3\u7801\uff0c\u56e0\u4e3a\u5927\u6a21\u578b\u5bf9\u4e8ePython\u7b49\u5176\u4ed6\u7f16\u7a0b\u8bed\u8a00\u7684\u8ba1\u7b97\u9898\u5f88\u6210\u719f\u4e86\u3002 \u6bd4\u5982\uff1a\u6c42\u4ee5\u4e0b\u591a\u9879\u5f0f\u7684\u6240\u6709\u5b9e\u503c\u6839\uff1a3*x**5 - 5*x**4 - 3*x**3 - 7*x - 10\u3002\u60a8\u9700\u8981\u901a\u8fc7\u5c06 Python \u4ee3\u7801\u62ec\u5728\u4e09\u4e2a\u53cd\u5f15\u53f7\u4e2d\u6765\u7f16\u5199\u548c\u6267\u884c\uff0c\u4f8b\u5982\"\"\"\u4ee3\u7801\u653e\u5728\u8fd9\u91cc\"\"\"\u3002\u7528\u5b83\u6765\u6267\u884c\u8ba1\u7b97\u3002","title":"2.5.2 \u4f7f\u7528\u4ee3\u7801\u6267\u884c\u6765\u8fdb\u884c\u66f4\u51c6\u786e\u7684\u8ba1\u7b97\u6216\u8c03\u7528\u5916\u90e8API"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/01-%E5%A4%A7%E6%A8%A1%E5%9E%8BPrompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97.html#_3","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u8bb2\u89e3\u4e86\u5173\u4e8ePrompt Engineering\u7684\u4f7f\u7528\u6280\u5de7\u3002","title":"\u672c\u8282\u5c0f\u7ed3"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html","text":"\u91d1\u878d\u884c\u4e1a\u52a8\u6001\u65b9\u5411\u8bc4\u4f30\u9879\u76ee\u4ecb\u7ecd \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u4e86\u89e3\u9879\u76ee\u80cc\u666f \u4e86\u89e3\u6574\u4f53\u9879\u76ee\u4efb\u52a1 \u638c\u63e1Few-shot\u3001Zero-shot\u7684\u601d\u60f3 \u5b8c\u6210\u8bfe\u524d\u73af\u5883\u642d\u914d 1 \u9879\u76ee\u80cc\u666f \u00b6 \u5f53\u524d\u91d1\u878d\u9886\u57df\u4fe1\u606f\u5316\u53d1\u5c55\u7684\u65f6\u4ee3,\u91d1\u878d\u6570\u636e\u5927\u91cf\u6fc0\u589e,\u8bb8\u591a\u6295\u8d44\u8005\u548c\u7814\u7a76\u8005\u8bd5\u56fe\u901a\u8fc7\u5bf9\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u6df1\u5ea6\u5206\u6790\u800c\u83b7\u5f97\u4e00\u4e9b\u6709\u6548\u7684\u51b3\u7b56\u548c\u5e2e\u52a9,\u5c3d\u53ef\u80fd\u51cf\u5c11\u51b3\u7b56\u5931\u8bef\u5e26\u6765\u7684\u635f\u5931\u3002\u6240\u4ee5,\u9488\u5bf9\u91d1\u878d\u6570\u636e\u7684\u5206\u6790\u65b9\u6cd5\u7814\u7a76\u662f\u76ee\u524d\u5341\u5206\u6709\u76ca\u4e14\u70ed\u95e8\u7684\u8bdd\u9898\u3002 \u8fd1\u5e74\u6765\uff0c\u968f\u7740\u79d1\u6280\u7684\u8fdb\u6b65\uff0c\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5728\u5404\u884c\u4e1a\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u800c\u91d1\u878d\u9886\u57df\u4e5f\u4e0d\u4f8b\u5916\u3002\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5e94\u7528\u53ef\u4ee5\u4e3a\u91d1\u878d\u4f01\u4e1a\u63d0\u4f9b\u66f4\u9ad8\u6548\u3001\u7cbe\u51c6\u7684\u670d\u52a1\uff0c\u4e5f\u53ef\u4ee5\u5e2e\u52a9\u6295\u8d44\u8005\u66f4\u597d\u7684\u5730\u8fdb\u884c\u6295\u8d44\u51b3\u7b56\u3002 \u5f53\u524d\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5728\u91d1\u878d\u884c\u4e1a\u52a8\u6001\u5206\u6790\u9886\u57df\u7684\u5e94\u7528\u4e3b\u8981\u5305\u62ec\uff1a \u98ce\u9669\u8bc4\u4f30\uff1a\u901a\u8fc7AI\u5bf9\u5927\u6570\u636e\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u4e0d\u540c\u91d1\u878d\u98ce\u9669\u4e8b\u4ef6\u7c7b\u578b\u3001\u53cd\u6b3a\u8bc8\u884c\u4e3a\u3001\u4fe1\u7528\u8bc4\u5206\u4f4e\u7b49\u98ce\u9669\uff0c\u5e2e\u52a9\u91d1\u878d\u673a\u6784\u5168\u9762\u8bc4\u4f30\u8d37\u6b3e\u4eba\u7684\u4fe1\u7528\u72b6\u51b5\uff0c\u4ece\u800c\u63d0\u9ad8\u8d37\u6b3e\u7684\u51c6\u786e\u6027\u548c\u98ce\u9669\u63a7\u5236\u80fd\u529b\u3002 \u6295\u8d44\u51b3\u7b56\uff1a\u901a\u8fc7AI\u6280\u672f\u5bf9\u5386\u53f2\u6570\u636e\u3001\u8d22\u52a1\u62a5\u8868\u7b49\u4fe1\u606f\u5206\u6790\uff0c\u4e3a\u6295\u8d44\u8005\u63d0\u4f9b\u7cbe\u51c6\u7684\u6295\u8d44\u51b3\u7b56\u652f\u6301\u3002 \u5ba2\u6237\u670d\u52a1\uff1a\u901a\u8fc7AI\u6280\u672f\uff0c\u5b9e\u73b0\u667a\u80fd\u5ba2\u670d\u7b49\u529f\u80fd\uff0c\u8fdb\u800c\u4e3a\u5ba2\u6237\u63d0\u4f9b\u4fbf\u6377\u800c\u53c8\u51c6\u786e\u7684\u7b54\u6848 \u4f46\u662f\uff0c\u4e0a\u8ff0\u4f20\u7edf\u5e94\u7528\u7684\u5b9e\u73b0\uff0c\u901a\u5e38\u9700\u8981\u4e13\u4e1a\u7684AI\u6280\u672f\u52a0\u6301\u5982\uff1aNLP\u3001CV\u3001\u673a\u5668\u5b66\u4e60\u7b49\u77e5\u8bc6\uff0c\u5bf9\u5e94\u7684\u5c31\u9700\u8981\u4e13\u4e1a\u7684\u7b97\u6cd5\u4eba\u5458\u53bb\u5206\u6790\u6570\u636e\u3001\u8bad\u7ec3\u6a21\u578b\u4ece\u5b9e\u73b0\u9884\u6d4b\u5206\u6790\u3002\u800c\u8fd9\u5bf9\u4e8e\u975e\u4e13\u4e1a\u4eba\u5458\u6765\u8bf4\u8981\u60f3\u5b9e\u73b0\u4e0a\u8ff0\u5e94\u7528\uff0c\u53ef\u8c13\u662f\u4e3e\u6b65\u7ef4\u8270\u3002 \u7136\u800c\uff0c\u4f34\u968f\u7740ChatGPT\u7b49\u5927\u6a21\u578b\u95ee\u4e16\uff0c\u4f7f\u5f97\u975e\u4e13\u4e1a\u4eba\u5458\u5b9e\u73b0\u4e0a\u8ff0\u5e94\u7528\u6210\u4e3a\u53ef\u80fd\uff0c\u5e94\u7528\u8005\u4e0d\u9700\u8981\u7279\u522b\u4e13\u4e1a\u7684\u7b97\u6cd5\u77e5\u8bc6\uff0c\u5c31\u53ef\u4ee5\u5229\u7528\u5927\u6a21\u578b\u6765\u5b9e\u73b0\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u3002 \u56e0\u6b64\uff0c\u672c\u9879\u76ee\u4e3b\u8981\u57fa\u4e8e\u5927\u6a21\u578b\u6765\u76f4\u63a5\u5b9e\u73b0\u5728\u91d1\u878d\u9886\u57df\u76f8\u5173\u4efb\u52a1\u7684\u5e94\u7528\u3002\u91cd\u70b9\u5728\u4e8e\u5982\u4f55\u5bf9\u5927\u6a21\u578b\u8bbe\u8ba1prompt\uff0c\u4ece\u800c\u6fc0\u53d1\u5927\u6a21\u578b\u7684\"\u6d8c\u73b0\u80fd\u529b\"\uff0c\u8fdb\u800c\u7ed9\u51fa\u51c6\u786e\u7684\u7b54\u6848\u3002 2 \u9879\u76ee\u4efb\u52a1\u4e0e\u65b9\u6cd5\u4ecb\u7ecd \u00b6 \u9879\u76ee\u4efb\u52a1\uff08\u4e09\u5927\u4e1a\u52a1\u573a\u666f\uff09\uff1a \u91d1\u878d\u6587\u672c\u5206\u7c7b \u91d1\u878d\u6587\u672c\u4fe1\u606f\u62bd\u53d6 \u91d1\u878d\u6587\u672c\u5339\u914d \u5927\u6a21\u578b\u9009\u62e9\uff1aChatGLM-6B \u91c7\u7528\u65b9\u6cd5\uff1a\u57fa\u4e8eFew-Shot+Zero-Shot\u4ee5\u53caInstrunction\u7684\u601d\u60f3\uff0c\u8bbe\u8ba1prompt, \u8fdb\u800c\u5e94\u7528ChatGLM-6B\u6a21\u578b\u5b8c\u6210\u76f8\u5e94\u7684\u4efb\u52a1 \u6ce8\u610f\uff0c\u672c\u9879\u76ee\u4e3b\u8981\u4ee5\u91d1\u878d\u9886\u57df\u7684\u6587\u672c\u8fdb\u884c\u5206\u6790\uff0c\u4f46\u662f\u8be5\u601d\u60f3\u540c\u6837\u9002\u7528\u4e8e\u5176\u4ed6\u573a\u666f\u6570\u636e\u3002 3 Zero-shot/Few-shot\u56de\u987e \u00b6 3.1 Zero-shot \u00b6 Zero-shot\u5b66\u4e60\uff08Zero-shot Learning\uff09\u662f\u6307\u5728\u8bad\u7ec3\u9636\u6bb5\u4e0d\u5b58\u5728\u4e0e\u6d4b\u8bd5\u9636\u6bb5\u5b8c\u5168\u76f8\u540c\u7684\u7c7b\u522b\uff0c\u4f46\u662f\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u8fc7\u7684\u77e5\u8bc6\u6765\u63a8\u5e7f\u5230\u6d4b\u8bd5\u96c6\u4e2d\u7684\u65b0\u7c7b\u522b\u4e0a\u3002\u8fd9\u79cd\u80fd\u529b\u88ab\u79f0\u4e3a\u201c\u96f6\u6837\u672c\u201d\u5b66\u4e60\uff0c\u56e0\u4e3a\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u4ece\u672a\u89c1\u8fc7\u6d4b\u8bd5\u96c6\u4e2d\u7684\u65b0\u7c7b\u522b. \u6df1\u5165\u6316\u6398Zero-shot\u601d\u60f3\uff1a \u4e3e\u4f8b\uff1a \u6709\u4e00\u5929\uff0c\u5c0f\u660e\u548c\u7238\u7238\u4e00\u5757\u53bb\u52a8\u7269\u56ed\uff0c\u770b\u5230\u4e86\u9a6c\uff0c\u7136\u540e\u7238\u7238\u544a\u8bc9\u4ed6\uff0c\u8fd9\u5c31\u662f\u9a6c\uff1b\u4e4b\u540e\uff0c\u53c8\u770b\u5230\u4e86\u8001\u864e\uff0c\u544a\u8bc9\u4ed6\uff1a\u201c\u770b\uff0c\u8fd9\u79cd\u8eab\u4e0a\u6709\u6761\u7eb9\u7684\u52a8\u7269\u5c31\u662f\u8001\u864e\u3002\u201d\uff1b\u6700\u540e\uff0c\u53c8\u5e26\u4ed6\u53bb\u770b\u4e86\u718a\u732b\uff0c\u5bf9\u4ed6\u8bf4\uff1a\u201c\u4f60\u770b\u8fd9\u718a\u732b\u662f\u9ed1\u767d\u8272\u7684\u3002\u201d\u7136\u540e\uff0c\u7238\u7238\u7ed9\u5c0f\u660e\u63d0\u4e86\u4e2a\u95ee\u9898\uff0c\u8ba9\u4ed6\u5728\u52a8\u7269\u56ed\u91cc\u627e\u4e00\u79cd\u4ed6\u4ece\u6ca1\u89c1\u8fc7\u7684\u52a8\u7269\uff0c\u53eb\u6591\u9a6c\uff0c\u5e76\u544a\u8bc9\u4e86\u5c0f\u660e\u6709\u5173\u4e8e\u6591\u9a6c\u7684\u4fe1\u606f\uff1a\u201c\u6591\u9a6c\u6709\u7740\u9a6c\u7684\u8f6e\u5ed3\uff0c\u8eab\u4e0a\u6709\u50cf\u8001\u864e\u4e00\u6837\u7684\u6761\u7eb9\uff0c\u800c\u4e14\u5b83\u50cf\u718a\u732b\u4e00\u6837\u662f\u9ed1\u767d\u8272\u7684\u3002\u201d\u6700\u540e\uff0c\u5c0f\u660e\u6839\u636e\u7238\u7238\u7684\u63d0\u793a\uff0c\u5728\u52a8\u7269\u56ed\u91cc\u627e\u5230\u4e86\u6591\u9a6c\uff08\u610f\u6599\u4e4b\u4e2d\u7684\u7ed3\u5c40\u3002\u3002\u3002\uff09\u3002 \u4e0a\u8ff0\u4f8b\u5b50\u4e2d\u5305\u542b\u4e86\u4e00\u4e2a\u4eba\u7c7b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5c31\u662f\u5229\u7528\u8fc7\u53bb\u7684\u77e5\u8bc6\uff08\u9a6c\uff0c\u8001\u864e\uff0c\u718a\u732b\u548c\u6591\u9a6c\u7684\u63cf\u8ff0\uff09\uff0c\u5728\u8111\u6d77\u4e2d\u63a8\u7406\u51fa\u65b0\u5bf9\u8c61\u7684\u5177\u4f53\u5f62\u6001\uff0c\u4ece\u800c\u80fd\u5bf9\u65b0\u5bf9\u8c61\u8fdb\u884c\u8fa8\u8ba4\u3002\uff08\u5982\u56fe1\u6240\u793a\uff09ZSL\u5c31\u662f\u5e0c\u671b\u80fd\u591f\u6a21\u4eff\u4eba\u7c7b\u7684\u8fd9\u4e2a\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f7f\u5f97\u8ba1\u7b97\u673a\u5177\u6709\u8bc6\u522b\u65b0\u4e8b\u7269\u7684\u80fd\u529b\u3002 \u76ee\u524d\uff0c\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u5f88\u591a\u4efb\u52a1\u5728\u7eaf\u76d1\u7763\u4efb\u52a1\u5b66\u4e60\u4e0a\u90fd\u8fbe\u5230\u4e86\u8ba9\u4eba\u60ca\u53f9\u7684\u7ed3\u679c\uff0c\u4f46\u662f\u5176\u9650\u5236\u662f\uff1a\u9700\u8981\u66f4\u591a\u7684\u6837\u672c\u624d\u80fd\u8bad\u7ec3\u51fa\u8db3\u591f\u597d\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u5229\u7528\"\u732b\u9f20\"\u8bad\u7ec3\u51fa\u6765\u7684\u5206\u7c7b\u5668\uff0c\u53ea\u80fd\u5bf9\"\u732b\u9f20\"\u8fdb\u884c\u5206\u7c7b\uff0c\u5176\u4ed6\u7269\u79cd\u65e0\u6cd5\u8bc6\u522b\u3002\u663e\u7136\u8fd9\u6837\u7684\u6a21\u578b\u4e0d\u7b26\u5408\u4eba\u5de5\u667a\u80fd\u7684\u7ec8\u6781\u76ee\u6807\u3002ZSL\u5c31\u662f\u5e0c\u671b\u6a21\u578b\u80fd\u591f\u5bf9\u5176\u4ece\u6ca1\u89c1\u8fc7\u7684\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\uff0c\u8ba9\u673a\u5668\u5177\u6709\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u667a\u80fd\u3002 \u90a3\u4e48\u9488\u5bf9\u6a21\u578b\u96f6\u6b21\u5b66\u4e60\u60c5\u51b5\u4e0b\u5c31\u80fd\u51c6\u786e\u8bc6\u522b\u51fa\u7c7b\u522b\uff0c\u5982\u4f55\u5b9e\u73b0\u5462\uff1f\u5047\u8bbe\u73b0\u5728\u6a21\u578b\u5df2\u7ecf\u80fd\u591f\u8bc6\u522b\u9a6c\uff0c\u8001\u864e\u548c\u718a\u732b\u4e86\uff0c\u90a3\u4e48\u5982\u679c\u60f3\u8ba9\u5b83\u8bc6\u522b\u6591\u9a6c\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u9700\u8981\u626e\u6f14\"\u7238\u7238\"\u7684\u89d2\u8272\uff0c\u544a\u8bc9\u6a21\u578b\u4ec0\u4e48\u6837\u7684\u5bf9\u8c61\u624d\u662f\u6591\u9a6c\uff0c\u4f46\u662f\u524d\u63d0\u662f\u6a21\u578b\u4ece\u672a\"\u770b\u89c1\"\u6591\u9a6c\u3002\u6240\u4ee5\u6a21\u578b\u9700\u8981\u77e5\u9053\u7684\u4fe1\u606f\u662f\u9a6c\u7684\u6837\u672c\u3001\u8001\u864e\u7684\u6837\u672c\u3001\u718a\u732b\u7684\u6837\u672c\u548c\u6837\u672c\u7684\u6807\u7b7e\uff0c\u4ee5\u53ca\u5173\u4e8e\u524d\u4e09\u79cd\u52a8\u7269\u548c\u6591\u9a6c\u7684\u63cf\u8ff0\u3002\u5c06\u5176\u8f6c\u6362\u4e3a\u5e38\u89c4\u7684\u673a\u5668\u5b66\u4e60\uff0c\u8fd9\u91cc\u6211\u4eec\u53ea\u8ba8\u8bba\u4e00\u822c\u7684\u56fe\u7247\u5206\u7c7b\u95ee\u9898\uff1a 1\u3001\u8bad\u7ec3\u96c6\u6570\u636ex1\u53ca\u5176\u6807\u7b7e y1\uff0c\u5305\u542b\u4e86\u6a21\u578b\u9700\u8981\u5b66\u4e60\u7684\u7c7b\u522b\uff08\u9a6c\u3001\u8001\u864e\u548c\u718a\u732b\uff09\uff0c\u8fd9\u91cc\u548c\u4f20\u7edf\u7684\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u5b9a\u4e49\u4e00\u81f4\uff1b 2\u3001\u6d4b\u8bd5\u96c6\u6570\u636e x2 \u53ca\u5176\u6807\u7b7e y2 \uff0c\u5305\u542b\u4e86\u6a21\u578b\u9700\u8981\u8fa8\u8bc6\u7684\u7c7b\u522b\uff08\u6591\u9a6c\uff09\uff0c\u8fd9\u91cc\u548c\u4f20\u7edf\u7684\u76d1\u7763\u5b66\u4e60\u4e2d\u4e5f\u5b9a\u4e49\u4e00\u81f4\uff1b 3\u3001\u8bad\u7ec3\u96c6\u7c7b\u522b\u7684\u63cf\u8ff0 A1 \uff0c\u4ee5\u53ca\u6d4b\u8bd5\u96c6\u7c7b\u522b\u7684\u63cf\u8ff0A2\uff1b\u6211\u4eec\u5c06\u6bcf\u4e00\u4e2a\u7c7b\u522by1\u2208Y\uff0c\u90fd\u8868\u793a\u6210\u4e00\u4e2a\u8bed\u4e49\u5411\u91cf ai\u2208A \u7684\u5f62\u5f0f\uff0c\u800c\u8fd9\u4e2a\u8bed\u4e49\u5411\u91cf\u7684\u6bcf\u4e00\u4e2a\u7ef4\u5ea6\u90fd\u8868\u793a\u4e00\u79cd\u9ad8\u7ea7\u7684\u5c5e\u6027\uff0c\u6bd4\u5982\u201c\u9ed1\u767d\u8272\u201d\u3001\u201c\u6709\u5c3e\u5df4\u201d\u3001\u201c\u6709\u7fbd\u6bdb\u201d\u7b49\u7b49\uff0c\u5f53\u8fd9\u4e2a\u7c7b\u522b\u5305\u542b\u8fd9\u79cd\u5c5e\u6027\u65f6\uff0c\u90a3\u5728\u5176\u7ef4\u5ea6\u4e0a\u88ab\u8bbe\u7f6e\u4e3a\u975e\u96f6\u503c\u3002\u5bf9\u4e8e\u4e00\u4e2a\u6570\u636e\u96c6\u6765\u8bf4\uff0c\u8bed\u4e49\u5411\u91cf\u7684\u7ef4\u5ea6\u662f\u56fa\u5b9a\u7684\uff0c\u5b83\u5305\u542b\u4e86\u80fd\u591f\u8f83\u5145\u5206\u63cf\u8ff0\u6570\u636e\u96c6\u4e2d\u7c7b\u522b\u7684\u5c5e\u6027\u3002 \u5728ZSL\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u5229\u7528 x1 \u548c y1 \u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u800c\u6a21\u578b\u80fd\u591f\u5177\u6709\u8bc6\u522bx2 \u7684\u80fd\u529b\uff0c\u56e0\u6b64\u6a21\u578b\u9700\u8981\u77e5\u9053\u6240\u6709\u7c7b\u522b\u7684\u63cf\u8ff0 A1\u548c A2 \u3002ZSL\u8fd9\u6837\u7684\u8bbe\u7f6e\u5176\u5b9e\u5c31\u662f\u4e0a\u6587\u4e2d\u5c0f\u660e\u8bc6\u522b\u6591\u9a6c\u7684\u8fc7\u7a0b\u4e2d\uff0c\u7238\u7238\u4e3a\u4ed6\u63d0\u4f9b\u7684\u6761\u4ef6\u3002 3.2 Few-shot \u00b6 Few-shot\u5b66\u4e60\uff08Few-shot Learning\uff09\u662f\u6307\u5c11\u6837\u672c\u5b66\u4e60\uff0c\u5f53\u6a21\u578b\u5728\u5b66\u4e60\u4e86\u4e00\u5b9a\u7c7b\u522b\u7684\u5927\u91cf\u6570\u636e\u540e\uff0c\u5bf9\u4e8e\u65b0\u7684\u7c7b\u522b\uff0c\u53ea\u9700\u8981\u5c11\u91cf\u7684\u6837\u672c\u5c31\u80fd\u5feb\u901f\u5b66\u4e60\uff0c\u5bf9\u5e94\u7684\u6709one-shot learning\uff0c\u5355\u6837\u672c\u5b66\u4e60\uff0c\u4e5f\u7b97\u6837\u672c\u5c11\u5230\u4e3a\u4e00\u7684\u60c5\u51b5\u4e0b\u7684\u4e00\u79cdfew-shot learning,\u3002 Few-shot\u76f8\u6bd4Zero-shot\uff0c\u8868\u73b0\u6548\u679c\u66f4\u597d\uff0c\u4ee5\u53ca\u6cdb\u5316\u6027\u80fd\u66f4\u597d\u3002 4 \u73af\u5883\u51c6\u5907 \u00b6 \u672c\u9879\u76ee\u8fd0\u884c\u524d\u8bf7\u5b89\u88c5\u76f8\u5173\u4f9d\u8d56\u5305\uff1a protobuf>=3.19.5,<3.20.1 transformers>=4.26.1 icetk cpm_kernels streamlit==1.17.0 \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u56de\u987e\u4e86Zero-shot/Few-shot\u5b66\u4e60\u65b9\u5f0f\uff0c\u5e76\u8bf4\u660e\u4e86\u8bfe\u7a0b\u4f9d\u8d56\u73af\u5883\u3002","title":"4.2 \u91d1\u878d\u884c\u4e1a\u52a8\u6001\u65b9\u5411\u8bc4\u4f30\u9879\u76ee\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#_1","text":"","title":"\u91d1\u878d\u884c\u4e1a\u52a8\u6001\u65b9\u5411\u8bc4\u4f30\u9879\u76ee\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#_2","text":"\u4e86\u89e3\u9879\u76ee\u80cc\u666f \u4e86\u89e3\u6574\u4f53\u9879\u76ee\u4efb\u52a1 \u638c\u63e1Few-shot\u3001Zero-shot\u7684\u601d\u60f3 \u5b8c\u6210\u8bfe\u524d\u73af\u5883\u642d\u914d","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#1","text":"\u5f53\u524d\u91d1\u878d\u9886\u57df\u4fe1\u606f\u5316\u53d1\u5c55\u7684\u65f6\u4ee3,\u91d1\u878d\u6570\u636e\u5927\u91cf\u6fc0\u589e,\u8bb8\u591a\u6295\u8d44\u8005\u548c\u7814\u7a76\u8005\u8bd5\u56fe\u901a\u8fc7\u5bf9\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u6df1\u5ea6\u5206\u6790\u800c\u83b7\u5f97\u4e00\u4e9b\u6709\u6548\u7684\u51b3\u7b56\u548c\u5e2e\u52a9,\u5c3d\u53ef\u80fd\u51cf\u5c11\u51b3\u7b56\u5931\u8bef\u5e26\u6765\u7684\u635f\u5931\u3002\u6240\u4ee5,\u9488\u5bf9\u91d1\u878d\u6570\u636e\u7684\u5206\u6790\u65b9\u6cd5\u7814\u7a76\u662f\u76ee\u524d\u5341\u5206\u6709\u76ca\u4e14\u70ed\u95e8\u7684\u8bdd\u9898\u3002 \u8fd1\u5e74\u6765\uff0c\u968f\u7740\u79d1\u6280\u7684\u8fdb\u6b65\uff0c\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5728\u5404\u884c\u4e1a\u4e2d\u7684\u5e94\u7528\u8d8a\u6765\u8d8a\u5e7f\u6cdb\uff0c\u800c\u91d1\u878d\u9886\u57df\u4e5f\u4e0d\u4f8b\u5916\u3002\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5e94\u7528\u53ef\u4ee5\u4e3a\u91d1\u878d\u4f01\u4e1a\u63d0\u4f9b\u66f4\u9ad8\u6548\u3001\u7cbe\u51c6\u7684\u670d\u52a1\uff0c\u4e5f\u53ef\u4ee5\u5e2e\u52a9\u6295\u8d44\u8005\u66f4\u597d\u7684\u5730\u8fdb\u884c\u6295\u8d44\u51b3\u7b56\u3002 \u5f53\u524d\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5728\u91d1\u878d\u884c\u4e1a\u52a8\u6001\u5206\u6790\u9886\u57df\u7684\u5e94\u7528\u4e3b\u8981\u5305\u62ec\uff1a \u98ce\u9669\u8bc4\u4f30\uff1a\u901a\u8fc7AI\u5bf9\u5927\u6570\u636e\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u4e0d\u540c\u91d1\u878d\u98ce\u9669\u4e8b\u4ef6\u7c7b\u578b\u3001\u53cd\u6b3a\u8bc8\u884c\u4e3a\u3001\u4fe1\u7528\u8bc4\u5206\u4f4e\u7b49\u98ce\u9669\uff0c\u5e2e\u52a9\u91d1\u878d\u673a\u6784\u5168\u9762\u8bc4\u4f30\u8d37\u6b3e\u4eba\u7684\u4fe1\u7528\u72b6\u51b5\uff0c\u4ece\u800c\u63d0\u9ad8\u8d37\u6b3e\u7684\u51c6\u786e\u6027\u548c\u98ce\u9669\u63a7\u5236\u80fd\u529b\u3002 \u6295\u8d44\u51b3\u7b56\uff1a\u901a\u8fc7AI\u6280\u672f\u5bf9\u5386\u53f2\u6570\u636e\u3001\u8d22\u52a1\u62a5\u8868\u7b49\u4fe1\u606f\u5206\u6790\uff0c\u4e3a\u6295\u8d44\u8005\u63d0\u4f9b\u7cbe\u51c6\u7684\u6295\u8d44\u51b3\u7b56\u652f\u6301\u3002 \u5ba2\u6237\u670d\u52a1\uff1a\u901a\u8fc7AI\u6280\u672f\uff0c\u5b9e\u73b0\u667a\u80fd\u5ba2\u670d\u7b49\u529f\u80fd\uff0c\u8fdb\u800c\u4e3a\u5ba2\u6237\u63d0\u4f9b\u4fbf\u6377\u800c\u53c8\u51c6\u786e\u7684\u7b54\u6848 \u4f46\u662f\uff0c\u4e0a\u8ff0\u4f20\u7edf\u5e94\u7528\u7684\u5b9e\u73b0\uff0c\u901a\u5e38\u9700\u8981\u4e13\u4e1a\u7684AI\u6280\u672f\u52a0\u6301\u5982\uff1aNLP\u3001CV\u3001\u673a\u5668\u5b66\u4e60\u7b49\u77e5\u8bc6\uff0c\u5bf9\u5e94\u7684\u5c31\u9700\u8981\u4e13\u4e1a\u7684\u7b97\u6cd5\u4eba\u5458\u53bb\u5206\u6790\u6570\u636e\u3001\u8bad\u7ec3\u6a21\u578b\u4ece\u5b9e\u73b0\u9884\u6d4b\u5206\u6790\u3002\u800c\u8fd9\u5bf9\u4e8e\u975e\u4e13\u4e1a\u4eba\u5458\u6765\u8bf4\u8981\u60f3\u5b9e\u73b0\u4e0a\u8ff0\u5e94\u7528\uff0c\u53ef\u8c13\u662f\u4e3e\u6b65\u7ef4\u8270\u3002 \u7136\u800c\uff0c\u4f34\u968f\u7740ChatGPT\u7b49\u5927\u6a21\u578b\u95ee\u4e16\uff0c\u4f7f\u5f97\u975e\u4e13\u4e1a\u4eba\u5458\u5b9e\u73b0\u4e0a\u8ff0\u5e94\u7528\u6210\u4e3a\u53ef\u80fd\uff0c\u5e94\u7528\u8005\u4e0d\u9700\u8981\u7279\u522b\u4e13\u4e1a\u7684\u7b97\u6cd5\u77e5\u8bc6\uff0c\u5c31\u53ef\u4ee5\u5229\u7528\u5927\u6a21\u578b\u6765\u5b9e\u73b0\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\u3002 \u56e0\u6b64\uff0c\u672c\u9879\u76ee\u4e3b\u8981\u57fa\u4e8e\u5927\u6a21\u578b\u6765\u76f4\u63a5\u5b9e\u73b0\u5728\u91d1\u878d\u9886\u57df\u76f8\u5173\u4efb\u52a1\u7684\u5e94\u7528\u3002\u91cd\u70b9\u5728\u4e8e\u5982\u4f55\u5bf9\u5927\u6a21\u578b\u8bbe\u8ba1prompt\uff0c\u4ece\u800c\u6fc0\u53d1\u5927\u6a21\u578b\u7684\"\u6d8c\u73b0\u80fd\u529b\"\uff0c\u8fdb\u800c\u7ed9\u51fa\u51c6\u786e\u7684\u7b54\u6848\u3002","title":"1 \u9879\u76ee\u80cc\u666f"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#2","text":"\u9879\u76ee\u4efb\u52a1\uff08\u4e09\u5927\u4e1a\u52a1\u573a\u666f\uff09\uff1a \u91d1\u878d\u6587\u672c\u5206\u7c7b \u91d1\u878d\u6587\u672c\u4fe1\u606f\u62bd\u53d6 \u91d1\u878d\u6587\u672c\u5339\u914d \u5927\u6a21\u578b\u9009\u62e9\uff1aChatGLM-6B \u91c7\u7528\u65b9\u6cd5\uff1a\u57fa\u4e8eFew-Shot+Zero-Shot\u4ee5\u53caInstrunction\u7684\u601d\u60f3\uff0c\u8bbe\u8ba1prompt, \u8fdb\u800c\u5e94\u7528ChatGLM-6B\u6a21\u578b\u5b8c\u6210\u76f8\u5e94\u7684\u4efb\u52a1 \u6ce8\u610f\uff0c\u672c\u9879\u76ee\u4e3b\u8981\u4ee5\u91d1\u878d\u9886\u57df\u7684\u6587\u672c\u8fdb\u884c\u5206\u6790\uff0c\u4f46\u662f\u8be5\u601d\u60f3\u540c\u6837\u9002\u7528\u4e8e\u5176\u4ed6\u573a\u666f\u6570\u636e\u3002","title":"2 \u9879\u76ee\u4efb\u52a1\u4e0e\u65b9\u6cd5\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#3-zero-shotfew-shot","text":"","title":"3 Zero-shot/Few-shot\u56de\u987e"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#31-zero-shot","text":"Zero-shot\u5b66\u4e60\uff08Zero-shot Learning\uff09\u662f\u6307\u5728\u8bad\u7ec3\u9636\u6bb5\u4e0d\u5b58\u5728\u4e0e\u6d4b\u8bd5\u9636\u6bb5\u5b8c\u5168\u76f8\u540c\u7684\u7c7b\u522b\uff0c\u4f46\u662f\u6a21\u578b\u53ef\u4ee5\u4f7f\u7528\u8bad\u7ec3\u8fc7\u7684\u77e5\u8bc6\u6765\u63a8\u5e7f\u5230\u6d4b\u8bd5\u96c6\u4e2d\u7684\u65b0\u7c7b\u522b\u4e0a\u3002\u8fd9\u79cd\u80fd\u529b\u88ab\u79f0\u4e3a\u201c\u96f6\u6837\u672c\u201d\u5b66\u4e60\uff0c\u56e0\u4e3a\u6a21\u578b\u5728\u8bad\u7ec3\u65f6\u4ece\u672a\u89c1\u8fc7\u6d4b\u8bd5\u96c6\u4e2d\u7684\u65b0\u7c7b\u522b. \u6df1\u5165\u6316\u6398Zero-shot\u601d\u60f3\uff1a \u4e3e\u4f8b\uff1a \u6709\u4e00\u5929\uff0c\u5c0f\u660e\u548c\u7238\u7238\u4e00\u5757\u53bb\u52a8\u7269\u56ed\uff0c\u770b\u5230\u4e86\u9a6c\uff0c\u7136\u540e\u7238\u7238\u544a\u8bc9\u4ed6\uff0c\u8fd9\u5c31\u662f\u9a6c\uff1b\u4e4b\u540e\uff0c\u53c8\u770b\u5230\u4e86\u8001\u864e\uff0c\u544a\u8bc9\u4ed6\uff1a\u201c\u770b\uff0c\u8fd9\u79cd\u8eab\u4e0a\u6709\u6761\u7eb9\u7684\u52a8\u7269\u5c31\u662f\u8001\u864e\u3002\u201d\uff1b\u6700\u540e\uff0c\u53c8\u5e26\u4ed6\u53bb\u770b\u4e86\u718a\u732b\uff0c\u5bf9\u4ed6\u8bf4\uff1a\u201c\u4f60\u770b\u8fd9\u718a\u732b\u662f\u9ed1\u767d\u8272\u7684\u3002\u201d\u7136\u540e\uff0c\u7238\u7238\u7ed9\u5c0f\u660e\u63d0\u4e86\u4e2a\u95ee\u9898\uff0c\u8ba9\u4ed6\u5728\u52a8\u7269\u56ed\u91cc\u627e\u4e00\u79cd\u4ed6\u4ece\u6ca1\u89c1\u8fc7\u7684\u52a8\u7269\uff0c\u53eb\u6591\u9a6c\uff0c\u5e76\u544a\u8bc9\u4e86\u5c0f\u660e\u6709\u5173\u4e8e\u6591\u9a6c\u7684\u4fe1\u606f\uff1a\u201c\u6591\u9a6c\u6709\u7740\u9a6c\u7684\u8f6e\u5ed3\uff0c\u8eab\u4e0a\u6709\u50cf\u8001\u864e\u4e00\u6837\u7684\u6761\u7eb9\uff0c\u800c\u4e14\u5b83\u50cf\u718a\u732b\u4e00\u6837\u662f\u9ed1\u767d\u8272\u7684\u3002\u201d\u6700\u540e\uff0c\u5c0f\u660e\u6839\u636e\u7238\u7238\u7684\u63d0\u793a\uff0c\u5728\u52a8\u7269\u56ed\u91cc\u627e\u5230\u4e86\u6591\u9a6c\uff08\u610f\u6599\u4e4b\u4e2d\u7684\u7ed3\u5c40\u3002\u3002\u3002\uff09\u3002 \u4e0a\u8ff0\u4f8b\u5b50\u4e2d\u5305\u542b\u4e86\u4e00\u4e2a\u4eba\u7c7b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u5c31\u662f\u5229\u7528\u8fc7\u53bb\u7684\u77e5\u8bc6\uff08\u9a6c\uff0c\u8001\u864e\uff0c\u718a\u732b\u548c\u6591\u9a6c\u7684\u63cf\u8ff0\uff09\uff0c\u5728\u8111\u6d77\u4e2d\u63a8\u7406\u51fa\u65b0\u5bf9\u8c61\u7684\u5177\u4f53\u5f62\u6001\uff0c\u4ece\u800c\u80fd\u5bf9\u65b0\u5bf9\u8c61\u8fdb\u884c\u8fa8\u8ba4\u3002\uff08\u5982\u56fe1\u6240\u793a\uff09ZSL\u5c31\u662f\u5e0c\u671b\u80fd\u591f\u6a21\u4eff\u4eba\u7c7b\u7684\u8fd9\u4e2a\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f7f\u5f97\u8ba1\u7b97\u673a\u5177\u6709\u8bc6\u522b\u65b0\u4e8b\u7269\u7684\u80fd\u529b\u3002 \u76ee\u524d\uff0c\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u5f88\u591a\u4efb\u52a1\u5728\u7eaf\u76d1\u7763\u4efb\u52a1\u5b66\u4e60\u4e0a\u90fd\u8fbe\u5230\u4e86\u8ba9\u4eba\u60ca\u53f9\u7684\u7ed3\u679c\uff0c\u4f46\u662f\u5176\u9650\u5236\u662f\uff1a\u9700\u8981\u66f4\u591a\u7684\u6837\u672c\u624d\u80fd\u8bad\u7ec3\u51fa\u8db3\u591f\u597d\u7684\u6a21\u578b\uff0c\u5e76\u4e14\u5229\u7528\"\u732b\u9f20\"\u8bad\u7ec3\u51fa\u6765\u7684\u5206\u7c7b\u5668\uff0c\u53ea\u80fd\u5bf9\"\u732b\u9f20\"\u8fdb\u884c\u5206\u7c7b\uff0c\u5176\u4ed6\u7269\u79cd\u65e0\u6cd5\u8bc6\u522b\u3002\u663e\u7136\u8fd9\u6837\u7684\u6a21\u578b\u4e0d\u7b26\u5408\u4eba\u5de5\u667a\u80fd\u7684\u7ec8\u6781\u76ee\u6807\u3002ZSL\u5c31\u662f\u5e0c\u671b\u6a21\u578b\u80fd\u591f\u5bf9\u5176\u4ece\u6ca1\u89c1\u8fc7\u7684\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\uff0c\u8ba9\u673a\u5668\u5177\u6709\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u667a\u80fd\u3002 \u90a3\u4e48\u9488\u5bf9\u6a21\u578b\u96f6\u6b21\u5b66\u4e60\u60c5\u51b5\u4e0b\u5c31\u80fd\u51c6\u786e\u8bc6\u522b\u51fa\u7c7b\u522b\uff0c\u5982\u4f55\u5b9e\u73b0\u5462\uff1f\u5047\u8bbe\u73b0\u5728\u6a21\u578b\u5df2\u7ecf\u80fd\u591f\u8bc6\u522b\u9a6c\uff0c\u8001\u864e\u548c\u718a\u732b\u4e86\uff0c\u90a3\u4e48\u5982\u679c\u60f3\u8ba9\u5b83\u8bc6\u522b\u6591\u9a6c\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u9700\u8981\u626e\u6f14\"\u7238\u7238\"\u7684\u89d2\u8272\uff0c\u544a\u8bc9\u6a21\u578b\u4ec0\u4e48\u6837\u7684\u5bf9\u8c61\u624d\u662f\u6591\u9a6c\uff0c\u4f46\u662f\u524d\u63d0\u662f\u6a21\u578b\u4ece\u672a\"\u770b\u89c1\"\u6591\u9a6c\u3002\u6240\u4ee5\u6a21\u578b\u9700\u8981\u77e5\u9053\u7684\u4fe1\u606f\u662f\u9a6c\u7684\u6837\u672c\u3001\u8001\u864e\u7684\u6837\u672c\u3001\u718a\u732b\u7684\u6837\u672c\u548c\u6837\u672c\u7684\u6807\u7b7e\uff0c\u4ee5\u53ca\u5173\u4e8e\u524d\u4e09\u79cd\u52a8\u7269\u548c\u6591\u9a6c\u7684\u63cf\u8ff0\u3002\u5c06\u5176\u8f6c\u6362\u4e3a\u5e38\u89c4\u7684\u673a\u5668\u5b66\u4e60\uff0c\u8fd9\u91cc\u6211\u4eec\u53ea\u8ba8\u8bba\u4e00\u822c\u7684\u56fe\u7247\u5206\u7c7b\u95ee\u9898\uff1a 1\u3001\u8bad\u7ec3\u96c6\u6570\u636ex1\u53ca\u5176\u6807\u7b7e y1\uff0c\u5305\u542b\u4e86\u6a21\u578b\u9700\u8981\u5b66\u4e60\u7684\u7c7b\u522b\uff08\u9a6c\u3001\u8001\u864e\u548c\u718a\u732b\uff09\uff0c\u8fd9\u91cc\u548c\u4f20\u7edf\u7684\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u5b9a\u4e49\u4e00\u81f4\uff1b 2\u3001\u6d4b\u8bd5\u96c6\u6570\u636e x2 \u53ca\u5176\u6807\u7b7e y2 \uff0c\u5305\u542b\u4e86\u6a21\u578b\u9700\u8981\u8fa8\u8bc6\u7684\u7c7b\u522b\uff08\u6591\u9a6c\uff09\uff0c\u8fd9\u91cc\u548c\u4f20\u7edf\u7684\u76d1\u7763\u5b66\u4e60\u4e2d\u4e5f\u5b9a\u4e49\u4e00\u81f4\uff1b 3\u3001\u8bad\u7ec3\u96c6\u7c7b\u522b\u7684\u63cf\u8ff0 A1 \uff0c\u4ee5\u53ca\u6d4b\u8bd5\u96c6\u7c7b\u522b\u7684\u63cf\u8ff0A2\uff1b\u6211\u4eec\u5c06\u6bcf\u4e00\u4e2a\u7c7b\u522by1\u2208Y\uff0c\u90fd\u8868\u793a\u6210\u4e00\u4e2a\u8bed\u4e49\u5411\u91cf ai\u2208A \u7684\u5f62\u5f0f\uff0c\u800c\u8fd9\u4e2a\u8bed\u4e49\u5411\u91cf\u7684\u6bcf\u4e00\u4e2a\u7ef4\u5ea6\u90fd\u8868\u793a\u4e00\u79cd\u9ad8\u7ea7\u7684\u5c5e\u6027\uff0c\u6bd4\u5982\u201c\u9ed1\u767d\u8272\u201d\u3001\u201c\u6709\u5c3e\u5df4\u201d\u3001\u201c\u6709\u7fbd\u6bdb\u201d\u7b49\u7b49\uff0c\u5f53\u8fd9\u4e2a\u7c7b\u522b\u5305\u542b\u8fd9\u79cd\u5c5e\u6027\u65f6\uff0c\u90a3\u5728\u5176\u7ef4\u5ea6\u4e0a\u88ab\u8bbe\u7f6e\u4e3a\u975e\u96f6\u503c\u3002\u5bf9\u4e8e\u4e00\u4e2a\u6570\u636e\u96c6\u6765\u8bf4\uff0c\u8bed\u4e49\u5411\u91cf\u7684\u7ef4\u5ea6\u662f\u56fa\u5b9a\u7684\uff0c\u5b83\u5305\u542b\u4e86\u80fd\u591f\u8f83\u5145\u5206\u63cf\u8ff0\u6570\u636e\u96c6\u4e2d\u7c7b\u522b\u7684\u5c5e\u6027\u3002 \u5728ZSL\u4e2d\uff0c\u6211\u4eec\u5e0c\u671b\u5229\u7528 x1 \u548c y1 \u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u800c\u6a21\u578b\u80fd\u591f\u5177\u6709\u8bc6\u522bx2 \u7684\u80fd\u529b\uff0c\u56e0\u6b64\u6a21\u578b\u9700\u8981\u77e5\u9053\u6240\u6709\u7c7b\u522b\u7684\u63cf\u8ff0 A1\u548c A2 \u3002ZSL\u8fd9\u6837\u7684\u8bbe\u7f6e\u5176\u5b9e\u5c31\u662f\u4e0a\u6587\u4e2d\u5c0f\u660e\u8bc6\u522b\u6591\u9a6c\u7684\u8fc7\u7a0b\u4e2d\uff0c\u7238\u7238\u4e3a\u4ed6\u63d0\u4f9b\u7684\u6761\u4ef6\u3002","title":"3.1 Zero-shot"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#32-few-shot","text":"Few-shot\u5b66\u4e60\uff08Few-shot Learning\uff09\u662f\u6307\u5c11\u6837\u672c\u5b66\u4e60\uff0c\u5f53\u6a21\u578b\u5728\u5b66\u4e60\u4e86\u4e00\u5b9a\u7c7b\u522b\u7684\u5927\u91cf\u6570\u636e\u540e\uff0c\u5bf9\u4e8e\u65b0\u7684\u7c7b\u522b\uff0c\u53ea\u9700\u8981\u5c11\u91cf\u7684\u6837\u672c\u5c31\u80fd\u5feb\u901f\u5b66\u4e60\uff0c\u5bf9\u5e94\u7684\u6709one-shot learning\uff0c\u5355\u6837\u672c\u5b66\u4e60\uff0c\u4e5f\u7b97\u6837\u672c\u5c11\u5230\u4e3a\u4e00\u7684\u60c5\u51b5\u4e0b\u7684\u4e00\u79cdfew-shot learning,\u3002 Few-shot\u76f8\u6bd4Zero-shot\uff0c\u8868\u73b0\u6548\u679c\u66f4\u597d\uff0c\u4ee5\u53ca\u6cdb\u5316\u6027\u80fd\u66f4\u597d\u3002","title":"3.2 Few-shot"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#4","text":"\u672c\u9879\u76ee\u8fd0\u884c\u524d\u8bf7\u5b89\u88c5\u76f8\u5173\u4f9d\u8d56\u5305\uff1a protobuf>=3.19.5,<3.20.1 transformers>=4.26.1 icetk cpm_kernels streamlit==1.17.0","title":"4  \u73af\u5883\u51c6\u5907"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/02-%E9%87%91%E8%9E%8D%E8%A1%8C%E4%B8%9A%E5%8A%A8%E6%80%81%E6%96%B9%E5%90%91%E8%AF%84%E4%BC%B0%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D.html#_3","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u9879\u76ee\u5f00\u53d1\u7684\u80cc\u666f\u53ca\u610f\u4e49\uff0c\u56de\u987e\u4e86Zero-shot/Few-shot\u5b66\u4e60\u65b9\u5f0f\uff0c\u5e76\u8bf4\u660e\u4e86\u8bfe\u7a0b\u4f9d\u8d56\u73af\u5883\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html","text":"\u57fa\u4e8eZero-shot\u65b9\u5f0f\u5b9e\u73b0LLM\u6587\u672c\u5206\u7c7b \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1Zero-shot\u65b9\u5f0f\u4e0bprompt\u7684\u8bbe\u8ba1\u65b9\u5f0f \u638c\u63e1\u5229\u7528LLM\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u4ee3\u7801 1 LLM\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4ecb\u7ecd \u00b6 \u4e0b\u9762\u51e0\u6bb5\u6587\u672c\u6765\u81ea\u67d0\u5e73\u53f0\u53d1\u5e03\u7684\u91d1\u878d\u9886\u57df\u6587\u672c\uff1a 1.\"\u4eca\u65e5\uff0c\u592e\u884c\u53d1\u5e03\u516c\u544a\u5ba3\u5e03\u964d\u4f4e\u5229\u7387\uff0c\u4ee5\u523a\u6fc0\u7ecf\u6d4e\u589e\u957f\u3002\u8fd9\u4e00\u964d\u606f\u4e3e\u63aa\u5c06\u5f71\u54cd\u8d37\u6b3e\u5229\u7387\uff0c\u5e76\u5728\u672a\u6765\u51e0\u4e2a\u5b63\u5ea6\u5185\u5bf9\u91d1\u878d\u5e02\u573a\u4ea7\u751f\u5f71\u54cd\u3002\", 2.\"ABC\u516c\u53f8\u4eca\u65e5\u53d1\u5e03\u516c\u544a\u79f0\uff0c\u5df2\u6210\u529f\u5b8c\u6210\u5bf9XYZ\u516c\u53f8\u80a1\u6743\u7684\u6536\u8d2d\u4ea4\u6613\u3002\u672c\u6b21\u4ea4\u6613\u662fABC\u516c\u53f8\u5728\u6269\u5927\u4e1a\u52a1\u8303\u56f4\u3001\u52a0\u5f3a\u5e02\u573a\u7ade\u4e89\u529b\u65b9\u9762\u7684\u91cd\u8981\u4e3e\u63aa\u3002\u636e\u6089\uff0c\u6b64\u6b21\u6536\u8d2d\u5c06\u8fdb\u4e00\u6b65\u5de9\u56faABC\u516c\u53f8\u5728\u884c\u4e1a\u4e2d\u7684\u5730\u4f4d\uff0c\u5e76\u4e3a\u672a\u6765\u4e1a\u52a1\u53d1\u5c55\u63d0\u4f9b\u66f4\u5e7f\u9614\u7684\u53d1\u5c55\u7a7a\u95f4\u3002\u8be6\u60c5\u8bf7\u89c1\u516c\u53f8\u5b98\u65b9\u7f51\u7ad9\u516c\u544a\u680f\", 3.\"\u516c\u53f8\u8d44\u4ea7\u8d1f\u503a\u8868\u663e\u793a\uff0c\u516c\u53f8\u507f\u503a\u80fd\u529b\u5f3a\u52b2\uff0c\u73b0\u91d1\u6d41\u5145\u8db3\uff0c\u4e3a\u672a\u6765\u6295\u8d44\u548c\u6269\u5f20\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u8d22\u52a1\u57fa\u7840\u3002\", 4.\"\u6700\u65b0\u7684\u5206\u6790\u62a5\u544a\u6307\u51fa\uff0c\u53ef\u518d\u751f\u80fd\u6e90\u884c\u4e1a\u9884\u8ba1\u5c06\u5728\u672a\u6765\u51e0\u5e74\u7ecf\u5386\u6301\u7eed\u589e\u957f\uff0c\u6295\u8d44\u8005\u5e94\u8be5\u5173\u6ce8\u8fd9\u4e00\u9886\u57df\u7684\u6295\u8d44\u673a\u4f1a\", \u6211\u4eec\u7684\u76ee\u7684\u662f\u671f\u671b\u6a21\u578b\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u8bc6\u522b\u51fa\u8fd94\u6bb5\u8bdd\u4e2d\uff0c\u6bcf\u4e00\u53e5\u8bdd\u63cf\u8ff0\u7684\u662f\u4e00\u4e2a\u4ec0\u4e48\u7c7b\u578b\u7684\u62a5\u544a\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u671f\u671b\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a\uff1a ['\u65b0\u95fb\u62a5\u9053', '\u516c\u53f8\u516c\u544a', '\u8d22\u52a1\u516c\u544a '\u5206\u6790\u5e08\u62a5\u544a'] 2 Prompt\u8bbe\u8ba1 \u00b6 \u5bf9\u4e8e\u5927\u6a21\u578b\u6765\u8bb2\uff0cprompt \u7684\u8bbe\u8ba1\u975e\u5e38\u91cd\u8981\uff0c\u4e00\u4e2a \u660e\u786e \u7684 prompt \u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u66f4\u597d\u4ece\u5927\u6a21\u578b\u4e2d\u83b7\u5f97\u6211\u4eec\u60f3\u8981\u7684\u7ed3\u679c\u3002 \u5728\u8be5\u4efb\u52a1\u7684 prompt \u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u8003\u8651 2 \u70b9\uff1a \u9700\u8981\u5411\u6a21\u578b\u89e3\u91ca\u4ec0\u4e48\u53eb\u4f5c\u300c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u300d \u9700\u8981\u8ba9\u6a21\u578b\u6309\u7167\u6211\u4eec\u6307\u5b9a\u7684\u683c\u5f0f\u8f93\u51fa \u4e3a\u4e86\u8ba9\u6a21\u578b\u77e5\u9053\u4ec0\u4e48\u53eb\u505a\u300c\u6587\u672c\u5206\u7c7b\u300d\uff0c\u6211\u4eec\u501f\u7528 Incontext Learning \u7684\u65b9\u5f0f\uff0c\u5148\u7ed9\u6a21\u578b\u5c55\u793a\u51e0\u4e2a\u6b63\u786e\u7684\u4f8b\u5b50\uff1a >>> User: \"\u4eca\u65e5\uff0c\u80a1\u5e02\u7ecf\u5386\u4e86\u4e00\u8f6e\u9707\u8361\uff0c\u53d7\u5230\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u548c\u5168\u7403\u8d38\u6613\u7d27\u5f20\u5c40\u52bf\u7684\u5f71\u54cd\u3002\u6295\u8d44\u8005\u5bc6\u5207\u5173\u6ce8\u7f8e\u8054\u50a8\u53ef\u80fd\u7684\u653f\u7b56\u8c03\u6574\uff0c\u4ee5\u9002\u5e94\u5e02\u573a\u7684\u4e0d\u786e\u5b9a\u6027\u3002\" \u662f['\u65b0\u95fb\u62a5\u9053', '\u516c\u53f8\u516c\u544a', '\u8d22\u52a1\u516c\u544a '\u5206\u6790\u5e08\u62a5\u544a']\u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f >>> Bot: \u65b0\u95fb\u62a5\u9053 >>> User: \"\u672c\u516c\u53f8\u5e74\u5ea6\u8d22\u52a1\u62a5\u544a\u663e\u793a\uff0c\u53bb\u5e74\u516c\u53f8\u5b9e\u73b0\u4e86\u7a33\u6b65\u589e\u957f\u7684\u76c8\u5229\uff0c\u540c\u65f6\u8d44\u4ea7\u8d1f\u503a\u8868\u5448\u73b0\u5f3a\u52b2\u7684\u72b6\u51b5\u3002\u7ecf\u6d4e\u73af\u5883\u7684\u7a33\u5b9a\u548c\u7ba1\u7406\u5c42\u7684\u6709\u6548\u6218\u7565\u6267\u884c\u4e3a\u516c\u53f8\u7684\u5065\u5eb7\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002\"\u662f['\u65b0\u95fb\u62a5\u9053', '\u516c\u53f8\u516c\u544a', '\u8d22\u52a1\u516c\u544a '\u5206\u6790\u5e08\u62a5\u544a']\u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f >>> Bot: \u8d22\u52a1\u62a5\u544a \u5176\u4e2d\uff0c User \u4ee3\u8868\u6211\u4eec\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u53e5\u5b50\uff0c Bot \u4ee3\u8868\u6a21\u578b\u7684\u56de\u590d\u5185\u5bb9\u3002 \u6ce8\u610f\uff1a\u4e0a\u8ff0\u4f8b\u5b50\u4e2d Bot \u7684\u90e8\u5206\u4e5f\u662f\u7531\u4eba\u5de5\u8f93\u5165\u7684\uff0c\u5176\u76ee\u7684\u662f\u5e0c\u671b\u770b\u5230\u5728\u770b\u5230\u7c7b\u4f3c User \u4e2d\u7684\u53e5\u5b50\u65f6\uff0c\u6a21\u578b\u5e94\u5f53\u505a\u51fa\u7c7b\u4f3c Bot \u7684\u56de\u7b54\u3002 3 \u5206\u7c7b\u4efb\u52a1\u4ee3\u7801\u5b9e\u73b0 \u00b6 \u672c\u7ae0\u8282\u4f7f\u7528\u7684\u6a21\u578b\u4e3aChatGLM-6B\uff0c\u53c2\u6570\u53c2\u6570\u8f83\u5927\uff086B\uff09\uff0c\u4e0b\u8f7d\u5230\u672c\u5730\u5927\u6982\u9700\u8981 12G+ \u7684\u78c1\u76d8\u7a7a\u95f4\uff0c\u8bf7\u786e\u4fdd\u78c1\u76d8\u6709\u5145\u8db3\u7684\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u52a0\u8f7d\u6a21\u578b\u5927\u6982\u9700\u8981 13G \u5de6\u53f3\u7684\u663e\u5b58\uff0c\u5982\u679c\u60a8\u663e\u5b58\u4e0d\u591f\uff0c\u53ef\u4ee5\u8fdb\u884c\u6a21\u578b\u91cf\u5316\u52a0\u8f7d\u4ee5\u7f29\u5c0f\u6a21\u578b\u6210\u672c\u3002 \u672c\u6b21\u5206\u7c7b\u4efb\u52a1\u5b9e\u73b0\u7684\u4e3b\u8981\u8fc7\u7a0b\uff1a \u6784\u9020prompt \u5b9e\u73b0\u6a21\u578b\u9884\u6d4b \u4ee3\u7801\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/zero-shot/finance_classify.py llm_classification.py\u811a\u672c\u4e2d\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1ainit_prompts()\u548cinference() 3.1 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 \u00b6 # \u2014*-coding:utf-8-*- \"\"\" \u5229\u7528 LLM \u8fdb\u884c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u3002 \"\"\" from rich import print from rich.console import Console from transformers import AutoTokenizer , AutoModel # \u63d0\u4f9b\u6240\u6709\u7c7b\u522b\u4ee5\u53ca\u6bcf\u4e2a\u7c7b\u522b\u4e0b\u7684\u6837\u4f8b class_examples = { '\u65b0\u95fb\u62a5\u9053' : '\u4eca\u65e5\uff0c\u80a1\u5e02\u7ecf\u5386\u4e86\u4e00\u8f6e\u9707\u8361\uff0c\u53d7\u5230\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u548c\u5168\u7403\u8d38\u6613\u7d27\u5f20\u5c40\u52bf\u7684\u5f71\u54cd\u3002\u6295\u8d44\u8005\u5bc6\u5207\u5173\u6ce8\u7f8e\u8054\u50a8\u53ef\u80fd\u7684\u653f\u7b56\u8c03\u6574\uff0c\u4ee5\u9002\u5e94\u5e02\u573a\u7684\u4e0d\u786e\u5b9a\u6027\u3002' , '\u8d22\u52a1\u62a5\u544a' : '\u672c\u516c\u53f8\u5e74\u5ea6\u8d22\u52a1\u62a5\u544a\u663e\u793a\uff0c\u53bb\u5e74\u516c\u53f8\u5b9e\u73b0\u4e86\u7a33\u6b65\u589e\u957f\u7684\u76c8\u5229\uff0c\u540c\u65f6\u8d44\u4ea7\u8d1f\u503a\u8868\u5448\u73b0\u5f3a\u52b2\u7684\u72b6\u51b5\u3002\u7ecf\u6d4e\u73af\u5883\u7684\u7a33\u5b9a\u548c\u7ba1\u7406\u5c42\u7684\u6709\u6548\u6218\u7565\u6267\u884c\u4e3a\u516c\u53f8\u7684\u5065\u5eb7\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002' , '\u516c\u53f8\u516c\u544a' : '\u672c\u516c\u53f8\u9ad8\u5174\u5730\u5ba3\u5e03\u6210\u529f\u5b8c\u6210\u6700\u65b0\u4e00\u8f6e\u5e76\u8d2d\u4ea4\u6613\uff0c\u6536\u8d2d\u4e86\u4e00\u5bb6\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u9886\u5148\u7684\u516c\u53f8\u3002\u8fd9\u4e00\u6218\u7565\u4e3e\u63aa\u5c06\u6709\u52a9\u4e8e\u6269\u5927\u6211\u4eec\u7684\u4e1a\u52a1\u9886\u57df\uff0c\u63d0\u9ad8\u5e02\u573a\u7ade\u4e89\u529b' , '\u5206\u6790\u5e08\u62a5\u544a' : '\u6700\u65b0\u7684\u884c\u4e1a\u5206\u6790\u62a5\u544a\u6307\u51fa\uff0c\u79d1\u6280\u516c\u53f8\u7684\u521b\u65b0\u5c06\u6210\u4e3a\u672a\u6765\u589e\u957f\u7684\u4e3b\u8981\u63a8\u52a8\u529b\u3002\u4e91\u8ba1\u7b97\u3001\u4eba\u5de5\u667a\u80fd\u548c\u6570\u5b57\u5316\u8f6c\u578b\u88ab\u8ba4\u4e3a\u662f\u5f15\u9886\u884c\u4e1a\u53d1\u5c55\u7684\u5173\u952e\u56e0\u7d20\uff0c\u6295\u8d44\u8005\u5e94\u5173\u6ce8\u8fd9\u4e9b\u8d8b\u52bf' } 3.2 \u6784\u5efainit_prompts()\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u8fdb\u884cprompt\u8bbe\u8ba1 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a def init_prompts (): \"\"\" \u521d\u59cb\u5316\u524d\u7f6eprompt\uff0c\u4fbf\u4e8e\u6a21\u578b\u505a incontext learning\u3002 \"\"\" class_list = list ( class_examples . keys ()) pre_history = [ ( f '\u73b0\u5728\u4f60\u662f\u4e00\u4e2a\u6587\u672c\u5206\u7c7b\u5668\uff0c\u4f60\u9700\u8981\u6309\u7167\u8981\u6c42\u5c06\u6211\u7ed9\u4f60\u7684\u53e5\u5b50\u5206\u7c7b\u5230\uff1a { class_list } \u7c7b\u522b\u4e2d\u3002' , f '\u597d\u7684\u3002' ) ] for _type , exmpale in class_examples . items (): pre_history . append (( f '\u201c { exmpale } \u201d\u662f { class_list } \u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f' , _type )) return { 'class_list' : class_list , 'pre_history' : pre_history } 3.3 \u6784\u5efainference()\u51fd\u6570 \u76ee\u7684\uff1a\u5b9e\u73b0\u6587\u672c\u5206\u7c7b \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def inference ( sentences : list , custom_settings : dict ): \"\"\" \u63a8\u7406\u51fd\u6570\u3002 Args: sentences (List[str]): \u5f85\u63a8\u7406\u7684\u53e5\u5b50\u3002 custom_settings (dict): \u521d\u59cb\u8bbe\u5b9a\uff0c\u5305\u542b\u4eba\u4e3a\u7ed9\u5b9a\u7684 few-shot example\u3002 \"\"\" for sentence in sentences : with console . status ( \"[bold bright_green] Model Inference...\" ): sentence_with_prompt = f \"\u201c { sentence } \u201d\u662f { custom_settings [ 'class_list' ] } \u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f\" response , history = model . chat ( tokenizer , sentence_with_prompt , history = custom_settings [ 'pre_history' ]) print ( f '>>> [bold bright_red]sentence: { sentence } ' ) print ( f '>>> [bold bright_green]inference answer: { response } ' ) \u4ee3\u7801\u8c03\u7528 if __name__ == '__main__' : console = Console () #device = 'cuda:0' device = 'cpu' tokenizer = AutoTokenizer . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b-int4\" , trust_remote_code = True ) # model = AutoModel.from_pretrained(\"./ChatGLM-6B/THUDM/chatglm-6b\", trust_remote_code=True).half().cuda() model = AutoModel . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b-int4\" , trust_remote_code = True ) . float () model . to ( device ) sentences = [ \"\u4eca\u65e5\uff0c\u592e\u884c\u53d1\u5e03\u516c\u544a\u5ba3\u5e03\u964d\u4f4e\u5229\u7387\uff0c\u4ee5\u523a\u6fc0\u7ecf\u6d4e\u589e\u957f\u3002\u8fd9\u4e00\u964d\u606f\u4e3e\u63aa\u5c06\u5f71\u54cd\u8d37\u6b3e\u5229\u7387\uff0c\u5e76\u5728\u672a\u6765\u51e0\u4e2a\u5b63\u5ea6\u5185\u5bf9\u91d1\u878d\u5e02\u573a\u4ea7\u751f\u5f71\u54cd\u3002\" , \"ABC\u516c\u53f8\u4eca\u65e5\u53d1\u5e03\u516c\u544a\u79f0\uff0c\u5df2\u6210\u529f\u5b8c\u6210\u5bf9XYZ\u516c\u53f8\u80a1\u6743\u7684\u6536\u8d2d\u4ea4\u6613\u3002\u672c\u6b21\u4ea4\u6613\u662fABC\u516c\u53f8\u5728\u6269\u5927\u4e1a\u52a1\u8303\u56f4\u3001\u52a0\u5f3a\u5e02\u573a\u7ade\u4e89\u529b\u65b9\u9762\u7684\u91cd\u8981\u4e3e\u63aa\u3002\u636e\u6089\uff0c\u6b64\u6b21\u6536\u8d2d\u5c06\u8fdb\u4e00\u6b65\u5de9\u56faABC\u516c\u53f8\u5728\u884c\u4e1a\u4e2d\u7684\u5730\u4f4d\uff0c\u5e76\u4e3a\u672a\u6765\u4e1a\u52a1\u53d1\u5c55\u63d0\u4f9b\u66f4\u5e7f\u9614\u7684\u53d1\u5c55\u7a7a\u95f4\u3002\u8be6\u60c5\u8bf7\u89c1\u516c\u53f8\u5b98\u65b9\u7f51\u7ad9\u516c\u544a\u680f\" , \"\u516c\u53f8\u8d44\u4ea7\u8d1f\u503a\u8868\u663e\u793a\uff0c\u516c\u53f8\u507f\u503a\u80fd\u529b\u5f3a\u52b2\uff0c\u73b0\u91d1\u6d41\u5145\u8db3\uff0c\u4e3a\u672a\u6765\u6295\u8d44\u548c\u6269\u5f20\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u8d22\u52a1\u57fa\u7840\u3002\" , \"\u6700\u65b0\u7684\u5206\u6790\u62a5\u544a\u6307\u51fa\uff0c\u53ef\u518d\u751f\u80fd\u6e90\u884c\u4e1a\u9884\u8ba1\u5c06\u5728\u672a\u6765\u51e0\u5e74\u7ecf\u5386\u6301\u7eed\u589e\u957f\uff0c\u6295\u8d44\u8005\u5e94\u8be5\u5173\u6ce8\u8fd9\u4e00\u9886\u57df\u7684\u6295\u8d44\u673a\u4f1a\" , ] custom_settings = init_prompts () print ( custom_settings ) inference ( sentences , custom_settings ) \u6253\u5370\u7ed3\u679c\uff1a \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u57fa\u4e8eFew-shot\u65b9\u5f0f\u5b9e\u73b0ChatGLM\u6a21\u578b\u6765\u5b8c\u6210\u6587\u672c\u5206\u7c7b\u7684\u8fc7\u7a0b\u3002","title":"4.3 LLM\u5b9e\u73b0\u91d1\u878d\u6587\u672c\u5206\u7c7b"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#zero-shotllm","text":"","title":"\u57fa\u4e8eZero-shot\u65b9\u5f0f\u5b9e\u73b0LLM\u6587\u672c\u5206\u7c7b"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#_1","text":"\u638c\u63e1Zero-shot\u65b9\u5f0f\u4e0bprompt\u7684\u8bbe\u8ba1\u65b9\u5f0f \u638c\u63e1\u5229\u7528LLM\u5b9e\u73b0\u6587\u672c\u5206\u7c7b\u7684\u4ee3\u7801","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#1-llm","text":"\u4e0b\u9762\u51e0\u6bb5\u6587\u672c\u6765\u81ea\u67d0\u5e73\u53f0\u53d1\u5e03\u7684\u91d1\u878d\u9886\u57df\u6587\u672c\uff1a 1.\"\u4eca\u65e5\uff0c\u592e\u884c\u53d1\u5e03\u516c\u544a\u5ba3\u5e03\u964d\u4f4e\u5229\u7387\uff0c\u4ee5\u523a\u6fc0\u7ecf\u6d4e\u589e\u957f\u3002\u8fd9\u4e00\u964d\u606f\u4e3e\u63aa\u5c06\u5f71\u54cd\u8d37\u6b3e\u5229\u7387\uff0c\u5e76\u5728\u672a\u6765\u51e0\u4e2a\u5b63\u5ea6\u5185\u5bf9\u91d1\u878d\u5e02\u573a\u4ea7\u751f\u5f71\u54cd\u3002\", 2.\"ABC\u516c\u53f8\u4eca\u65e5\u53d1\u5e03\u516c\u544a\u79f0\uff0c\u5df2\u6210\u529f\u5b8c\u6210\u5bf9XYZ\u516c\u53f8\u80a1\u6743\u7684\u6536\u8d2d\u4ea4\u6613\u3002\u672c\u6b21\u4ea4\u6613\u662fABC\u516c\u53f8\u5728\u6269\u5927\u4e1a\u52a1\u8303\u56f4\u3001\u52a0\u5f3a\u5e02\u573a\u7ade\u4e89\u529b\u65b9\u9762\u7684\u91cd\u8981\u4e3e\u63aa\u3002\u636e\u6089\uff0c\u6b64\u6b21\u6536\u8d2d\u5c06\u8fdb\u4e00\u6b65\u5de9\u56faABC\u516c\u53f8\u5728\u884c\u4e1a\u4e2d\u7684\u5730\u4f4d\uff0c\u5e76\u4e3a\u672a\u6765\u4e1a\u52a1\u53d1\u5c55\u63d0\u4f9b\u66f4\u5e7f\u9614\u7684\u53d1\u5c55\u7a7a\u95f4\u3002\u8be6\u60c5\u8bf7\u89c1\u516c\u53f8\u5b98\u65b9\u7f51\u7ad9\u516c\u544a\u680f\", 3.\"\u516c\u53f8\u8d44\u4ea7\u8d1f\u503a\u8868\u663e\u793a\uff0c\u516c\u53f8\u507f\u503a\u80fd\u529b\u5f3a\u52b2\uff0c\u73b0\u91d1\u6d41\u5145\u8db3\uff0c\u4e3a\u672a\u6765\u6295\u8d44\u548c\u6269\u5f20\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u8d22\u52a1\u57fa\u7840\u3002\", 4.\"\u6700\u65b0\u7684\u5206\u6790\u62a5\u544a\u6307\u51fa\uff0c\u53ef\u518d\u751f\u80fd\u6e90\u884c\u4e1a\u9884\u8ba1\u5c06\u5728\u672a\u6765\u51e0\u5e74\u7ecf\u5386\u6301\u7eed\u589e\u957f\uff0c\u6295\u8d44\u8005\u5e94\u8be5\u5173\u6ce8\u8fd9\u4e00\u9886\u57df\u7684\u6295\u8d44\u673a\u4f1a\", \u6211\u4eec\u7684\u76ee\u7684\u662f\u671f\u671b\u6a21\u578b\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u8bc6\u522b\u51fa\u8fd94\u6bb5\u8bdd\u4e2d\uff0c\u6bcf\u4e00\u53e5\u8bdd\u63cf\u8ff0\u7684\u662f\u4e00\u4e2a\u4ec0\u4e48\u7c7b\u578b\u7684\u62a5\u544a\u3002 \u56e0\u6b64\uff0c\u6211\u4eec\u671f\u671b\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a\uff1a ['\u65b0\u95fb\u62a5\u9053', '\u516c\u53f8\u516c\u544a', '\u8d22\u52a1\u516c\u544a '\u5206\u6790\u5e08\u62a5\u544a']","title":"1 LLM\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#2-prompt","text":"\u5bf9\u4e8e\u5927\u6a21\u578b\u6765\u8bb2\uff0cprompt \u7684\u8bbe\u8ba1\u975e\u5e38\u91cd\u8981\uff0c\u4e00\u4e2a \u660e\u786e \u7684 prompt \u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u66f4\u597d\u4ece\u5927\u6a21\u578b\u4e2d\u83b7\u5f97\u6211\u4eec\u60f3\u8981\u7684\u7ed3\u679c\u3002 \u5728\u8be5\u4efb\u52a1\u7684 prompt \u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u8003\u8651 2 \u70b9\uff1a \u9700\u8981\u5411\u6a21\u578b\u89e3\u91ca\u4ec0\u4e48\u53eb\u4f5c\u300c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u300d \u9700\u8981\u8ba9\u6a21\u578b\u6309\u7167\u6211\u4eec\u6307\u5b9a\u7684\u683c\u5f0f\u8f93\u51fa \u4e3a\u4e86\u8ba9\u6a21\u578b\u77e5\u9053\u4ec0\u4e48\u53eb\u505a\u300c\u6587\u672c\u5206\u7c7b\u300d\uff0c\u6211\u4eec\u501f\u7528 Incontext Learning \u7684\u65b9\u5f0f\uff0c\u5148\u7ed9\u6a21\u578b\u5c55\u793a\u51e0\u4e2a\u6b63\u786e\u7684\u4f8b\u5b50\uff1a >>> User: \"\u4eca\u65e5\uff0c\u80a1\u5e02\u7ecf\u5386\u4e86\u4e00\u8f6e\u9707\u8361\uff0c\u53d7\u5230\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u548c\u5168\u7403\u8d38\u6613\u7d27\u5f20\u5c40\u52bf\u7684\u5f71\u54cd\u3002\u6295\u8d44\u8005\u5bc6\u5207\u5173\u6ce8\u7f8e\u8054\u50a8\u53ef\u80fd\u7684\u653f\u7b56\u8c03\u6574\uff0c\u4ee5\u9002\u5e94\u5e02\u573a\u7684\u4e0d\u786e\u5b9a\u6027\u3002\" \u662f['\u65b0\u95fb\u62a5\u9053', '\u516c\u53f8\u516c\u544a', '\u8d22\u52a1\u516c\u544a '\u5206\u6790\u5e08\u62a5\u544a']\u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f >>> Bot: \u65b0\u95fb\u62a5\u9053 >>> User: \"\u672c\u516c\u53f8\u5e74\u5ea6\u8d22\u52a1\u62a5\u544a\u663e\u793a\uff0c\u53bb\u5e74\u516c\u53f8\u5b9e\u73b0\u4e86\u7a33\u6b65\u589e\u957f\u7684\u76c8\u5229\uff0c\u540c\u65f6\u8d44\u4ea7\u8d1f\u503a\u8868\u5448\u73b0\u5f3a\u52b2\u7684\u72b6\u51b5\u3002\u7ecf\u6d4e\u73af\u5883\u7684\u7a33\u5b9a\u548c\u7ba1\u7406\u5c42\u7684\u6709\u6548\u6218\u7565\u6267\u884c\u4e3a\u516c\u53f8\u7684\u5065\u5eb7\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002\"\u662f['\u65b0\u95fb\u62a5\u9053', '\u516c\u53f8\u516c\u544a', '\u8d22\u52a1\u516c\u544a '\u5206\u6790\u5e08\u62a5\u544a']\u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f >>> Bot: \u8d22\u52a1\u62a5\u544a \u5176\u4e2d\uff0c User \u4ee3\u8868\u6211\u4eec\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u53e5\u5b50\uff0c Bot \u4ee3\u8868\u6a21\u578b\u7684\u56de\u590d\u5185\u5bb9\u3002 \u6ce8\u610f\uff1a\u4e0a\u8ff0\u4f8b\u5b50\u4e2d Bot \u7684\u90e8\u5206\u4e5f\u662f\u7531\u4eba\u5de5\u8f93\u5165\u7684\uff0c\u5176\u76ee\u7684\u662f\u5e0c\u671b\u770b\u5230\u5728\u770b\u5230\u7c7b\u4f3c User \u4e2d\u7684\u53e5\u5b50\u65f6\uff0c\u6a21\u578b\u5e94\u5f53\u505a\u51fa\u7c7b\u4f3c Bot \u7684\u56de\u7b54\u3002","title":"2 Prompt\u8bbe\u8ba1"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#3","text":"\u672c\u7ae0\u8282\u4f7f\u7528\u7684\u6a21\u578b\u4e3aChatGLM-6B\uff0c\u53c2\u6570\u53c2\u6570\u8f83\u5927\uff086B\uff09\uff0c\u4e0b\u8f7d\u5230\u672c\u5730\u5927\u6982\u9700\u8981 12G+ \u7684\u78c1\u76d8\u7a7a\u95f4\uff0c\u8bf7\u786e\u4fdd\u78c1\u76d8\u6709\u5145\u8db3\u7684\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u52a0\u8f7d\u6a21\u578b\u5927\u6982\u9700\u8981 13G \u5de6\u53f3\u7684\u663e\u5b58\uff0c\u5982\u679c\u60a8\u663e\u5b58\u4e0d\u591f\uff0c\u53ef\u4ee5\u8fdb\u884c\u6a21\u578b\u91cf\u5316\u52a0\u8f7d\u4ee5\u7f29\u5c0f\u6a21\u578b\u6210\u672c\u3002 \u672c\u6b21\u5206\u7c7b\u4efb\u52a1\u5b9e\u73b0\u7684\u4e3b\u8981\u8fc7\u7a0b\uff1a \u6784\u9020prompt \u5b9e\u73b0\u6a21\u578b\u9884\u6d4b \u4ee3\u7801\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/zero-shot/finance_classify.py llm_classification.py\u811a\u672c\u4e2d\u5305\u542b\u4e24\u4e2a\u51fd\u6570\uff1ainit_prompts()\u548cinference()","title":"3 \u5206\u7c7b\u4efb\u52a1\u4ee3\u7801\u5b9e\u73b0"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#31","text":"# \u2014*-coding:utf-8-*- \"\"\" \u5229\u7528 LLM \u8fdb\u884c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u3002 \"\"\" from rich import print from rich.console import Console from transformers import AutoTokenizer , AutoModel # \u63d0\u4f9b\u6240\u6709\u7c7b\u522b\u4ee5\u53ca\u6bcf\u4e2a\u7c7b\u522b\u4e0b\u7684\u6837\u4f8b class_examples = { '\u65b0\u95fb\u62a5\u9053' : '\u4eca\u65e5\uff0c\u80a1\u5e02\u7ecf\u5386\u4e86\u4e00\u8f6e\u9707\u8361\uff0c\u53d7\u5230\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u548c\u5168\u7403\u8d38\u6613\u7d27\u5f20\u5c40\u52bf\u7684\u5f71\u54cd\u3002\u6295\u8d44\u8005\u5bc6\u5207\u5173\u6ce8\u7f8e\u8054\u50a8\u53ef\u80fd\u7684\u653f\u7b56\u8c03\u6574\uff0c\u4ee5\u9002\u5e94\u5e02\u573a\u7684\u4e0d\u786e\u5b9a\u6027\u3002' , '\u8d22\u52a1\u62a5\u544a' : '\u672c\u516c\u53f8\u5e74\u5ea6\u8d22\u52a1\u62a5\u544a\u663e\u793a\uff0c\u53bb\u5e74\u516c\u53f8\u5b9e\u73b0\u4e86\u7a33\u6b65\u589e\u957f\u7684\u76c8\u5229\uff0c\u540c\u65f6\u8d44\u4ea7\u8d1f\u503a\u8868\u5448\u73b0\u5f3a\u52b2\u7684\u72b6\u51b5\u3002\u7ecf\u6d4e\u73af\u5883\u7684\u7a33\u5b9a\u548c\u7ba1\u7406\u5c42\u7684\u6709\u6548\u6218\u7565\u6267\u884c\u4e3a\u516c\u53f8\u7684\u5065\u5eb7\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002' , '\u516c\u53f8\u516c\u544a' : '\u672c\u516c\u53f8\u9ad8\u5174\u5730\u5ba3\u5e03\u6210\u529f\u5b8c\u6210\u6700\u65b0\u4e00\u8f6e\u5e76\u8d2d\u4ea4\u6613\uff0c\u6536\u8d2d\u4e86\u4e00\u5bb6\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u9886\u5148\u7684\u516c\u53f8\u3002\u8fd9\u4e00\u6218\u7565\u4e3e\u63aa\u5c06\u6709\u52a9\u4e8e\u6269\u5927\u6211\u4eec\u7684\u4e1a\u52a1\u9886\u57df\uff0c\u63d0\u9ad8\u5e02\u573a\u7ade\u4e89\u529b' , '\u5206\u6790\u5e08\u62a5\u544a' : '\u6700\u65b0\u7684\u884c\u4e1a\u5206\u6790\u62a5\u544a\u6307\u51fa\uff0c\u79d1\u6280\u516c\u53f8\u7684\u521b\u65b0\u5c06\u6210\u4e3a\u672a\u6765\u589e\u957f\u7684\u4e3b\u8981\u63a8\u52a8\u529b\u3002\u4e91\u8ba1\u7b97\u3001\u4eba\u5de5\u667a\u80fd\u548c\u6570\u5b57\u5316\u8f6c\u578b\u88ab\u8ba4\u4e3a\u662f\u5f15\u9886\u884c\u4e1a\u53d1\u5c55\u7684\u5173\u952e\u56e0\u7d20\uff0c\u6295\u8d44\u8005\u5e94\u5173\u6ce8\u8fd9\u4e9b\u8d8b\u52bf' }","title":"3.1 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#32-init_prompts","text":"\u76ee\u7684\uff1a\u8fdb\u884cprompt\u8bbe\u8ba1 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a def init_prompts (): \"\"\" \u521d\u59cb\u5316\u524d\u7f6eprompt\uff0c\u4fbf\u4e8e\u6a21\u578b\u505a incontext learning\u3002 \"\"\" class_list = list ( class_examples . keys ()) pre_history = [ ( f '\u73b0\u5728\u4f60\u662f\u4e00\u4e2a\u6587\u672c\u5206\u7c7b\u5668\uff0c\u4f60\u9700\u8981\u6309\u7167\u8981\u6c42\u5c06\u6211\u7ed9\u4f60\u7684\u53e5\u5b50\u5206\u7c7b\u5230\uff1a { class_list } \u7c7b\u522b\u4e2d\u3002' , f '\u597d\u7684\u3002' ) ] for _type , exmpale in class_examples . items (): pre_history . append (( f '\u201c { exmpale } \u201d\u662f { class_list } \u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f' , _type )) return { 'class_list' : class_list , 'pre_history' : pre_history } 3.3 \u6784\u5efainference()\u51fd\u6570 \u76ee\u7684\uff1a\u5b9e\u73b0\u6587\u672c\u5206\u7c7b \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def inference ( sentences : list , custom_settings : dict ): \"\"\" \u63a8\u7406\u51fd\u6570\u3002 Args: sentences (List[str]): \u5f85\u63a8\u7406\u7684\u53e5\u5b50\u3002 custom_settings (dict): \u521d\u59cb\u8bbe\u5b9a\uff0c\u5305\u542b\u4eba\u4e3a\u7ed9\u5b9a\u7684 few-shot example\u3002 \"\"\" for sentence in sentences : with console . status ( \"[bold bright_green] Model Inference...\" ): sentence_with_prompt = f \"\u201c { sentence } \u201d\u662f { custom_settings [ 'class_list' ] } \u91cc\u7684\u4ec0\u4e48\u7c7b\u522b\uff1f\" response , history = model . chat ( tokenizer , sentence_with_prompt , history = custom_settings [ 'pre_history' ]) print ( f '>>> [bold bright_red]sentence: { sentence } ' ) print ( f '>>> [bold bright_green]inference answer: { response } ' ) \u4ee3\u7801\u8c03\u7528 if __name__ == '__main__' : console = Console () #device = 'cuda:0' device = 'cpu' tokenizer = AutoTokenizer . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b-int4\" , trust_remote_code = True ) # model = AutoModel.from_pretrained(\"./ChatGLM-6B/THUDM/chatglm-6b\", trust_remote_code=True).half().cuda() model = AutoModel . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b-int4\" , trust_remote_code = True ) . float () model . to ( device ) sentences = [ \"\u4eca\u65e5\uff0c\u592e\u884c\u53d1\u5e03\u516c\u544a\u5ba3\u5e03\u964d\u4f4e\u5229\u7387\uff0c\u4ee5\u523a\u6fc0\u7ecf\u6d4e\u589e\u957f\u3002\u8fd9\u4e00\u964d\u606f\u4e3e\u63aa\u5c06\u5f71\u54cd\u8d37\u6b3e\u5229\u7387\uff0c\u5e76\u5728\u672a\u6765\u51e0\u4e2a\u5b63\u5ea6\u5185\u5bf9\u91d1\u878d\u5e02\u573a\u4ea7\u751f\u5f71\u54cd\u3002\" , \"ABC\u516c\u53f8\u4eca\u65e5\u53d1\u5e03\u516c\u544a\u79f0\uff0c\u5df2\u6210\u529f\u5b8c\u6210\u5bf9XYZ\u516c\u53f8\u80a1\u6743\u7684\u6536\u8d2d\u4ea4\u6613\u3002\u672c\u6b21\u4ea4\u6613\u662fABC\u516c\u53f8\u5728\u6269\u5927\u4e1a\u52a1\u8303\u56f4\u3001\u52a0\u5f3a\u5e02\u573a\u7ade\u4e89\u529b\u65b9\u9762\u7684\u91cd\u8981\u4e3e\u63aa\u3002\u636e\u6089\uff0c\u6b64\u6b21\u6536\u8d2d\u5c06\u8fdb\u4e00\u6b65\u5de9\u56faABC\u516c\u53f8\u5728\u884c\u4e1a\u4e2d\u7684\u5730\u4f4d\uff0c\u5e76\u4e3a\u672a\u6765\u4e1a\u52a1\u53d1\u5c55\u63d0\u4f9b\u66f4\u5e7f\u9614\u7684\u53d1\u5c55\u7a7a\u95f4\u3002\u8be6\u60c5\u8bf7\u89c1\u516c\u53f8\u5b98\u65b9\u7f51\u7ad9\u516c\u544a\u680f\" , \"\u516c\u53f8\u8d44\u4ea7\u8d1f\u503a\u8868\u663e\u793a\uff0c\u516c\u53f8\u507f\u503a\u80fd\u529b\u5f3a\u52b2\uff0c\u73b0\u91d1\u6d41\u5145\u8db3\uff0c\u4e3a\u672a\u6765\u6295\u8d44\u548c\u6269\u5f20\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u8d22\u52a1\u57fa\u7840\u3002\" , \"\u6700\u65b0\u7684\u5206\u6790\u62a5\u544a\u6307\u51fa\uff0c\u53ef\u518d\u751f\u80fd\u6e90\u884c\u4e1a\u9884\u8ba1\u5c06\u5728\u672a\u6765\u51e0\u5e74\u7ecf\u5386\u6301\u7eed\u589e\u957f\uff0c\u6295\u8d44\u8005\u5e94\u8be5\u5173\u6ce8\u8fd9\u4e00\u9886\u57df\u7684\u6295\u8d44\u673a\u4f1a\" , ] custom_settings = init_prompts () print ( custom_settings ) inference ( sentences , custom_settings ) \u6253\u5370\u7ed3\u679c\uff1a","title":"3.2 \u6784\u5efainit_prompts()\u51fd\u6570"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/03-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.html#_2","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u57fa\u4e8eFew-shot\u65b9\u5f0f\u5b9e\u73b0ChatGLM\u6a21\u578b\u6765\u5b8c\u6210\u6587\u672c\u5206\u7c7b\u7684\u8fc7\u7a0b\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html","text":"\u57fa\u4e8eZero-shot\u65b9\u5f0f\u5b9e\u73b0LLM\u4fe1\u606f\u62bd\u53d6 \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1Zero-shot\u65b9\u5f0f\u4e0bprompt\u7684\u8bbe\u8ba1\u65b9\u5f0f \u638c\u63e1\u5229\u7528LLM\u5b9e\u73b0\u4fe1\u606f\u62bd\u53d6\u7684\u4ee3\u7801 1 LLM\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4ecb\u7ecd \u00b6 \u9996\u5148\uff0c\u6211\u4eec\u5b9a\u4e49\u4fe1\u606f\u62bd\u53d6\u7684Schema\uff1a # \u5b9a\u4e49\u4e0d\u540c\u5b9e\u4f53\u4e0b\u7684\u5177\u5907\u5c5e\u6027 schema = { '\u91d1\u878d' : [ '\u65e5\u671f' , '\u80a1\u7968\u540d\u79f0' , '\u5f00\u76d8\u4ef7' , '\u6536\u76d8\u4ef7' , '\u6210\u4ea4\u91cf' ], } \u4e0b\u9762\u51e0\u6bb5\u6587\u672c\u6765\u81ea\u67d0\u5e73\u53f0\u53d1\u5e03\u7684\u80a1\u7968\u4fe1\u606f\uff1a 1.'2023-02-15\uff0c\u5bd3\u610f\u5409\u7965\u7684\u8282\u65e5\uff0c\u80a1\u7968\u4f70\u7b03[BD]\u7f8e\u80a1\u5f00\u76d8\u4ef710\u7f8e\u5143\uff0c\u867d\u7136\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee513\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u5fae\u5e45\u589e\u52a0\u81f3460,000\uff0c\u6295\u8d44\u8005\u60c5\u7eea\u8f83\u4e3a\u5e73\u7a33\u3002', 2.'2023-04-05\uff0c\u5e02\u573a\u8fce\u6765\u8f7b\u677e\u6c1b\u56f4\uff0c\u80a1\u7968\u76d8\u53e4(0021)\u5f00\u76d8\u4ef723\u5143\uff0c\u5c3d\u7ba1\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee526\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u7f29\u5c0f\u81f3310,000\uff0c\u6295\u8d44\u8005\u4fdd\u6301\u89c2\u671b\u6001\u5ea6\u3002', \u6211\u4eec\u7684\u76ee\u7684\u662f\u671f\u671b\u6a21\u578b\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u8bc6\u522b\u51fa\u8fd92\u6bb5\u8bdd\u4e2d\u7684SPO\u4e09\u5143\u7ec4\u4fe1\u606f\u3002 2 Prompt\u8bbe\u8ba1 \u00b6 \u5728\u8be5\u4efb\u52a1\u7684 prompt \u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u8003\u8651 2 \u70b9\uff1a \u9700\u8981\u5411\u6a21\u578b\u89e3\u91ca\u4ec0\u4e48\u53eb\u4f5c\u300c\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u300d \u9700\u8981\u8ba9\u6a21\u578b\u6309\u7167\u6211\u4eec\u6307\u5b9a\u7684\u683c\u5f0f\uff08json\uff09\u8f93\u51fa \u4e3a\u4e86\u8ba9\u6a21\u578b\u77e5\u9053\u4ec0\u4e48\u53eb\u505a\u300c\u4fe1\u606f\u62bd\u53d6\u300d\uff0c\u6211\u4eec\u501f\u7528 Incontext Learning \u7684\u65b9\u5f0f\uff0c\u5148\u7ed9\u6a21\u578b\u5c55\u793a\u51e0\u4e2a\u6b63\u786e\u7684\u4f8b\u5b50\uff1a >>> User:'2023-01-10\uff0c\u80a1\u5e02\u9707\u8361\u3002\u80a1\u7968\u53e4\u54e5-D[EOOE]\u7f8e\u80a1\u4eca\u65e5\u5f00\u76d8\u4ef7100\u7f8e\u5143\uff0c\u4e00\u5ea6\u98d9\u5347\u81f3105\u7f8e\u5143\uff0c\u968f\u540e\u56de\u843d\u81f398\u7f8e\u5143\uff0c\u6700\u7ec8\u4ee5102\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u8fbe\u5230520000\u3002'\u3002\u63d0\u53d6\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u201c\u91d1\u878d\u201d('\u65e5\u671f', '\u80a1\u7968\u540d\u79f0', '\u5f00\u76d8\u4ef7', '\u6536\u76d8\u4ef7', '\u6210\u4ea4\u91cf')\u7c7b\u578b\u7684\u5b9e\u4f53\uff0c\u5e76\u6309\u7167JSON\u683c\u5f0f\u8f93\u51fa\uff0c\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u6ca1\u6709\u7684\u4fe1\u606f\u7528['\u539f\u6587\u4e2d\u672a\u63d0\u53ca']\u6765\u8868\u793a\uff0c\u591a\u4e2a\u503c\u4e4b\u95f4\u7528','\u5206\u9694\u3002 >>> Bot: {'\u65e5\u671f': ['2023-01-10'],'\u80a1\u7968\u540d\u79f0': ['\u53e4\u54e5-D[EOOE]\u7f8e\u80a1'],'\u5f00\u76d8\u4ef7': ['100\u7f8e\u5143'],'\u6536\u76d8\u4ef7': ['102\u7f8e\u5143'],\u6210\u4ea4\u91cf': ['520000']} \u5176\u4e2d\uff0c User \u4ee3\u8868\u6211\u4eec\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u53e5\u5b50\uff0c Bot \u4ee3\u8868\u6a21\u578b\u7684\u56de\u590d\u5185\u5bb9\u3002 \u6ce8\u610f\uff1a\u4e0a\u8ff0\u4f8b\u5b50\u4e2d Bot \u7684\u90e8\u5206\u4e5f\u662f\u7531\u4eba\u5de5\u8f93\u5165\u7684\uff0c\u5176\u76ee\u7684\u662f\u5e0c\u671b\u770b\u5230\u5728\u770b\u5230\u7c7b\u4f3c User \u4e2d\u7684\u53e5\u5b50\u65f6\uff0c\u6a21\u578b\u5e94\u5f53\u505a\u51fa\u7c7b\u4f3c Bot \u7684\u56de\u7b54\u3002 3 \u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u4ee3\u7801\u5b9e\u73b0 \u00b6 \u672c\u7ae0\u8282\u4f7f\u7528\u7684\u6a21\u578b\u4e3aChatGLM-6B\uff0c\u53c2\u6570\u53c2\u6570\u8f83\u5927\uff086B\uff09\uff0c\u4e0b\u8f7d\u5230\u672c\u5730\u5927\u6982\u9700\u8981 12G+ \u7684\u78c1\u76d8\u7a7a\u95f4\uff0c\u8bf7\u786e\u4fdd\u78c1\u76d8\u6709\u5145\u8db3\u7684\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u52a0\u8f7d\u6a21\u578b\u5927\u6982\u9700\u8981 13G \u5de6\u53f3\u7684\u663e\u5b58\uff0c\u5982\u679c\u60a8\u663e\u5b58\u4e0d\u591f\uff0c\u53ef\u4ee5\u8fdb\u884c\u6a21\u578b\u91cf\u5316\u52a0\u8f7d\u4ee5\u7f29\u5c0f\u6a21\u578b\u6210\u672c\u3002 \u672c\u6b21\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u5b9e\u73b0\u7684\u4e3b\u8981\u8fc7\u7a0b\uff1a \u6784\u9020prompt \u5148\u5bf9\u53e5\u5b50\u505a\u5206\u7c7b \u518d\u8fdb\u884c\u4fe1\u606f\u62bd\u53d6 \u4ee3\u7801\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/zero-shot/finance_ie.py llm_information_extraction.py\u811a\u672c\u4e2d\u5305\u542b\u4e09\u4e2a\u51fd\u6570\uff1ainit_prompts()\u3001clean_response()\u548cinference() 3.1 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 \u00b6 import re import json from rich import print from transformers import AutoTokenizer , AutoModel # \u5b9a\u4e49\u4e0d\u540c\u5b9e\u4f53\u4e0b\u7684\u5177\u5907\u5c5e\u6027 schema = { '\u91d1\u878d' : [ '\u65e5\u671f' , '\u80a1\u7968\u540d\u79f0' , '\u5f00\u76d8\u4ef7' , '\u6536\u76d8\u4ef7' , '\u6210\u4ea4\u91cf' ], } IE_PATTERN = \" {} \\n\\n \u63d0\u53d6\u4e0a\u8ff0\u53e5\u5b50\u4e2d {} \u7684\u5b9e\u4f53\uff0c\u5e76\u6309\u7167JSON\u683c\u5f0f\u8f93\u51fa\uff0c\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u4e0d\u5b58\u5728\u7684\u4fe1\u606f\u7528['\u539f\u6587\u4e2d\u672a\u63d0\u53ca']\u6765\u8868\u793a\uff0c\u591a\u4e2a\u503c\u4e4b\u95f4\u7528','\u5206\u9694\u3002\" # \u63d0\u4f9b\u4e00\u4e9b\u4f8b\u5b50\u4f9b\u6a21\u578b\u53c2\u8003 ie_examples = { '\u91d1\u878d' : [ { 'content' : '2023-01-10\uff0c\u80a1\u5e02\u9707\u8361\u3002\u80a1\u7968\u53e4\u54e5-D[EOOE]\u7f8e\u80a1\u4eca\u65e5\u5f00\u76d8\u4ef7100\u7f8e\u5143\uff0c\u4e00\u5ea6\u98d9\u5347\u81f3105\u7f8e\u5143\uff0c\u968f\u540e\u56de\u843d\u81f398\u7f8e\u5143\uff0c\u6700\u7ec8\u4ee5102\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u8fbe\u5230520000\u3002' , 'answers' : { '\u65e5\u671f' : [ '2023-01-10' ], '\u80a1\u7968\u540d\u79f0' : [ '\u53e4\u54e5-D[EOOE]\u7f8e\u80a1' ], '\u5f00\u76d8\u4ef7' : [ '100\u7f8e\u5143' ], '\u6536\u76d8\u4ef7' : [ '102\u7f8e\u5143' ], '\u6210\u4ea4\u91cf' : [ '520000' ], } } ] } 3.2 \u6784\u5efainit_prompts()\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u8fdb\u884cprompt\u8bbe\u8ba1 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a def init_prompts (): \"\"\" \u521d\u59cb\u5316\u524d\u7f6eprompt\uff0c\u4fbf\u4e8e\u6a21\u578b\u505a incontext learning\u3002 \"\"\" ie_pre_history = [ ( \"\u73b0\u5728\u4f60\u9700\u8981\u5e2e\u52a9\u6211\u5b8c\u6210\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\uff0c\u5f53\u6211\u7ed9\u4f60\u4e00\u4e2a\u53e5\u5b50\u65f6\uff0c\u4f60\u9700\u8981\u5e2e\u6211\u62bd\u53d6\u51fa\u53e5\u5b50\u4e2d\u5b9e\u4f53\u4fe1\u606f\uff0c\u5e76\u6309\u7167JSON\u7684\u683c\u5f0f\u8f93\u51fa\uff0c\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u6ca1\u6709\u7684\u4fe1\u606f\u7528['\u539f\u6587\u4e2d\u672a\u63d0\u53ca']\u6765\u8868\u793a\uff0c\u591a\u4e2a\u503c\u4e4b\u95f4\u7528','\u5206\u9694\u3002\" , '\u597d\u7684\uff0c\u8bf7\u8f93\u5165\u60a8\u7684\u53e5\u5b50\u3002' ) ] for _type , example_list in ie_examples . items (): print ( f '\u4fe1\u606f\u62bd\u53d6\u6837\u672c\u7684\u539f\u59cb\u53e5\u5b50\u662f--\u300b { example_list } ' ) for example in example_list : sentence = example [ 'content' ] properties_str = ', ' . join ( schema [ _type ]) schema_str_list = f '\u201c { _type } \u201d( { properties_str } )' sentence_with_prompt = IE_PATTERN . format ( sentence , schema_str_list ) ie_pre_history . append (( f ' { sentence_with_prompt } ' , f \" { json . dumps ( example [ 'answers' ], ensure_ascii = False ) } \" )) print ( f 'ie_pre_history--> { ie_pre_history } ' ) return { 'ie_pre_history' : ie_pre_history } 3.3 \u6784\u5efaclean_response()\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u6a21\u578b\u7ed3\u679c\u540e\u5904\u7406 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def clean_response ( response : str ): \"\"\" \u540e\u5904\u7406\u6a21\u578b\u8f93\u51fa\u3002 Args: response (str): _description_ \"\"\" if '```json' in response : res = re . findall ( r '```json(.*?)```' , response ) if len ( res ) and res [ 0 ]: response = res [ 0 ] response . replace ( '\u3001' , ',' ) try : return json . loads ( response ) except : return response 3.4 \u6784\u5efainference()\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u6a21\u578b\u5b9e\u73b0\u4fe1\u606f\u62bd\u53d6 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def inference ( sentences : list , custom_settings : dict ): \"\"\" \u63a8\u7406\u51fd\u6570\u3002 Args: sentences (List[str]): \u5f85\u62bd\u53d6\u7684\u53e5\u5b50\u3002 custom_settings (dict): \u521d\u59cb\u8bbe\u5b9a\uff0c\u5305\u542b\u4eba\u4e3a\u7ed9\u5b9a\u7684 few-shot example\u3002 \"\"\" for sentence in sentences : cls_res = \"\u91d1\u878d\" if cls_res not in schema : print ( f 'The type model inferenced { cls_res } which is not in schema dict, exited.' ) exit () properties_str = ', ' . join ( schema [ cls_res ]) schema_str_list = f '\u201c { cls_res } \u201d( { properties_str } )' sentence_with_ie_prompt = IE_PATTERN . format ( sentence , schema_str_list ) ie_res , _ = model . chat ( tokenizer , sentence_with_ie_prompt , history = custom_settings [ 'ie_pre_history' ]) ie_res = clean_response ( ie_res ) print ( f '>>> [bold bright_red]sentence: { sentence } ' ) print ( f '>>> [bold bright_green]inference answer: ' ) print ( ie_res ) \u4ee3\u7801\u8c03\u7528 if __name__ == '__main__' : #device = 'cuda:0' device = 'cpu' tokenizer = AutoTokenizer . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) #model = AutoModel.from_pretrained(\"./ChatGLM-6B/THUDM/chatglm-6b\", # trust_remote_code=True).half().cuda() model = AutoModel . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) . float () model . to ( device ) sentences = [ '2023-02-15\uff0c\u5bd3\u610f\u5409\u7965\u7684\u8282\u65e5\uff0c\u80a1\u7968\u4f70\u7b03[BD]\u7f8e\u80a1\u5f00\u76d8\u4ef710\u7f8e\u5143\uff0c\u867d\u7136\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee513\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u5fae\u5e45\u589e\u52a0\u81f3460,000\uff0c\u6295\u8d44\u8005\u60c5\u7eea\u8f83\u4e3a\u5e73\u7a33\u3002' , '2023-04-05\uff0c\u5e02\u573a\u8fce\u6765\u8f7b\u677e\u6c1b\u56f4\uff0c\u80a1\u7968\u76d8\u53e4(0021)\u5f00\u76d8\u4ef723\u5143\uff0c\u5c3d\u7ba1\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee526\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u7f29\u5c0f\u81f3310,000\uff0c\u6295\u8d44\u8005\u4fdd\u6301\u89c2\u671b\u6001\u5ea6\u3002' , ] custom_settings = init_prompts () inference ( sentences , custom_settings ) \u6253\u5370\u7ed3\u679c\uff1a \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u5982\u4f55\u5229\u7528Few-shot\u65b9\u5f0f\u57fa\u4e8eChatGLM-6B\u5b9e\u73b0\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u3002","title":"4.4 LLM\u5b9e\u73b0\u91d1\u878d\u6587\u672c\u4fe1\u606f\u62bd\u53d6"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#zero-shotllm","text":"","title":"\u57fa\u4e8eZero-shot\u65b9\u5f0f\u5b9e\u73b0LLM\u4fe1\u606f\u62bd\u53d6"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#_1","text":"\u638c\u63e1Zero-shot\u65b9\u5f0f\u4e0bprompt\u7684\u8bbe\u8ba1\u65b9\u5f0f \u638c\u63e1\u5229\u7528LLM\u5b9e\u73b0\u4fe1\u606f\u62bd\u53d6\u7684\u4ee3\u7801","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#1-llm","text":"\u9996\u5148\uff0c\u6211\u4eec\u5b9a\u4e49\u4fe1\u606f\u62bd\u53d6\u7684Schema\uff1a # \u5b9a\u4e49\u4e0d\u540c\u5b9e\u4f53\u4e0b\u7684\u5177\u5907\u5c5e\u6027 schema = { '\u91d1\u878d' : [ '\u65e5\u671f' , '\u80a1\u7968\u540d\u79f0' , '\u5f00\u76d8\u4ef7' , '\u6536\u76d8\u4ef7' , '\u6210\u4ea4\u91cf' ], } \u4e0b\u9762\u51e0\u6bb5\u6587\u672c\u6765\u81ea\u67d0\u5e73\u53f0\u53d1\u5e03\u7684\u80a1\u7968\u4fe1\u606f\uff1a 1.'2023-02-15\uff0c\u5bd3\u610f\u5409\u7965\u7684\u8282\u65e5\uff0c\u80a1\u7968\u4f70\u7b03[BD]\u7f8e\u80a1\u5f00\u76d8\u4ef710\u7f8e\u5143\uff0c\u867d\u7136\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee513\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u5fae\u5e45\u589e\u52a0\u81f3460,000\uff0c\u6295\u8d44\u8005\u60c5\u7eea\u8f83\u4e3a\u5e73\u7a33\u3002', 2.'2023-04-05\uff0c\u5e02\u573a\u8fce\u6765\u8f7b\u677e\u6c1b\u56f4\uff0c\u80a1\u7968\u76d8\u53e4(0021)\u5f00\u76d8\u4ef723\u5143\uff0c\u5c3d\u7ba1\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee526\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u7f29\u5c0f\u81f3310,000\uff0c\u6295\u8d44\u8005\u4fdd\u6301\u89c2\u671b\u6001\u5ea6\u3002', \u6211\u4eec\u7684\u76ee\u7684\u662f\u671f\u671b\u6a21\u578b\u80fd\u591f\u5e2e\u52a9\u6211\u4eec\u8bc6\u522b\u51fa\u8fd92\u6bb5\u8bdd\u4e2d\u7684SPO\u4e09\u5143\u7ec4\u4fe1\u606f\u3002","title":"1 LLM\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#2-prompt","text":"\u5728\u8be5\u4efb\u52a1\u7684 prompt \u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u8003\u8651 2 \u70b9\uff1a \u9700\u8981\u5411\u6a21\u578b\u89e3\u91ca\u4ec0\u4e48\u53eb\u4f5c\u300c\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u300d \u9700\u8981\u8ba9\u6a21\u578b\u6309\u7167\u6211\u4eec\u6307\u5b9a\u7684\u683c\u5f0f\uff08json\uff09\u8f93\u51fa \u4e3a\u4e86\u8ba9\u6a21\u578b\u77e5\u9053\u4ec0\u4e48\u53eb\u505a\u300c\u4fe1\u606f\u62bd\u53d6\u300d\uff0c\u6211\u4eec\u501f\u7528 Incontext Learning \u7684\u65b9\u5f0f\uff0c\u5148\u7ed9\u6a21\u578b\u5c55\u793a\u51e0\u4e2a\u6b63\u786e\u7684\u4f8b\u5b50\uff1a >>> User:'2023-01-10\uff0c\u80a1\u5e02\u9707\u8361\u3002\u80a1\u7968\u53e4\u54e5-D[EOOE]\u7f8e\u80a1\u4eca\u65e5\u5f00\u76d8\u4ef7100\u7f8e\u5143\uff0c\u4e00\u5ea6\u98d9\u5347\u81f3105\u7f8e\u5143\uff0c\u968f\u540e\u56de\u843d\u81f398\u7f8e\u5143\uff0c\u6700\u7ec8\u4ee5102\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u8fbe\u5230520000\u3002'\u3002\u63d0\u53d6\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u201c\u91d1\u878d\u201d('\u65e5\u671f', '\u80a1\u7968\u540d\u79f0', '\u5f00\u76d8\u4ef7', '\u6536\u76d8\u4ef7', '\u6210\u4ea4\u91cf')\u7c7b\u578b\u7684\u5b9e\u4f53\uff0c\u5e76\u6309\u7167JSON\u683c\u5f0f\u8f93\u51fa\uff0c\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u6ca1\u6709\u7684\u4fe1\u606f\u7528['\u539f\u6587\u4e2d\u672a\u63d0\u53ca']\u6765\u8868\u793a\uff0c\u591a\u4e2a\u503c\u4e4b\u95f4\u7528','\u5206\u9694\u3002 >>> Bot: {'\u65e5\u671f': ['2023-01-10'],'\u80a1\u7968\u540d\u79f0': ['\u53e4\u54e5-D[EOOE]\u7f8e\u80a1'],'\u5f00\u76d8\u4ef7': ['100\u7f8e\u5143'],'\u6536\u76d8\u4ef7': ['102\u7f8e\u5143'],\u6210\u4ea4\u91cf': ['520000']} \u5176\u4e2d\uff0c User \u4ee3\u8868\u6211\u4eec\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u53e5\u5b50\uff0c Bot \u4ee3\u8868\u6a21\u578b\u7684\u56de\u590d\u5185\u5bb9\u3002 \u6ce8\u610f\uff1a\u4e0a\u8ff0\u4f8b\u5b50\u4e2d Bot \u7684\u90e8\u5206\u4e5f\u662f\u7531\u4eba\u5de5\u8f93\u5165\u7684\uff0c\u5176\u76ee\u7684\u662f\u5e0c\u671b\u770b\u5230\u5728\u770b\u5230\u7c7b\u4f3c User \u4e2d\u7684\u53e5\u5b50\u65f6\uff0c\u6a21\u578b\u5e94\u5f53\u505a\u51fa\u7c7b\u4f3c Bot \u7684\u56de\u7b54\u3002","title":"2 Prompt\u8bbe\u8ba1"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#3","text":"\u672c\u7ae0\u8282\u4f7f\u7528\u7684\u6a21\u578b\u4e3aChatGLM-6B\uff0c\u53c2\u6570\u53c2\u6570\u8f83\u5927\uff086B\uff09\uff0c\u4e0b\u8f7d\u5230\u672c\u5730\u5927\u6982\u9700\u8981 12G+ \u7684\u78c1\u76d8\u7a7a\u95f4\uff0c\u8bf7\u786e\u4fdd\u78c1\u76d8\u6709\u5145\u8db3\u7684\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u52a0\u8f7d\u6a21\u578b\u5927\u6982\u9700\u8981 13G \u5de6\u53f3\u7684\u663e\u5b58\uff0c\u5982\u679c\u60a8\u663e\u5b58\u4e0d\u591f\uff0c\u53ef\u4ee5\u8fdb\u884c\u6a21\u578b\u91cf\u5316\u52a0\u8f7d\u4ee5\u7f29\u5c0f\u6a21\u578b\u6210\u672c\u3002 \u672c\u6b21\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u5b9e\u73b0\u7684\u4e3b\u8981\u8fc7\u7a0b\uff1a \u6784\u9020prompt \u5148\u5bf9\u53e5\u5b50\u505a\u5206\u7c7b \u518d\u8fdb\u884c\u4fe1\u606f\u62bd\u53d6 \u4ee3\u7801\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/**/PycharmProjects/llm/zero-shot/finance_ie.py llm_information_extraction.py\u811a\u672c\u4e2d\u5305\u542b\u4e09\u4e2a\u51fd\u6570\uff1ainit_prompts()\u3001clean_response()\u548cinference()","title":"3 \u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u4ee3\u7801\u5b9e\u73b0"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#31","text":"import re import json from rich import print from transformers import AutoTokenizer , AutoModel # \u5b9a\u4e49\u4e0d\u540c\u5b9e\u4f53\u4e0b\u7684\u5177\u5907\u5c5e\u6027 schema = { '\u91d1\u878d' : [ '\u65e5\u671f' , '\u80a1\u7968\u540d\u79f0' , '\u5f00\u76d8\u4ef7' , '\u6536\u76d8\u4ef7' , '\u6210\u4ea4\u91cf' ], } IE_PATTERN = \" {} \\n\\n \u63d0\u53d6\u4e0a\u8ff0\u53e5\u5b50\u4e2d {} \u7684\u5b9e\u4f53\uff0c\u5e76\u6309\u7167JSON\u683c\u5f0f\u8f93\u51fa\uff0c\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u4e0d\u5b58\u5728\u7684\u4fe1\u606f\u7528['\u539f\u6587\u4e2d\u672a\u63d0\u53ca']\u6765\u8868\u793a\uff0c\u591a\u4e2a\u503c\u4e4b\u95f4\u7528','\u5206\u9694\u3002\" # \u63d0\u4f9b\u4e00\u4e9b\u4f8b\u5b50\u4f9b\u6a21\u578b\u53c2\u8003 ie_examples = { '\u91d1\u878d' : [ { 'content' : '2023-01-10\uff0c\u80a1\u5e02\u9707\u8361\u3002\u80a1\u7968\u53e4\u54e5-D[EOOE]\u7f8e\u80a1\u4eca\u65e5\u5f00\u76d8\u4ef7100\u7f8e\u5143\uff0c\u4e00\u5ea6\u98d9\u5347\u81f3105\u7f8e\u5143\uff0c\u968f\u540e\u56de\u843d\u81f398\u7f8e\u5143\uff0c\u6700\u7ec8\u4ee5102\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u8fbe\u5230520000\u3002' , 'answers' : { '\u65e5\u671f' : [ '2023-01-10' ], '\u80a1\u7968\u540d\u79f0' : [ '\u53e4\u54e5-D[EOOE]\u7f8e\u80a1' ], '\u5f00\u76d8\u4ef7' : [ '100\u7f8e\u5143' ], '\u6536\u76d8\u4ef7' : [ '102\u7f8e\u5143' ], '\u6210\u4ea4\u91cf' : [ '520000' ], } } ] }","title":"3.1 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#32-init_prompts","text":"\u76ee\u7684\uff1a\u8fdb\u884cprompt\u8bbe\u8ba1 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a def init_prompts (): \"\"\" \u521d\u59cb\u5316\u524d\u7f6eprompt\uff0c\u4fbf\u4e8e\u6a21\u578b\u505a incontext learning\u3002 \"\"\" ie_pre_history = [ ( \"\u73b0\u5728\u4f60\u9700\u8981\u5e2e\u52a9\u6211\u5b8c\u6210\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\uff0c\u5f53\u6211\u7ed9\u4f60\u4e00\u4e2a\u53e5\u5b50\u65f6\uff0c\u4f60\u9700\u8981\u5e2e\u6211\u62bd\u53d6\u51fa\u53e5\u5b50\u4e2d\u5b9e\u4f53\u4fe1\u606f\uff0c\u5e76\u6309\u7167JSON\u7684\u683c\u5f0f\u8f93\u51fa\uff0c\u4e0a\u8ff0\u53e5\u5b50\u4e2d\u6ca1\u6709\u7684\u4fe1\u606f\u7528['\u539f\u6587\u4e2d\u672a\u63d0\u53ca']\u6765\u8868\u793a\uff0c\u591a\u4e2a\u503c\u4e4b\u95f4\u7528','\u5206\u9694\u3002\" , '\u597d\u7684\uff0c\u8bf7\u8f93\u5165\u60a8\u7684\u53e5\u5b50\u3002' ) ] for _type , example_list in ie_examples . items (): print ( f '\u4fe1\u606f\u62bd\u53d6\u6837\u672c\u7684\u539f\u59cb\u53e5\u5b50\u662f--\u300b { example_list } ' ) for example in example_list : sentence = example [ 'content' ] properties_str = ', ' . join ( schema [ _type ]) schema_str_list = f '\u201c { _type } \u201d( { properties_str } )' sentence_with_prompt = IE_PATTERN . format ( sentence , schema_str_list ) ie_pre_history . append (( f ' { sentence_with_prompt } ' , f \" { json . dumps ( example [ 'answers' ], ensure_ascii = False ) } \" )) print ( f 'ie_pre_history--> { ie_pre_history } ' ) return { 'ie_pre_history' : ie_pre_history }","title":"3.2 \u6784\u5efainit_prompts()\u51fd\u6570"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#33-clean_response","text":"\u76ee\u7684\uff1a\u6a21\u578b\u7ed3\u679c\u540e\u5904\u7406 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def clean_response ( response : str ): \"\"\" \u540e\u5904\u7406\u6a21\u578b\u8f93\u51fa\u3002 Args: response (str): _description_ \"\"\" if '```json' in response : res = re . findall ( r '```json(.*?)```' , response ) if len ( res ) and res [ 0 ]: response = res [ 0 ] response . replace ( '\u3001' , ',' ) try : return json . loads ( response ) except : return response","title":"3.3 \u6784\u5efaclean_response()\u51fd\u6570"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#34-inference","text":"\u76ee\u7684\uff1a\u6a21\u578b\u5b9e\u73b0\u4fe1\u606f\u62bd\u53d6 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def inference ( sentences : list , custom_settings : dict ): \"\"\" \u63a8\u7406\u51fd\u6570\u3002 Args: sentences (List[str]): \u5f85\u62bd\u53d6\u7684\u53e5\u5b50\u3002 custom_settings (dict): \u521d\u59cb\u8bbe\u5b9a\uff0c\u5305\u542b\u4eba\u4e3a\u7ed9\u5b9a\u7684 few-shot example\u3002 \"\"\" for sentence in sentences : cls_res = \"\u91d1\u878d\" if cls_res not in schema : print ( f 'The type model inferenced { cls_res } which is not in schema dict, exited.' ) exit () properties_str = ', ' . join ( schema [ cls_res ]) schema_str_list = f '\u201c { cls_res } \u201d( { properties_str } )' sentence_with_ie_prompt = IE_PATTERN . format ( sentence , schema_str_list ) ie_res , _ = model . chat ( tokenizer , sentence_with_ie_prompt , history = custom_settings [ 'ie_pre_history' ]) ie_res = clean_response ( ie_res ) print ( f '>>> [bold bright_red]sentence: { sentence } ' ) print ( f '>>> [bold bright_green]inference answer: ' ) print ( ie_res ) \u4ee3\u7801\u8c03\u7528 if __name__ == '__main__' : #device = 'cuda:0' device = 'cpu' tokenizer = AutoTokenizer . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) #model = AutoModel.from_pretrained(\"./ChatGLM-6B/THUDM/chatglm-6b\", # trust_remote_code=True).half().cuda() model = AutoModel . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) . float () model . to ( device ) sentences = [ '2023-02-15\uff0c\u5bd3\u610f\u5409\u7965\u7684\u8282\u65e5\uff0c\u80a1\u7968\u4f70\u7b03[BD]\u7f8e\u80a1\u5f00\u76d8\u4ef710\u7f8e\u5143\uff0c\u867d\u7136\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee513\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u5fae\u5e45\u589e\u52a0\u81f3460,000\uff0c\u6295\u8d44\u8005\u60c5\u7eea\u8f83\u4e3a\u5e73\u7a33\u3002' , '2023-04-05\uff0c\u5e02\u573a\u8fce\u6765\u8f7b\u677e\u6c1b\u56f4\uff0c\u80a1\u7968\u76d8\u53e4(0021)\u5f00\u76d8\u4ef723\u5143\uff0c\u5c3d\u7ba1\u7ecf\u5386\u4e86\u6ce2\u52a8\uff0c\u4f46\u6700\u7ec8\u4ee526\u7f8e\u5143\u6536\u76d8\uff0c\u6210\u4ea4\u91cf\u7f29\u5c0f\u81f3310,000\uff0c\u6295\u8d44\u8005\u4fdd\u6301\u89c2\u671b\u6001\u5ea6\u3002' , ] custom_settings = init_prompts () inference ( sentences , custom_settings ) \u6253\u5370\u7ed3\u679c\uff1a","title":"3.4 \u6784\u5efainference()\u51fd\u6570"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/04-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E4%BF%A1%E6%81%AF%E6%8A%BD%E5%8F%96.html#_2","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u5982\u4f55\u5229\u7528Few-shot\u65b9\u5f0f\u57fa\u4e8eChatGLM-6B\u5b9e\u73b0\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html","text":"\u57fa\u4e8eZero-shot\u65b9\u5f0f\u5b9e\u73b0LLM\u6587\u672c\u5339\u914d \u00b6 \u5b66\u4e60\u76ee\u6807 \u00b6 \u638c\u63e1Zero-shot\u65b9\u5f0f\u4e0bprompt\u7684\u8bbe\u8ba1\u65b9\u5f0f \u638c\u63e1\u5229\u7528LLM\u5b9e\u73b0\u6587\u672c\u5339\u914d\u7684\u4ee3\u7801 1 LLM\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4ecb\u7ecd \u00b6 \u9996\u5148\uff0c\u6211\u4eec\u6784\u9020\u51e0\u4e2a\u77ed\u6587\u672c\u5bf9\uff1a 1. ('\u80a1\u7968\u5e02\u573a\u4eca\u65e5\u5927\u6da8\uff0c\u6295\u8d44\u8005\u4e50\u89c2\u3002' , '\u6301\u7eed\u4e0a\u6da8\u7684\u5e02\u573a\u8ba9\u6295\u8d44\u8005\u611f\u5230\u6ee1\u610f\u3002') , 2. ('\u6cb9\u4ef7\u5927\u5e45\u4e0b\u8dcc\uff0c\u80fd\u6e90\u516c\u53f8\u9762\u4e34\u6311\u6218\u3002' , '\u672a\u6765\u667a\u80fd\u57ce\u5e02\u7684\u5efa\u8bbe\u8d8b\u52bf\u6108\u53d1\u660e\u663e\u3002') , 3. ('\u5229\u7387\u4e0a\u5347\uff0c\u5f71\u54cd\u623f\u5730\u4ea7\u5e02\u573a\u3002' , '\u9ad8\u5229\u7387\u5bf9\u623f\u5730\u4ea7\u6709\u4e00\u5b9a\u51b2\u51fb\u3002') , \u6211\u4eec\u671f\u671b\u6a21\u578b\u80fd\u591f\u5e2e\u6211\u4eec\u8bc6\u522b\u51fa\u8fd9 3 \u5bf9\u53e5\u5b50\u4e2d\uff0c\u54ea\u51e0\u5bf9\u63cf\u8ff0\u7684\u662f\u76f8\u4f3c\u7684\u8bed\u8a00\u3002 \u6211\u4eec\u671f\u671b\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a\uff1a ['\u76f8\u4f3c', '\u4e0d\u76f8\u4f3c', '\u76f8\u4f3c'] 2 Prompt\u8bbe\u8ba1 \u00b6 \u5728\u8be5\u4efb\u52a1\u7684 prompt \u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u8003\u8651 2 \u70b9\uff1a \u9700\u8981\u5411\u6a21\u578b\u89e3\u91ca\u4ec0\u4e48\u53eb\u4f5c\u300c\u6587\u672c\u5339\u914d\u4efb\u52a1\u300d \u9700\u8981\u8ba9\u6a21\u578b\u6309\u7167\u6211\u4eec\u6307\u5b9a\u7684\u683c\u5f0f\u8f93\u51fa \u4e3a\u4e86\u8ba9\u6a21\u578b\u77e5\u9053\u4ec0\u4e48\u53eb\u505a\u300c\u6587\u672c\u5339\u914d\u4efb\u52a1\u300d\uff0c\u6211\u4eec\u501f\u7528 Incontext Learning \u7684\u65b9\u5f0f\uff0c\u5148\u7ed9\u6a21\u578b\u5c55\u793a\u51e0\u4e2a\u6b63\u786e\u7684\u4f8b\u5b50\uff1a >>> User: \u53e5\u5b50\u4e00: \u516c\u53f8ABC\u53d1\u5e03\u4e86\u5b63\u5ea6\u8d22\u62a5\uff0c\u663e\u793a\u76c8\u5229\u589e\u957f\u3002\\n\u53e5\u5b50\u4e8c: \u8d22\u62a5\u62ab\u9732\uff0c\u516c\u53f8ABC\u5229\u6da6\u4e0a\u5347 >>> Bot: \u662f >>> User:\u53e5\u5b50\u4e00: \u9ec4\u91d1\u4ef7\u683c\u4e0b\u8dcc\uff0c\u6295\u8d44\u8005\u629b\u552e\u3002\\n\u53e5\u5b50\u4e8c: \u5916\u6c47\u5e02\u573a\u4ea4\u6613\u989d\u521b\u4e0b\u65b0\u9ad8 >>> Bot: \u4e0d\u662f \u5176\u4e2d\uff0c User \u4ee3\u8868\u6211\u4eec\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u53e5\u5b50\uff0c Bot \u4ee3\u8868\u6a21\u578b\u7684\u56de\u590d\u5185\u5bb9\u3002 \u6ce8\u610f\uff1a\u4e0a\u8ff0\u4f8b\u5b50\u4e2d Bot \u7684\u90e8\u5206\u4e5f\u662f\u7531\u4eba\u5de5\u8f93\u5165\u7684\uff0c\u5176\u76ee\u7684\u662f\u5e0c\u671b\u770b\u5230\u5728\u770b\u5230\u7c7b\u4f3c User \u4e2d\u7684\u53e5\u5b50\u65f6\uff0c\u6a21\u578b\u5e94\u5f53\u505a\u51fa\u7c7b\u4f3c Bot \u7684\u56de\u7b54\u3002 3 \u6587\u672c\u5339\u914d\u4efb\u52a1\u4ee3\u7801\u5b9e\u73b0 \u00b6 \u672c\u7ae0\u8282\u4f7f\u7528\u7684\u6a21\u578b\u4e3aChatGLM-6B\uff0c\u53c2\u6570\u53c2\u6570\u8f83\u5927\uff086B\uff09\uff0c\u4e0b\u8f7d\u5230\u672c\u5730\u5927\u6982\u9700\u8981 12G+ \u7684\u78c1\u76d8\u7a7a\u95f4\uff0c\u8bf7\u786e\u4fdd\u78c1\u76d8\u6709\u5145\u8db3\u7684\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u52a0\u8f7d\u6a21\u578b\u5927\u6982\u9700\u8981 13G \u5de6\u53f3\u7684\u663e\u5b58\uff0c\u5982\u679c\u60a8\u663e\u5b58\u4e0d\u591f\uff0c\u53ef\u4ee5\u8fdb\u884c\u6a21\u578b\u91cf\u5316\u52a0\u8f7d\u4ee5\u7f29\u5c0f\u6a21\u578b\u6210\u672c\u3002 \u672c\u6b21\u6587\u672c\u5339\u914d\u4efb\u52a1\u5b9e\u73b0\u7684\u4e3b\u8981\u8fc7\u7a0b\uff1a \u6784\u9020prompt \u5b9e\u73b0\u6587\u672c\u5339\u914d \u4ee3\u7801\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/***/PycharmProjects/llm/zero-shot/llm_text_matching.py llm_information_extraction.py\u811a\u672c\u4e2d\u5305\u542b\u4e09\u4e2a\u51fd\u6570\uff1ainit_prompts()\u548cinference() 3.1 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305 \u00b6 from rich import print from transformers import AutoTokenizer , AutoModel import os # \u63d0\u4f9b\u76f8\u4f3c\uff0c\u4e0d\u76f8\u4f3c\u7684\u8bed\u4e49\u5339\u914d\u4f8b\u5b50 examples = { '\u662f' : [ ( '\u516c\u53f8ABC\u53d1\u5e03\u4e86\u5b63\u5ea6\u8d22\u62a5\uff0c\u663e\u793a\u76c8\u5229\u589e\u957f\u3002' , '\u8d22\u62a5\u62ab\u9732\uff0c\u516c\u53f8ABC\u5229\u6da6\u4e0a\u5347\u3002' ), ], '\u4e0d\u662f' : [ ( '\u9ec4\u91d1\u4ef7\u683c\u4e0b\u8dcc\uff0c\u6295\u8d44\u8005\u629b\u552e\u3002' , '\u5916\u6c47\u5e02\u573a\u4ea4\u6613\u989d\u521b\u4e0b\u65b0\u9ad8\u3002' ), ( '\u592e\u884c\u964d\u606f\uff0c\u523a\u6fc0\u7ecf\u6d4e\u589e\u957f\u3002' , '\u65b0\u80fd\u6e90\u6280\u672f\u7684\u521b\u65b0\u3002' ) ] } 3.2 \u6784\u5efainit_prompts()\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u8fdb\u884cprompt\u8bbe\u8ba1 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a def init_prompts (): \"\"\" \u521d\u59cb\u5316\u524d\u7f6eprompt\uff0c\u4fbf\u4e8e\u6a21\u578b\u505a incontext learning\u3002 \"\"\" pre_history = [ ( '\u73b0\u5728\u4f60\u9700\u8981\u5e2e\u52a9\u6211\u5b8c\u6210\u6587\u672c\u5339\u914d\u4efb\u52a1\uff0c\u5f53\u6211\u7ed9\u4f60\u4e24\u4e2a\u53e5\u5b50\u65f6\uff0c\u4f60\u9700\u8981\u56de\u7b54\u6211\u8fd9\u4e24\u53e5\u8bdd\u8bed\u4e49\u662f\u5426\u76f8\u4f3c\u3002\u53ea\u9700\u8981\u56de\u7b54\u662f\u5426\u76f8\u4f3c\uff0c\u4e0d\u8981\u505a\u591a\u4f59\u7684\u56de\u7b54\u3002' , '\u597d\u7684\uff0c\u6211\u5c06\u53ea\u56de\u7b54\u201d\u662f\u201c\u6216\u201d\u4e0d\u662f\u201c\u3002' ) ] for key , sentence_pairs in examples . items (): for sentence_pair in sentence_pairs : sentence1 , sentence2 = sentence_pair pre_history . append (( f '\u53e5\u5b50\u4e00: { sentence1 } \\n \u53e5\u5b50\u4e8c: { sentence2 } \\n \u4e0a\u9762\u4e24\u53e5\u8bdd\u662f\u76f8\u4f3c\u7684\u8bed\u4e49\u5417\uff1f' , key )) return { 'pre_history' : pre_history } 3.3 \u6784\u5efainference()\u51fd\u6570 \u00b6 \u76ee\u7684\uff1a\u6a21\u578b\u5b9e\u73b0\u4fe1\u606f\u5339\u914d \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def inference ( sentence_pairs : list , custom_settings : dict ): \"\"\" \u63a8\u7406\u51fd\u6570\u3002 Args: model (transformers.AutoModel): Language Model \u6a21\u578b\u3002 sentence_pairs (List[str]): \u5f85\u63a8\u7406\u7684\u53e5\u5b50\u5bf9\u3002 custom_settings (dict): \u521d\u59cb\u8bbe\u5b9a\uff0c\u5305\u542b\u4eba\u4e3a\u7ed9\u5b9a\u7684 few-shot example\u3002 \"\"\" for sentence_pair in sentence_pairs : sentence1 , sentence2 = sentence_pair sentence_with_prompt = f '\u53e5\u5b50\u4e00: { sentence1 } \\n \u53e5\u5b50\u4e8c: { sentence2 } \\n \u4e0a\u9762\u4e24\u53e5\u8bdd\u662f\u76f8\u4f3c\u7684\u8bed\u4e49\u5417\uff1f' response , history = model . chat ( tokenizer , sentence_with_prompt , history = custom_settings [ 'pre_history' ]) print ( f '>>> [bold bright_red]sentence: { sentence_pair } ' ) print ( f '>>> [bold bright_green]inference answer: { response } ' ) # print(history) \u4ee3\u7801\u8c03\u7528 if __name__ == '__main__' : #device = 'cuda:0' device = 'cpu' tokenizer = AutoTokenizer . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) #model = AutoModel.from_pretrained(\"./ChatGLM-6B/THUDM/chatglm-6b\", # trust_remote_code=True).half().cuda() model = AutoModel . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) . float () model . to ( device ) sentence_pairs = [ ( '\u80a1\u7968\u5e02\u573a\u4eca\u65e5\u5927\u6da8\uff0c\u6295\u8d44\u8005\u4e50\u89c2\u3002' , '\u6301\u7eed\u4e0a\u6da8\u7684\u5e02\u573a\u8ba9\u6295\u8d44\u8005\u611f\u5230\u6ee1\u610f\u3002' ), ( '\u6cb9\u4ef7\u5927\u5e45\u4e0b\u8dcc\uff0c\u80fd\u6e90\u516c\u53f8\u9762\u4e34\u6311\u6218\u3002' , '\u672a\u6765\u667a\u80fd\u57ce\u5e02\u7684\u5efa\u8bbe\u8d8b\u52bf\u6108\u53d1\u660e\u663e\u3002' ), ( '\u5229\u7387\u4e0a\u5347\uff0c\u5f71\u54cd\u623f\u5730\u4ea7\u5e02\u573a\u3002' , '\u9ad8\u5229\u7387\u5bf9\u623f\u5730\u4ea7\u6709\u4e00\u5b9a\u51b2\u51fb\u3002' ), ] custom_settings = init_prompts () inference ( sentence_pairs , custom_settings ) \u6253\u5370\u7ed3\u679c\uff1a \u5c0f\u7ed3\u603b\u7ed3 \u00b6 \u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u5982\u4f55\u5229\u7528Few-Shot\u65b9\u5f0f\u57fa\u4e8eChatGLM-6B\u5b9e\u73b0\u6587\u672c\u5339\u914d\u4efb\u52a1\u3002","title":"4.5 LLM\u5b9e\u73b0\u91d1\u878d\u6587\u672c\u5339\u914d"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#zero-shotllm","text":"","title":"\u57fa\u4e8eZero-shot\u65b9\u5f0f\u5b9e\u73b0LLM\u6587\u672c\u5339\u914d"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#_1","text":"\u638c\u63e1Zero-shot\u65b9\u5f0f\u4e0bprompt\u7684\u8bbe\u8ba1\u65b9\u5f0f \u638c\u63e1\u5229\u7528LLM\u5b9e\u73b0\u6587\u672c\u5339\u914d\u7684\u4ee3\u7801","title":"\u5b66\u4e60\u76ee\u6807"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#1-llm","text":"\u9996\u5148\uff0c\u6211\u4eec\u6784\u9020\u51e0\u4e2a\u77ed\u6587\u672c\u5bf9\uff1a 1. ('\u80a1\u7968\u5e02\u573a\u4eca\u65e5\u5927\u6da8\uff0c\u6295\u8d44\u8005\u4e50\u89c2\u3002' , '\u6301\u7eed\u4e0a\u6da8\u7684\u5e02\u573a\u8ba9\u6295\u8d44\u8005\u611f\u5230\u6ee1\u610f\u3002') , 2. ('\u6cb9\u4ef7\u5927\u5e45\u4e0b\u8dcc\uff0c\u80fd\u6e90\u516c\u53f8\u9762\u4e34\u6311\u6218\u3002' , '\u672a\u6765\u667a\u80fd\u57ce\u5e02\u7684\u5efa\u8bbe\u8d8b\u52bf\u6108\u53d1\u660e\u663e\u3002') , 3. ('\u5229\u7387\u4e0a\u5347\uff0c\u5f71\u54cd\u623f\u5730\u4ea7\u5e02\u573a\u3002' , '\u9ad8\u5229\u7387\u5bf9\u623f\u5730\u4ea7\u6709\u4e00\u5b9a\u51b2\u51fb\u3002') , \u6211\u4eec\u671f\u671b\u6a21\u578b\u80fd\u591f\u5e2e\u6211\u4eec\u8bc6\u522b\u51fa\u8fd9 3 \u5bf9\u53e5\u5b50\u4e2d\uff0c\u54ea\u51e0\u5bf9\u63cf\u8ff0\u7684\u662f\u76f8\u4f3c\u7684\u8bed\u8a00\u3002 \u6211\u4eec\u671f\u671b\u6a21\u578b\u8f93\u51fa\u7684\u7ed3\u679c\u4e3a\uff1a ['\u76f8\u4f3c', '\u4e0d\u76f8\u4f3c', '\u76f8\u4f3c']","title":"1 LLM\u4fe1\u606f\u62bd\u53d6\u4efb\u52a1\u4ecb\u7ecd"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#2-prompt","text":"\u5728\u8be5\u4efb\u52a1\u7684 prompt \u8bbe\u8ba1\u4e2d\uff0c\u6211\u4eec\u4e3b\u8981\u8003\u8651 2 \u70b9\uff1a \u9700\u8981\u5411\u6a21\u578b\u89e3\u91ca\u4ec0\u4e48\u53eb\u4f5c\u300c\u6587\u672c\u5339\u914d\u4efb\u52a1\u300d \u9700\u8981\u8ba9\u6a21\u578b\u6309\u7167\u6211\u4eec\u6307\u5b9a\u7684\u683c\u5f0f\u8f93\u51fa \u4e3a\u4e86\u8ba9\u6a21\u578b\u77e5\u9053\u4ec0\u4e48\u53eb\u505a\u300c\u6587\u672c\u5339\u914d\u4efb\u52a1\u300d\uff0c\u6211\u4eec\u501f\u7528 Incontext Learning \u7684\u65b9\u5f0f\uff0c\u5148\u7ed9\u6a21\u578b\u5c55\u793a\u51e0\u4e2a\u6b63\u786e\u7684\u4f8b\u5b50\uff1a >>> User: \u53e5\u5b50\u4e00: \u516c\u53f8ABC\u53d1\u5e03\u4e86\u5b63\u5ea6\u8d22\u62a5\uff0c\u663e\u793a\u76c8\u5229\u589e\u957f\u3002\\n\u53e5\u5b50\u4e8c: \u8d22\u62a5\u62ab\u9732\uff0c\u516c\u53f8ABC\u5229\u6da6\u4e0a\u5347 >>> Bot: \u662f >>> User:\u53e5\u5b50\u4e00: \u9ec4\u91d1\u4ef7\u683c\u4e0b\u8dcc\uff0c\u6295\u8d44\u8005\u629b\u552e\u3002\\n\u53e5\u5b50\u4e8c: \u5916\u6c47\u5e02\u573a\u4ea4\u6613\u989d\u521b\u4e0b\u65b0\u9ad8 >>> Bot: \u4e0d\u662f \u5176\u4e2d\uff0c User \u4ee3\u8868\u6211\u4eec\u8f93\u5165\u7ed9\u6a21\u578b\u7684\u53e5\u5b50\uff0c Bot \u4ee3\u8868\u6a21\u578b\u7684\u56de\u590d\u5185\u5bb9\u3002 \u6ce8\u610f\uff1a\u4e0a\u8ff0\u4f8b\u5b50\u4e2d Bot \u7684\u90e8\u5206\u4e5f\u662f\u7531\u4eba\u5de5\u8f93\u5165\u7684\uff0c\u5176\u76ee\u7684\u662f\u5e0c\u671b\u770b\u5230\u5728\u770b\u5230\u7c7b\u4f3c User \u4e2d\u7684\u53e5\u5b50\u65f6\uff0c\u6a21\u578b\u5e94\u5f53\u505a\u51fa\u7c7b\u4f3c Bot \u7684\u56de\u7b54\u3002","title":"2 Prompt\u8bbe\u8ba1"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#3","text":"\u672c\u7ae0\u8282\u4f7f\u7528\u7684\u6a21\u578b\u4e3aChatGLM-6B\uff0c\u53c2\u6570\u53c2\u6570\u8f83\u5927\uff086B\uff09\uff0c\u4e0b\u8f7d\u5230\u672c\u5730\u5927\u6982\u9700\u8981 12G+ \u7684\u78c1\u76d8\u7a7a\u95f4\uff0c\u8bf7\u786e\u4fdd\u78c1\u76d8\u6709\u5145\u8db3\u7684\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u52a0\u8f7d\u6a21\u578b\u5927\u6982\u9700\u8981 13G \u5de6\u53f3\u7684\u663e\u5b58\uff0c\u5982\u679c\u60a8\u663e\u5b58\u4e0d\u591f\uff0c\u53ef\u4ee5\u8fdb\u884c\u6a21\u578b\u91cf\u5316\u52a0\u8f7d\u4ee5\u7f29\u5c0f\u6a21\u578b\u6210\u672c\u3002 \u672c\u6b21\u6587\u672c\u5339\u914d\u4efb\u52a1\u5b9e\u73b0\u7684\u4e3b\u8981\u8fc7\u7a0b\uff1a \u6784\u9020prompt \u5b9e\u73b0\u6587\u672c\u5339\u914d \u4ee3\u7801\u5b58\u653e\u4f4d\u7f6e\uff1a/Users/***/PycharmProjects/llm/zero-shot/llm_text_matching.py llm_information_extraction.py\u811a\u672c\u4e2d\u5305\u542b\u4e09\u4e2a\u51fd\u6570\uff1ainit_prompts()\u548cinference()","title":"3 \u6587\u672c\u5339\u914d\u4efb\u52a1\u4ee3\u7801\u5b9e\u73b0"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#31","text":"from rich import print from transformers import AutoTokenizer , AutoModel import os # \u63d0\u4f9b\u76f8\u4f3c\uff0c\u4e0d\u76f8\u4f3c\u7684\u8bed\u4e49\u5339\u914d\u4f8b\u5b50 examples = { '\u662f' : [ ( '\u516c\u53f8ABC\u53d1\u5e03\u4e86\u5b63\u5ea6\u8d22\u62a5\uff0c\u663e\u793a\u76c8\u5229\u589e\u957f\u3002' , '\u8d22\u62a5\u62ab\u9732\uff0c\u516c\u53f8ABC\u5229\u6da6\u4e0a\u5347\u3002' ), ], '\u4e0d\u662f' : [ ( '\u9ec4\u91d1\u4ef7\u683c\u4e0b\u8dcc\uff0c\u6295\u8d44\u8005\u629b\u552e\u3002' , '\u5916\u6c47\u5e02\u573a\u4ea4\u6613\u989d\u521b\u4e0b\u65b0\u9ad8\u3002' ), ( '\u592e\u884c\u964d\u606f\uff0c\u523a\u6fc0\u7ecf\u6d4e\u589e\u957f\u3002' , '\u65b0\u80fd\u6e90\u6280\u672f\u7684\u521b\u65b0\u3002' ) ] }","title":"3.1 \u5bfc\u5165\u5fc5\u5907\u7684\u5de5\u5177\u5305"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#32-init_prompts","text":"\u76ee\u7684\uff1a\u8fdb\u884cprompt\u8bbe\u8ba1 \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\uff1a def init_prompts (): \"\"\" \u521d\u59cb\u5316\u524d\u7f6eprompt\uff0c\u4fbf\u4e8e\u6a21\u578b\u505a incontext learning\u3002 \"\"\" pre_history = [ ( '\u73b0\u5728\u4f60\u9700\u8981\u5e2e\u52a9\u6211\u5b8c\u6210\u6587\u672c\u5339\u914d\u4efb\u52a1\uff0c\u5f53\u6211\u7ed9\u4f60\u4e24\u4e2a\u53e5\u5b50\u65f6\uff0c\u4f60\u9700\u8981\u56de\u7b54\u6211\u8fd9\u4e24\u53e5\u8bdd\u8bed\u4e49\u662f\u5426\u76f8\u4f3c\u3002\u53ea\u9700\u8981\u56de\u7b54\u662f\u5426\u76f8\u4f3c\uff0c\u4e0d\u8981\u505a\u591a\u4f59\u7684\u56de\u7b54\u3002' , '\u597d\u7684\uff0c\u6211\u5c06\u53ea\u56de\u7b54\u201d\u662f\u201c\u6216\u201d\u4e0d\u662f\u201c\u3002' ) ] for key , sentence_pairs in examples . items (): for sentence_pair in sentence_pairs : sentence1 , sentence2 = sentence_pair pre_history . append (( f '\u53e5\u5b50\u4e00: { sentence1 } \\n \u53e5\u5b50\u4e8c: { sentence2 } \\n \u4e0a\u9762\u4e24\u53e5\u8bdd\u662f\u76f8\u4f3c\u7684\u8bed\u4e49\u5417\uff1f' , key )) return { 'pre_history' : pre_history }","title":"3.2 \u6784\u5efainit_prompts()\u51fd\u6570"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#33-inference","text":"\u76ee\u7684\uff1a\u6a21\u578b\u5b9e\u73b0\u4fe1\u606f\u5339\u914d \u5177\u4f53\u4ee3\u7801\u5b9e\u73b0 def inference ( sentence_pairs : list , custom_settings : dict ): \"\"\" \u63a8\u7406\u51fd\u6570\u3002 Args: model (transformers.AutoModel): Language Model \u6a21\u578b\u3002 sentence_pairs (List[str]): \u5f85\u63a8\u7406\u7684\u53e5\u5b50\u5bf9\u3002 custom_settings (dict): \u521d\u59cb\u8bbe\u5b9a\uff0c\u5305\u542b\u4eba\u4e3a\u7ed9\u5b9a\u7684 few-shot example\u3002 \"\"\" for sentence_pair in sentence_pairs : sentence1 , sentence2 = sentence_pair sentence_with_prompt = f '\u53e5\u5b50\u4e00: { sentence1 } \\n \u53e5\u5b50\u4e8c: { sentence2 } \\n \u4e0a\u9762\u4e24\u53e5\u8bdd\u662f\u76f8\u4f3c\u7684\u8bed\u4e49\u5417\uff1f' response , history = model . chat ( tokenizer , sentence_with_prompt , history = custom_settings [ 'pre_history' ]) print ( f '>>> [bold bright_red]sentence: { sentence_pair } ' ) print ( f '>>> [bold bright_green]inference answer: { response } ' ) # print(history) \u4ee3\u7801\u8c03\u7528 if __name__ == '__main__' : #device = 'cuda:0' device = 'cpu' tokenizer = AutoTokenizer . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) #model = AutoModel.from_pretrained(\"./ChatGLM-6B/THUDM/chatglm-6b\", # trust_remote_code=True).half().cuda() model = AutoModel . from_pretrained ( \"./ChatGLM-6B/THUDM/chatglm-6b\" , trust_remote_code = True ) . float () model . to ( device ) sentence_pairs = [ ( '\u80a1\u7968\u5e02\u573a\u4eca\u65e5\u5927\u6da8\uff0c\u6295\u8d44\u8005\u4e50\u89c2\u3002' , '\u6301\u7eed\u4e0a\u6da8\u7684\u5e02\u573a\u8ba9\u6295\u8d44\u8005\u611f\u5230\u6ee1\u610f\u3002' ), ( '\u6cb9\u4ef7\u5927\u5e45\u4e0b\u8dcc\uff0c\u80fd\u6e90\u516c\u53f8\u9762\u4e34\u6311\u6218\u3002' , '\u672a\u6765\u667a\u80fd\u57ce\u5e02\u7684\u5efa\u8bbe\u8d8b\u52bf\u6108\u53d1\u660e\u663e\u3002' ), ( '\u5229\u7387\u4e0a\u5347\uff0c\u5f71\u54cd\u623f\u5730\u4ea7\u5e02\u573a\u3002' , '\u9ad8\u5229\u7387\u5bf9\u623f\u5730\u4ea7\u6709\u4e00\u5b9a\u51b2\u51fb\u3002' ), ] custom_settings = init_prompts () inference ( sentence_pairs , custom_settings ) \u6253\u5370\u7ed3\u679c\uff1a","title":"3.3 \u6784\u5efainference()\u51fd\u6570"},{"location":"%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B%E5%BA%94%E7%94%A8%E5%AE%9E%E6%88%98/05-LLM%E5%AE%9E%E7%8E%B0%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E5%8C%B9%E9%85%8D.html#_2","text":"\u672c\u7ae0\u8282\u4e3b\u8981\u4ecb\u7ecd\u4e86\u5982\u4f55\u5229\u7528Few-Shot\u65b9\u5f0f\u57fa\u4e8eChatGLM-6B\u5b9e\u73b0\u6587\u672c\u5339\u914d\u4efb\u52a1\u3002","title":"\u5c0f\u7ed3\u603b\u7ed3"}]}